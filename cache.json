{"2023-11-17T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2311.10702v1","updated":"2023-11-17T18:45:45Z","published":"2023-11-17T18:45:45Z","title":"Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2","summary":"  Since the release of T\\\"ULU [Wang et al., 2023b], open resources for\ninstruction tuning have developed quickly, from better base models to new\nfinetuning techniques. We test and incorporate a number of these advances into\nT\\\"ULU, resulting in T\\\"ULU 2, a suite of improved T\\\"ULU models for advancing\nthe understanding and best practices of adapting pretrained language models to\ndownstream tasks and user preferences. Concretely, we release: (1)\nT\\\"ULU-V2-mix, an improved collection of high-quality instruction datasets; (2)\nT\\\"ULU 2, LLAMA-2 models finetuned on the V2 mixture; (3) T\\\"ULU 2+DPO, T\\\"ULU\n2 models trained with direct preference optimization (DPO), including the\nlargest DPO-trained model to date (T\\\"ULU 2+DPO 70B); (4) CODE T\\\"ULU 2, CODE\nLLAMA models finetuned on our V2 mix that outperform CODE LLAMA and its\ninstruction-tuned variant, CODE LLAMA-Instruct. Our evaluation from multiple\nperspectives shows that the T\\\"ULU 2 suite achieves state-of-the-art\nperformance among open models and matches or exceeds the performance of\nGPT-3.5-turbo-0301 on several benchmarks. We release all the checkpoints, data,\ntraining and evaluation code to facilitate future open efforts on adapting\nlarge language models.\n","authors":["Hamish Ivison","Yizhong Wang","Valentina Pyatkin","Nathan Lambert","Matthew Peters","Pradeep Dasigi","Joel Jang","David Wadden","Noah A. Smith","Iz Beltagy","Hannaneh Hajishirzi"],"pdf_url":"https://arxiv.org/pdf/2311.10702v1.pdf","comment":"technical report"},{"id":"http://arxiv.org/abs/2308.06595v3","updated":"2023-11-17T18:39:46Z","published":"2023-08-12T15:27:51Z","title":"VisIT-Bench: A Benchmark for Vision-Language Instruction Following\n  Inspired by Real-World Use","summary":"  We introduce VisIT-Bench (Visual InsTruction Benchmark), a benchmark for\nevaluation of instruction-following vision-language models for real-world use.\nOur starting point is curating 70 'instruction families' that we envision\ninstruction tuned vision-language models should be able to address. Extending\nbeyond evaluations like VQAv2 and COCO, tasks range from basic recognition to\ngame playing and creative generation. Following curation, our dataset comprises\n592 test queries, each with a human-authored instruction-conditioned caption.\nThese descriptions surface instruction-specific factors, e.g., for an\ninstruction asking about the accessibility of a storefront for wheelchair\nusers, the instruction-conditioned caption describes ramps/potential obstacles.\nThese descriptions enable 1) collecting human-verified reference outputs for\neach instance; and 2) automatic evaluation of candidate multimodal generations\nusing a text-only LLM, aligning with human judgment. We quantify quality gaps\nbetween models and references using both human and automatic evaluations; e.g.,\nthe top-performing instruction-following model wins against the GPT-4 reference\nin just 27% of the comparison. VisIT-Bench is dynamic to participate,\npractitioners simply submit their model's response on the project website;\nData, code and leaderboard is available at visit-bench.github.io.\n","authors":["Yonatan Bitton","Hritik Bansal","Jack Hessel","Rulin Shao","Wanrong Zhu","Anas Awadalla","Josh Gardner","Rohan Taori","Ludwig Schmidt"],"pdf_url":"https://arxiv.org/pdf/2308.06595v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10697v1","updated":"2023-11-17T18:32:17Z","published":"2023-11-17T18:32:17Z","title":"PEFT-MedAware: Large Language Model for Medical Awareness","summary":"  Chat models are capable of answering a wide range of questions, however, the\naccuracy of their responses is highly uncertain. In this research, we propose a\nspecialized PEFT-MedAware model where we utilize parameter-efficient\nfine-tuning (PEFT) to enhance the Falcon-1b large language model on specialized\nMedQuAD data consisting of 16,407 medical QA pairs, leveraging only 0.44% of\nits trainable parameters to enhance computational efficiency. The paper adopts\ndata preprocessing and PEFT to optimize model performance, complemented by a\nBitsAndBytesConfig for efficient transformer training. The resulting model was\ncapable of outperforming other LLMs in medical question-answering tasks in\nspecific domains with greater accuracy utilizing limited computational\nresources making it suitable for deployment in resource-constrained\nenvironments. We propose further improvements through expanded datasets, larger\nmodels, and feedback mechanisms for sustained medical relevancy. Our work\nhighlights the efficiency gains and specialized capabilities of PEFT in medical\nAI, outpacing standard models in precision without extensive resource demands.\nThe proposed model and data are released for research purposes only.\n","authors":["Keivalya Pandya"],"pdf_url":"https://arxiv.org/pdf/2311.10697v1.pdf","comment":"7 pages, 1 figure, submitted to the Artificial Intelligence in\n  Medicine Journal"},{"id":"http://arxiv.org/abs/2305.14659v2","updated":"2023-11-17T17:31:52Z","published":"2023-05-24T02:53:22Z","title":"InteractiveIE: Towards Assessing the Strength of Human-AI Collaboration\n  in Improving the Performance of Information Extraction","summary":"  Learning template based information extraction from documents is a crucial\nyet difficult task. Prior template-based IE approaches assume foreknowledge of\nthe domain templates; however, real-world IE do not have pre-defined schemas\nand it is a figure-out-as you go phenomena. To quickly bootstrap templates in a\nreal-world setting, we need to induce template slots from documents with zero\nor minimal supervision. Since the purpose of question answering intersect with\nthe goal of information extraction, we use automatic question generation to\ninduce template slots from the documents and investigate how a tiny amount of a\nproxy human-supervision on-the-fly (termed as InteractiveIE) can further boost\nthe performance. Extensive experiments on biomedical and legal documents, where\nobtaining training data is expensive, reveal encouraging trends of performance\nimprovement using InteractiveIE over AI-only baseline.\n","authors":["Ishani Mondal","Michelle Yuan","Anandhavelu N","Aparna Garimella","Francis Ferraro","Andrew Blair-Stanek","Benjamin Van Durme","Jordan Boyd-Graber"],"pdf_url":"https://arxiv.org/pdf/2305.14659v2.pdf","comment":"Version 2"},{"id":"http://arxiv.org/abs/2311.10642v1","updated":"2023-11-17T16:58:52Z","published":"2023-11-17T16:58:52Z","title":"Rethinking Attention: Exploring Shallow Feed-Forward Neural Networks as\n  an Alternative to Attention Layers in Transformers","summary":"  This work presents an analysis of the effectiveness of using standard shallow\nfeed-forward networks to mimic the behavior of the attention mechanism in the\noriginal Transformer model, a state-of-the-art architecture for\nsequence-to-sequence tasks. We substitute key elements of the attention\nmechanism in the Transformer with simple feed-forward networks, trained using\nthe original components via knowledge distillation. Our experiments, conducted\non the IWSLT2017 dataset, reveal the capacity of these \"attentionless\nTransformers\" to rival the performance of the original architecture. Through\nrigorous ablation studies, and experimenting with various replacement network\ntypes and sizes, we offer insights that support the viability of our approach.\nThis not only sheds light on the adaptability of shallow feed-forward networks\nin emulating attention mechanisms but also underscores their potential to\nstreamline complex architectures for sequence-to-sequence tasks.\n","authors":["Vukasin Bozic","Danilo Dordervic","Daniele Coppola","Joseph Thommes"],"pdf_url":"https://arxiv.org/pdf/2311.10642v1.pdf","comment":"Accepted at AAAI24(https://aaai.org/aaai-conference/)"},{"id":"http://arxiv.org/abs/2203.08436v2","updated":"2023-11-17T16:46:38Z","published":"2022-03-16T07:13:52Z","title":"Don't Say What You Don't Know: Improving the Consistency of Abstractive\n  Summarization by Constraining Beam Search","summary":"  Abstractive summarization systems today produce fluent and relevant output,\nbut often \"hallucinate\" statements not supported by the source text. We analyze\nthe connection between hallucinations and training data, and find evidence that\nmodels hallucinate because they train on target summaries that are unsupported\nby the source. Based on our findings, we present PINOCCHIO, a new decoding\nmethod that improves the consistency of a transformer-based abstractive\nsummarizer by constraining beam search to avoid hallucinations. Given the model\nstates and outputs at a given step, PINOCCHIO detects likely model\nhallucinations based on various measures of attribution to the source text.\nPINOCCHIO backtracks to find more consistent output, and can opt to produce no\nsummary at all when no consistent generation can be found. In experiments, we\nfind that PINOCCHIO improves the consistency of generation (in terms of F1) by\nan average of~67% on two abstractive summarization datasets.\n","authors":["Daniel King","Zejiang Shen","Nishant Subramani","Daniel S. Weld","Iz Beltagy","Doug Downey"],"pdf_url":"https://arxiv.org/pdf/2203.08436v2.pdf","comment":"16 pages, 2 figures, 7 tables"},{"id":"http://arxiv.org/abs/2311.10614v1","updated":"2023-11-17T16:09:10Z","published":"2023-11-17T16:09:10Z","title":"A Self-enhancement Approach for Domain-specific Chatbot Training via\n  Knowledge Mining and Digest","summary":"  Large Language Models (LLMs), despite their great power in language\ngeneration, often encounter challenges when dealing with intricate and\nknowledge-demanding queries in specific domains. This paper introduces a novel\napproach to enhance LLMs by effectively extracting the relevant knowledge from\ndomain-specific textual sources, and the adaptive training of a chatbot with\ndomain-specific inquiries. Our two-step approach starts from training a\nknowledge miner, namely LLMiner, which autonomously extracts Question-Answer\npairs from relevant documents through a chain-of-thought reasoning process.\nSubsequently, we blend the mined QA pairs with a conversational dataset to\nfine-tune the LLM as a chatbot, thereby enriching its domain-specific expertise\nand conversational capabilities. We also developed a new evaluation benchmark\nwhich comprises four domain-specific text corpora and associated human-crafted\nQA pairs for testing. Our model shows remarkable performance improvement over\ngenerally aligned LLM and surpasses domain-adapted models directly fine-tuned\non domain corpus. In particular, LLMiner achieves this with minimal human\nintervention, requiring only 600 seed instances, thereby providing a pathway\ntowards self-improvement of LLMs through model-synthesized training data.\n","authors":["Ruohong Zhang","Luyu Gao","Chen Zheng","Zhen Fan","Guokun Lai","Zheng Zhang","Fangzhou Ai","Yiming Yang","Hongxia Yang"],"pdf_url":"https://arxiv.org/pdf/2311.10614v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2311.10596v1","updated":"2023-11-17T15:49:11Z","published":"2023-11-17T15:49:11Z","title":"Hashing it Out: Predicting Unhealthy Conversations on Twitter","summary":"  Personal attacks in the context of social media conversations often lead to\nfast-paced derailment, leading to even more harmful exchanges being made.\nState-of-the-art systems for the detection of such conversational derailment\noften make use of deep learning approaches for prediction purposes. In this\npaper, we show that an Attention-based BERT architecture, pre-trained on a\nlarge Twitter corpus and fine-tuned on our task, is efficient and effective in\nmaking such predictions. This model shows clear advantages in performance to\nthe existing LSTM model we use as a baseline. Additionally, we show that this\nimpressive performance can be attained through fine-tuning on a relatively\nsmall, novel dataset, particularly after mitigating overfitting issues through\nsynthetic oversampling techniques. By introducing the first transformer based\nmodel for forecasting conversational events on Twitter, this work lays the\nfoundation for a practical tool to encourage better interactions on one of the\nmost ubiquitous social media platforms.\n","authors":["Steven Leung","Filippos Papapolyzos"],"pdf_url":"https://arxiv.org/pdf/2311.10596v1.pdf","comment":"7 pages, 3 figures, academic"},{"id":"http://arxiv.org/abs/2309.15991v2","updated":"2023-11-17T15:47:35Z","published":"2023-09-27T20:12:41Z","title":"Targeted Image Data Augmentation Increases Basic Skills Captioning\n  Robustness","summary":"  Artificial neural networks typically struggle in generalizing to\nout-of-context examples. One reason for this limitation is caused by having\ndatasets that incorporate only partial information regarding the potential\ncorrelational structure of the world. In this work, we propose TIDA (Targeted\nImage-editing Data Augmentation), a targeted data augmentation method focused\non improving models' human-like abilities (e.g., gender recognition) by filling\nthe correlational structure gap using a text-to-image generative model. More\nspecifically, TIDA identifies specific skills in captions describing images\n(e.g., the presence of a specific gender in the image), changes the caption\n(e.g., \"woman\" to \"man\"), and then uses a text-to-image model to edit the image\nin order to match the novel caption (e.g., uniquely changing a woman to a man\nwhile maintaining the context identical). Based on the Flickr30K benchmark, we\nshow that, compared with the original data set, a TIDA-enhanced dataset related\nto gender, color, and counting abilities induces better performance in several\nimage captioning metrics. Furthermore, on top of relying on the classical BLEU\nmetric, we conduct a fine-grained analysis of the improvements of our models\nagainst the baseline in different ways. We compared text-to-image generative\nmodels and found different behaviors of the image captioning models in terms of\nencoding visual encoding and textual decoding.\n","authors":["Valentin Barriere","Felipe del Rio","Andres Carvallo De Ferari","Carlos Aspillaga","Eugenio Herrera-Berg","Cristian Buc Calderon"],"pdf_url":"https://arxiv.org/pdf/2309.15991v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10587v1","updated":"2023-11-17T15:37:18Z","published":"2023-11-17T15:37:18Z","title":"Countering Misinformation via Emotional Response Generation","summary":"  The proliferation of misinformation on social media platforms (SMPs) poses a\nsignificant danger to public health, social cohesion and ultimately democracy.\nPrevious research has shown how social correction can be an effective way to\ncurb misinformation, by engaging directly in a constructive dialogue with users\nwho spread -- often in good faith -- misleading messages. Although professional\nfact-checkers are crucial to debunking viral claims, they usually do not engage\nin conversations on social media. Thereby, significant effort has been made to\nautomate the use of fact-checker material in social correction; however, no\nprevious work has tried to integrate it with the style and pragmatics that are\ncommonly employed in social media communication. To fill this gap, we present\nVerMouth, the first large-scale dataset comprising roughly 12 thousand\nclaim-response pairs (linked to debunking articles), accounting for both\nSMP-style and basic emotions, two factors which have a significant role in\nmisinformation credibility and spreading. To collect this dataset we used a\ntechnique based on an author-reviewer pipeline, which efficiently combines LLMs\nand human annotators to obtain high-quality data. We also provide comprehensive\nexperiments showing how models trained on our proposed dataset have significant\nimprovements in terms of output quality and generalization capabilities.\n","authors":["Daniel Russo","Shane Peter Kaszefski-Yaschuk","Jacopo Staiano","Marco Guerini"],"pdf_url":"https://arxiv.org/pdf/2311.10587v1.pdf","comment":"Accepted to EMNLP 2023 main conference"},{"id":"http://arxiv.org/abs/2305.14937v2","updated":"2023-11-17T15:28:00Z","published":"2023-05-24T09:20:15Z","title":"A Fair and In-Depth Evaluation of Existing End-to-End Entity Linking\n  Systems","summary":"  Existing evaluations of entity linking systems often say little about how the\nsystem is going to perform for a particular application. There are two\nfundamental reasons for this. One is that many evaluations only use aggregate\nmeasures (like precision, recall, and F1 score), without a detailed error\nanalysis or a closer look at the results. The other is that all of the widely\nused benchmarks have strong biases and artifacts, in particular: a strong focus\non named entities, an unclear or missing specification of what else counts as\nan entity mention, poor handling of ambiguities, and an over- or\nunderrepresentation of certain kinds of entities.\n  We provide a more meaningful and fair in-depth evaluation of a variety of\nexisting end-to-end entity linkers. We characterize their strengths and\nweaknesses and also report on reproducibility aspects. The detailed results of\nour evaluation can be inspected under\nhttps://elevant.cs.uni-freiburg.de/emnlp2023 . Our evaluation is based on\nseveral widely used benchmarks, which exhibit the problems mentioned above to\nvarious degrees, as well as on two new benchmarks, which address the problems\nmentioned above. The new benchmarks can be found under\nhttps://github.com/ad-freiburg/fair-entity-linking-benchmarks .\n","authors":["Hannah Bast","Matthias Hertel","Natalie Prange"],"pdf_url":"https://arxiv.org/pdf/2305.14937v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.04354v2","updated":"2023-11-17T15:15:17Z","published":"2023-11-07T21:27:17Z","title":"Uncovering Intermediate Variables in Transformers using Circuit Probing","summary":"  Neural network models have achieved high performance on a wide variety of\ncomplex tasks, but the algorithms that they implement are notoriously difficult\nto interpret. In order to understand these algorithms, it is often necessary to\nhypothesize intermediate variables involved in the network's computation. For\nexample, does a language model depend on particular syntactic properties when\ngenerating a sentence? However, existing analysis tools make it difficult to\ntest hypotheses of this type. We propose a new analysis technique -- circuit\nprobing -- that automatically uncovers low-level circuits that compute\nhypothesized intermediate variables. This enables causal analysis through\ntargeted ablation at the level of model parameters. We apply this method to\nmodels trained on simple arithmetic tasks, demonstrating its effectiveness at\n(1) deciphering the algorithms that models have learned, (2) revealing modular\nstructure within a model, and (3) tracking the development of circuits over\ntraining. We compare circuit probing to other methods across these three\nexperiments, and find it on par or more effective than existing analysis\nmethods. Finally, we demonstrate circuit probing on a real-world use case,\nuncovering circuits that are responsible for subject-verb agreement and\nreflexive anaphora in GPT2-Small and Medium.\n","authors":["Michael A. Lepori","Thomas Serre","Ellie Pavlick"],"pdf_url":"https://arxiv.org/pdf/2311.04354v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10541v1","updated":"2023-11-17T14:08:44Z","published":"2023-11-17T14:08:44Z","title":"Detection of Offensive and Threatening Online Content in a Low Resource\n  Language","summary":"  Hausa is a major Chadic language, spoken by over 100 million people in\nAfrica. However, from a computational linguistic perspective, it is considered\na low-resource language, with limited resources to support Natural Language\nProcessing (NLP) tasks. Online platforms often facilitate social interactions\nthat can lead to the use of offensive and threatening language, which can go\nundetected due to the lack of detection systems designed for Hausa. This study\naimed to address this issue by (1) conducting two user studies (n=308) to\ninvestigate cyberbullying-related issues, (2) collecting and annotating the\nfirst set of offensive and threatening datasets to support relevant downstream\ntasks in Hausa, (3) developing a detection system to flag offensive and\nthreatening content, and (4) evaluating the detection system and the efficacy\nof the Google-based translation engine in detecting offensive and threatening\nterms in Hausa. We found that offensive and threatening content is quite\ncommon, particularly when discussing religion and politics. Our detection\nsystem was able to detect more than 70% of offensive and threatening content,\nalthough many of these were mistranslated by Google's translation engine. We\nattribute this to the subtle relationship between offensive and threatening\ncontent and idiomatic expressions in the Hausa language. We recommend that\ndiverse stakeholders participate in understanding local conventions and\ndemographics in order to develop a more effective detection system. These\ninsights are essential for implementing targeted moderation strategies to\ncreate a safe and inclusive online environment.\n","authors":["Fatima Muhammad Adam","Abubakar Yakubu Zandam","Isa Inuwa-Dutse"],"pdf_url":"https://arxiv.org/pdf/2311.10541v1.pdf","comment":"25 pages, 5 figures, 8 tables"},{"id":"http://arxiv.org/abs/2311.10514v1","updated":"2023-11-17T13:35:10Z","published":"2023-11-17T13:35:10Z","title":"When a Language Question Is at Stake. A Revisited Approach to Label\n  Sensitive Content","summary":"  Many under-resourced languages require high-quality datasets for specific\ntasks such as offensive language detection, disinformation, or misinformation\nidentification. However, the intricacies of the content may have a detrimental\neffect on the annotators. The article aims to revisit an approach of\npseudo-labeling sensitive data on the example of Ukrainian tweets covering the\nRussian-Ukrainian war. Nowadays, this acute topic is in the spotlight of\nvarious language manipulations that cause numerous disinformation and profanity\non social media platforms. The conducted experiment highlights three main\nstages of data annotation and underlines the main obstacles during machine\nannotation. Ultimately, we provide a fundamental statistical analysis of the\nobtained data, evaluation of models used for pseudo-labelling, and set further\nguidelines on how the scientists can leverage the corpus to execute more\nadvanced research and extend the existing data samples without annotators'\nengagement.\n","authors":["Stetsenko Daria"],"pdf_url":"https://arxiv.org/pdf/2311.10514v1.pdf","comment":"Ukrainian language, pseudo-labelling, dataset, offensive-language"},{"id":"http://arxiv.org/abs/2311.10505v1","updated":"2023-11-17T13:10:58Z","published":"2023-11-17T13:10:58Z","title":"CNL2ASP: converting controlled natural language sentences into ASP","summary":"  Answer Set Programming (ASP) is a popular declarative programming language\nfor solving hard combinatorial problems. Although ASP has gained widespread\nacceptance in academic and industrial contexts, there are certain user groups\nwho may find it more advantageous to employ a higher-level language that\nclosely resembles natural language when specifying ASP programs. In this paper,\nwe propose a novel tool, called CNL2ASP, for translating English sentences\nexpressed in a controlled natural language (CNL) form into ASP. In particular,\nwe first provide a definition of the type of sentences allowed by our CNL and\ntheir translation as ASP rules, and then exemplify the usage of the CNL for the\nspecification of both synthetic and real-world combinatorial problems. Finally,\nwe report the results of an experimental analysis conducted on the real-world\nproblems to compare the performance of automatically generated encodings with\nthe ones written by ASP practitioners, showing that our tool can obtain\nsatisfactory performance on these benchmarks. Under consideration in Theory and\nPractice of Logic Programming (TPLP).\n","authors":["Simone Caruso","Carmine Dodaro","Marco Maratea","Marco Mochi","Francesco Riccio"],"pdf_url":"https://arxiv.org/pdf/2311.10505v1.pdf","comment":"Under consideration in Theory and Practice of Logic Programming\n  (TPLP)"},{"id":"http://arxiv.org/abs/2201.05613v3","updated":"2023-11-17T13:01:01Z","published":"2022-01-14T16:04:09Z","title":"The Dark Side of the Language: Pre-trained Transformers in the DarkNet","summary":"  Pre-trained Transformers are challenging human performances in many NLP\ntasks. The massive datasets used for pre-training seem to be the key to their\nsuccess on existing tasks. In this paper, we explore how a range of pre-trained\nNatural Language Understanding models perform on definitely unseen sentences\nprovided by classification tasks over a DarkNet corpus. Surprisingly, results\nshow that syntactic and lexical neural networks perform on par with pre-trained\nTransformers even after fine-tuning. Only after what we call extreme domain\nadaptation, that is, retraining with the masked language model task on all the\nnovel corpus, pre-trained Transformers reach their standard high results. This\nsuggests that huge pre-training corpora may give Transformers unexpected help\nsince they are exposed to many of the possible sentences.\n","authors":["Leonardo Ranaldi","Aria Nourbakhsh","Arianna Patrizi","Elena Sofia Ruzzetti","Dario Onorati","Francesca Fallucchi","Fabio Massimo Zanzotto"],"pdf_url":"https://arxiv.org/pdf/2201.05613v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10436v1","updated":"2023-11-17T10:14:45Z","published":"2023-11-17T10:14:45Z","title":"Sinhala-English Word Embedding Alignment: Introducing Datasets and\n  Benchmark for a Low Resource Language","summary":"  Since their inception, embeddings have become a primary ingredient in many\nflavours of Natural Language Processing (NLP) tasks supplanting earlier types\nof representation. Even though multilingual embeddings have been used for the\nincreasing number of multilingual tasks, due to the scarcity of parallel\ntraining data, low-resource languages such as Sinhala, tend to focus more on\nmonolingual embeddings. Then when it comes to the aforementioned multi-lingual\ntasks, it is challenging to utilize these monolingual embeddings given that\neven if the embedding spaces have a similar geometric arrangement due to an\nidentical training process, the embeddings of the languages considered are not\naligned. This is solved by the embedding alignment task. Even in this,\nhigh-resource language pairs are in the limelight while low-resource languages\nsuch as Sinhala which is in dire need of help seem to have fallen by the\nwayside. In this paper, we try to align Sinhala and English word embedding\nspaces based on available alignment techniques and introduce a benchmark for\nSinhala language embedding alignment. In addition to that, to facilitate the\nsupervised alignment, as an intermediate task, we also introduce\nSinhala-English alignment datasets. These datasets serve as our anchor datasets\nfor supervised word embedding alignment. Even though we do not obtain results\ncomparable to the high-resource languages such as French, German, or Chinese,\nwe believe our work lays the groundwork for more specialized alignment between\nEnglish and Sinhala embeddings.\n","authors":["Kasun Wickramasinghe","Nisansa de Silva"],"pdf_url":"https://arxiv.org/pdf/2311.10436v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10431v1","updated":"2023-11-17T10:09:12Z","published":"2023-11-17T10:09:12Z","title":"Causal Graph in Language Model Rediscovers Cortical Hierarchy in Human\n  Narrative Processing","summary":"  Understanding how humans process natural language has long been a vital\nresearch direction. The field of natural language processing (NLP) has recently\nexperienced a surge in the development of powerful language models. These\nmodels have proven to be invaluable tools for studying another complex system\nknown to process human language: the brain. Previous studies have demonstrated\nthat the features of language models can be mapped to fMRI brain activity. This\nraises the question: is there a commonality between information processing in\nlanguage models and the human brain? To estimate information flow patterns in a\nlanguage model, we examined the causal relationships between different layers.\nDrawing inspiration from the workspace framework for consciousness, we\nhypothesized that features integrating more information would more accurately\npredict higher hierarchical brain activity. To validate this hypothesis, we\nclassified language model features into two categories based on causal network\nmeasures: 'low in-degree' and 'high in-degree'. We subsequently compared the\nbrain prediction accuracy maps for these two groups. Our results reveal that\nthe difference in prediction accuracy follows a hierarchical pattern,\nconsistent with the cortical hierarchy map revealed by activity time constants.\nThis finding suggests a parallel between how language models and the human\nbrain process linguistic information.\n","authors":["Zhengqi He","Taro Toyoizumi"],"pdf_url":"https://arxiv.org/pdf/2311.10431v1.pdf","comment":"15 pages, 16 figures"},{"id":"http://arxiv.org/abs/2207.08522v2","updated":"2023-11-17T09:13:27Z","published":"2022-07-18T11:37:47Z","title":"Classifying COVID-19 vaccine narratives","summary":"  Vaccine hesitancy is widespread, despite the government's information\ncampaigns and the efforts of the World Health Organisation (WHO). Categorising\nthe topics within vaccine-related narratives is crucial to understand the\nconcerns expressed in discussions and identify the specific issues that\ncontribute to vaccine hesitancy. This paper addresses the need for monitoring\nand analysing vaccine narratives online by introducing a novel vaccine\nnarrative classification task, which categorises COVID-19 vaccine claims into\none of seven categories. Following a data augmentation approach, we first\nconstruct a novel dataset for this new classification task, focusing on the\nminority classes. We also make use of fact-checker annotated data. The paper\nalso presents a neural vaccine narrative classifier that achieves an accuracy\nof 84% under cross-validation. The classifier is publicly available for\nresearchers and journalists.\n","authors":["Yue Li","Carolina Scarton","Xingyi Song","Kalina Bontcheva"],"pdf_url":"https://arxiv.org/pdf/2207.08522v2.pdf","comment":"In Proceedings of the 14th International Conference on Recent\n  Advances in Natural Language Processing, 2023"},{"id":"http://arxiv.org/abs/2311.10395v1","updated":"2023-11-17T08:56:13Z","published":"2023-11-17T08:56:13Z","title":"Bias A-head? Analyzing Bias in Transformer-Based Language Model\n  Attention Heads","summary":"  Transformer-based pretrained large language models (PLM) such as BERT and GPT\nhave achieved remarkable success in NLP tasks. However, PLMs are prone to\nencoding stereotypical biases. Although a burgeoning literature has emerged on\nstereotypical bias mitigation in PLMs, such as work on debiasing gender and\nracial stereotyping, how such biases manifest and behave internally within PLMs\nremains largely unknown. Understanding the internal stereotyping mechanisms may\nallow better assessment of model fairness and guide the development of\neffective mitigation strategies. In this work, we focus on attention heads, a\nmajor component of the Transformer architecture, and propose a bias analysis\nframework to explore and identify a small set of biased heads that are found to\ncontribute to a PLM's stereotypical bias. We conduct extensive experiments to\nvalidate the existence of these biased heads and to better understand how they\nbehave. We investigate gender and racial bias in the English language in two\ntypes of Transformer-based PLMs: the encoder-based BERT model and the\ndecoder-based autoregressive GPT model. Overall, the results shed light on\nunderstanding the bias behavior in pretrained language models.\n","authors":["Yi Yang","Hanyu Duan","Ahmed Abbasi","John P. Lalor","Kar Yan Tam"],"pdf_url":"https://arxiv.org/pdf/2311.10395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10373v1","updated":"2023-11-17T07:56:01Z","published":"2023-11-17T07:56:01Z","title":"FOAL: Fine-grained Contrastive Learning for Cross-domain Aspect\n  Sentiment Triplet Extraction","summary":"  Aspect Sentiment Triplet Extraction (ASTE) has achieved promising results\nwhile relying on sufficient annotation data in a specific domain. However, it\nis infeasible to annotate data for each individual domain. We propose to\nexplore ASTE in the cross-domain setting, which transfers knowledge from a\nresource-rich source domain to a resource-poor target domain, thereby\nalleviating the reliance on labeled data in the target domain. To effectively\ntransfer the knowledge across domains and extract the sentiment triplets\naccurately, we propose a method named Fine-grained cOntrAstive Learning (FOAL)\nto reduce the domain discrepancy and preserve the discriminability of each\ncategory. Experiments on six transfer pairs show that FOAL achieves 6%\nperformance gains and reduces the domain discrepancy significantly compared\nwith strong baselines. Our code will be publicly available once accepted.\n","authors":["Ting Xu","Zhen Wu","Huiyun Yang","Xinyu Dai"],"pdf_url":"https://arxiv.org/pdf/2311.10373v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10367v1","updated":"2023-11-17T07:40:46Z","published":"2023-11-17T07:40:46Z","title":"Exploring the Relationship between In-Context Learning and Instruction\n  Tuning","summary":"  In-Context Learning (ICL) and Instruction Tuning (IT) are two primary\nparadigms of adopting Large Language Models (LLMs) to downstream applications.\nHowever, they are significantly different. In ICL, a set of demonstrations are\nprovided at inference time but the LLM's parameters are not updated. In IT, a\nset of demonstrations are used to tune LLM's parameters in training time but no\ndemonstrations are used at inference time. Although a growing body of\nliterature has explored ICL and IT, studies on these topics have largely been\nconducted in isolation, leading to a disconnect between these two paradigms. In\nthis work, we explore the relationship between ICL and IT by examining how the\nhidden states of LLMs change in these two paradigms. Through carefully designed\nexperiments conducted with LLaMA-2 (7B and 13B), we find that ICL is implicit\nIT. In other words, ICL changes an LLM's hidden states as if the demonstrations\nwere used to instructionally tune the model. Furthermore, the convergence\nbetween ICL and IT is largely contingent upon several factors related to the\nprovided demonstrations. Overall, this work offers a unique perspective to\nexplore the connection between ICL and IT and sheds light on understanding the\nbehaviors of LLM.\n","authors":["Hanyu Duan","Yixuan Tang","Yi Yang","Ahmed Abbasi","Kar Yan Tam"],"pdf_url":"https://arxiv.org/pdf/2311.10367v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.18075v3","updated":"2023-11-17T06:55:45Z","published":"2023-10-27T11:43:46Z","title":"DUMA: a Dual-Mind Conversational Agent with Fast and Slow Thinking","summary":"  Inspired by the dual-process theory of human cognition, we introduce DUMA, a\nnovel conversational agent framework that embodies a dual-mind mechanism\nthrough the utilization of two generative Large Language Models (LLMs)\ndedicated to fast and slow thinking respectively. The fast thinking model\nserves as the primary interface for external interactions and initial response\ngeneration, evaluating the necessity for engaging the slow thinking model based\non the complexity of the complete response. When invoked, the slow thinking\nmodel takes over the conversation, engaging in meticulous planning, reasoning,\nand tool utilization to provide a well-analyzed response. This dual-mind\nconfiguration allows for a seamless transition between intuitive responses and\ndeliberate problem-solving processes based on the situation. We have\nconstructed a conversational agent to handle online inquiries in the real\nestate industry. The experiment proves that our method balances effectiveness\nand efficiency, and has a significant improvement compared to the baseline.\n","authors":["Xiaoyu Tian","Liangyu Chen","Na Liu","Yaxuan Liu","Wei Zou","Kaijiang Chen","Ming Cui"],"pdf_url":"https://arxiv.org/pdf/2310.18075v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.00312v4","updated":"2023-11-17T06:32:49Z","published":"2023-09-01T07:53:28Z","title":"Insights Into the Nutritional Prevention of Macular Degeneration based\n  on a Comparative Topic Modeling Approach","summary":"  Topic modeling and text mining are subsets of Natural Language Processing\n(NLP) with relevance for conducting meta-analysis (MA) and systematic review\n(SR). For evidence synthesis, the above NLP methods are conventionally used for\ntopic-specific literature searches or extracting values from reports to\nautomate essential phases of SR and MA. Instead, this work proposes a\ncomparative topic modeling approach to analyze reports of contradictory results\non the same general research question. Specifically, the objective is to\nidentify topics exhibiting distinct associations with significant results for\nan outcome of interest by ranking them according to their proportional\noccurrence in (and consistency of distribution across) reports of significant\neffects. The proposed method was tested on broad-scope studies addressing\nwhether supplemental nutritional compounds significantly benefit macular\ndegeneration (MD). Four of these were further supported in terms of\neffectiveness upon conducting a follow-up literature search for validation\n(omega-3 fatty acids, copper, zeaxanthin, and nitrates). The two not supported\nby the follow-up literature search (niacin and molybdenum) also had scores in\nthe lowest range under the proposed scoring system, suggesting that the\nproposed methods score for a given topic may be a viable proxy for its degree\nof association with the outcome of interest and can be helpful in the search\nfor potentially causal relationships. These results underpin the proposed\nmethods potential to add specificity in understanding effects from broad-scope\nreports, elucidate topics of interest for future research, and guide evidence\nsynthesis in a systematic and scalable way. All of this is accomplished while\nyielding valuable insights into the prevention of MD.\n","authors":["Lucas Cassiel Jacaruso"],"pdf_url":"https://arxiv.org/pdf/2309.00312v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10344v1","updated":"2023-11-17T06:13:02Z","published":"2023-11-17T06:13:02Z","title":"Complementary Advantages of ChatGPTs and Human Readers in Reasoning:\n  Evidence from English Text Reading Comprehension","summary":"  ChatGPT has shown its great power in text processing, including its reasoning\nability from text reading. However, there has not been any direct comparison\nbetween human readers and ChatGPT in reasoning ability related to text reading.\nThis study was undertaken to investigate how ChatGPTs (i.e., ChatGPT and\nChatGPT Plus) and Chinese senior school students as ESL learners exhibited\ntheir reasoning ability from English narrative texts. Additionally, we compared\nthe two ChatGPTs in the reasoning performances when commands were updated\nelaborately. The whole study was composed of three reasoning tests: Test 1 for\ncommonsense inference, Test 2 for emotional inference, and Test 3 for causal\ninference. The results showed that in Test 1, the students outdid the two\nChatGPT versions in local-culture-related inferences but performed worse than\nthe chatbots in daily-life inferences. In Test 2, ChatGPT Plus excelled whereas\nChatGPT lagged behind in accuracy. In association with both accuracy and\nfrequency of correct responses, the students were inferior to the two chatbots.\nCompared with ChatGPTs' better performance in positive emotions, the students\nshowed their superiority in inferring negative emotions. In Test 3, the\nstudents demonstrated better logical analysis, outdoing both chatbots. In\nupdating command condition, ChatGPT Plus displayed good causal reasoning\nability while ChatGPT kept unchanged. Our study reveals that human readers and\nChatGPTs have their respective advantages and disadvantages in drawing\ninferences from text reading comprehension, unlocking a complementary\nrelationship in text-based reasoning.\n","authors":["Tongquan Zhou","Yao Zhang","Siyi Cao","Yulu Li","Tao Wang"],"pdf_url":"https://arxiv.org/pdf/2311.10344v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.15060v2","updated":"2023-11-17T04:20:01Z","published":"2023-05-24T11:49:52Z","title":"Who Wrote this Code? Watermarking for Code Generation","summary":"  With the remarkable generation performance of large language models, ethical\nand legal concerns about using them have been raised, such as plagiarism and\ncopyright issues. For such concerns, several approaches to watermark and detect\nLLM-generated text have been proposed very recently. However, we discover that\nthe previous methods fail to function appropriately with code generation tasks\nbecause of the syntactic and semantic characteristics of code. Based on\n\\citet{Kirchenbauer2023watermark}, we propose a new watermarking method,\nSelective WatErmarking via Entropy Thresholding (SWEET), that promotes \"green\"\ntokens only at the position with high entropy of the token distribution during\ngeneration, thereby preserving the correctness of the generated code. The\nwatermarked code is detected by the statistical test and Z-score based on the\nentropy information. Our experiments on HumanEval and MBPP show that SWEET\nsignificantly improves the Pareto Frontier between the code correctness and\nwatermark detection performance. We also show that notable post-hoc detection\nmethods (e.g. DetectGPT) fail to work well in this task. Finally, we show that\nsetting a reasonable entropy threshold is not much of a challenge. Code is\navailable at https://github.com/hongcheki/sweet-watermark.\n","authors":["Taehyun Lee","Seokhee Hong","Jaewoo Ahn","Ilgee Hong","Hwaran Lee","Sangdoo Yun","Jamin Shin","Gunhee Kim"],"pdf_url":"https://arxiv.org/pdf/2305.15060v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.09861v2","updated":"2023-11-17T03:17:05Z","published":"2023-11-16T12:43:18Z","title":"PsyBench: a balanced and in-depth Psychological Chinese Evaluation\n  Benchmark for Foundation Models","summary":"  As Large Language Models (LLMs) are becoming prevalent in various fields,\nthere is an urgent need for improved NLP benchmarks that encompass all the\nnecessary knowledge of individual discipline. Many contemporary benchmarks for\nfoundational models emphasize a broad range of subjects but often fall short in\npresenting all the critical subjects and encompassing necessary professional\nknowledge of them. This shortfall has led to skewed results, given that LLMs\nexhibit varying performance across different subjects and knowledge areas. To\naddress this issue, we present psybench, the first comprehensive Chinese\nevaluation suite that covers all the necessary knowledge required for graduate\nentrance exams. psybench offers a deep evaluation of a model's strengths and\nweaknesses in psychology through multiple-choice questions. Our findings show\nsignificant differences in performance across different sections of a subject,\nhighlighting the risk of skewed results when the knowledge in test sets is not\nbalanced. Notably, only the ChatGPT model reaches an average accuracy above\n$70\\%$, indicating that there is still plenty of room for improvement. We\nexpect that psybench will help to conduct thorough evaluations of base models'\nstrengths and weaknesses and assist in practical application in the field of\npsychology.\n","authors":["Junlei Zhang","Hongliang He","Nirui Song","Shuyuan He","Shuai Zhang","Huachuan Qiu","Anqi Li","Lizhi Ma","Zhenzhong Lan"],"pdf_url":"https://arxiv.org/pdf/2311.09861v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.11248v2","updated":"2023-11-17T02:51:39Z","published":"2023-10-17T13:18:01Z","title":"CrossCodeEval: A Diverse and Multilingual Benchmark for Cross-File Code\n  Completion","summary":"  Code completion models have made significant progress in recent years, yet\ncurrent popular evaluation datasets, such as HumanEval and MBPP, predominantly\nfocus on code completion tasks within a single file. This over-simplified\nsetting falls short of representing the real-world software development\nscenario where repositories span multiple files with numerous cross-file\ndependencies, and accessing and understanding cross-file context is often\nrequired to complete the code correctly.\n  To fill in this gap, we propose CrossCodeEval, a diverse and multilingual\ncode completion benchmark that necessitates an in-depth cross-file contextual\nunderstanding to complete the code accurately. CrossCodeEval is built on a\ndiverse set of real-world, open-sourced, permissively-licensed repositories in\nfour popular programming languages: Python, Java, TypeScript, and C#. To create\nexamples that strictly require cross-file context for accurate completion, we\npropose a straightforward yet efficient static-analysis-based approach to\npinpoint the use of cross-file context within the current file.\n  Extensive experiments on state-of-the-art code language models like CodeGen\nand StarCoder demonstrate that CrossCodeEval is extremely challenging when the\nrelevant cross-file context is absent, and we see clear improvements when\nadding these context into the prompt. However, despite such improvements, the\npinnacle of performance remains notably unattained even with the\nhighest-performing model, indicating that CrossCodeEval is also capable of\nassessing model's capability in leveraging extensive context to make better\ncode completion. Finally, we benchmarked various methods in retrieving\ncross-file context, and show that CrossCodeEval can also be used to measure the\ncapability of code retrievers.\n","authors":["Yangruibo Ding","Zijian Wang","Wasi Uddin Ahmad","Hantian Ding","Ming Tan","Nihal Jain","Murali Krishna Ramanathan","Ramesh Nallapati","Parminder Bhatia","Dan Roth","Bing Xiang"],"pdf_url":"https://arxiv.org/pdf/2310.11248v2.pdf","comment":"To appear at NeurIPS 2023 (Datasets and Benchmarks Track)"},{"id":"http://arxiv.org/abs/2304.03512v3","updated":"2023-11-17T02:08:14Z","published":"2023-04-07T07:13:35Z","title":"Hierarchical Catalogue Generation for Literature Review: A Benchmark","summary":"  Scientific literature review generation aims to extract and organize\nimportant information from an abundant collection of reference papers and\nproduces corresponding reviews while lacking a clear and logical hierarchy. We\nobserve that a high-quality catalogue-guided generation process can effectively\nalleviate this problem. Therefore, we present an atomic and challenging task\nnamed Hierarchical Catalogue Generation for Literature Review as the first step\nfor review generation, which aims to produce a hierarchical catalogue of a\nreview paper given various references. We construct a novel English\nHierarchical Catalogues of Literature Reviews Dataset with 7.6k literature\nreview catalogues and 389k reference papers. To accurately assess the model\nperformance, we design two evaluation metrics for informativeness and\nsimilarity to ground truth from semantics and structure.Our extensive analyses\nverify the high quality of our dataset and the effectiveness of our evaluation\nmetrics. We further benchmark diverse experiments on state-of-the-art\nsummarization models like BART and large language models like ChatGPT to\nevaluate their capabilities. We further discuss potential directions for this\ntask to motivate future research.\n","authors":["Kun Zhu","Xiaocheng Feng","Xiachong Feng","Yingsheng Wu","Bing Qin"],"pdf_url":"https://arxiv.org/pdf/2304.03512v3.pdf","comment":"EMNLP 2023 findings"},{"id":"http://arxiv.org/abs/2303.17807v2","updated":"2023-11-17T01:49:57Z","published":"2023-03-31T05:43:21Z","title":"GPT-4 can pass the Korean National Licensing Examination for Korean\n  Medicine Doctors","summary":"  Traditional Korean medicine (TKM) emphasizes individualized diagnosis and\ntreatment. This uniqueness makes AI modeling difficult due to limited data and\nimplicit processes. Large language models (LLMs) have demonstrated impressive\nmedical inference, even without advanced training in medical texts. This study\nassessed the capabilities of GPT-4 in TKM, using the Korean National Licensing\nExamination for Korean Medicine Doctors (K-NLEKMD) as a benchmark. The\nK-NLEKMD, administered by a national organization, encompasses 12 major\nsubjects in TKM. We optimized prompts with Chinese-term annotation, English\ntranslation for questions and instruction, exam-optimized instruction, and\nself-consistency. GPT-4 with optimized prompts achieved 66.18% accuracy,\nsurpassing both the examination's average pass mark of 60% and the 40% minimum\nfor each subject. The gradual introduction of language-related prompts and\nprompting techniques enhanced the accuracy from 51.82% to its maximum accuracy.\nGPT-4 showed low accuracy in subjects including public health &\nmedicine-related law, internal medicine (2) which are localized in Korea and\nTKM. The model's accuracy was lower for questions requiring TKM-specialized\nknowledge. It exhibited higher accuracy in diagnosis-based and recall-based\nquestions than in intervention-based questions. A positive correlation was\nobserved between the consistency and accuracy of GPT-4's responses. This study\nunveils both the potential and challenges of applying LLMs to TKM. These\nfindings underline the potential of LLMs like GPT-4 in culturally adapted\nmedicine, especially TKM, for tasks such as clinical assistance, medical\neducation, and research. But they also point towards the necessity for the\ndevelopment of methods to mitigate cultural bias inherent in large language\nmodels and validate their efficacy in real-world clinical settings.\n","authors":["Dongyeop Jang","Tae-Rim Yun","Choong-Yeol Lee","Young-Kyu Kwon","Chang-Eop Kim"],"pdf_url":"https://arxiv.org/pdf/2303.17807v2.pdf","comment":"23 pages, 4 figures"},{"id":"http://arxiv.org/abs/2311.10271v1","updated":"2023-11-17T01:33:05Z","published":"2023-11-17T01:33:05Z","title":"Prompt Pool based Class-Incremental Continual Learning for Dialog State\n  Tracking","summary":"  Continual learning is crucial for dialog state tracking (DST) in dialog\nsystems, since requirements from users for new functionalities are often\nencountered. However, most of existing continual learning methods for DST\nrequire task identities during testing, which is a severe limit in real-world\napplications. In this paper, we aim to address continual learning of DST in the\nclass-incremental scenario (namely the task identity is unknown in testing).\nInspired by the recently emerging prompt tuning method that performs well on\ndialog systems, we propose to use the prompt pool method, where we maintain a\npool of key-value paired prompts and select prompts from the pool according to\nthe distance between the dialog history and the prompt keys. The proposed\nmethod can automatically identify tasks and select appropriate prompts during\ntesting. We conduct experiments on Schema-Guided Dialog dataset (SGD) and\nanother dataset collected from a real-world dialog application. Experiment\nresults show that the prompt pool method achieves much higher joint goal\naccuracy than the baseline. After combining with a rehearsal buffer, the model\nperformance can be further improved.\n","authors":["Hong Liu","Yucheng Cai","Yuan Zhou","Zhijian Ou","Yi Huang","Junlan Feng"],"pdf_url":"https://arxiv.org/pdf/2311.10271v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10267v1","updated":"2023-11-17T01:27:01Z","published":"2023-11-17T01:27:01Z","title":"Energy and Carbon Considerations of Fine-Tuning BERT","summary":"  Despite the popularity of the `pre-train then fine-tune' paradigm in the NLP\ncommunity, existing work quantifying energy costs and associated carbon\nemissions has largely focused on language model pre-training. Although a single\npre-training run draws substantially more energy than fine-tuning, fine-tuning\nis performed more frequently by many more individual actors, and thus must be\naccounted for when considering the energy and carbon footprint of NLP. In order\nto better characterize the role of fine-tuning in the landscape of energy and\ncarbon emissions in NLP, we perform a careful empirical study of the\ncomputational costs of fine-tuning across tasks, datasets, hardware\ninfrastructure and measurement modalities. Our experimental results allow us to\nplace fine-tuning energy and carbon costs into perspective with respect to\npre-training and inference, and outline recommendations to NLP researchers and\npractitioners who wish to improve their fine-tuning energy efficiency.\n","authors":["Xiaorong Wang","Clara Na","Emma Strubell","Sorelle Friedler","Sasha Luccioni"],"pdf_url":"https://arxiv.org/pdf/2311.10267v1.pdf","comment":"EMNLP 2023 Findings; First two authors contributed equally; 12 pages"},{"id":"http://arxiv.org/abs/2311.10266v1","updated":"2023-11-17T01:20:08Z","published":"2023-11-17T01:20:08Z","title":"Diagnosing and Debiasing Corpus-Based Political Bias and Insults in GPT2","summary":"  The training of large language models (LLMs) on extensive, unfiltered corpora\nsourced from the internet is a common and advantageous practice. Consequently,\nLLMs have learned and inadvertently reproduced various types of biases,\nincluding violent, offensive, and toxic language. However, recent research\nshows that generative pretrained transformer (GPT) language models can\nrecognize their own biases and detect toxicity in generated content, a process\nreferred to as self-diagnosis. In response, researchers have developed a\ndecoding algorithm that allows LLMs to self-debias, or reduce their likelihood\nof generating harmful text. This study investigates the efficacy of the\ndiagnosing-debiasing approach in mitigating two additional types of biases:\ninsults and political bias. These biases are often used interchangeably in\ndiscourse, despite exhibiting potentially dissimilar semantic and syntactic\nproperties. We aim to contribute to the ongoing effort of investigating the\nethical and social implications of human-AI interaction.\n","authors":["Ambri Ma","Arnav Kumar","Brett Zeligson"],"pdf_url":"https://arxiv.org/pdf/2311.10266v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2311.06233v2","updated":"2023-11-17T00:20:44Z","published":"2023-11-10T18:48:58Z","title":"Data Contamination Quiz: A Tool to Detect and Estimate Contamination in\n  Large Language Models","summary":"  We propose the Data Contamination Quiz, a simple and effective approach to\ndetect data contamination in large language models (LLMs) and estimate the\namount of it. Specifically, we frame data contamination detection as a series\nof multiple-choice questions. We devise a quiz format wherein three perturbed\nversions of each dataset instance are created. These changes only include\nword-level perturbations, replacing words with their contextual synonyms,\nensuring both the semantic and sentence structure remain exactly the same as\nthe original instance. Together with the original instance, these perturbed\nversions constitute the choices in the quiz. Given that the only distinguishing\nsignal among these choices is the exact wording, an LLM, when tasked with\nidentifying the original instance from the choices, opts for the original if it\nhas memorized it in its pre-training phase--a trait intrinsic to LLMs. A\ndataset partition is then marked as contaminated if the LLM's performance on\nthe quiz surpasses what random chance suggests. Our evaluation spans seven\ndatasets and their respective splits (train and test/validation) on two\nstate-of-the-art LLMs: GPT-4 and GPT-3.5. While lacking access to the\npre-training data, our results suggest that our approach not only enhances the\ndetection of data contamination but also provides an accurate estimation of its\nextent, even when the contamination signal is weak.\n","authors":["Shahriar Golchin","Mihai Surdeanu"],"pdf_url":"https://arxiv.org/pdf/2311.06233v2.pdf","comment":"v1.1 preprint"},{"id":"http://arxiv.org/abs/2105.01311v3","updated":"2023-11-17T23:37:23Z","published":"2021-05-04T06:40:33Z","title":"Inferring the Reader: Guiding Automated Story Generation with\n  Commonsense Reasoning","summary":"  Transformer-based language model approaches to automated story generation\ncurrently provide state-of-the-art results. However, they still suffer from\nplot incoherence when generating narratives over time, and critically lack\nbasic commonsense reasoning. Furthermore, existing methods generally focus only\non single-character stories, or fail to track characters at all. To improve the\ncoherence of generated narratives and to expand the scope of character-centric\nnarrative generation, we introduce Commonsense-inference Augmented neural\nStoryTelling (CAST), a framework for introducing commonsense reasoning into the\ngeneration process with the option to model the interaction between multiple\ncharacters. We find that our CAST method produces significantly more coherent,\non-topic, enjoyable and fluent stories than existing models in both the\nsingle-character and two-character settings in three storytelling domains.\n","authors":["Xiangyu Peng","Siyan Li","Sarah Wiegreffe","Mark Riedl"],"pdf_url":"https://arxiv.org/pdf/2105.01311v3.pdf","comment":"Findings of EMNLP 2022. For conference video and anthology version,\n  see https://aclanthology.org/2022.findings-emnlp.520/"},{"id":"http://arxiv.org/abs/2311.10905v1","updated":"2023-11-17T23:02:42Z","published":"2023-11-17T23:02:42Z","title":"Flexible Model Interpretability through Natural Language Model Editing","summary":"  Model interpretability and model editing are crucial goals in the age of\nlarge language models. Interestingly, there exists a link between these two\ngoals: if a method is able to systematically edit model behavior with regard to\na human concept of interest, this editor method can help make internal\nrepresentations more interpretable by pointing towards relevant representations\nand systematically manipulating them.\n","authors":["Karel D'Oosterlinck","Thomas Demeester","Chris Develder","Christopher Potts"],"pdf_url":"https://arxiv.org/pdf/2311.10905v1.pdf","comment":"Extended Abstract -- work in progress. BlackboxNLP2023"},{"id":"http://arxiv.org/abs/2311.10899v1","updated":"2023-11-17T22:44:05Z","published":"2023-11-17T22:44:05Z","title":"Extraction and Summarization of Explicit Video Content using Multi-Modal\n  Deep Learning","summary":"  With the increase in video-sharing platforms across the internet, it is\ndifficult for humans to moderate the data for explicit content. Hence, an\nautomated pipeline to scan through video data for explicit content has become\nthe need of the hour. We propose a novel pipeline that uses multi-modal deep\nlearning to first extract the explicit segments of input videos and then\nsummarize their content using text to determine its age appropriateness and age\nrating. We also evaluate our pipeline's effectiveness in the end using standard\nmetrics.\n","authors":["Shaunak Joshi","Raghav Gaggar"],"pdf_url":"https://arxiv.org/pdf/2311.10899v1.pdf","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.06453v3","updated":"2023-11-17T22:30:27Z","published":"2023-11-11T01:14:37Z","title":"DocGen: Generating Detailed Parameter Docstrings in Python","summary":"  Documentation debt hinders the effective utilization of open-source software.\nAlthough code summarization tools have been helpful for developers, most would\nprefer a detailed account of each parameter in a function rather than a\nhigh-level summary. However, generating such a summary is too intricate for a\nsingle generative model to produce reliably due to the lack of high-quality\ntraining data. Thus, we propose a multi-step approach that combines multiple\ntask-specific models, each adept at producing a specific section of a\ndocstring. The combination of these models ensures the inclusion of each\nsection in the final docstring. We compared the results from our approach with\nexisting generative models using both automatic metrics and a human-centred\nevaluation with 17 participating developers, which proves the superiority of\nour approach over existing methods.\n","authors":["Vatsal Venkatkrishna","Durga Shree Nagabushanam","Emmanuel Iko-Ojo Simon","Melina Vidoni"],"pdf_url":"https://arxiv.org/pdf/2311.06453v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10883v1","updated":"2023-11-17T21:58:26Z","published":"2023-11-17T21:58:26Z","title":"Labeling Indoor Scenes with Fusion of Out-of-the-Box Perception Models","summary":"  The image annotation stage is a critical and often the most time-consuming\npart required for training and evaluating object detection and semantic\nsegmentation models. Deployment of the existing models in novel environments\noften requires detecting novel semantic classes not present in the training\ndata. Furthermore, indoor scenes contain significant viewpoint variations,\nwhich need to be handled properly by trained perception models. We propose to\nleverage the recent advancements in state-of-the-art models for bottom-up\nsegmentation (SAM), object detection (Detic), and semantic segmentation\n(MaskFormer), all trained on large-scale datasets. We aim to develop a\ncost-effective labeling approach to obtain pseudo-labels for semantic\nsegmentation and object instance detection in indoor environments, with the\nultimate goal of facilitating the training of lightweight models for various\ndownstream tasks. We also propose a multi-view labeling fusion stage, which\nconsiders the setting where multiple views of the scenes are available and can\nbe used to identify and rectify single-view inconsistencies. We demonstrate the\neffectiveness of the proposed approach on the Active Vision dataset and the\nADE20K dataset. We evaluate the quality of our labeling process by comparing it\nwith human annotations. Also, we demonstrate the effectiveness of the obtained\nlabels in downstream tasks such as object goal navigation and part discovery.\nIn the context of object goal navigation, we depict enhanced performance using\nthis fusion approach compared to a zero-shot baseline that utilizes large\nmonolithic vision-language pre-trained models.\n","authors":["Yimeng Li","Navid Rajabi","Sulabh Shrestha","Md Alimoor Reza","Jana Kosecka"],"pdf_url":"https://arxiv.org/pdf/2311.10883v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10862v1","updated":"2023-11-17T20:48:58Z","published":"2023-11-17T20:48:58Z","title":"Formal concept analysis for evaluating intrinsic dimension of a natural\n  language","summary":"  Some results of a computational experiment for determining the intrinsic\ndimension of linguistic varieties for the Bengali and Russian languages are\npresented. At the same time, both sets of words and sets of bigrams in these\nlanguages were considered separately. The method used to solve this problem was\nbased on formal concept analysis algorithms. It was found that the intrinsic\ndimensions of these languages are significantly less than the dimensions used\nin popular neural network models in natural language processing.\n","authors":["Sergei O. Kuznetsov","Vasilii A. Gromov","Nikita S. Borodin","Andrei M. Divavin"],"pdf_url":"https://arxiv.org/pdf/2311.10862v1.pdf","comment":"Preprint, 10th International Conference on Pattern Recognition and\n  Machine Intelligence (PReMI 2023)"},{"id":"http://arxiv.org/abs/2311.10847v1","updated":"2023-11-17T20:07:54Z","published":"2023-11-17T20:07:54Z","title":"Token-level Adaptation of LoRA Adapters for Downstream Task\n  Generalization","summary":"  This paper introduces a method for adapting LoRA adapters in smaller-sized\nlanguage models to arbitrary downstream tasks. Unlike standard\nmixture-of-expert architectures, our method employs a gradient-free routing\nfunction to choose a weighted combination of experts without increasing the\ncompute requirements for training or inference. The results show that\ntoken-level adaptation of LoRA adapters outperforms the base Llama-2-7b model\nacross mathematical (GSM8K), scientific (ARC-Challenge), reading comprehension\n(SQuAD), and coding (CodeAlpaca-20k) tasks. Further evaluations also show that\nthe average performance of token-level adaptation outperforms individual models\nfine-tuned for each of the tasks with the best performance observed in\nadaptation of every-other token during inference. The code for this study is\nmade available through a public repository.\n","authors":["Joshua Belofsky"],"pdf_url":"https://arxiv.org/pdf/2311.10847v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05507v2","updated":"2023-11-17T19:30:10Z","published":"2023-02-10T20:50:58Z","title":"Language Decision Transformers with Exponential Tilt for Interactive\n  Text Environments","summary":"  Text-based game environments are challenging because agents must deal with\nlong sequences of text, execute compositional actions using text and learn from\nsparse rewards. We address these challenges by proposing Language Decision\nTransformers (LDTs), a framework that is based on transformer language models\nand decision transformers (DTs). Our LDTs extend DTs with 3 components: (1)\nexponential tilt to guide the agent towards high obtainable goals, (2) novel\ngoal conditioning methods yielding better results than the traditional\nreturn-to-go (sum of all future rewards), and (3) a model of future\nobservations that improves agent performance. LDTs are the first to address\noffline RL with DTs on these challenging games. Our experiments show that LDTs\nachieve the highest scores among many different types of agents on some of the\nmost challenging Jericho games, such as Enchanter.\n","authors":["Nicolas Gontier","Pau Rodriguez","Issam Laradji","David Vazquez","Christopher Pal"],"pdf_url":"https://arxiv.org/pdf/2302.05507v2.pdf","comment":"19 pages, 6 figures, 5 tables"},{"id":"http://arxiv.org/abs/2311.10813v1","updated":"2023-11-17T18:59:56Z","published":"2023-11-17T18:59:56Z","title":"A Language Agent for Autonomous Driving","summary":"  Human-level driving is an ultimate goal of autonomous driving. Conventional\napproaches formulate autonomous driving as a perception-prediction-planning\nframework, yet their systems do not capitalize on the inherent reasoning\nability and experiential knowledge of humans. In this paper, we propose a\nfundamental paradigm shift from current pipelines, exploiting Large Language\nModels (LLMs) as a cognitive agent to integrate human-like intelligence into\nautonomous driving systems. Our approach, termed Agent-Driver, transforms the\ntraditional autonomous driving pipeline by introducing a versatile tool library\naccessible via function calls, a cognitive memory of common sense and\nexperiential knowledge for decision-making, and a reasoning engine capable of\nchain-of-thought reasoning, task planning, motion planning, and\nself-reflection. Powered by LLMs, our Agent-Driver is endowed with intuitive\ncommon sense and robust reasoning capabilities, thus enabling a more nuanced,\nhuman-like approach to autonomous driving. We evaluate our approach on the\nlarge-scale nuScenes benchmark, and extensive experiments substantiate that our\nAgent-Driver significantly outperforms the state-of-the-art driving methods by\na large margin. Our approach also demonstrates superior interpretability and\nfew-shot learning ability to these methods. Project page:\n\\href{https://github.com/USC-GVL/Agent-Driver/blob/main/index.html}{here}.\n","authors":["Jiageng Mao","Junjie Ye","Yuxi Qian","Marco Pavone","Yue Wang"],"pdf_url":"https://arxiv.org/pdf/2311.10813v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10810v1","updated":"2023-11-17T18:14:08Z","published":"2023-11-17T18:14:08Z","title":"Use GPT-J Prompt Generation with RoBERTa for NER Models on Diagnosis\n  Extraction of Periodontal Diagnosis from Electronic Dental Records","summary":"  This study explored the usability of prompt generation on named entity\nrecognition (NER) tasks and the performance in different settings of the\nprompt. The prompt generation by GPT-J models was utilized to directly test the\ngold standard as well as to generate the seed and further fed to the RoBERTa\nmodel with the spaCy package. In the direct test, a lower ratio of negative\nexamples with higher numbers of examples in prompt achieved the best results\nwith a F1 score of 0.72. The performance revealed consistency, 0.92-0.97 in the\nF1 score, in all settings after training with the RoBERTa model. The study\nhighlighted the importance of seed quality rather than quantity in feeding NER\nmodels. This research reports on an efficient and accurate way to mine clinical\nnotes for periodontal diagnoses, allowing researchers to easily and quickly\nbuild a NER model with the prompt generation approach.\n","authors":["Yao-Shun Chuang","Xiaoqian Jiang","Chun-Teh Lee","Ryan Brandon","Duong Tran","Oluwabunmi Tokede","Muhammad F. Walji"],"pdf_url":"https://arxiv.org/pdf/2311.10810v1.pdf","comment":"2023 AMIA Annual Symposium, see\n  https://amia.org/education-events/amia-2023-annual-symposium"},{"id":"http://arxiv.org/abs/2311.10642v1","updated":"2023-11-17T16:58:52Z","published":"2023-11-17T16:58:52Z","title":"Rethinking Attention: Exploring Shallow Feed-Forward Neural Networks as\n  an Alternative to Attention Layers in Transformers","summary":"  This work presents an analysis of the effectiveness of using standard shallow\nfeed-forward networks to mimic the behavior of the attention mechanism in the\noriginal Transformer model, a state-of-the-art architecture for\nsequence-to-sequence tasks. We substitute key elements of the attention\nmechanism in the Transformer with simple feed-forward networks, trained using\nthe original components via knowledge distillation. Our experiments, conducted\non the IWSLT2017 dataset, reveal the capacity of these \"attentionless\nTransformers\" to rival the performance of the original architecture. Through\nrigorous ablation studies, and experimenting with various replacement network\ntypes and sizes, we offer insights that support the viability of our approach.\nThis not only sheds light on the adaptability of shallow feed-forward networks\nin emulating attention mechanisms but also underscores their potential to\nstreamline complex architectures for sequence-to-sequence tasks.\n","authors":["Vukasin Bozic","Danilo Dordevic","Daniele Coppola","Joseph Thommes"],"pdf_url":"https://arxiv.org/pdf/2311.10642v1.pdf","comment":"Accepted at AAAI24(https://aaai.org/aaai-conference/)"},{"id":"http://arxiv.org/abs/2311.10804v1","updated":"2023-11-17T13:07:00Z","published":"2023-11-17T13:07:00Z","title":"A Study on Altering the Latent Space of Pretrained Text to Speech Models\n  for Improved Expressiveness","summary":"  This report explores the challenge of enhancing expressiveness control in\nText-to-Speech (TTS) models by augmenting a frozen pretrained model with a\nDiffusion Model that is conditioned on joint semantic audio/text embeddings.\nThe paper identifies the challenges encountered when working with a VAE-based\nTTS model and evaluates different image-to-image methods for altering latent\nspeech features. Our results offer valuable insights into the complexities of\nadding expressiveness control to TTS systems and open avenues for future\nresearch in this direction.\n","authors":["Mathias Vogel"],"pdf_url":"https://arxiv.org/pdf/2311.10804v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10797v1","updated":"2023-11-17T06:55:32Z","published":"2023-11-17T06:55:32Z","title":"TaCo: Enhancing Cross-Lingual Transfer for Low-Resource Languages in\n  LLMs through Translation-Assisted Chain-of-Thought Processes","summary":"  LLMs such as ChatGPT and PaLM can be utilized to train on a new language and\nrevitalize low-resource languages. However, it is evidently very costly to\npretrain pr fine-tune LLMs to adopt new languages. Another challenge is the\nlimitation of benchmark datasets and the metrics used to measure the\nperformance of models in multilingual settings. This paper proposes\ncost-effective solutions to both of the aforementioned challenges. We introduce\nthe Multilingual Instruction-Tuning Dataset (MITS), which is comprised of the\ntranslation of Alpaca-52K, Dolly-15K, and Vicuna Benchmark in 132 languages.\nAlso, we propose a new method called \\emph{TaCo: Translation-Assisted\nCross-Linguality}, which make uses of translation in a chain-of-thought process\nto instruction-tune LLMs on a new languages through a curriculum learning\nprocess. As a proof of concept, we experimented with the instruction-tuned\nGuanaco-33B model and performed further instruction tuning using the TaCo\nmethod in three low-resource languages and one high-resource language. Our\nresults show that the TaCo method impresses the GPT-4 with 82% for a\nlow-resource language in the Vicuna Benchmark dataset, and boosts performance\nby double in contrast to the performance of instruction tuning only. Our\nresults show that TaCo is a promising method for creating multilingual LLMs,\neven for low-resource languages. We have released our datasets and the model\nadapters, and encourage the research community to make use of these resources\ntowards advancing work on multilingual LLMs.\n","authors":["Bibek Upadhayay","Vahid Behzadan"],"pdf_url":"https://arxiv.org/pdf/2311.10797v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2311.10709v1","updated":"2023-11-17T18:59:04Z","published":"2023-11-17T18:59:04Z","title":"Emu Video: Factorizing Text-to-Video Generation by Explicit Image\n  Conditioning","summary":"  We present Emu Video, a text-to-video generation model that factorizes the\ngeneration into two steps: first generating an image conditioned on the text,\nand then generating a video conditioned on the text and the generated image. We\nidentify critical design decisions--adjusted noise schedules for diffusion, and\nmulti-stage training--that enable us to directly generate high quality and high\nresolution videos, without requiring a deep cascade of models as in prior work.\nIn human evaluations, our generated videos are strongly preferred in quality\ncompared to all prior work--81% vs. Google's Imagen Video, 90% vs. Nvidia's\nPYOCO, and 96% vs. Meta's Make-A-Video. Our model outperforms commercial\nsolutions such as RunwayML's Gen2 and Pika Labs. Finally, our factorizing\napproach naturally lends itself to animating images based on a user's text\nprompt, where our generations are preferred 96% over prior work.\n","authors":["Rohit Girdhar","Mannat Singh","Andrew Brown","Quentin Duval","Samaneh Azadi","Sai Saketh Rambhatla","Akbar Shah","Xi Yin","Devi Parikh","Ishan Misra"],"pdf_url":"https://arxiv.org/pdf/2311.10709v1.pdf","comment":"Project page: https://emu-video.metademolab.com"},{"id":"http://arxiv.org/abs/2311.10708v1","updated":"2023-11-17T18:58:16Z","published":"2023-11-17T18:58:16Z","title":"SelfEval: Leveraging the discriminative nature of generative models for\n  evaluation","summary":"  In this work, we show that text-to-image generative models can be 'inverted'\nto assess their own text-image understanding capabilities in a completely\nautomated manner.\n  Our method, called SelfEval, uses the generative model to compute the\nlikelihood of real images given text prompts, making the generative model\ndirectly applicable to discriminative tasks.\n  Using SelfEval, we repurpose standard datasets created for evaluating\nmultimodal text-image discriminative models to evaluate generative models in a\nfine-grained manner: assessing their performance on attribute binding, color\nrecognition, counting, shape recognition, spatial understanding.\n  To the best of our knowledge SelfEval is the first automated metric to show a\nhigh degree of agreement for measuring text-faithfulness with the gold-standard\nhuman evaluations across multiple models and benchmarks.\n  Moreover, SelfEval enables us to evaluate generative models on challenging\ntasks such as Winoground image-score where they demonstrate competitive\nperformance to discriminative models.\n  We also show severe drawbacks of standard automated metrics such as\nCLIP-score to measure text faithfulness on benchmarks such as DrawBench, and\nhow SelfEval sidesteps these issues.\n  We hope SelfEval enables easy and reliable automated evaluation for diffusion\nmodels.\n","authors":["Sai Saketh Rambhatla","Ishan Misra"],"pdf_url":"https://arxiv.org/pdf/2311.10708v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10707v1","updated":"2023-11-17T18:57:40Z","published":"2023-11-17T18:57:40Z","title":"Multimodal Representation Learning by Alternating Unimodal Adaptation","summary":"  Multimodal learning, which integrates data from diverse sensory modes, plays\na pivotal role in artificial intelligence. However, existing multimodal\nlearning methods often struggle with challenges where some modalities appear\nmore dominant than others during multimodal learning, resulting in suboptimal\nperformance. To address this challenge, we propose MLA (Multimodal Learning\nwith Alternating Unimodal Adaptation). MLA reframes the conventional joint\nmultimodal learning process by transforming it into an alternating unimodal\nlearning process, thereby minimizing interference between modalities.\nSimultaneously, it captures cross-modal interactions through a shared head,\nwhich undergoes continuous optimization across different modalities. This\noptimization process is controlled by a gradient modification mechanism to\nprevent the shared head from losing previously acquired information. During the\ninference phase, MLA utilizes a test-time uncertainty-based model fusion\nmechanism to integrate multimodal information. Extensive experiments are\nconducted on five diverse datasets, encompassing scenarios with complete\nmodalities and scenarios with missing modalities. These experiments demonstrate\nthe superiority of MLA over competing prior approaches.\n","authors":["Xiaohui Zhang","Jaehong Yoon","Mohit Bansal","Huaxiu Yao"],"pdf_url":"https://arxiv.org/pdf/2311.10707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.08003v2","updated":"2023-11-17T18:47:42Z","published":"2023-07-16T11:10:35Z","title":"SHAMSUL: Systematic Holistic Analysis to investigate Medical\n  Significance Utilizing Local interpretability methods in deep learning for\n  chest radiography pathology prediction","summary":"  The interpretability of deep neural networks has become a subject of great\ninterest within the medical and healthcare domain. This attention stems from\nconcerns regarding transparency, legal and ethical considerations, and the\nmedical significance of predictions generated by these deep neural networks in\nclinical decision support systems. To address this matter, our study delves\ninto the application of four well-established interpretability methods: Local\nInterpretable Model-agnostic Explanations (LIME), Shapley Additive exPlanations\n(SHAP), Gradient-weighted Class Activation Mapping (Grad-CAM), and Layer-wise\nRelevance Propagation (LRP). Leveraging the approach of transfer learning with\na multi-label-multi-class chest radiography dataset, we aim to interpret\npredictions pertaining to specific pathology classes. Our analysis encompasses\nboth single-label and multi-label predictions, providing a comprehensive and\nunbiased assessment through quantitative and qualitative investigations, which\nare compared against human expert annotation. Notably, Grad-CAM demonstrates\nthe most favorable performance in quantitative evaluation, while the LIME\nheatmap score segmentation visualization exhibits the highest level of medical\nsignificance. Our research underscores both the outcomes and the challenges\nfaced in the holistic approach adopted for assessing these interpretability\nmethods and suggests that a multimodal-based approach, incorporating diverse\nsources of information beyond chest radiography images, could offer additional\ninsights for enhancing interpretability in the medical domain.\n","authors":["Mahbub Ul Alam","Jaakko Hollmén","Jón Rúnar Baldvinsson","Rahim Rahmani"],"pdf_url":"https://arxiv.org/pdf/2307.08003v2.pdf","comment":"This version contains extensive modifications compared to the\n  previous version. The published version of this article can be obtained using\n  the following link: https://doi.org/10.5617/nmi.10471 Code Repository:\n  https://github.com/anondo1969/SHAMSUL"},{"id":"http://arxiv.org/abs/2311.10701v1","updated":"2023-11-17T18:45:00Z","published":"2023-11-17T18:45:00Z","title":"SpACNN-LDVAE: Spatial Attention Convolutional Latent Dirichlet\n  Variational Autoencoder for Hyperspectral Pixel Unmixing","summary":"  The Hyperspectral Unxming problem is to find the pure spectral signal of the\nunderlying materials (endmembers) and their proportions (abundances). The\nproposed method builds upon the recently proposed method, Latent Dirichlet\nVariational Autoencoder (LDVAE). It assumes that abundances can be encoded as\nDirichlet Distributions while mixed pixels and endmembers are represented by\nMultivariate Normal Distributions. However, LDVAE does not leverage spatial\ninformation present in an HSI; we propose an Isotropic CNN encoder with spatial\nattention to solve the hyperspectral unmixing problem. We evaluated our model\non Samson, Hydice Urban, Cuprite, and OnTech-HSI-Syn-21 datasets. Our model\nalso leverages the transfer learning paradigm for Cuprite Dataset, where we\ntrain the model on synthetic data and evaluate it on real-world data. We are\nable to observe the improvement in the results for the endmember extraction and\nabundance estimation by incorporating the spatial information. Code can be\nfound at https://github.com/faisalqureshi/cnn-ldvae\n","authors":["Soham Chitnis","Kiran Mantripragada","Faisal Z. Qureshi"],"pdf_url":"https://arxiv.org/pdf/2311.10701v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10699v1","updated":"2023-11-17T18:43:32Z","published":"2023-11-17T18:43:32Z","title":"Using linear initialisation to improve speed of convergence and\n  fully-trained error in Autoencoders","summary":"  Good weight initialisation is an important step in successful training of\nArtificial Neural Networks. Over time a number of improvements have been\nproposed to this process. In this paper we introduce a novel weight\ninitialisation technique called the Straddled Matrix Initialiser. This\ninitialisation technique is motivated by our assumption that major,\nglobal-scale relationships in data are linear with only smaller effects\nrequiring complex non-linearities. Combination of Straddled Matrix and ReLU\nactivation function initialises a Neural Network as a de facto linear model,\nwhich we postulate should be a better starting point for optimisation given our\nassumptions. We test this by training autoencoders on three datasets using\nStraddled Matrix and seven other state-of-the-art weight initialisation\ntechniques. In all our experiments the Straddeled Matrix Initialiser clearly\noutperforms all other methods.\n","authors":["Marcel Marais","Mate Hartstein","George Cevora"],"pdf_url":"https://arxiv.org/pdf/2311.10699v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.06595v3","updated":"2023-11-17T18:39:46Z","published":"2023-08-12T15:27:51Z","title":"VisIT-Bench: A Benchmark for Vision-Language Instruction Following\n  Inspired by Real-World Use","summary":"  We introduce VisIT-Bench (Visual InsTruction Benchmark), a benchmark for\nevaluation of instruction-following vision-language models for real-world use.\nOur starting point is curating 70 'instruction families' that we envision\ninstruction tuned vision-language models should be able to address. Extending\nbeyond evaluations like VQAv2 and COCO, tasks range from basic recognition to\ngame playing and creative generation. Following curation, our dataset comprises\n592 test queries, each with a human-authored instruction-conditioned caption.\nThese descriptions surface instruction-specific factors, e.g., for an\ninstruction asking about the accessibility of a storefront for wheelchair\nusers, the instruction-conditioned caption describes ramps/potential obstacles.\nThese descriptions enable 1) collecting human-verified reference outputs for\neach instance; and 2) automatic evaluation of candidate multimodal generations\nusing a text-only LLM, aligning with human judgment. We quantify quality gaps\nbetween models and references using both human and automatic evaluations; e.g.,\nthe top-performing instruction-following model wins against the GPT-4 reference\nin just 27% of the comparison. VisIT-Bench is dynamic to participate,\npractitioners simply submit their model's response on the project website;\nData, code and leaderboard is available at visit-bench.github.io.\n","authors":["Yonatan Bitton","Hritik Bansal","Jack Hessel","Rulin Shao","Wanrong Zhu","Anas Awadalla","Josh Gardner","Rohan Taori","Ludwig Schmidt"],"pdf_url":"https://arxiv.org/pdf/2308.06595v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10696v1","updated":"2023-11-17T18:28:32Z","published":"2023-11-17T18:28:32Z","title":"Versatile Medical Image Segmentation Learned from Multi-Source Datasets\n  via Model Self-Disambiguation","summary":"  A versatile medical image segmentation model applicable to imaging data\ncollected with diverse equipment and protocols can facilitate model deployment\nand maintenance. However, building such a model typically requires a large,\ndiverse, and fully annotated dataset, which is rarely available due to the\nlabor-intensive and costly data curation. In this study, we develop a\ncost-efficient method by harnessing readily available data with partially or\neven sparsely annotated segmentation labels. We devise strategies for model\nself-disambiguation, prior knowledge incorporation, and imbalance mitigation to\naddress challenges associated with inconsistently labeled data from various\nsources, including label ambiguity and imbalances across modalities, datasets,\nand segmentation labels. Experimental results on a multi-modal dataset compiled\nfrom eight different sources for abdominal organ segmentation have demonstrated\nour method's effectiveness and superior performance over alternative\nstate-of-the-art methods, highlighting its potential for optimizing the use of\nexisting annotated data and reducing the annotation efforts for new data to\nfurther enhance model capability.\n","authors":["Xiaoyang Chen","Hao Zheng","Yuemeng Li","Yuncong Ma","Liang Ma","Hongming Li","Yong Fan"],"pdf_url":"https://arxiv.org/pdf/2311.10696v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10651v1","updated":"2023-11-17T17:13:14Z","published":"2023-11-17T17:13:14Z","title":"3D-TexSeg: Unsupervised Segmentation of 3D Texture using Mutual\n  Transformer Learning","summary":"  Analysis of the 3D Texture is indispensable for various tasks, such as\nretrieval, segmentation, classification, and inspection of sculptures, knitted\nfabrics, and biological tissues. A 3D texture is a locally repeated surface\nvariation independent of the surface's overall shape and can be determined\nusing the local neighborhood and its characteristics. Existing techniques\ntypically employ computer vision techniques that analyze a 3D mesh globally,\nderive features, and then utilize the obtained features for retrieval or\nclassification. Several traditional and learning-based methods exist in the\nliterature, however, only a few are on 3D texture, and nothing yet, to the best\nof our knowledge, on the unsupervised schemes. This paper presents an original\nframework for the unsupervised segmentation of the 3D texture on the mesh\nmanifold. We approach this problem as binary surface segmentation, partitioning\nthe mesh surface into textured and non-textured regions without prior\nannotation. We devise a mutual transformer-based system comprising a label\ngenerator and a cleaner. The two models take geometric image representations of\nthe surface mesh facets and label them as texture or non-texture across an\niterative mutual learning scheme. Extensive experiments on three publicly\navailable datasets with diverse texture patterns demonstrate that the proposed\nframework outperforms standard and SOTA unsupervised techniques and competes\nreasonably with supervised methods.\n","authors":["Iyyakutti Iyappan Ganapathi","Fayaz Ali","Sajid Javed","Syed Sadaf Ali","Naoufel Werghi"],"pdf_url":"https://arxiv.org/pdf/2311.10651v1.pdf","comment":"This paper is accepted in 3DV-2024"},{"id":"http://arxiv.org/abs/2311.00690v2","updated":"2023-11-17T17:09:56Z","published":"2023-11-01T17:45:52Z","title":"What User Behaviors Make the Differences During the Process of Visual\n  Analytics?","summary":"  The understanding of visual analytics process can benefit visualization\nresearchers from multiple aspects, including improving visual designs and\ndeveloping advanced interaction functions. However, the log files of user\nbehaviors are still hard to analyze due to the complexity of sensemaking and\nour lack of knowledge on the related user behaviors. This work presents a study\non a comprehensive data collection of user behaviors, and our analysis approach\nwith time-series classification methods. We have chosen a classical\nvisualization application, Covid-19 data analysis, with common analysis tasks\ncovering geo-spatial, time-series and multi-attributes. Our user study collects\nuser behaviors on a diverse set of visualization tasks with two comparable\nsystems, desktop and immersive visualizations. We summarize the classification\nresults with three time-series machine learning algorithms at two scales, and\nexplore the influences of behavior features. Our results reveal that user\nbehaviors can be distinguished during the process of visual analytics and there\nis a potentially strong association between the physical behaviors of users and\nthe visualization tasks they perform. We also demonstrate the usage of our\nmodels by interpreting open sessions of visual analytics, which provides an\nautomatic way to study sensemaking without tedious manual annotations.\n","authors":["Shahin Doroudian","Zekun Wu","Aidong Lu"],"pdf_url":"https://arxiv.org/pdf/2311.00690v2.pdf","comment":"The authors have decided to withdraw the paper due to identified\n  critical errors. These errors were deemed substantial enough to compromise\n  the integrity and reliability of the research findings presented in the\n  paper. As a result, the authors have chosen to retract the paper to maintain\n  academic standards and transparency in the dissemination of scientific\n  knowledge"},{"id":"http://arxiv.org/abs/2311.10648v1","updated":"2023-11-17T17:06:59Z","published":"2023-11-17T17:06:59Z","title":"Self-trained Panoptic Segmentation","summary":"  Panoptic segmentation is an important computer vision task which combines\nsemantic and instance segmentation. It plays a crucial role in domains of\nmedical image analysis, self-driving vehicles, and robotics by providing a\ncomprehensive understanding of visual environments. Traditionally, deep\nlearning panoptic segmentation models have relied on dense and accurately\nannotated training data, which is expensive and time consuming to obtain.\nRecent advancements in self-supervised learning approaches have shown great\npotential in leveraging synthetic and unlabelled data to generate pseudo-labels\nusing self-training to improve the performance of instance and semantic\nsegmentation models. The three available methods for self-supervised panoptic\nsegmentation use proposal-based transformer architectures which are\ncomputationally expensive, complicated and engineered for specific tasks. The\naim of this work is to develop a framework to perform embedding-based\nself-supervised panoptic segmentation using self-training in a\nsynthetic-to-real domain adaptation problem setting.\n","authors":["Shourya Verma"],"pdf_url":"https://arxiv.org/pdf/2311.10648v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10617v1","updated":"2023-11-17T16:14:11Z","published":"2023-11-17T16:14:11Z","title":"Astronomical Images Quality Assessment with Automated Machine Learning","summary":"  Electronically Assisted Astronomy consists in capturing deep sky images with\na digital camera coupled to a telescope to display views of celestial objects\nthat would have been invisible through direct observation. This practice\ngenerates a large quantity of data, which may then be enhanced with dedicated\nimage editing software after observation sessions. In this study, we show how\nImage Quality Assessment can be useful for automatically rating astronomical\nimages, and we also develop a dedicated model by using Automated Machine\nLearning.\n","authors":["Olivier Parisot","Pierrick Bruneau","Patrik Hitzelberger"],"pdf_url":"https://arxiv.org/pdf/2311.10617v1.pdf","comment":"8 pages, accepted at DATA2024"},{"id":"http://arxiv.org/abs/2311.10605v1","updated":"2023-11-17T16:01:06Z","published":"2023-11-17T16:01:06Z","title":"CA-Jaccard: Camera-aware Jaccard Distance for Person Re-identification","summary":"  Person re-identification (re-ID) is a challenging task that aims to learn\ndiscriminative features for person retrieval. In person re-ID, Jaccard distance\nis a widely used distance metric, especially in re-ranking and clustering\nscenarios. However, we discover that camera variation has a significant\nnegative impact on the reliability of Jaccard distance. In particular, Jaccard\ndistance calculates the distance based on the overlap of relevant neighbors.\nDue to camera variation, intra-camera samples dominate the relevant neighbors,\nwhich reduces the reliability of the neighbors by introducing intra-camera\nnegative samples and excluding inter-camera positive samples. To overcome this\nproblem, we propose a novel camera-aware Jaccard (CA-Jaccard) distance that\nleverages camera information to enhance the reliability of Jaccard distance.\nSpecifically, we introduce camera-aware k-reciprocal nearest neighbors (CKRNNs)\nto find k-reciprocal nearest neighbors on the intra-camera and inter-camera\nranking lists, which improves the reliability of relevant neighbors and\nguarantees the contribution of inter-camera samples in the overlap. Moreover,\nwe propose a camera-aware local query expansion (CLQE) to exploit camera\nvariation as a strong constraint to mine reliable samples in relevant neighbors\nand assign these samples higher weights in overlap to further improve the\nreliability. Our CA-Jaccard distance is simple yet effective and can serve as a\ngeneral distance metric for person re-ID methods with high reliability and low\ncomputational cost. Extensive experiments demonstrate the effectiveness of our\nmethod.\n","authors":["Yiyu Chen","Zheyi Fan","Zhaoru Chen","Yixuan Zhu"],"pdf_url":"https://arxiv.org/pdf/2311.10605v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10601v1","updated":"2023-11-17T15:57:32Z","published":"2023-11-17T15:57:32Z","title":"Multimodal Indoor Localization Using Crowdsourced Radio Maps","summary":"  Indoor Positioning Systems (IPS) traditionally rely on odometry and building\ninfrastructures like WiFi, often supplemented by building floor plans for\nincreased accuracy. However, the limitation of floor plans in terms of\navailability and timeliness of updates challenges their wide applicability. In\ncontrast, the proliferation of smartphones and WiFi-enabled robots has made\ncrowdsourced radio maps - databases pairing locations with their corresponding\nReceived Signal Strengths (RSS) - increasingly accessible. These radio maps not\nonly provide WiFi fingerprint-location pairs but encode movement regularities\nakin to the constraints imposed by floor plans. This work investigates the\npossibility of leveraging these radio maps as a substitute for floor plans in\nmultimodal IPS. We introduce a new framework to address the challenges of radio\nmap inaccuracies and sparse coverage. Our proposed system integrates an\nuncertainty-aware neural network model for WiFi localization and a bespoken\nBayesian fusion technique for optimal fusion. Extensive evaluations on multiple\nreal-world sites indicate a significant performance enhancement, with results\nshowing ~ 25% improvement over the best baseline\n","authors":["Zhaoguang Yi","Xiangyu Wen","Qiyue Xia","Peize Li","Francisco Zampella","Firas Alsehly","Chris Xiaoxuan Lu"],"pdf_url":"https://arxiv.org/pdf/2311.10601v1.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2310.18849v2","updated":"2023-11-17T15:53:50Z","published":"2023-10-28T23:38:30Z","title":"Deep Learning-based Compressed Domain Multimedia for Man and Machine: A\n  Taxonomy and Application to Point Cloud Classification","summary":"  In the current golden age of multimedia, human visualization is no longer the\nsingle main target, with the final consumer often being a machine which\nperforms some processing or computer vision tasks. In both cases, deep learning\nplays a undamental role in extracting features from the multimedia\nrepresentation data, usually producing a compressed representation referred to\nas latent representation. The increasing development and adoption of deep\nlearning-based solutions in a wide area of multimedia applications have opened\nan exciting new vision where a common compressed multimedia representation is\nused for both man and machine. The main benefits of this vision are two-fold:\ni) improved performance for the computer vision tasks, since the effects of\ncoding artifacts are mitigated; and ii) reduced computational complexity, since\nprior decoding is not required. This paper proposes the first taxonomy for\ndesigning compressed domain computer vision solutions driven by the\narchitecture and weights compatibility with an available spatio-temporal\ncomputer vision processor. The potential of the proposed taxonomy is\ndemonstrated for the specific case of point cloud classification by designing\nnovel compressed domain processors using the JPEG Pleno Point Cloud Coding\nstandard under development and adaptations of the PointGrid classifier.\nExperimental results show that the designed compressed domain point cloud\nclassification solutions can significantly outperform the spatial-temporal\ndomain classification benchmarks when applied to the decompressed data,\ncontaining coding artifacts, and even surpass their performance when applied to\nthe original uncompressed data.\n","authors":["Abdelrahman Seleem","André F. R. Guarda","Nuno M. M. Rodrigues","Fernando Pereira"],"pdf_url":"https://arxiv.org/pdf/2310.18849v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.15991v2","updated":"2023-11-17T15:47:35Z","published":"2023-09-27T20:12:41Z","title":"Targeted Image Data Augmentation Increases Basic Skills Captioning\n  Robustness","summary":"  Artificial neural networks typically struggle in generalizing to\nout-of-context examples. One reason for this limitation is caused by having\ndatasets that incorporate only partial information regarding the potential\ncorrelational structure of the world. In this work, we propose TIDA (Targeted\nImage-editing Data Augmentation), a targeted data augmentation method focused\non improving models' human-like abilities (e.g., gender recognition) by filling\nthe correlational structure gap using a text-to-image generative model. More\nspecifically, TIDA identifies specific skills in captions describing images\n(e.g., the presence of a specific gender in the image), changes the caption\n(e.g., \"woman\" to \"man\"), and then uses a text-to-image model to edit the image\nin order to match the novel caption (e.g., uniquely changing a woman to a man\nwhile maintaining the context identical). Based on the Flickr30K benchmark, we\nshow that, compared with the original data set, a TIDA-enhanced dataset related\nto gender, color, and counting abilities induces better performance in several\nimage captioning metrics. Furthermore, on top of relying on the classical BLEU\nmetric, we conduct a fine-grained analysis of the improvements of our models\nagainst the baseline in different ways. We compared text-to-image generative\nmodels and found different behaviors of the image captioning models in terms of\nencoding visual encoding and textual decoding.\n","authors":["Valentin Barriere","Felipe del Rio","Andres Carvallo De Ferari","Carlos Aspillaga","Eugenio Herrera-Berg","Cristian Buc Calderon"],"pdf_url":"https://arxiv.org/pdf/2309.15991v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10592v1","updated":"2023-11-17T15:46:50Z","published":"2023-11-17T15:46:50Z","title":"Détection d'objets célestes dans des images astronomiques par IA\n  explicable","summary":"  Amateur and professional astronomers can easily capture a large number of\ndeep sky images with recent smart telescopes. However, afterwards verification\nis still required to check whether the celestial objects targeted are actually\nvisible in the images produced. Depending on the magnitude of the targets, the\nobservation conditions and the time during which the data is captured, it is\npossible that only stars are present in the images. In this study, we propose\nan approach based on explainable Artificial Intelligence to automatically\ndetect the presence and position of captured objects. -- --\n  Gr\\^ace \\`a l'apport des t\\'elescopes automatis\\'es grand public, les\nastronomes amateurs et professionnels peuvent capturer facilement une grande\nquantit\\'e d'images du ciel profond (comme par exemple les galaxies,\nn\\'ebuleuses, ou amas globulaires). N\\'eanmoins, une v\\'erification reste\nn\\'ecessaire \\`a post\\'eriori pour v\\'erifier si les objets c\\'elestes vis\\'es\nsont effectivement visibles dans les images produites: cela d\\'epend notamment\nde la magnitude des cibles, des conditions d'observation mais aussi de la\ndur\\'ee pendant laquelle les donn\\'ees sont captur\\'ees. Dans cette \\'etude,\nnous proposons une approche bas\\'ee sur l'IA explicable pour d\\'etecter\nautomatiquement la pr\\'esence et la position des objets captur\\'es.\n","authors":["Olivier Parisot","Mahmoud Jaziri"],"pdf_url":"https://arxiv.org/pdf/2311.10592v1.pdf","comment":"9 pages, in French, accepted in short version for EGC2024 (24\\`eme\n  conf\\'erence francophone sur l'Extraction et la Gestion des Connaissances)"},{"id":"http://arxiv.org/abs/2311.10591v1","updated":"2023-11-17T15:46:09Z","published":"2023-11-17T15:46:09Z","title":"FOCAL: A Cost-Aware Video Dataset for Active Learning","summary":"  In this paper, we introduce the FOCAL (Ford-OLIVES Collaboration on Active\nLearning) dataset which enables the study of the impact of annotation-cost\nwithin a video active learning setting. Annotation-cost refers to the time it\ntakes an annotator to label and quality-assure a given video sequence. A\npractical motivation for active learning research is to minimize\nannotation-cost by selectively labeling informative samples that will maximize\nperformance within a given budget constraint. However, previous work in video\nactive learning lacks real-time annotation labels for accurately assessing cost\nminimization and instead operates under the assumption that annotation-cost\nscales linearly with the amount of data to annotate. This assumption does not\ntake into account a variety of real-world confounding factors that contribute\nto a nonlinear cost such as the effect of an assistive labeling tool and the\nvariety of interactions within a scene such as occluded objects, weather, and\nmotion of objects. FOCAL addresses this discrepancy by providing real\nannotation-cost labels for 126 video sequences across 69 unique city scenes\nwith a variety of weather, lighting, and seasonal conditions. We also introduce\na set of conformal active learning algorithms that take advantage of the\nsequential structure of video data in order to achieve a better trade-off\nbetween annotation-cost and performance while also reducing floating point\noperations (FLOPS) overhead by at least 77.67%. We show how these approaches\nbetter reflect how annotations on videos are done in practice through a\nsequence selection framework. We further demonstrate the advantage of these\napproaches by introducing two performance-cost metrics and show that the best\nconformal active learning method is cheaper than the best traditional active\nlearning method by 113 hours.\n","authors":["Kiran Kokilepersaud","Yash-Yee Logan","Ryan Benkert","Chen Zhou","Mohit Prabhushankar","Ghassan AlRegib","Enrique Corona","Kunjan Singh","Mostafa Parchami"],"pdf_url":"https://arxiv.org/pdf/2311.10591v1.pdf","comment":"This paper was accepted as a main conference paper at the IEEE\n  International Conference on Big Data"},{"id":"http://arxiv.org/abs/2311.10582v1","updated":"2023-11-17T15:32:21Z","published":"2023-11-17T15:32:21Z","title":"Human motion trajectory prediction using the Social Force Model for\n  real-time and low computational cost applications","summary":"  Human motion trajectory prediction is a very important functionality for\nhuman-robot collaboration, specifically in accompanying, guiding, or\napproaching tasks, but also in social robotics, self-driving vehicles, or\nsecurity systems. In this paper, a novel trajectory prediction model, Social\nForce Generative Adversarial Network (SoFGAN), is proposed. SoFGAN uses a\nGenerative Adversarial Network (GAN) and Social Force Model (SFM) to generate\ndifferent plausible people trajectories reducing collisions in a scene.\nFurthermore, a Conditional Variational Autoencoder (CVAE) module is added to\nemphasize the destination learning. We show that our method is more accurate in\nmaking predictions in UCY or BIWI datasets than most of the current\nstate-of-the-art models and also reduces collisions in comparison to other\napproaches. Through real-life experiments, we demonstrate that the model can be\nused in real-time without GPU's to perform good quality predictions with a low\ncomputational cost.\n","authors":["Oscar Gil","Alberto Sanfeliu"],"pdf_url":"https://arxiv.org/pdf/2311.10582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10572v1","updated":"2023-11-17T15:14:40Z","published":"2023-11-17T15:14:40Z","title":"SSB: Simple but Strong Baseline for Boosting Performance of Open-Set\n  Semi-Supervised Learning","summary":"  Semi-supervised learning (SSL) methods effectively leverage unlabeled data to\nimprove model generalization. However, SSL models often underperform in\nopen-set scenarios, where unlabeled data contain outliers from novel categories\nthat do not appear in the labeled set. In this paper, we study the challenging\nand realistic open-set SSL setting, where the goal is to both correctly\nclassify inliers and to detect outliers. Intuitively, the inlier classifier\nshould be trained on inlier data only. However, we find that inlier\nclassification performance can be largely improved by incorporating\nhigh-confidence pseudo-labeled data, regardless of whether they are inliers or\noutliers. Also, we propose to utilize non-linear transformations to separate\nthe features used for inlier classification and outlier detection in the\nmulti-task learning framework, preventing adverse effects between them.\nAdditionally, we introduce pseudo-negative mining, which further boosts outlier\ndetection performance. The three ingredients lead to what we call Simple but\nStrong Baseline (SSB) for open-set SSL. In experiments, SSB greatly improves\nboth inlier classification and outlier detection performance, outperforming\nexisting methods by a large margin. Our code will be released at\nhttps://github.com/YUE-FAN/SSB.\n","authors":["Yue Fan","Anna Kukleva","Dengxin Dai","Bernt Schiele"],"pdf_url":"https://arxiv.org/pdf/2311.10572v1.pdf","comment":"Paper accepted in ICCV 2023"},{"id":"http://arxiv.org/abs/2311.10568v1","updated":"2023-11-17T15:08:15Z","published":"2023-11-17T15:08:15Z","title":"Phase Guided Light Field for Spatial-Depth High Resolution 3D Imaging","summary":"  On 3D imaging, light field cameras typically are of single shot, and however,\nthey heavily suffer from low spatial resolution and depth accuracy. In this\npaper, by employing an optical projector to project a group of single\nhigh-frequency phase-shifted sinusoid patterns, we propose a phase guided light\nfield algorithm to significantly improve both the spatial and depth resolutions\nfor off-the-shelf light field cameras. First, for correcting the axial\naberrations caused by the main lens of our light field camera, we propose a\ndeformed cone model to calibrate our structured light field system. Second,\nover wrapped phases computed from patterned images, we propose a stereo\nmatching algorithm, i.e. phase guided sum of absolute difference, to robustly\nobtain the correspondence for each pair of neighbored two lenslets. Finally, by\nintroducing a virtual camera according to the basic geometrical optics of light\nfield imaging, we propose a reorganization strategy to reconstruct 3D point\nclouds with spatial-depth high resolution. Experimental results show that,\ncompared with the state-of-the-art active light field methods, the proposed\nreconstructs 3D point clouds with a spatial resolution of 1280$\\times$720 with\nfactors 10$\\times$ increased, while maintaining the same high depth resolution\nand needing merely a single group of high-frequency patterns.\n","authors":["Geyou Zhang","Ce Zhu","Kai Liu","Yipeng Liu"],"pdf_url":"https://arxiv.org/pdf/2311.10568v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10549v1","updated":"2023-11-17T14:24:12Z","published":"2023-11-17T14:24:12Z","title":"Archtree: on-the-fly tree-structured exploration for latency-aware\n  pruning of deep neural networks","summary":"  Deep neural networks (DNNs) have become ubiquitous in addressing a number of\nproblems, particularly in computer vision. However, DNN inference is\ncomputationally intensive, which can be prohibitive e.g. when considering edge\ndevices. To solve this problem, a popular solution is DNN pruning, and more so\nstructured pruning, where coherent computational blocks (e.g. channels for\nconvolutional networks) are removed: as an exhaustive search of the space of\npruned sub-models is intractable in practice, channels are typically removed\niteratively based on an importance estimation heuristic. Recently, promising\nlatency-aware pruning methods were proposed, where channels are removed until\nthe network reaches a target budget of wall-clock latency pre-emptively\nestimated on specific hardware. In this paper, we present Archtree, a novel\nmethod for latency-driven structured pruning of DNNs. Archtree explores\nmultiple candidate pruned sub-models in parallel in a tree-like fashion,\nallowing for a better exploration of the search space. Furthermore, it involves\non-the-fly latency estimation on the target hardware, accounting for closer\nlatencies as compared to the specified budget. Empirical results on several DNN\narchitectures and target hardware show that Archtree better preserves the\noriginal model accuracy while better fitting the latency budget as compared to\nexisting state-of-the-art methods.\n","authors":["Rémi Ouazan Reboul","Edouard Yvinec","Arnaud Dapogny","Kevin Bailly"],"pdf_url":"https://arxiv.org/pdf/2311.10549v1.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.10543v1","updated":"2023-11-17T14:10:55Z","published":"2023-11-17T14:10:55Z","title":"Joint covariance property under geometric image transformations for\n  spatio-temporal receptive fields according to generalized Gaussian model for\n  receptive fields","summary":"  The influence of natural image transformations on receptive field responses\nis crucial for modelling visual operations in computer vision and biological\nvision. In this regard, covariance properties with respect to geometric image\ntransformations in the earliest layers of the visual hierarchy are essential\nfor expressing robust image operations and for formulating invariant visual\noperations at higher levels. This paper defines and proves a joint covariance\nproperty under compositions of spatial scaling transformations, spatial affine\ntransformations, Galilean transformations and temporal scaling transformations,\nwhich makes it possible to characterize how different types of image\ntransformations interact with each other. Specifically, the derived relations\nshow the receptive field parameters need to be transformed, in order to match\nthe output from spatio-temporal receptive fields with the underlying\nspatio-temporal image transformations.\n","authors":["Tony Lindeberg"],"pdf_url":"https://arxiv.org/pdf/2311.10543v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2311.09178v2","updated":"2023-11-17T14:02:35Z","published":"2023-11-15T18:15:30Z","title":"RBPGAN: Recurrent Back-Projection GAN for Video Super Resolution","summary":"  Recently, video super resolution (VSR) has become a very impactful task in\nthe area of Computer Vision due to its various applications. In this paper, we\npropose Recurrent Back-Projection Generative Adversarial Network (RBPGAN) for\nVSR in an attempt to generate temporally coherent solutions while preserving\nspatial details. RBPGAN integrates two state-of-the-art models to get the best\nin both worlds without compromising the accuracy of produced video. The\ngenerator of the model is inspired by RBPN system, while the discriminator is\ninspired by TecoGAN. We also utilize Ping-Pong loss to increase temporal\nconsistency over time. Our contribution together results in a model that\noutperforms earlier work in terms of temporally consistent details, as we will\ndemonstrate qualitatively and quantitatively using different datasets.\n","authors":["Israa Fahmy","Marwah Sulaiman","Zahraa Shehabeldin","Mohammed Barakat","Dareen Hussein","Mohammed El-Naggar","Hesham Eraqi","Moustafa Youssef"],"pdf_url":"https://arxiv.org/pdf/2311.09178v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10529v1","updated":"2023-11-17T13:49:00Z","published":"2023-11-17T13:49:00Z","title":"Segment Anything Model with Uncertainty Rectification for Auto-Prompting\n  Medical Image Segmentation","summary":"  The introduction of the Segment Anything Model (SAM) has marked a significant\nadvancement in prompt-driven image segmentation. However, SAM's application to\nmedical image segmentation requires manual prompting of target structures to\nobtain acceptable performance, which is still labor-intensive. Despite attempts\nof auto-prompting to turn SAM into a fully automatic manner, it still exhibits\nsubpar performance and lacks of reliability in the field of medical imaging. In\nthis paper, we propose UR-SAM, an uncertainty rectified SAM framework to\nenhance the robustness and reliability for auto-prompting medical image\nsegmentation. Our method incorporates a prompt augmentation module to estimate\nthe distribution of predictions and generate uncertainty maps, and an\nuncertainty-based rectification module to further enhance the performance of\nSAM. Extensive experiments on two public 3D medical datasets covering the\nsegmentation of 35 organs demonstrate that without supplementary training or\nfine-tuning, our method further improves the segmentation performance with up\nto 10.7 % and 13.8 % in dice similarity coefficient, demonstrating efficiency\nand broad capabilities for medical image segmentation without manual prompting.\n","authors":["Yichi Zhang","Shiyao Hu","Chen Jiang","Yuan Cheng","Yuan Qi"],"pdf_url":"https://arxiv.org/pdf/2311.10529v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10523v1","updated":"2023-11-17T13:44:51Z","published":"2023-11-17T13:44:51Z","title":"Removing Adverse Volumetric Effects From Trained Neural Radiance Fields","summary":"  While the use of neural radiance fields (NeRFs) in different challenging\nsettings has been explored, only very recently have there been any\ncontributions that focus on the use of NeRF in foggy environments. We argue\nthat the traditional NeRF models are able to replicate scenes filled with fog\nand propose a method to remove the fog when synthesizing novel views. By\ncalculating the global contrast of a scene, we can estimate a density threshold\nthat, when applied, removes all visible fog. This makes it possible to use NeRF\nas a way of rendering clear views of objects of interest located in fog-filled\nenvironments. Additionally, to benchmark performance on such scenes, we\nintroduce a new dataset that expands some of the original synthetic NeRF scenes\nthrough the addition of fog and natural environments. The code, dataset, and\nvideo results can be found on our project page: https://vegardskui.com/fognerf/\n","authors":["Andreas L. Teigen","Mauhing Yip","Victor P. Hamran","Vegard Skui","Annette Stahl","Rudolf Mester"],"pdf_url":"https://arxiv.org/pdf/2311.10523v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2311.10522v1","updated":"2023-11-17T13:43:43Z","published":"2023-11-17T13:43:43Z","title":"Enhancing Object Coherence in Layout-to-Image Synthesis","summary":"  Layout-to-image synthesis is an emerging technique in conditional image\ngeneration. It aims to generate complex scenes, where users require fine\ncontrol over the layout of the objects in a scene. However, it remains\nchallenging to control the object coherence, including semantic coherence\n(e.g., the cat looks at the flowers or not) and physical coherence (e.g., the\nhand and the racket should not be misaligned). In this paper, we propose a\nnovel diffusion model with effective global semantic fusion (GSF) and\nself-similarity feature enhancement modules to guide the object coherence for\nthis task. For semantic coherence, we argue that the image caption contains\nrich information for defining the semantic relationship within the objects in\nthe images. Instead of simply employing cross-attention between captions and\ngenerated images, which addresses the highly relevant layout restriction and\nsemantic coherence separately and thus leads to unsatisfying results shown in\nour experiments, we develop GSF to fuse the supervision from the layout\nrestriction and semantic coherence requirement and exploit it to guide the\nimage synthesis process. Moreover, to improve the physical coherence, we\ndevelop a Self-similarity Coherence Attention (SCA) module to explicitly\nintegrate local contextual physical coherence into each pixel's generation\nprocess. Specifically, we adopt a self-similarity map to encode the coherence\nrestrictions and employ it to extract coherent features from text embedding.\nThrough visualization of our self-similarity map, we explore the essence of\nSCA, revealing that its effectiveness is not only in capturing reliable\nphysical coherence patterns but also in enhancing complex texture generation.\nExtensive experiments demonstrate the superiority of our proposed method in\nboth image generation quality and controllability.\n","authors":["Yibin Wang","Weizhong Zhang","Jianwei Zheng","Cheng Jin"],"pdf_url":"https://arxiv.org/pdf/2311.10522v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10517v1","updated":"2023-11-17T13:40:10Z","published":"2023-11-17T13:40:10Z","title":"Mind the map! Accounting for existing map information when estimating\n  online HDMaps from sensor data","summary":"  Online High Definition Map (HDMap) estimation from sensors offers a low-cost\nalternative to manually acquired HDMaps. As such, it promises to lighten costs\nfor already HDMap-reliant Autonomous Driving systems, and potentially even\nspread their use to new systems. In this paper, we propose to improve online\nHDMap estimation by accounting for already existing maps. We identify 3\nreasonable types of useful existing maps (minimalist, noisy, and outdated). We\nalso introduce MapEX, a novel online HDMap estimation framework that accounts\nfor existing maps. MapEX achieves this by encoding map elements into query\ntokens and by refining the matching algorithm used to train classic query based\nmap estimation models. We demonstrate that MapEX brings significant\nimprovements on the nuScenes dataset. For instance, MapEX - given noisy maps -\nimproves by 38% over the MapTRv2 detector it is based on and by 16% over the\ncurrent SOTA.\n","authors":["Rémy Sun","Li Yang","Diane Lingrand","Frédéric Precioso"],"pdf_url":"https://arxiv.org/pdf/2311.10517v1.pdf","comment":"12 pages, 4 figures, 7 tables"},{"id":"http://arxiv.org/abs/2311.10513v1","updated":"2023-11-17T13:34:58Z","published":"2023-11-17T13:34:58Z","title":"A Framework of Landsat-8 Band Selection based on UMDA for Deforestation\n  Detection","summary":"  The conservation of tropical forests is a current subject of social and\necological relevance due to their crucial role in the global ecosystem.\nUnfortunately, millions of hectares are deforested and degraded each year.\nTherefore, government or private initiatives are needed for monitoring tropical\nforests. In this sense, this work proposes a novel framework, which uses of\ndistribution estimation algorithm (UMDA) to select spectral bands from\nLandsat-8 that yield a better representation of deforestation areas to guide a\nsemantic segmentation architecture called DeepLabv3+. In performed experiments,\nit was possible to find several compositions that reach balanced accuracy\nsuperior to 90% in segment classification tasks. Furthermore, the best\ncomposition (651) found by UMDA algorithm fed the DeepLabv3+ architecture and\nsurpassed in efficiency and effectiveness all compositions compared in this\nwork.\n","authors":["Eduardo B. Neto","Paulo R. C. Pedro","Alvaro Fazenda","Fabio A. Faria"],"pdf_url":"https://arxiv.org/pdf/2311.10513v1.pdf","comment":"in Portuguese language. Best Paper Award at the Workshop of\n  Undergraduate Works (WUW), SIBGRAPI 2023"},{"id":"http://arxiv.org/abs/2306.08984v3","updated":"2023-11-17T13:14:58Z","published":"2023-06-15T09:25:04Z","title":"Tree Variational Autoencoders","summary":"  We propose Tree Variational Autoencoder (TreeVAE), a new generative\nhierarchical clustering model that learns a flexible tree-based posterior\ndistribution over latent variables. TreeVAE hierarchically divides samples\naccording to their intrinsic characteristics, shedding light on hidden\nstructures in the data. It adapts its architecture to discover the optimal tree\nfor encoding dependencies between latent variables. The proposed tree-based\ngenerative architecture enables lightweight conditional inference and improves\ngenerative performance by utilizing specialized leaf decoders. We show that\nTreeVAE uncovers underlying clusters in the data and finds meaningful\nhierarchical relations between the different groups on a variety of datasets,\nincluding real-world imaging data. We present empirically that TreeVAE provides\na more competitive log-likelihood lower bound than the sequential counterparts.\nFinally, due to its generative nature, TreeVAE is able to generate new samples\nfrom the discovered clusters via conditional sampling.\n","authors":["Laura Manduchi","Moritz Vandenhirtz","Alain Ryser","Julia Vogt"],"pdf_url":"https://arxiv.org/pdf/2306.08984v3.pdf","comment":"Accepted as Spotlight to NeurIPS 2023"},{"id":"http://arxiv.org/abs/2303.01913v2","updated":"2023-11-17T12:47:26Z","published":"2023-03-03T13:27:00Z","title":"Bespoke: A Block-Level Neural Network Optimization Framework for\n  Low-Cost Deployment","summary":"  As deep learning models become popular, there is a lot of need for deploying\nthem to diverse device environments. Because it is costly to develop and\noptimize a neural network for every single environment, there is a line of\nresearch to search neural networks for multiple target environments\nefficiently. However, existing works for such a situation still suffer from\nrequiring many GPUs and expensive costs. Motivated by this, we propose a novel\nneural network optimization framework named Bespoke for low-cost deployment.\nOur framework searches for a lightweight model by replacing parts of an\noriginal model with randomly selected alternatives, each of which comes from a\npretrained neural network or the original model. In the practical sense,\nBespoke has two significant merits. One is that it requires near zero cost for\ndesigning the search space of neural networks. The other merit is that it\nexploits the sub-networks of public pretrained neural networks, so the total\ncost is minimal compared to the existing works. We conduct experiments\nexploring Bespoke's the merits, and the results show that it finds efficient\nmodels for multiple targets with meager cost.\n","authors":["Jong-Ryul Lee","Yong-Hyuk Moon"],"pdf_url":"https://arxiv.org/pdf/2303.01913v2.pdf","comment":"This is the extended version of our AAAI-2023 paper\n  (https://ojs.aaai.org/index.php/AAAI/article/view/26020)"},{"id":"http://arxiv.org/abs/2311.10492v1","updated":"2023-11-17T12:45:30Z","published":"2023-11-17T12:45:30Z","title":"A Relay System for Semantic Image Transmission based on Shared Feature\n  Extraction and Hyperprior Entropy Compression","summary":"  Nowadays, the need for high-quality image reconstruction and restoration is\nmore and more urgent. However, most image transmission systems may suffer from\nimage quality degradation or transmission interruption in the face of\ninterference such as channel noise and link fading. To solve this problem, a\nrelay communication network for semantic image transmission based on shared\nfeature extraction and hyperprior entropy compression (HEC) is proposed, where\nthe shared feature extraction technology based on Pearson correlation is\nproposed to eliminate partial shared feature of extracted semantic latent\nfeature. In addition, the HEC technology is used to resist the effect of\nchannel noise and link fading and carried out respectively at the source node\nand the relay node. Experimental results demonstrate that compared with other\nrecent research methods, the proposed system has lower transmission overhead\nand higher semantic image transmission performance. Particularly, under the\nsame conditions, the multi-scale structural similarity (MS-SSIM) of this system\nis superior to the comparison method by approximately 0.2.\n","authors":["Wannian An","Zhicheng Bao","Haotai Liang","Chen Dong"," Xiaodong"],"pdf_url":"https://arxiv.org/pdf/2311.10492v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.07945v4","updated":"2023-11-17T12:43:46Z","published":"2023-03-14T14:35:59Z","title":"Edit-A-Video: Single Video Editing with Object-Aware Consistency","summary":"  Despite the fact that text-to-video (TTV) model has recently achieved\nremarkable success, there have been few approaches on TTV for its extension to\nvideo editing. Motivated by approaches on TTV models adapting from\ndiffusion-based text-to-image (TTI) models, we suggest the video editing\nframework given only a pretrained TTI model and a single <text, video> pair,\nwhich we term Edit-A-Video. The framework consists of two stages: (1) inflating\nthe 2D model into the 3D model by appending temporal modules and tuning on the\nsource video (2) inverting the source video into the noise and editing with\ntarget text prompt and attention map injection. Each stage enables the temporal\nmodeling and preservation of semantic attributes of the source video. One of\nthe key challenges for video editing include a background inconsistency\nproblem, where the regions not included for the edit suffer from undesirable\nand inconsistent temporal alterations. To mitigate this issue, we also\nintroduce a novel mask blending method, termed as sparse-causal blending (SC\nBlending). We improve previous mask blending methods to reflect the temporal\nconsistency so that the area where the editing is applied exhibits smooth\ntransition while also achieving spatio-temporal consistency of the unedited\nregions. We present extensive experimental results over various types of text\nand videos, and demonstrate the superiority of the proposed method compared to\nbaselines in terms of background consistency, text alignment, and video editing\nquality.\n","authors":["Chaehun Shin","Heeseung Kim","Che Hyun Lee","Sang-gil Lee","Sungroh Yoon"],"pdf_url":"https://arxiv.org/pdf/2303.07945v4.pdf","comment":"ACML 2023 Best Paper Award"},{"id":"http://arxiv.org/abs/2303.17245v3","updated":"2023-11-17T12:43:09Z","published":"2023-03-30T09:22:17Z","title":"Investigating and Mitigating the Side Effects of Noisy Views for\n  Self-Supervised Clustering Algorithms in Practical Multi-View Scenarios","summary":"  Multi-view clustering (MVC) aims at exploring category structures among\nmulti-view data in self-supervised manners. Multiple views provide more\ninformation than single views and thus existing MVC methods can achieve\nsatisfactory performance. However, their performance might seriously degenerate\nwhen the views are noisy in practical multi-view scenarios. In this paper, we\nfirst formally investigate the drawback of noisy views and then propose a\ntheoretically grounded deep MVC method (namely MVCAN) to address this issue.\nSpecifically, we propose a novel MVC objective that enables un-shared\nparameters and inconsistent clustering predictions across multiple views to\nreduce the side effects of noisy views. Furthermore, a two-level multi-view\niterative optimization is designed to generate robust learning targets for\nrefining individual views' representation learning. Theoretical analysis\nreveals that MVCAN works by achieving the multi-view consistency,\ncomplementarity, and noise robustness. Finally, experiments on extensive public\ndatasets demonstrate that MVCAN outperforms state-of-the-art methods and is\nrobust against the existence of noisy views.\n","authors":["Jie Xu","Yazhou Ren","Xiaolong Wang","Lei Feng","Zheng Zhang","Gang Niu","Xiaofeng Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.17245v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10476v1","updated":"2023-11-17T12:15:40Z","published":"2023-11-17T12:15:40Z","title":"FRCSyn Challenge at WACV 2024:Face Recognition Challenge in the Era of\n  Synthetic Data","summary":"  Despite the widespread adoption of face recognition technology around the\nworld, and its remarkable performance on current benchmarks, there are still\nseveral challenges that must be covered in more detail. This paper offers an\noverview of the Face Recognition Challenge in the Era of Synthetic Data\n(FRCSyn) organized at WACV 2024. This is the first international challenge\naiming to explore the use of synthetic data in face recognition to address\nexisting limitations in the technology. Specifically, the FRCSyn Challenge\ntargets concerns related to data privacy issues, demographic biases,\ngeneralization to unseen scenarios, and performance limitations in challenging\nscenarios, including significant age disparities between enrollment and\ntesting, pose variations, and occlusions. The results achieved in the FRCSyn\nChallenge, together with the proposed benchmark, contribute significantly to\nthe application of synthetic data to improve face recognition technology.\n","authors":["Pietro Melzi","Ruben Tolosana","Ruben Vera-Rodriguez","Minchul Kim","Christian Rathgeb","Xiaoming Liu","Ivan DeAndres-Tame","Aythami Morales","Julian Fierrez","Javier Ortega-Garcia","Weisong Zhao","Xiangyu Zhu","Zheyu Yan","Xiao-Yu Zhang","Jinlin Wu","Zhen Lei","Suvidha Tripathi","Mahak Kothari","Md Haider Zama","Debayan Deb","Bernardo Biesseck","Pedro Vidal","Roger Granada","Guilherme Fickel","Gustavo Führ","David Menotti","Alexander Unnervik","Anjith George","Christophe Ecabert","Hatef Otroshi Shahreza","Parsa Rahimi","Sébastien Marcel","Ioannis Sarridis","Christos Koutlis","Georgia Baltsou","Symeon Papadopoulos","Christos Diou","Nicolò Di Domenico","Guido Borghi","Lorenzo Pellegrini","Enrique Mas-Candela","Ángela Sánchez-Pérez","Andrea Atzori","Fadi Boutros","Naser Damer","Gianni Fenu","Mirko Marras"],"pdf_url":"https://arxiv.org/pdf/2311.10476v1.pdf","comment":"10 pages, 1 figure, WACV 2024 Workshops"},{"id":"http://arxiv.org/abs/2311.10472v1","updated":"2023-11-17T11:56:53Z","published":"2023-11-17T11:56:53Z","title":"End-to-end autoencoding architecture for the simultaneous generation of\n  medical images and corresponding segmentation masks","summary":"  Despite the increasing use of deep learning in medical image segmentation,\nacquiring sufficient training data remains a challenge in the medical field. In\nresponse, data augmentation techniques have been proposed; however, the\ngeneration of diverse and realistic medical images and their corresponding\nmasks remains a difficult task, especially when working with insufficient\ntraining sets. To address these limitations, we present an end-to-end\narchitecture based on the Hamiltonian Variational Autoencoder (HVAE). This\napproach yields an improved posterior distribution approximation compared to\ntraditional Variational Autoencoders (VAE), resulting in higher image\ngeneration quality. Our method outperforms generative adversarial architectures\nunder data-scarce conditions, showcasing enhancements in image quality and\nprecise tumor mask synthesis. We conduct experiments on two publicly available\ndatasets, MICCAI's Brain Tumor Segmentation Challenge (BRATS), and Head and\nNeck Tumor Segmentation Challenge (HECKTOR), demonstrating the effectiveness of\nour method on different medical imaging modalities.\n","authors":["Aghiles Kebaili","Jérôme Lapuyade-Lahorgue","Pierre Vera","Su Ruan"],"pdf_url":"https://arxiv.org/pdf/2311.10472v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10463v1","updated":"2023-11-17T11:34:01Z","published":"2023-11-17T11:34:01Z","title":"Correlation-Distance Graph Learning for Treatment Response Prediction\n  from rs-fMRI","summary":"  Resting-state fMRI (rs-fMRI) functional connectivity (FC) analysis provides\nvaluable insights into the relationships between different brain regions and\ntheir potential implications for neurological or psychiatric disorders.\nHowever, specific design efforts to predict treatment response from rs-fMRI\nremain limited due to difficulties in understanding the current brain state and\nthe underlying mechanisms driving the observed patterns, which limited the\nclinical application of rs-fMRI. To overcome that, we propose a graph learning\nframework that captures comprehensive features by integrating both correlation\nand distance-based similarity measures under a contrastive loss. This approach\nresults in a more expressive framework that captures brain dynamic features at\ndifferent scales and enables more accurate prediction of treatment response.\nOur experiments on the chronic pain and depersonalization disorder datasets\ndemonstrate that our proposed method outperforms current methods in different\nscenarios. To the best of our knowledge, we are the first to explore the\nintegration of distance-based and correlation-based neural similarity into\ngraph learning for treatment response prediction.\n","authors":["Xiatian Zhang","Sisi Zheng","Hubert P. H. Shum","Haozheng Zhang","Nan Song","Mingkang Song","Hongxiao Jia"],"pdf_url":"https://arxiv.org/pdf/2311.10463v1.pdf","comment":"Proceedings of the 2023 International Conference on Neural\n  Information Processing (ICONIP)"},{"id":"http://arxiv.org/abs/2307.07482v2","updated":"2023-11-17T11:30:33Z","published":"2023-07-14T17:06:49Z","title":"Dual-Query Multiple Instance Learning for Dynamic Meta-Embedding based\n  Tumor Classification","summary":"  Whole slide image (WSI) assessment is a challenging and crucial step in\ncancer diagnosis and treatment planning. WSIs require high magnifications to\nfacilitate sub-cellular analysis. Precise annotations for patch- or even\npixel-level classifications in the context of gigapixel WSIs are tedious to\nacquire and require domain experts. Coarse-grained labels, on the other hand,\nare easily accessible, which makes WSI classification an ideal use case for\nmultiple instance learning (MIL). In our work, we propose a novel\nembedding-based Dual-Query MIL pipeline (DQ-MIL). We contribute to both the\nembedding and aggregation steps. Since all-purpose visual feature\nrepresentations are not yet available, embedding models are currently limited\nin terms of generalizability. With our work, we explore the potential of\ndynamic meta-embedding based on cutting-edge self-supervised pre-trained models\nin the context of MIL. Moreover, we propose a new MIL architecture capable of\ncombining MIL-attention with correlated self-attention. The Dual-Query\nPerceiver design of our approach allows us to leverage the concept of\nself-distillation and to combine the advantages of a small model in the context\nof a low data regime with the rich feature representation of a larger model. We\ndemonstrate the superior performance of our approach on three histopathological\ndatasets, where we show improvement of up to 10% over state-of-the-art\napproaches.\n","authors":["Simon Holdenried-Krafft","Peter Somers","Ivonne A. Montes-Majarro","Diana Silimon","Cristina Tarín","Falko Fend","Hendrik P. A. Lensch"],"pdf_url":"https://arxiv.org/pdf/2307.07482v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10448v1","updated":"2023-11-17T11:03:13Z","published":"2023-11-17T11:03:13Z","title":"DeepClean: Machine Unlearning on the Cheap by Resetting Privacy\n  Sensitive Weights using the Fisher Diagonal","summary":"  Machine learning models trained on sensitive or private data can\ninadvertently memorize and leak that information. Machine unlearning seeks to\nretroactively remove such details from model weights to protect privacy. We\ncontribute a lightweight unlearning algorithm that leverages the Fisher\nInformation Matrix (FIM) for selective forgetting. Prior work in this area\nrequires full retraining or large matrix inversions, which are computationally\nexpensive. Our key insight is that the diagonal elements of the FIM, which\nmeasure the sensitivity of log-likelihood to changes in weights, contain\nsufficient information for effective forgetting. Specifically, we compute the\nFIM diagonal over two subsets -- the data to retain and forget -- for all\ntrainable weights. This diagonal representation approximates the complete FIM\nwhile dramatically reducing computation. We then use it to selectively update\nweights to maximize forgetting of the sensitive subset while minimizing impact\non the retained subset. Experiments show that our algorithm can successfully\nforget any randomly selected subsets of training data across neural network\narchitectures. By leveraging the FIM diagonal, our approach provides an\ninterpretable, lightweight, and efficient solution for machine unlearning with\npractical privacy benefits.\n","authors":["Jiaeli Shi","Najah Ghalyan","Kostis Gourgoulias","John Buford","Sean Moran"],"pdf_url":"https://arxiv.org/pdf/2311.10448v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10437v1","updated":"2023-11-17T10:26:26Z","published":"2023-11-17T10:26:26Z","title":"DUA-DA: Distillation-based Unbiased Alignment for Domain Adaptive Object\n  Detection","summary":"  Though feature-alignment based Domain Adaptive Object Detection (DAOD) have\nachieved remarkable progress, they ignore the source bias issue, i.e. the\naligned features are more favorable towards the source domain, leading to a\nsub-optimal adaptation. Furthermore, the presence of domain shift between the\nsource and target domains exacerbates the problem of inconsistent\nclassification and localization in general detection pipelines. To overcome\nthese challenges, we propose a novel Distillation-based Unbiased Alignment\n(DUA) framework for DAOD, which can distill the source features towards a more\nbalanced position via a pre-trained teacher model during the training process,\nalleviating the problem of source bias effectively. In addition, we design a\nTarget-Relevant Object Localization Network (TROLN), which can mine\ntarget-related knowledge to produce two classification-free metrics (IoU and\ncenterness). Accordingly, we implement a Domain-aware Consistency Enhancing\n(DCE) strategy that utilizes these two metrics to further refine classification\nconfidences, achieving a harmonization between classification and localization\nin cross-domain scenarios. Extensive experiments have been conducted to\nmanifest the effectiveness of this method, which consistently improves the\nstrong baseline by large margins, outperforming existing alignment-based works.\n","authors":["Yongchao Feng","Shiwei Li","Yingjie Gao","Ziyue Huang","Yanan Zhang","Qingjie Liu","Yunhong Wang"],"pdf_url":"https://arxiv.org/pdf/2311.10437v1.pdf","comment":"10pages,5 figures"},{"id":"http://arxiv.org/abs/2311.10430v1","updated":"2023-11-17T10:05:10Z","published":"2023-11-17T10:05:10Z","title":"Deep Residual CNN for Multi-Class Chest Infection Diagnosis","summary":"  The advent of deep learning has significantly propelled the capabilities of\nautomated medical image diagnosis, providing valuable tools and resources in\nthe realm of healthcare and medical diagnostics. This research delves into the\ndevelopment and evaluation of a Deep Residual Convolutional Neural Network\n(CNN) for the multi-class diagnosis of chest infections, utilizing chest X-ray\nimages. The implemented model, trained and validated on a dataset amalgamated\nfrom diverse sources, demonstrated a robust overall accuracy of 93%. However,\nnuanced disparities in performance across different classes, particularly\nFibrosis, underscored the complexity and challenges inherent in automated\nmedical image diagnosis. The insights derived pave the way for future research,\nfocusing on enhancing the model's proficiency in classifying conditions that\npresent more subtle and nuanced visual features in the images, as well as\noptimizing and refining the model architecture and training process. This paper\nprovides a comprehensive exploration into the development, implementation, and\nevaluation of the model, offering insights and directions for future research\nand development in the field.\n","authors":["Ryan Donghan Kwon","Dohyun Lim","Yoonha Lee","Seung Won Lee"],"pdf_url":"https://arxiv.org/pdf/2311.10430v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.03574v5","updated":"2023-11-17T10:01:56Z","published":"2022-02-04T12:30:49Z","title":"Structured Prediction Problem Archive","summary":"  Structured prediction problems are one of the fundamental tools in machine\nlearning. In order to facilitate algorithm development for their numerical\nsolution, we collect in one place a large number of datasets in easy to read\nformats for a diverse set of problem classes. We provide archival links to\ndatasets, description of the considered problems and problem formats, and a\nshort summary of problem characteristics including size, number of instances\netc. For reference we also give a non-exhaustive selection of algorithms\nproposed in the literature for their solution. We hope that this central\nrepository will make benchmarking and comparison to established works easier.\nWe welcome submission of interesting new datasets and algorithms for inclusion\nin our archive.\n","authors":["Paul Swoboda","Bjoern Andres","Andrea Hornakova","Florian Bernard","Jannik Irmai","Paul Roetzer","Bogdan Savchynskyy","David Stein","Ahmed Abbas"],"pdf_url":"https://arxiv.org/pdf/2202.03574v5.pdf","comment":"Added multicast instances from Andres group"},{"id":"http://arxiv.org/abs/2303.11573v2","updated":"2023-11-17T09:33:22Z","published":"2023-03-21T03:41:57Z","title":"BigSmall: Efficient Multi-Task Learning for Disparate Spatial and\n  Temporal Physiological Measurements","summary":"  Understanding of human visual perception has historically inspired the design\nof computer vision architectures. As an example, perception occurs at different\nscales both spatially and temporally, suggesting that the extraction of salient\nvisual information may be made more effective by paying attention to specific\nfeatures at varying scales. Visual changes in the body due to physiological\nprocesses also occur at different scales and with modality-specific\ncharacteristic properties. Inspired by this, we present BigSmall, an efficient\narchitecture for physiological and behavioral measurement. We present the first\njoint camera-based facial action, cardiac, and pulmonary measurement model. We\npropose a multi-branch network with wrapping temporal shift modules that yields\nboth accuracy and efficiency gains. We observe that fusing low-level features\nleads to suboptimal performance, but that fusing high level features enables\nefficiency gains with negligible loss in accuracy. Experimental results\ndemonstrate that BigSmall significantly reduces the computational costs.\nFurthermore, compared to existing task-specific models, BigSmall achieves\ncomparable or better results on multiple physiological measurement tasks\nsimultaneously with a unified model.\n","authors":["Girish Narayanswamy","Yujia Liu","Yuzhe Yang","Chengqian Ma","Xin Liu","Daniel McDuff","Shwetak Patel"],"pdf_url":"https://arxiv.org/pdf/2303.11573v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10408v1","updated":"2023-11-17T09:24:04Z","published":"2023-11-17T09:24:04Z","title":"Deep Learning based CNN Model for Classification and Detection of\n  Individuals Wearing Face Mask","summary":"  In response to the global COVID-19 pandemic, there has been a critical demand\nfor protective measures, with face masks emerging as a primary safeguard. The\napproach involves a two-fold strategy: first, recognizing the presence of a\nface by detecting faces, and second, identifying masks on those faces. This\nproject utilizes deep learning to create a model that can detect face masks in\nreal-time streaming video as well as images. Face detection, a facet of object\ndetection, finds applications in diverse fields such as security, biometrics,\nand law enforcement. Various detector systems worldwide have been developed and\nimplemented, with convolutional neural networks chosen for their superior\nperformance accuracy and speed in object detection. Experimental results attest\nto the model's excellent accuracy on test data. The primary focus of this\nresearch is to enhance security, particularly in sensitive areas. The research\npaper proposes a rapid image pre-processing method with masks centred on faces.\nEmploying feature extraction and Convolutional Neural Network, the system\nclassifies and detects individuals wearing masks. The research unfolds in three\nstages: image pre-processing, image cropping, and image classification,\ncollectively contributing to the identification of masked faces. Continuous\nsurveillance through webcams or CCTV cameras ensures constant monitoring,\ntriggering a security alert if a person is detected without a mask.\n","authors":["R. Chinnaiyan","Iyyappan M","Al Raiyan Shariff A","Kondaveeti Sai","Mallikarjunaiah B M","P Bharath"],"pdf_url":"https://arxiv.org/pdf/2311.10408v1.pdf","comment":"8 Pages , 6 figures , 1 Table"},{"id":"http://arxiv.org/abs/2311.10399v1","updated":"2023-11-17T09:00:44Z","published":"2023-11-17T09:00:44Z","title":"Optimized Deep Learning Models for AUV Seabed Image Analysis","summary":"  Using autonomous underwater vehicles, or AUVs, has completely changed how we\ngather data from the ocean floor. AUV innovation has advanced significantly,\nespecially in the analysis of images, due to the increasing need for accurate\nand efficient seafloor mapping. This blog post provides a detailed summary and\ncomparison of the most current advancements in AUV seafloor image processing.\nWe will go into the realm of undersea technology, covering everything through\ncomputer and algorithmic advancements to advances in sensors and cameras. After\nreading this page through to the end, you will have a solid understanding of\nthe most up-to-date techniques and tools for using AUVs to process seabed\nphotos and how they could further our comprehension of the ocean floor\n","authors":["Rajesh Sharma R","Akey Sungheetha","Chinnaiyan R"],"pdf_url":"https://arxiv.org/pdf/2311.10399v1.pdf","comment":"6 pages , 4 figures"},{"id":"http://arxiv.org/abs/2207.08387v2","updated":"2023-11-17T08:50:15Z","published":"2022-07-18T05:38:37Z","title":"A Semantic-aware Attention and Visual Shielding Network for\n  Cloth-changing Person Re-identification","summary":"  Cloth-changing person reidentification (ReID) is a newly emerging research\ntopic that aims to retrieve pedestrians whose clothes are changed. Since the\nhuman appearance with different clothes exhibits large variations, it is very\ndifficult for existing approaches to extract discriminative and robust feature\nrepresentations. Current works mainly focus on body shape or contour sketches,\nbut the human semantic information and the potential consistency of pedestrian\nfeatures before and after changing clothes are not fully explored or are\nignored. To solve these issues, in this work, a novel semantic-aware attention\nand visual shielding network for cloth-changing person ReID (abbreviated as\nSAVS) is proposed where the key idea is to shield clues related to the\nappearance of clothes and only focus on visual semantic information that is not\nsensitive to view/posture changes. Specifically, a visual semantic encoder is\nfirst employed to locate the human body and clothing regions based on human\nsemantic segmentation information. Then, a human semantic attention module\n(HSA) is proposed to highlight the human semantic information and reweight the\nvisual feature map. In addition, a visual clothes shielding module (VCS) is\nalso designed to extract a more robust feature representation for the\ncloth-changing task by covering the clothing regions and focusing the model on\nthe visual semantic information unrelated to the clothes. Most importantly,\nthese two modules are jointly explored in an end-to-end unified framework.\nExtensive experiments demonstrate that the proposed method can significantly\noutperform state-of-the-art methods, and more robust features can be extracted\nfor cloth-changing persons. Compared with FSAM (published in CVPR 2021), this\nmethod can achieve improvements of 32.7% (16.5%) and 14.9% (-) on the LTCC and\nPRCC datasets in terms of mAP (rank-1), respectively.\n","authors":["Zan Gao","Hongwei Wei","Weili Guan","Jie Nie","Meng Wang","Shenyong Chen"],"pdf_url":"https://arxiv.org/pdf/2207.08387v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2108.04527"},{"id":"http://arxiv.org/abs/2304.04400v2","updated":"2023-11-17T08:49:56Z","published":"2023-04-10T06:05:54Z","title":"Identity-Guided Collaborative Learning for Cloth-Changing Person\n  Reidentification","summary":"  Cloth-changing person reidentification (ReID) is a newly emerging research\ntopic that is aimed at addressing the issues of large feature variations due to\ncloth-changing and pedestrian view/pose changes. Although significant progress\nhas been achieved by introducing extra information (e.g., human contour\nsketching information, human body keypoints, and 3D human information),\ncloth-changing person ReID is still challenging due to impressionable\npedestrian representations. Moreover, human semantic information and pedestrian\nidentity information are not fully explored. To solve these issues, we propose\na novel identity-guided collaborative learning scheme (IGCL) for cloth-changing\nperson ReID, where the human semantic is fully utilized and the identity is\nunchangeable to guide collaborative learning. First, we design a novel clothing\nattention degradation stream to reasonably reduce the interference caused by\nclothing information where clothing attention and mid-level collaborative\nlearning are employed. Second, we propose a human semantic attention and body\njigsaw stream to highlight the human semantic information and simulate\ndifferent poses of the same identity. In this way, the extraction features not\nonly focus on human semantic information that is unrelated to the background\nbut also are suitable for pedestrian pose variations. Moreover, a pedestrian\nidentity enhancement stream is further proposed to enhance the identity\nimportance and extract more favorable identity robust features. Most\nimportantly, all these streams are jointly explored in an end-to-end unified\nframework, and the identity is utilized to guide the optimization. Extensive\nexperiments on five public clothing person ReID datasets demonstrate that the\nproposed IGCL significantly outperforms SOTA methods and that the extracted\nfeature is more robust, discriminative, and clothing-irrelevant.\n","authors":["Zan Gao","Shenxun Wei","Weili Guan","Lei Zhu","Meng Wang","Shenyong Chen"],"pdf_url":"https://arxiv.org/pdf/2304.04400v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10389v1","updated":"2023-11-17T08:35:02Z","published":"2023-11-17T08:35:02Z","title":"Two-Factor Authentication Approach Based on Behavior Patterns for\n  Defeating Puppet Attacks","summary":"  Fingerprint traits are widely recognized for their unique qualities and\nsecurity benefits. Despite their extensive use, fingerprint features can be\nvulnerable to puppet attacks, where attackers manipulate a reluctant but\ngenuine user into completing the authentication process. Defending against such\nattacks is challenging due to the coexistence of a legitimate identity and an\nillegitimate intent. In this paper, we propose PUPGUARD, a solution designed to\nguard against puppet attacks. This method is based on user behavioral patterns,\nspecifically, the user needs to press the capture device twice successively\nwith different fingers during the authentication process. PUPGUARD leverages\nboth the image features of fingerprints and the timing characteristics of the\npressing intervals to establish two-factor authentication. More specifically,\nafter extracting image features and timing characteristics, and performing\nfeature selection on the image features, PUPGUARD fuses these two features into\na one-dimensional feature vector, and feeds it into a one-class classifier to\nobtain the classification result. This two-factor authentication method\nemphasizes dynamic behavioral patterns during the authentication process,\nthereby enhancing security against puppet attacks. To assess PUPGUARD's\neffectiveness, we conducted experiments on datasets collected from 31 subjects,\nincluding image features and timing characteristics. Our experimental results\ndemonstrate that PUPGUARD achieves an impressive accuracy rate of 97.87% and a\nremarkably low false positive rate (FPR) of 1.89%. Furthermore, we conducted\ncomparative experiments to validate the superiority of combining image features\nand timing characteristics within PUPGUARD for enhancing resistance against\npuppet attacks.\n","authors":["Wenhao Wang","Guyue Li","Zhiming Chu","Haobo Li","Daniele Faccio"],"pdf_url":"https://arxiv.org/pdf/2311.10389v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02058v2","updated":"2023-11-17T08:26:16Z","published":"2023-11-03T17:38:35Z","title":"LOTUS: Continual Imitation Learning for Robot Manipulation Through\n  Unsupervised Skill Discovery","summary":"  We introduce LOTUS, a continual imitation learning algorithm that empowers a\nphysical robot to continuously and efficiently learn to solve new manipulation\ntasks throughout its lifespan. The core idea behind LOTUS is constructing an\never-growing skill library from a sequence of new tasks with a small number of\nhuman demonstrations. LOTUS starts with a continual skill discovery process\nusing an open-vocabulary vision model, which extracts skills as recurring\npatterns presented in unsegmented demonstrations. Continual skill discovery\nupdates existing skills to avoid catastrophic forgetting of previous tasks and\nadds new skills to solve novel tasks. LOTUS trains a meta-controller that\nflexibly composes various skills to tackle vision-based manipulation tasks in\nthe lifelong learning process. Our comprehensive experiments show that LOTUS\noutperforms state-of-the-art baselines by over 11% in success rate, showing its\nsuperior knowledge transfer ability compared to prior methods. More results and\nvideos can be found on the project website:\nhttps://ut-austin-rpl.github.io/Lotus/.\n","authors":["Weikang Wan","Yifeng Zhu","Rutav Shah","Yuke Zhu"],"pdf_url":"https://arxiv.org/pdf/2311.02058v2.pdf","comment":"Submitted to ICRA 2024"},{"id":"http://arxiv.org/abs/2306.04226v2","updated":"2023-11-17T08:23:05Z","published":"2023-06-07T08:05:46Z","title":"Normalization Layers Are All That Sharpness-Aware Minimization Needs","summary":"  Sharpness-aware minimization (SAM) was proposed to reduce sharpness of minima\nand has been shown to enhance generalization performance in various settings.\nIn this work we show that perturbing only the affine normalization parameters\n(typically comprising 0.1% of the total parameters) in the adversarial step of\nSAM can outperform perturbing all of the parameters.This finding generalizes to\ndifferent SAM variants and both ResNet (Batch Normalization) and Vision\nTransformer (Layer Normalization) architectures. We consider alternative sparse\nperturbation approaches and find that these do not achieve similar performance\nenhancement at such extreme sparsity levels, showing that this behaviour is\nunique to the normalization layers. Although our findings reaffirm the\neffectiveness of SAM in improving generalization performance, they cast doubt\non whether this is solely caused by reduced sharpness.\n","authors":["Maximilian Mueller","Tiffany Vlaar","David Rolnick","Matthias Hein"],"pdf_url":"https://arxiv.org/pdf/2306.04226v2.pdf","comment":"camera ready version"},{"id":"http://arxiv.org/abs/2311.10382v1","updated":"2023-11-17T08:17:49Z","published":"2023-11-17T08:17:49Z","title":"Single-Shot and Multi-Shot Feature Learning for Multi-Object Tracking","summary":"  Multi-Object Tracking (MOT) remains a vital component of intelligent video\nanalysis, which aims to locate targets and maintain a consistent identity for\neach target throughout a video sequence. Existing works usually learn a\ndiscriminative feature representation, such as motion and appearance, to\nassociate the detections across frames, which are easily affected by mutual\nocclusion and background clutter in practice. In this paper, we propose a\nsimple yet effective two-stage feature learning paradigm to jointly learn\nsingle-shot and multi-shot features for different targets, so as to achieve\nrobust data association in the tracking process. For the detections without\nbeing associated, we design a novel single-shot feature learning module to\nextract discriminative features of each detection, which can efficiently\nassociate targets between adjacent frames. For the tracklets being lost several\nframes, we design a novel multi-shot feature learning module to extract\ndiscriminative features of each tracklet, which can accurately refind these\nlost targets after a long period. Once equipped with a simple data association\nlogic, the resulting VisualTracker can perform robust MOT based on the\nsingle-shot and multi-shot feature representations. Extensive experimental\nresults demonstrate that our method has achieved significant improvements on\nMOT17 and MOT20 datasets while reaching state-of-the-art performance on\nDanceTrack dataset.\n","authors":["Yizhe Li","Sanping Zhou","Zheng Qin","Le Wang","Jinjun Wang","Nanning Zheng"],"pdf_url":"https://arxiv.org/pdf/2311.10382v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10380v1","updated":"2023-11-17T08:14:24Z","published":"2023-11-17T08:14:24Z","title":"MSE-Nets: Multi-annotated Semi-supervised Ensemble Networks for\n  Improving Segmentation of Medical Image with Ambiguous Boundaries","summary":"  Medical image segmentation annotations exhibit variations among experts due\nto the ambiguous boundaries of segmented objects and backgrounds in medical\nimages. Although using multiple annotations for each image in the\nfully-supervised has been extensively studied for training deep models,\nobtaining a large amount of multi-annotated data is challenging due to the\nsubstantial time and manpower costs required for segmentation annotations,\nresulting in most images lacking any annotations. To address this, we propose\nMulti-annotated Semi-supervised Ensemble Networks (MSE-Nets) for learning\nsegmentation from limited multi-annotated and abundant unannotated data.\nSpecifically, we introduce the Network Pairwise Consistency Enhancement (NPCE)\nmodule and Multi-Network Pseudo Supervised (MNPS) module to enhance MSE-Nets\nfor the segmentation task by considering two major factors: (1) to optimize the\nutilization of all accessible multi-annotated data, the NPCE separates\n(dis)agreement annotations of multi-annotated data at the pixel level and\nhandles agreement and disagreement annotations in different ways, (2) to\nmitigate the introduction of imprecise pseudo-labels, the MNPS extends the\ntraining data by leveraging consistent pseudo-labels from unannotated data.\nFinally, we improve confidence calibration by averaging the predictions of base\nnetworks. Experiments on the ISIC dataset show that we reduced the demand for\nmulti-annotated data by 97.75\\% and narrowed the gap with the best\nfully-supervised baseline to just a Jaccard index of 4\\%. Furthermore, compared\nto other semi-supervised methods that rely only on a single annotation or a\ncombined fusion approach, the comprehensive experimental results on ISIC and\nRIGA datasets demonstrate the superior performance of our proposed method in\nmedical image segmentation with ambiguous boundaries.\n","authors":["Shuai Wang","Tengjin Weng","Jingyi Wang","Yang Shen","Zhidong Zhao","Yixiu Liu","Pengfei Jiao","Zhiming Cheng","Yaqi Wang"],"pdf_url":"https://arxiv.org/pdf/2311.10380v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.11239v2","updated":"2023-11-17T07:57:57Z","published":"2023-08-22T07:27:09Z","title":"LOCATE: Self-supervised Object Discovery via Flow-guided Graph-cut and\n  Bootstrapped Self-training","summary":"  Learning object segmentation in image and video datasets without human\nsupervision is a challenging problem. Humans easily identify moving salient\nobjects in videos using the gestalt principle of common fate, which suggests\nthat what moves together belongs together. Building upon this idea, we propose\na self-supervised object discovery approach that leverages motion and\nappearance information to produce high-quality object segmentation masks.\nSpecifically, we redesign the traditional graph cut on images to include motion\ninformation in a linear combination with appearance information to produce edge\nweights. Remarkably, this step produces object segmentation masks comparable to\nthe current state-of-the-art on multiple benchmarks. To further improve\nperformance, we bootstrap a segmentation network trained on these preliminary\nmasks as pseudo-ground truths to learn from its own outputs via self-training.\nWe demonstrate the effectiveness of our approach, named LOCATE, on multiple\nstandard video object segmentation, image saliency detection, and object\nsegmentation benchmarks, achieving results on par with and, in many cases\nsurpassing state-of-the-art methods. We also demonstrate the transferability of\nour approach to novel domains through a qualitative study on in-the-wild\nimages. Additionally, we present extensive ablation analysis to support our\ndesign choices and highlight the contribution of each component of our proposed\nmethod.\n","authors":["Silky Singh","Shripad Deshmukh","Mausoom Sarkar","Balaji Krishnamurthy"],"pdf_url":"https://arxiv.org/pdf/2308.11239v2.pdf","comment":"Accepted to British Machine Vision Conference (BMVC) 2023"},{"id":"http://arxiv.org/abs/2311.10366v1","updated":"2023-11-17T07:39:42Z","published":"2023-11-17T07:39:42Z","title":"Breaking Temporal Consistency: Generating Video Universal Adversarial\n  Perturbations Using Image Models","summary":"  As video analysis using deep learning models becomes more widespread, the\nvulnerability of such models to adversarial attacks is becoming a pressing\nconcern. In particular, Universal Adversarial Perturbation (UAP) poses a\nsignificant threat, as a single perturbation can mislead deep learning models\non entire datasets. We propose a novel video UAP using image data and image\nmodel. This enables us to take advantage of the rich image data and image\nmodel-based studies available for video applications. However, there is a\nchallenge that image models are limited in their ability to analyze the\ntemporal aspects of videos, which is crucial for a successful video attack. To\naddress this challenge, we introduce the Breaking Temporal Consistency (BTC)\nmethod, which is the first attempt to incorporate temporal information into\nvideo attacks using image models. We aim to generate adversarial videos that\nhave opposite patterns to the original. Specifically, BTC-UAP minimizes the\nfeature similarity between neighboring frames in videos. Our approach is simple\nbut effective at attacking unseen video models. Additionally, it is applicable\nto videos of varying lengths and invariant to temporal shifts. Our approach\nsurpasses existing methods in terms of effectiveness on various datasets,\nincluding ImageNet, UCF-101, and Kinetics-400.\n","authors":["Hee-Seon Kim","Minji Son","Minbeom Kim","Myung-Joon Kwon","Changick Kim"],"pdf_url":"https://arxiv.org/pdf/2311.10366v1.pdf","comment":"ICCV 2023"},{"id":"http://arxiv.org/abs/2311.10365v1","updated":"2023-11-17T07:37:41Z","published":"2023-11-17T07:37:41Z","title":"Dates Fruit Disease Recognition using Machine Learning","summary":"  Many countries such as Saudi Arabia, Morocco and Tunisia are among the top\nexporters and consumers of palm date fruits. Date fruit production plays a\nmajor role in the economies of the date fruit exporting countries. Date fruits\nare susceptible to disease just like any fruit and early detection and\nintervention can end up saving the produce. However, with the vast farming\nlands, it is nearly impossible for farmers to observe date trees on a frequent\nbasis for early disease detection. In addition, even with human observation the\nprocess is prone to human error and increases the date fruit cost. With the\nrecent advances in computer vision, machine learning, drone technology, and\nother technologies; an integrated solution can be proposed for the automatic\ndetection of date fruit disease. In this paper, a hybrid features based method\nwith the standard classifiers is proposed based on the extraction of L*a*b\ncolor features, statistical features, and Discrete Wavelet Transform (DWT)\ntexture features for the early detection and classification of date fruit\ndisease. A dataset was developed for this work consisting of 871 images divided\ninto the following classes; Healthy date, Initial stage of disease,\nMalnourished date, and Parasite infected. The extracted features were input to\ncommon classifiers such as the Random Forest (RF), Multilayer Perceptron (MLP),\nNa\\\"ive Bayes (NB), and Fuzzy Decision Trees (FDT). The highest average\naccuracy was achieved when combining the L*a*b, Statistical, and DWT Features.\n","authors":["Ghassen Ben Brahim","Jaafar Alghazo","Ghazanfar Latif","Khalid Alnujaidi"],"pdf_url":"https://arxiv.org/pdf/2311.10365v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10361v1","updated":"2023-11-17T07:30:00Z","published":"2023-11-17T07:30:00Z","title":"Video-based Sequential Bayesian Homography Estimation for Soccer Field\n  Registration","summary":"  A novel Bayesian framework is proposed, which explicitly relates the\nhomography of one video frame to the next through an affine transformation\nwhile explicitly modelling keypoint uncertainty. The literature has previously\nused differential homography between subsequent frames, but not in a Bayesian\nsetting. In cases where Bayesian methods have been applied, camera motion is\nnot adequately modelled, and keypoints are treated as deterministic. The\nproposed method, Bayesian Homography Inference from Tracked Keypoints (BHITK),\nemploys a two-stage Kalman filter and significantly improves existing methods.\nExisting keypoint detection methods may be easily augmented with BHITK. It\nenables less sophisticated and less computationally expensive methods to\noutperform the state-of-the-art approaches in most homography evaluation\nmetrics. Furthermore, the homography annotations of the WorldCup and\nTS-WorldCup datasets have been refined using a custom homography annotation\ntool released for public use. The refined datasets are consolidated and\nreleased as the consolidated and refined WorldCup (CARWC) dataset.\n","authors":["Paul J. Claasen","J. P. de Villiers"],"pdf_url":"https://arxiv.org/pdf/2311.10361v1.pdf","comment":"Submitted to Expert Systems with Applications and currently under\n  review"},{"id":"http://arxiv.org/abs/2310.15105v4","updated":"2023-11-17T07:27:34Z","published":"2023-10-23T17:12:01Z","title":"FD-Align: Feature Discrimination Alignment for Fine-tuning Pre-Trained\n  Models in Few-Shot Learning","summary":"  Due to the limited availability of data, existing few-shot learning methods\ntrained from scratch fail to achieve satisfactory performance. In contrast,\nlarge-scale pre-trained models such as CLIP demonstrate remarkable few-shot and\nzero-shot capabilities. To enhance the performance of pre-trained models for\ndownstream tasks, fine-tuning the model on downstream data is frequently\nnecessary. However, fine-tuning the pre-trained model leads to a decrease in\nits generalizability in the presence of distribution shift, while the limited\nnumber of samples in few-shot learning makes the model highly susceptible to\noverfitting. Consequently, existing methods for fine-tuning few-shot learning\nprimarily focus on fine-tuning the model's classification head or introducing\nadditional structure. In this paper, we introduce a fine-tuning approach termed\nFeature Discrimination Alignment (FD-Align). Our method aims to bolster the\nmodel's generalizability by preserving the consistency of spurious features\nacross the fine-tuning process. Extensive experimental results validate the\nefficacy of our approach for both ID and OOD tasks. Once fine-tuned, the model\ncan seamlessly integrate with existing methods, leading to performance\nimprovements. Our code can be found in https://github.com/skingorz/FD-Align.\n","authors":["Kun Song","Huimin Ma","Bochao Zou","Huishuai Zhang","Weiran Huang"],"pdf_url":"https://arxiv.org/pdf/2310.15105v4.pdf","comment":"Accepted by NeurIPS 2023"},{"id":"http://arxiv.org/abs/2306.06048v2","updated":"2023-11-17T07:22:04Z","published":"2023-06-09T17:16:50Z","title":"How Does Fine-Tuning Impact Out-of-Distribution Detection for\n  Vision-Language Models?","summary":"  Recent large vision-language models such as CLIP have shown remarkable\nout-of-distribution (OOD) detection and generalization performance. However,\ntheir zero-shot in-distribution (ID) accuracy is often limited for downstream\ndatasets. Recent CLIP-based fine-tuning methods such as prompt learning have\ndemonstrated significant improvements in ID classification and OOD\ngeneralization where OOD labels are available. Nonetheless, it remains unclear\nwhether the model is reliable to semantic shifts without OOD labels. In this\npaper, we aim to bridge the gap and present a comprehensive study to understand\nhow fine-tuning impact OOD detection for few-shot downstream tasks. By framing\nOOD detection as multi-modal concept matching, we establish a connection\nbetween fine-tuning methods and various OOD scores. Our results suggest that a\nproper choice of OOD scores is essential for CLIP-based fine-tuning. In\nparticular, the maximum concept matching (MCM) score provides a promising\nsolution consistently. We also show that prompt learning demonstrates the\nstate-of-the-art OOD detection performance over the zero-shot counterpart.\n","authors":["Yifei Ming","Yixuan Li"],"pdf_url":"https://arxiv.org/pdf/2306.06048v2.pdf","comment":"Accepted to IJCV 2023"},{"id":"http://arxiv.org/abs/2311.10356v1","updated":"2023-11-17T07:06:21Z","published":"2023-11-17T07:06:21Z","title":"Garment Recovery with Shape and Deformation Priors","summary":"  While modeling people wearing tight-fitting clothing has made great strides\nin recent years, loose-fitting clothing remains a challenge. We propose a\nmethod that delivers realistic garment models from real-world images,\nregardless of garment shape or deformation. To this end, we introduce a fitting\napproach that utilizes shape and deformation priors learned from synthetic data\nto accurately capture garment shapes and deformations, including large ones.\nNot only does our approach recover the garment geometry accurately, it also\nyields models that can be directly used by downstream applications such as\nanimation and simulation.\n","authors":["Ren Li","Corentin Dumery","Benoît Guillard","Pascal Fua"],"pdf_url":"https://arxiv.org/pdf/2311.10356v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02256v2","updated":"2023-11-17T06:58:21Z","published":"2023-11-03T22:13:58Z","title":"Image Recognition of Oil Leakage Area Based on Logical Semantic\n  Discrimination","summary":"  Implementing precise detection of oil leaks in peak load equipment through\nimage analysis can significantly enhance inspection quality and ensure the\nsystem's safety and reliability. However, challenges such as varying shapes of\noil-stained regions, background noise, and fluctuating lighting conditions\ncomplicate the detection process. To address this, the integration of logical\nrule-based discrimination into image recognition has been proposed. This\napproach involves recognizing the spatial relationships among objects to\nsemantically segment images of oil spills using a Mask RCNN network. The\nprocess begins with histogram equalization to enhance the original image,\nfollowed by the use of Mask RCNN to identify the preliminary positions and\noutlines of oil tanks, the ground, and areas of potential oil contamination.\nSubsequent to this identification, the spatial relationships between these\nobjects are analyzed. Logical rules are then applied to ascertain whether the\nsuspected areas are indeed oil spills. This method's effectiveness has been\nconfirmed by testing on images captured from peak power equipment in the field.\nThe results indicate that this approach can adeptly tackle the challenges in\nidentifying oil-contaminated areas, showing a substantial improvement in\naccuracy compared to existing methods.\n","authors":["Weiying Lin","Che Liu","Xin Zhang","Zhen Wei","Sizhe Li","Xun Ma"],"pdf_url":"https://arxiv.org/pdf/2311.02256v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10349v1","updated":"2023-11-17T06:36:43Z","published":"2023-11-17T06:36:43Z","title":"Pseudo Label-Guided Data Fusion and Output Consistency for\n  Semi-Supervised Medical Image Segmentation","summary":"  Supervised learning algorithms based on Convolutional Neural Networks have\nbecome the benchmark for medical image segmentation tasks, but their\neffectiveness heavily relies on a large amount of labeled data. However,\nannotating medical image datasets is a laborious and time-consuming process.\nInspired by semi-supervised algorithms that use both labeled and unlabeled data\nfor training, we propose the PLGDF framework, which builds upon the mean\nteacher network for segmenting medical images with less annotation. We propose\na novel pseudo-label utilization scheme, which combines labeled and unlabeled\ndata to augment the dataset effectively. Additionally, we enforce the\nconsistency between different scales in the decoder module of the segmentation\nnetwork and propose a loss function suitable for evaluating the consistency.\nMoreover, we incorporate a sharpening operation on the predicted results,\nfurther enhancing the accuracy of the segmentation.\n  Extensive experiments on three publicly available datasets demonstrate that\nthe PLGDF framework can largely improve performance by incorporating the\nunlabeled data. Meanwhile, our framework yields superior performance compared\nto six state-of-the-art semi-supervised learning methods. The codes of this\nstudy are available at https://github.com/ortonwang/PLGDF.\n","authors":["Tao Wang","Yuanbin Chen","Xinlin Zhang","Yuanbo Zhou","Junlin Lan","Bizhe Bai","Tao Tan","Min Du","Qinquan Gao","Tong Tong"],"pdf_url":"https://arxiv.org/pdf/2311.10349v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10343v1","updated":"2023-11-17T06:07:54Z","published":"2023-11-17T06:07:54Z","title":"Enhancing Student Engagement in Online Learning through Facial\n  Expression Analysis and Complex Emotion Recognition using Deep Learning","summary":"  In response to the COVID-19 pandemic, traditional physical classrooms have\ntransitioned to online environments, necessitating effective strategies to\nensure sustained student engagement. A significant challenge in online teaching\nis the absence of real-time feedback from teachers on students learning\nprogress. This paper introduces a novel approach employing deep learning\ntechniques based on facial expressions to assess students engagement levels\nduring online learning sessions. Human emotions cannot be adequately conveyed\nby a student using only the basic emotions, including anger, disgust, fear,\njoy, sadness, surprise, and neutrality. To address this challenge, proposed a\ngeneration of four complex emotions such as confusion, satisfaction,\ndisappointment, and frustration by combining the basic emotions. These complex\nemotions are often experienced simultaneously by students during the learning\nsession. To depict these emotions dynamically,utilized a continuous stream of\nimage frames instead of discrete images. The proposed work utilized a\nConvolutional Neural Network (CNN) model to categorize the fundamental\nemotional states of learners accurately. The proposed CNN model demonstrates\nstrong performance, achieving a 95% accuracy in precise categorization of\nlearner emotions.\n","authors":["Rekha R Nair","Tina Babu","Pavithra K"],"pdf_url":"https://arxiv.org/pdf/2311.10343v1.pdf","comment":"Face emotion recognition work"},{"id":"http://arxiv.org/abs/2311.10339v1","updated":"2023-11-17T05:49:50Z","published":"2023-11-17T05:49:50Z","title":"A2XP: Towards Private Domain Generalization","summary":"  Deep Neural Networks (DNNs) have become pivotal in various fields, especially\nin computer vision, outperforming previous methodologies. A critical challenge\nin their deployment is the bias inherent in data across different domains, such\nas image style, and environmental conditions, leading to domain gaps. This\nnecessitates techniques for learning general representations from biased\ntraining data, known as domain generalization. This paper presents Attend to\neXpert Prompts (A2XP), a novel approach for domain generalization that\npreserves the privacy and integrity of the network architecture. A2XP consists\nof two phases: Expert Adaptation and Domain Generalization. In the first phase,\nprompts for each source domain are optimized to guide the model towards the\noptimal direction. In the second phase, two embedder networks are trained to\neffectively amalgamate these expert prompts, aiming for an optimal output. Our\nextensive experiments demonstrate that A2XP achieves state-of-the-art results\nover existing non-private domain generalization methods. The experimental\nresults validate that the proposed approach not only tackles the domain\ngeneralization challenge in DNNs but also offers a privacy-preserving,\nefficient solution to the broader field of computer vision.\n","authors":["Geunhyeok Yu","Hyoseok Hwang"],"pdf_url":"https://arxiv.org/pdf/2311.10339v1.pdf","comment":"10 pages (8 pages except for references), 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2311.10336v1","updated":"2023-11-17T05:41:23Z","published":"2023-11-17T05:41:23Z","title":"Cooperative Perception with Learning-Based V2V communications","summary":"  Cooperative perception has been widely used in autonomous driving to\nalleviate the inherent limitation of single automated vehicle perception. To\nenable cooperation, vehicle-to-vehicle (V2V) communication plays an\nindispensable role. This work analyzes the performance of cooperative\nperception accounting for communications channel impairments. Different fusion\nmethods and channel impairments are evaluated. A new late fusion scheme is\nproposed to leverage the robustness of intermediate features. In order to\ncompress the data size incurred by cooperation, a convolution neural\nnetwork-based autoencoder is adopted. Numerical results demonstrate that\nintermediate fusion is more robust to channel impairments than early fusion and\nlate fusion, when the SNR is greater than 0 dB. Also, the proposed fusion\nscheme outperforms the conventional late fusion using detection outputs, and\nautoencoder provides a good compromise between detection accuracy and bandwidth\nusage.\n","authors":["Chenguang Liu","Yunfei Chen","Jianjun Chen","Ryan Payton","Michael Riley","Shuang-Hua Yang"],"pdf_url":"https://arxiv.org/pdf/2311.10336v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.05370v2","updated":"2023-11-17T05:38:45Z","published":"2023-05-09T12:05:14Z","title":"MSVQ: Self-Supervised Learning with Multiple Sample Views and Queues","summary":"  Self-supervised methods based on contrastive learning have achieved great\nsuccess in unsupervised visual representation learning. However, most methods\nunder this framework suffer from the problem of false negative samples.\nInspired by the mean shift for self-supervised learning, we propose a new\nsimple framework, namely Multiple Sample Views and Queues (MSVQ). We jointly\nconstruct three soft labels on-the-fly by utilizing two complementary and\nsymmetric approaches: multiple augmented positive views and two momentum\nencoders that generate various semantic features for negative samples. Two\nteacher networks perform similarity relationship calculations with negative\nsamples and then transfer this knowledge to the student network. Let the\nstudent network mimic the similarity relationships between the samples, thus\ngiving the student network a more flexible ability to identify false negative\nsamples in the dataset. The classification results on four benchmark image\ndatasets demonstrate the high effectiveness and efficiency of our approach\ncompared to some classical methods. Source code and pretrained models are\navailable \\href{https://github.com/pc-cp/MSVQ}{here}.\n","authors":["Chen Peng","Xianzhong Long","Yun Li"],"pdf_url":"https://arxiv.org/pdf/2305.05370v2.pdf","comment":"Accepted in KBS(Knowledge-Based Systems)"},{"id":"http://arxiv.org/abs/2311.10331v1","updated":"2023-11-17T05:23:57Z","published":"2023-11-17T05:23:57Z","title":"Leveraging Multimodal Fusion for Enhanced Diagnosis of Multiple Retinal\n  Diseases in Ultra-wide OCTA","summary":"  Ultra-wide optical coherence tomography angiography (UW-OCTA) is an emerging\nimaging technique that offers significant advantages over traditional OCTA by\nproviding an exceptionally wide scanning range of up to 24 x 20 $mm^{2}$,\ncovering both the anterior and posterior regions of the retina. However, the\ncurrently accessible UW-OCTA datasets suffer from limited comprehensive\nhierarchical information and corresponding disease annotations. To address this\nlimitation, we have curated the pioneering M3OCTA dataset, which is the first\nmultimodal (i.e., multilayer), multi-disease, and widest field-of-view UW-OCTA\ndataset. Furthermore, the effective utilization of multi-layer ultra-wide\nocular vasculature information from UW-OCTA remains underdeveloped. To tackle\nthis challenge, we propose the first cross-modal fusion framework that\nleverages multi-modal information for diagnosing multiple diseases. Through\nextensive experiments conducted on our openly available M3OCTA dataset, we\ndemonstrate the effectiveness and superior performance of our method, both in\nfixed and varying modalities settings. The construction of the M3OCTA dataset,\nthe first multimodal OCTA dataset encompassing multiple diseases, aims to\nadvance research in the ophthalmic image analysis community.\n","authors":["Hao Wei","Peilun Shi","Guitao Bai","Minqing Zhang","Shuangle Li","Wu Yuan"],"pdf_url":"https://arxiv.org/pdf/2311.10331v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.00022v2","updated":"2023-11-17T05:22:38Z","published":"2023-09-28T18:04:43Z","title":"CtxMIM: Context-Enhanced Masked Image Modeling for Remote Sensing Image\n  Understanding","summary":"  Learning representations through self-supervision on unlabeled data has\nproven highly effective for understanding diverse images. However, remote\nsensing images often have complex and densely populated scenes with multiple\nland objects and no clear foreground objects. This intrinsic property generates\nhigh object density, resulting in false positive pairs or missing contextual\ninformation in self-supervised learning. To address these problems, we propose\na context-enhanced masked image modeling method (CtxMIM), a simple yet\nefficient MIM-based self-supervised learning for remote sensing image\nunderstanding. CtxMIM formulates original image patches as a reconstructive\ntemplate and employs a Siamese framework to operate on two sets of image\npatches. A context-enhanced generative branch is introduced to provide\ncontextual information through context consistency constraints in the\nreconstruction. With the simple and elegant design, CtxMIM encourages the\npre-training model to learn object-level or pixel-level features on a\nlarge-scale dataset without specific temporal or geographical constraints.\nFinally, extensive experiments show that features learned by CtxMIM outperform\nfully supervised and state-of-the-art self-supervised learning methods on\nvarious downstream tasks, including land cover classification, semantic\nsegmentation, object detection, and instance segmentation. These results\ndemonstrate that CtxMIM learns impressive remote sensing representations with\nhigh generalization and transferability. Code and data will be made public\navailable.\n","authors":["Mingming Zhang","Qingjie Liu","Yunhong Wang"],"pdf_url":"https://arxiv.org/pdf/2310.00022v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10329v1","updated":"2023-11-17T05:03:53Z","published":"2023-11-17T05:03:53Z","title":"High-fidelity Person-centric Subject-to-Image Synthesis","summary":"  Current subject-driven image generation methods encounter significant\nchallenges in person-centric image generation. The reason is that they learn\nthe semantic scene and person generation by fine-tuning a common pre-trained\ndiffusion, which involves an irreconcilable training imbalance. Precisely, to\ngenerate realistic persons, they need to sufficiently tune the pre-trained\nmodel, which inevitably causes the model to forget the rich semantic scene\nprior and makes scene generation over-fit to the training data. Moreover, even\nwith sufficient fine-tuning, these methods can still not generate high-fidelity\npersons since joint learning of the scene and person generation also lead to\nquality compromise. In this paper, we propose Face-diffuser, an effective\ncollaborative generation pipeline to eliminate the above training imbalance and\nquality compromise. Specifically, we first develop two specialized pre-trained\ndiffusion models, i.e., Text-driven Diffusion Model (TDM) and Subject-augmented\nDiffusion Model (SDM), for scene and person generation, respectively. The\nsampling process is divided into three sequential stages, i.e., semantic scene\nconstruction, subject-scene fusion, and subject enhancement. The first and last\nstages are performed by TDM and SDM respectively. The subject-scene fusion\nstage, that is the collaboration achieved through a novel and highly effective\nmechanism, Saliency-adaptive Noise Fusion (SNF). Specifically, it is based on\nour key observation that there exists a robust link between classifier-free\nguidance responses and the saliency of generated images. In each time step, SNF\nleverages the unique strengths of each model and allows for the spatial\nblending of predicted noises from both models automatically in a saliency-aware\nmanner. Extensive experiments confirm the impressive effectiveness and\nrobustness of the Face-diffuser.\n","authors":["Yibin Wang","Weizhong Zhang","Jianwei Zheng","Cheng Jin"],"pdf_url":"https://arxiv.org/pdf/2311.10329v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10328v1","updated":"2023-11-17T04:59:08Z","published":"2023-11-17T04:59:08Z","title":"TransONet: Automatic Segmentation of Vasculature in Computed Tomographic\n  Angiograms Using Deep Learning","summary":"  Pathological alterations in the human vascular system underlie many chronic\ndiseases, such as atherosclerosis and aneurysms. However, manually analyzing\ndiagnostic images of the vascular system, such as computed tomographic\nangiograms (CTAs) is a time-consuming and tedious process. To address this\nissue, we propose a deep learning model to segment the vascular system in CTA\nimages of patients undergoing surgery for peripheral arterial disease (PAD).\nOur study focused on accurately segmenting the vascular system (1) from the\ndescending thoracic aorta to the iliac bifurcation and (2) from the descending\nthoracic aorta to the knees in CTA images using deep learning techniques. Our\napproach achieved average Dice accuracies of 93.5% and 80.64% in test dataset\nfor (1) and (2), respectively, highlighting its high accuracy and potential\nclinical utility. These findings demonstrate the use of deep learning\ntechniques as a valuable tool for medical professionals to analyze the health\nof the vascular system efficiently and accurately. Please visit the GitHub page\nfor this paper at https://github.com/pip-alireza/TransOnet.\n","authors":["Alireza Bagheri Rajeoni","Breanna Pederson","Ali Firooz","Hamed Abdollahi","Andrew K. Smith","Daniel G. Clair","Susan M. Lessner","Homayoun Valafar"],"pdf_url":"https://arxiv.org/pdf/2311.10328v1.pdf","comment":"Accepted for the 2023 International Conference on Computational\n  Science and Computational Intelligence (CSCI), Las Vegas, USA"},{"id":"http://arxiv.org/abs/2303.10076v5","updated":"2023-11-17T04:25:19Z","published":"2023-03-17T15:57:14Z","title":"A Simple Framework for 3D Occupancy Estimation in Autonomous Driving","summary":"  The task of estimating 3D occupancy from surrounding-view images is an\nexciting development in the field of autonomous driving, following the success\nof Bird's Eye View (BEV) perception. This task provides crucial 3D attributes\nof the driving environment, enhancing the overall understanding and perception\nof the surrounding space. In this work, we present a simple framework for 3D\noccupancy estimation, which is a CNN-based framework designed to reveal several\nkey factors for 3D occupancy estimation, such as network design, optimization,\nand evaluation. In addition, we explore the relationship between 3D occupancy\nestimation and other related tasks, such as monocular depth estimation and 3D\nreconstruction, which could advance the study of 3D perception in autonomous\ndriving. For evaluation, we propose a simple sampling strategy to define the\nmetric for occupancy evaluation, which is flexible for current public datasets.\nMoreover, we establish the benchmark in terms of the depth estimation metric,\nwhere we compare our proposed method with monocular depth estimation methods on\nthe DDAD and Nuscenes datasets and achieve competitive performance. The\nrelevant code will be updated in https://github.com/GANWANSHUI/SimpleOccupancy.\n","authors":["Wanshui Gan","Ningkai Mo","Hongbin Xu","Naoto Yokoya"],"pdf_url":"https://arxiv.org/pdf/2303.10076v5.pdf","comment":"15 pages, 8 figures"},{"id":"http://arxiv.org/abs/2306.11719v2","updated":"2023-11-17T04:17:34Z","published":"2023-06-20T17:53:00Z","title":"Diffusion with Forward Models: Solving Stochastic Inverse Problems\n  Without Direct Supervision","summary":"  Denoising diffusion models are a powerful type of generative models used to\ncapture complex distributions of real-world signals. However, their\napplicability is limited to scenarios where training samples are readily\navailable, which is not always the case in real-world applications. For\nexample, in inverse graphics, the goal is to generate samples from a\ndistribution of 3D scenes that align with a given image, but ground-truth 3D\nscenes are unavailable and only 2D images are accessible. To address this\nlimitation, we propose a novel class of denoising diffusion probabilistic\nmodels that learn to sample from distributions of signals that are never\ndirectly observed. Instead, these signals are measured indirectly through a\nknown differentiable forward model, which produces partial observations of the\nunknown signal. Our approach involves integrating the forward model directly\ninto the denoising process. This integration effectively connects the\ngenerative modeling of observations with the generative modeling of the\nunderlying signals, allowing for end-to-end training of a conditional\ngenerative model over signals. During inference, our approach enables sampling\nfrom the distribution of underlying signals that are consistent with a given\npartial observation. We demonstrate the effectiveness of our method on three\nchallenging computer vision tasks. For instance, in the context of inverse\ngraphics, our model enables direct sampling from the distribution of 3D scenes\nthat align with a single 2D input image.\n","authors":["Ayush Tewari","Tianwei Yin","George Cazenavette","Semon Rezchikov","Joshua B. Tenenbaum","Frédo Durand","William T. Freeman","Vincent Sitzmann"],"pdf_url":"https://arxiv.org/pdf/2306.11719v2.pdf","comment":"Project page: https://diffusion-with-forward-models.github.io/"},{"id":"http://arxiv.org/abs/2311.10320v1","updated":"2023-11-17T04:06:20Z","published":"2023-11-17T04:06:20Z","title":"Learning transformer-based heterogeneously salient graph representation\n  for multimodal fusion classification of hyperspectral image and LiDAR data","summary":"  Data collected by different modalities can provide a wealth of complementary\ninformation, such as hyperspectral image (HSI) to offer rich spectral-spatial\nproperties, synthetic aperture radar (SAR) to provide structural information\nabout the Earth's surface, and light detection and ranging (LiDAR) to cover\naltitude information about ground elevation. Therefore, a natural idea is to\ncombine multimodal images for refined and accurate land-cover interpretation.\nAlthough many efforts have been attempted to achieve multi-source remote\nsensing image classification, there are still three issues as follows: 1)\nindiscriminate feature representation without sufficiently considering modal\nheterogeneity, 2) abundant features and complex computations associated with\nmodeling long-range dependencies, and 3) overfitting phenomenon caused by\nsparsely labeled samples. To overcome the above barriers, a transformer-based\nheterogeneously salient graph representation (THSGR) approach is proposed in\nthis paper. First, a multimodal heterogeneous graph encoder is presented to\nencode distinctively non-Euclidean structural features from heterogeneous data.\nThen, a self-attention-free multi-convolutional modulator is designed for\neffective and efficient long-term dependency modeling. Finally, a mean forward\nis put forward in order to avoid overfitting. Based on the above structures,\nthe proposed model is able to break through modal gaps to obtain differentiated\ngraph representation with competitive time cost, even for a small fraction of\ntraining samples. Experiments and analyses on three benchmark datasets with\nvarious state-of-the-art (SOTA) methods show the performance of the proposed\napproach.\n","authors":["Jiaqi Yang","Bo Du","Liangpei Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.10320v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10319v1","updated":"2023-11-17T04:04:29Z","published":"2023-11-17T04:04:29Z","title":"Shifting to Machine Supervision: Annotation-Efficient Semi and\n  Self-Supervised Learning for Automatic Medical Image Segmentation and\n  Classification","summary":"  Advancements in clinical treatment and research are limited by supervised\nlearning techniques that rely on large amounts of annotated data, an expensive\ntask requiring many hours of clinical specialists' time. In this paper, we\npropose using self-supervised and semi-supervised learning. These techniques\nperform an auxiliary task that is label-free, scaling up machine-supervision is\neasier compared with fully-supervised techniques. This paper proposes S4MI\n(Self-Supervision and Semi-Supervision for Medical Imaging), our pipeline to\nleverage advances in self and semi-supervision learning. We benchmark them on\nthree medical imaging datasets to analyze their efficacy for classification and\nsegmentation. This advancement in self-supervised learning with 10% annotation\nperformed better than 100% annotation for the classification of most datasets.\nThe semi-supervised approach yielded favorable outcomes for segmentation,\noutperforming the fully-supervised approach by using 50% fewer labels in all\nthree datasets.\n","authors":["Pranav Singh","Raviteja Chukkapalli","Shravan Chaudhari","Luoyao Chen","Mei Chen","Jinqian Pan","Craig Smuda","Jacopo Cirrone"],"pdf_url":"https://arxiv.org/pdf/2311.10319v1.pdf","comment":"Seventeen pages (incl. references), five figures, and one table.\n  (Under Review)"},{"id":"http://arxiv.org/abs/2311.10318v1","updated":"2023-11-17T04:04:11Z","published":"2023-11-17T04:04:11Z","title":"Nonparametric Teaching for Multiple Learners","summary":"  We study the problem of teaching multiple learners simultaneously in the\nnonparametric iterative teaching setting, where the teacher iteratively\nprovides examples to the learner for accelerating the acquisition of a target\nconcept. This problem is motivated by the gap between current single-learner\nteaching setting and the real-world scenario of human instruction where a\nteacher typically imparts knowledge to multiple students. Under the new problem\nformulation, we introduce a novel framework -- Multi-learner Nonparametric\nTeaching (MINT). In MINT, the teacher aims to instruct multiple learners, with\neach learner focusing on learning a scalar-valued target model. To achieve\nthis, we frame the problem as teaching a vector-valued target model and extend\nthe target model space from a scalar-valued reproducing kernel Hilbert space\nused in single-learner scenarios to a vector-valued space. Furthermore, we\ndemonstrate that MINT offers significant teaching speed-up over repeated\nsingle-learner teaching, particularly when the multiple learners can\ncommunicate with each other. Lastly, we conduct extensive experiments to\nvalidate the practicality and efficiency of MINT.\n","authors":["Chen Zhang","Xiaofeng Cao","Weiyang Liu","Ivor Tsang","James Kwok"],"pdf_url":"https://arxiv.org/pdf/2311.10318v1.pdf","comment":"NeurIPS 2023 (31 pages, 20 figures)"},{"id":"http://arxiv.org/abs/2311.10306v1","updated":"2023-11-17T03:33:09Z","published":"2023-11-17T03:33:09Z","title":"MPSeg : Multi-Phase strategy for coronary artery Segmentation","summary":"  Accurate segmentation of coronary arteries is a pivotal process in assessing\ncardiovascular diseases. However, the intricate structure of the cardiovascular\nsystem presents significant challenges for automatic segmentation, especially\nwhen utilizing methodologies like the SYNTAX Score, which relies extensively on\ndetailed structural information for precise risk stratification. To address\nthese difficulties and cater to this need, we present MPSeg, an innovative\nmulti-phase strategy designed for coronary artery segmentation. Our approach\nspecifically accommodates these structural complexities and adheres to the\nprinciples of the SYNTAX Score. Initially, our method segregates vessels into\ntwo categories based on their unique morphological characteristics: Left\nCoronary Artery (LCA) and Right Coronary Artery (RCA). Specialized ensemble\nmodels are then deployed for each category to execute the challenging\nsegmentation task. Due to LCA's higher complexity over RCA, a refinement model\nis utilized to scrutinize and correct initial class predictions on segmented\nareas. Notably, our approach demonstrated exceptional effectiveness when\nevaluated in the Automatic Region-based Coronary Artery Disease diagnostics\nusing x-ray angiography imagEs (ARCADE) Segmentation Detection Algorithm\nchallenge at MICCAI 2023.\n","authors":["Jonghoe Ku","Yong-Hee Lee","Junsup Shin","In Kyu Lee","Hyun-Woo Kim"],"pdf_url":"https://arxiv.org/pdf/2311.10306v1.pdf","comment":"MICCAI 2023 Conference ARCADE Challenge"},{"id":"http://arxiv.org/abs/2311.10305v1","updated":"2023-11-17T03:32:11Z","published":"2023-11-17T03:32:11Z","title":"Semi-supervised ViT knowledge distillation network with style transfer\n  normalization for colorectal liver metastases survival prediction","summary":"  Colorectal liver metastases (CLM) significantly impact colon cancer patients,\ninfluencing survival based on systemic chemotherapy response. Traditional\nmethods like tumor grading scores (e.g., tumor regression grade - TRG) for\nprognosis suffer from subjectivity, time constraints, and expertise demands.\nCurrent machine learning approaches often focus on radiological data, yet the\nrelevance of histological images for survival predictions, capturing intricate\ntumor microenvironment characteristics, is gaining recognition. To address\nthese limitations, we propose an end-to-end approach for automated prognosis\nprediction using histology slides stained with H&E and HPS. We first employ a\nGenerative Adversarial Network (GAN) for slide normalization to reduce staining\nvariations and improve the overall quality of the images that are used as input\nto our prediction pipeline. We propose a semi-supervised model to perform\ntissue classification from sparse annotations, producing feature maps. We use\nan attention-based approach that weighs the importance of different slide\nregions in producing the final classification results. We exploit the extracted\nfeatures for the metastatic nodules and surrounding tissue to train a prognosis\nmodel. In parallel, we train a vision Transformer (ViT) in a knowledge\ndistillation framework to replicate and enhance the performance of the\nprognosis prediction. In our evaluation on a clinical dataset of 258 patients,\nour approach demonstrates superior performance with c-indexes of 0.804 (0.014)\nfor OS and 0.733 (0.014) for TTR. Achieving 86.9% to 90.3% accuracy in\npredicting TRG dichotomization and 78.5% to 82.1% accuracy for the 3-class TRG\nclassification task, our approach outperforms comparative methods. Our proposed\npipeline can provide automated prognosis for pathologists and oncologists, and\ncan greatly promote precision medicine progress in managing CLM patients.\n","authors":["Mohamed El Amine Elforaici","Emmanuel Montagnon","Francisco Perdigon Romero","William Trung Le","Feryel Azzi","Dominique Trudel","Bich Nguyen","Simon Turcotte","An Tang","Samuel Kadoury"],"pdf_url":"https://arxiv.org/pdf/2311.10305v1.pdf","comment":"16 pages, 7 figures and 7 tables. Submitted to Medical Journal\n  Analysis (MedIA) journal"},{"id":"http://arxiv.org/abs/2311.10296v1","updated":"2023-11-17T03:01:37Z","published":"2023-11-17T03:01:37Z","title":"BiHRNet: A Binary high-resolution network for Human Pose Estimation","summary":"  Human Pose Estimation (HPE) plays a crucial role in computer vision\napplications. However, it is difficult to deploy state-of-the-art models on\nresouce-limited devices due to the high computational costs of the networks. In\nthis work, a binary human pose estimator named BiHRNet(Binary HRNet) is\nproposed, whose weights and activations are expressed as $\\pm$1. BiHRNet\nretains the keypoint extraction ability of HRNet, while using fewer computing\nresources by adapting binary neural network (BNN). In order to reduce the\naccuracy drop caused by network binarization, two categories of techniques are\nproposed in this work. For optimizing the training process for binary pose\nestimator, we propose a new loss function combining KL divergence loss with\nAWing loss, which makes the binary network obtain more comprehensive output\ndistribution from its real-valued counterpart to reduce information loss caused\nby binarization. For designing more binarization-friendly structures, we\npropose a new information reconstruction bottleneck called IR Bottleneck to\nretain more information in the initial stage of the network. In addition, we\nalso propose a multi-scale basic block called MS-Block for information\nretention. Our work has less computation cost with few precision drop.\nExperimental results demonstrate that BiHRNet achieves a PCKh of 87.9 on the\nMPII dataset, which outperforms all binary pose estimation networks. On the\nchallenging of COCO dataset, the proposed method enables the binary neural\nnetwork to achieve 70.8 mAP, which is better than most tested lightweight\nfull-precision networks.\n","authors":["Zhicheng Zhang","Xueyao Sun","Yonghao Dang","Jianqin Yin"],"pdf_url":"https://arxiv.org/pdf/2311.10296v1.pdf","comment":"12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.10293v1","updated":"2023-11-17T02:48:20Z","published":"2023-11-17T02:48:20Z","title":"Hierarchical Pruning of Deep Ensembles with Focal Diversity","summary":"  Deep neural network ensembles combine the wisdom of multiple deep neural\nnetworks to improve the generalizability and robustness over individual\nnetworks. It has gained increasing popularity to study deep ensemble techniques\nin the deep learning community. Some mission-critical applications utilize a\nlarge number of deep neural networks to form deep ensembles to achieve desired\naccuracy and resilience, which introduces high time and space costs for\nensemble execution. However, it still remains a critical challenge whether a\nsmall subset of the entire deep ensemble can achieve the same or better\ngeneralizability and how to effectively identify these small deep ensembles for\nimproving the space and time efficiency of ensemble execution. This paper\npresents a novel deep ensemble pruning approach, which can efficiently identify\nsmaller deep ensembles and provide higher ensemble accuracy than the entire\ndeep ensemble of a large number of member networks. Our hierarchical ensemble\npruning approach (HQ) leverages three novel ensemble pruning techniques. First,\nwe show that the focal diversity metrics can accurately capture the\ncomplementary capacity of the member networks of an ensemble, which can guide\nensemble pruning. Second, we design a focal diversity based hierarchical\npruning approach, which will iteratively find high quality deep ensembles with\nlow cost and high accuracy. Third, we develop a focal diversity consensus\nmethod to integrate multiple focal diversity metrics to refine ensemble pruning\nresults, where smaller deep ensembles can be effectively identified to offer\nhigh accuracy, high robustness and high efficiency. Evaluated using popular\nbenchmark datasets, we demonstrate that the proposed hierarchical ensemble\npruning approach can effectively identify high quality deep ensembles with\nbetter generalizability while being more time and space efficient in ensemble\ndecision making.\n","authors":["Yanzhao Wu","Ka-Ho Chow","Wenqi Wei","Ling Liu"],"pdf_url":"https://arxiv.org/pdf/2311.10293v1.pdf","comment":"To appear on ACM Transactions on Intelligent Systems and Technology"},{"id":"http://arxiv.org/abs/2308.14113v3","updated":"2023-11-17T02:37:13Z","published":"2023-08-27T14:07:57Z","title":"Semantic-aware Consistency Network for Cloth-changing Person\n  Re-Identification","summary":"  Cloth-changing Person Re-Identification (CC-ReID) is a challenging task that\naims to retrieve the target person across multiple surveillance cameras when\nclothing changes might happen. Despite recent progress in CC-ReID, existing\napproaches are still hindered by the interference of clothing variations since\nthey lack effective constraints to keep the model consistently focused on\nclothing-irrelevant regions. To address this issue, we present a Semantic-aware\nConsistency Network (SCNet) to learn identity-related semantic features by\nproposing effective consistency constraints. Specifically, we generate the\nblack-clothing image by erasing pixels in the clothing area, which explicitly\nmitigates the interference from clothing variations. In addition, to fully\nexploit the fine-grained identity information, a head-enhanced attention module\nis introduced, which learns soft attention maps by utilizing the proposed\npart-based matching loss to highlight head information. We further design a\nsemantic consistency loss to facilitate the learning of high-level\nidentity-related semantic features, forcing the model to focus on semantically\nconsistent cloth-irrelevant regions. By using the consistency constraint, our\nmodel does not require any extra auxiliary segmentation module to generate the\nblack-clothing image or locate the head region during the inference stage.\nExtensive experiments on four cloth-changing person Re-ID datasets (LTCC, PRCC,\nVc-Clothes, and DeepChange) demonstrate that our proposed SCNet makes\nsignificant improvements over prior state-of-the-art approaches. Our code is\navailable at: https://github.com/Gpn-star/SCNet.\n","authors":["Peini Guo","Hong Liu","Jianbing Wu","Guoquan Wang","Tao Wang"],"pdf_url":"https://arxiv.org/pdf/2308.14113v3.pdf","comment":"Accepted by ACM MM 2023"},{"id":"http://arxiv.org/abs/2311.05836v3","updated":"2023-11-17T02:35:52Z","published":"2023-11-10T02:47:15Z","title":"UMedNeRF: Uncertainty-aware Single View Volumetric Rendering for Medical\n  Neural Radiance Fields","summary":"  In the field of clinical medicine, computed tomography (CT) is an effective\nmedical imaging modality for the diagnosis of various pathologies. Compared\nwith X-ray images, CT images can provide more information, including\nmulti-planar slices and three-dimensional structures for clinical diagnosis.\nHowever, CT imaging requires patients to be exposed to large doses of ionizing\nradiation for a long time, which may cause irreversible physical harm. In this\npaper, we propose an Uncertainty-aware MedNeRF (UMedNeRF) network based on\ngenerated radiation fields. The network can learn a continuous representation\nof CT projections from 2D X-ray images by obtaining the internal structure and\ndepth information and using adaptive loss weights to ensure the quality of the\ngenerated images. Our model is trained on publicly available knee and chest\ndatasets, and we show the results of CT projection rendering with a single\nX-ray and compare our method with other methods based on generated radiation\nfields.\n","authors":["Jing Hu","Qinrui Fan","Shu Hu","Siwei Lyu","Xi Wu","Xin Wang"],"pdf_url":"https://arxiv.org/pdf/2311.05836v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10281v1","updated":"2023-11-17T02:01:19Z","published":"2023-11-17T02:01:19Z","title":"SSASS: Semi-Supervised Approach for Stenosis Segmentation","summary":"  Coronary artery stenosis is a critical health risk, and its precise\nidentification in Coronary Angiography (CAG) can significantly aid medical\npractitioners in accurately evaluating the severity of a patient's condition.\nThe complexity of coronary artery structures combined with the inherent noise\nin X-ray images poses a considerable challenge to this task. To tackle these\nobstacles, we introduce a semi-supervised approach for cardiovascular stenosis\nsegmentation. Our strategy begins with data augmentation, specifically tailored\nto replicate the structural characteristics of coronary arteries. We then apply\na pseudo-label-based semi-supervised learning technique that leverages the data\ngenerated through our augmentation process. Impressively, our approach\ndemonstrated an exceptional performance in the Automatic Region-based Coronary\nArtery Disease diagnostics using x-ray angiography imagEs (ARCADE) Stenosis\nDetection Algorithm challenge by utilizing a single model instead of relying on\nan ensemble of multiple models. This success emphasizes our method's capability\nand efficiency in providing an automated solution for accurately assessing\nstenosis severity from medical imaging data.\n","authors":["In Kyu Lee","Junsup Shin","Yong-Hee Lee","Jonghoe Ku","Hyun-Woo Kim"],"pdf_url":"https://arxiv.org/pdf/2311.10281v1.pdf","comment":"MICCAI 2023 Conference ARCADE Challenge"},{"id":"http://arxiv.org/abs/2311.10065v2","updated":"2023-11-17T01:59:10Z","published":"2023-11-16T18:02:10Z","title":"Visual Environment Assessment for Safe Autonomous Quadrotor Landing","summary":"  Autonomous identification and evaluation of safe landing zones are of\nparamount importance for ensuring the safety and effectiveness of aerial robots\nin the event of system failures, low battery, or the successful completion of\nspecific tasks. In this paper, we present a novel approach for detection and\nassessment of potential landing sites for safe quadrotor landing. Our solution\nefficiently integrates 2D and 3D environmental information, eliminating the\nneed for external aids such as GPS and computationally intensive elevation\nmaps. The proposed pipeline combines semantic data derived from a Neural\nNetwork (NN), to extract environmental features, with geometric data obtained\nfrom a disparity map, to extract critical geometric attributes such as slope,\nflatness, and roughness. We define several cost metrics based on these\nattributes to evaluate safety, stability, and suitability of regions in the\nenvironments and identify the most suitable landing area. Our approach runs in\nreal-time on quadrotors equipped with limited computational capabilities.\nExperimental results conducted in diverse environments demonstrate that the\nproposed method can effectively assess and identify suitable landing areas,\nenabling the safe and autonomous landing of a quadrotor.\n","authors":["Mattia Secchiero","Nishanth Bobbili","Yang Zhou","Giuseppe Loianno"],"pdf_url":"https://arxiv.org/pdf/2311.10065v2.pdf","comment":"7 pages, 5 figures, 1 table, submitted to IEEE International\n  Conference on Robotics and Automation (ICRA), 2024"},{"id":"http://arxiv.org/abs/2311.10278v1","updated":"2023-11-17T01:55:15Z","published":"2023-11-17T01:55:15Z","title":"Physics-Enhanced Multi-fidelity Learning for Optical Surface Imprint","summary":"  Human fingerprints serve as one unique and powerful characteristic for each\nperson, from which policemen can recognize the identity. Similar to humans,\nmany natural bodies and intrinsic mechanical qualities can also be uniquely\nidentified from surface characteristics. To measure the elasto-plastic\nproperties of one material, one formally sharp indenter is pushed into the\nmeasured body under constant force and retracted, leaving a unique residual\nimprint of the minute size from several micrometers to nanometers. However, one\ngreat challenge is how to map the optical image of this residual imprint into\nthe real wanted mechanical properties, i.e., the tensile force curve. In this\npaper, we propose a novel method to use multi-fidelity neural networks (MFNN)\nto solve this inverse problem. We first actively train the NN model via pure\nsimulation data, and then bridge the sim-to-real gap via transfer learning. The\nmost innovative part is that we use NN to dig out the unknown physics and also\nimplant the known physics into the transfer learning framework, thus highly\nimproving the model stability and decreasing the data requirement. This work\nserves as one great example of applying machine learning into the real\nexperimental research, especially under the constraints of data limitation and\nfidelity variance.\n","authors":["Yongchao Chen"],"pdf_url":"https://arxiv.org/pdf/2311.10278v1.pdf","comment":"8 pages, 4 figures, NeurIPS 2023 Workshop on Adaptive Experimental\n  Design and Active Learning in the Real World"},{"id":"http://arxiv.org/abs/2311.10269v1","updated":"2023-11-17T01:29:16Z","published":"2023-11-17T01:29:16Z","title":"Interpretable pap smear cell representation for cervical cancer\n  screening","summary":"  Screening is critical for prevention and early detection of cervical cancer\nbut it is time-consuming and laborious. Supervised deep convolutional neural\nnetworks have been developed to automate pap smear screening and the results\nare promising. However, the interest in using only normal samples to train deep\nneural networks has increased owing to class imbalance problems and\nhigh-labeling costs that are both prevalent in healthcare. In this study, we\nintroduce a method to learn explainable deep cervical cell representations for\npap smear cytology images based on one class classification using variational\nautoencoders. Findings demonstrate that a score can be calculated for cell\nabnormality without training models with abnormal samples and localize\nabnormality to interpret our results with a novel metric based on absolute\ndifference in cross entropy in agglomerative clustering. The best model that\ndiscriminates squamous cell carcinoma (SCC) from normals gives 0.908 +- 0.003\narea under operating characteristic curve (AUC) and one that discriminates\nhigh-grade epithelial lesion (HSIL) 0.920 +- 0.002 AUC. Compared to other\nclustering methods, our method enhances the V-measure and yields higher\nhomogeneity scores, which more effectively isolate different abnormality\nregions, aiding in the interpretation of our results. Evaluation using in-house\nand additional open dataset show that our model can discriminate abnormality\nwithout the need of additional training of deep models.\n","authors":["Yu Ando","Nora Jee-Young Park and","Gun Oh Chong","Seokhwan Ko","Donghyeon Lee","Junghwan Cho","Hyungsoo Han"],"pdf_url":"https://arxiv.org/pdf/2311.10269v1.pdf","comment":"20 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.09574v2","updated":"2023-11-17T01:24:47Z","published":"2023-11-16T05:17:14Z","title":"LymphoML: An interpretable artificial intelligence-based method\n  identifies morphologic features that correlate with lymphoma subtype","summary":"  The accurate classification of lymphoma subtypes using hematoxylin and eosin\n(H&E)-stained tissue is complicated by the wide range of morphological features\nthese cancers can exhibit. We present LymphoML - an interpretable machine\nlearning method that identifies morphologic features that correlate with\nlymphoma subtypes. Our method applies steps to process H&E-stained tissue\nmicroarray cores, segment nuclei and cells, compute features encompassing\nmorphology, texture, and architecture, and train gradient-boosted models to\nmake diagnostic predictions. LymphoML's interpretable models, developed on a\nlimited volume of H&E-stained tissue, achieve non-inferior diagnostic accuracy\nto pathologists using whole-slide images and outperform black box deep-learning\non a dataset of 670 cases from Guatemala spanning 8 lymphoma subtypes. Using\nSHapley Additive exPlanation (SHAP) analysis, we assess the impact of each\nfeature on model prediction and find that nuclear shape features are most\ndiscriminative for DLBCL (F1-score: 78.7%) and classical Hodgkin lymphoma\n(F1-score: 74.5%). Finally, we provide the first demonstration that a model\ncombining features from H&E-stained tissue with features from a standardized\npanel of 6 immunostains results in a similar diagnostic accuracy (85.3%) to a\n46-stain panel (86.1%).\n","authors":["Vivek Shankar","Xiaoli Yang","Vrishab Krishna","Brent Tan","Oscar Silva","Rebecca Rojansky","Andrew Ng","Fabiola Valvert","Edward Briercheck","David Weinstock","Yasodha Natkunam","Sebastian Fernandez-Pol","Pranav Rajpurkar"],"pdf_url":"https://arxiv.org/pdf/2311.09574v2.pdf","comment":"To be published in Proceedings of the 3rd Machine Learning for Health\n  symposium, Proceedings of Machine Learning Research (PMLR)"},{"id":"http://arxiv.org/abs/2311.10261v1","updated":"2023-11-17T01:07:37Z","published":"2023-11-17T01:07:37Z","title":"Vision meets mmWave Radar: 3D Object Perception Benchmark for Autonomous\n  Driving","summary":"  Sensor fusion is crucial for an accurate and robust perception system on\nautonomous vehicles. Most existing datasets and perception solutions focus on\nfusing cameras and LiDAR. However, the collaboration between camera and radar\nis significantly under-exploited. The incorporation of rich semantic\ninformation from the camera, and reliable 3D information from the radar can\npotentially achieve an efficient, cheap, and portable solution for 3D object\nperception tasks. It can also be robust to different lighting or all-weather\ndriving scenarios due to the capability of mmWave radars. In this paper, we\nintroduce the CRUW3D dataset, including 66K synchronized and well-calibrated\ncamera, radar, and LiDAR frames in various driving scenarios. Unlike other\nlarge-scale autonomous driving datasets, our radar data is in the format of\nradio frequency (RF) tensors that contain not only 3D location information but\nalso spatio-temporal semantic information. This kind of radar format can enable\nmachine learning models to generate more reliable object perception results\nafter interacting and fusing the information or features between the camera and\nradar.\n","authors":["Yizhou Wang","Jen-Hao Cheng","Jui-Te Huang","Sheng-Yao Kuan","Qiqian Fu","Chiming Ni","Shengyu Hao","Gaoang Wang","Guanbin Xing","Hui Liu","Jenq-Neng Hwang"],"pdf_url":"https://arxiv.org/pdf/2311.10261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10251v1","updated":"2023-11-17T00:44:56Z","published":"2023-11-17T00:44:56Z","title":"UniMOS: A Universal Framework For Multi-Organ Segmentation Over\n  Label-Constrained Datasets","summary":"  Machine learning models for medical images can help physicians diagnose and\nmanage diseases. However, due to the fact that medical image annotation\nrequires a great deal of manpower and expertise, as well as the fact that\nclinical departments perform image annotation based on task orientation, there\nis the problem of having fewer medical image annotation data with more\nunlabeled data and having many datasets that annotate only a single organ. In\nthis paper, we present UniMOS, the first universal framework for achieving the\nutilization of fully and partially labeled images as well as unlabeled images.\nSpecifically, we construct a Multi-Organ Segmentation (MOS) module over\nfully/partially labeled data as the basenet and designed a new target adaptive\nloss. Furthermore, we incorporate a semi-supervised training module that\ncombines consistent regularization and pseudolabeling techniques on unlabeled\ndata, which significantly improves the segmentation of unlabeled data.\nExperiments show that the framework exhibits excellent performance in several\nmedical image segmentation tasks compared to other advanced methods, and also\nsignificantly improves data utilization and reduces annotation cost. Code and\nmodels are available at: https://github.com/lw8807001/UniMOS.\n","authors":["Can Li","Sheng Shao","Junyi Qu","Shuchao Pang","Mehmet A. Orgun"],"pdf_url":"https://arxiv.org/pdf/2311.10251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10245v1","updated":"2023-11-17T00:28:19Z","published":"2023-11-17T00:28:19Z","title":"Segment Anything in Defect Detection","summary":"  Defect detection plays a crucial role in infrared non-destructive testing\nsystems, offering non-contact, safe, and efficient inspection capabilities.\nHowever, challenges such as low resolution, high noise, and uneven heating in\ninfrared thermal images hinder comprehensive and accurate defect detection. In\nthis study, we propose DefectSAM, a novel approach for segmenting defects on\nhighly noisy thermal images based on the widely adopted model, Segment Anything\n(SAM)\\cite{kirillov2023segany}. Harnessing the power of a meticulously curated\ndataset generated through labor-intensive lab experiments and valuable prompts\nfrom experienced experts, DefectSAM surpasses existing state-of-the-art\nsegmentation algorithms and achieves significant improvements in defect\ndetection rates. Notably, DefectSAM excels in detecting weaker and smaller\ndefects on complex and irregular surfaces, reducing the occurrence of missed\ndetections and providing more accurate defect size estimations. Experimental\nstudies conducted on various materials have validated the effectiveness of our\nsolutions in defect detection, which hold significant potential to expedite the\nevolution of defect detection tools, enabling enhanced inspection capabilities\nand accuracy in defect identification.\n","authors":["Bozhen Hu","Bin Gao","Cheng Tan","Tongle Wu","Stan Z. Li"],"pdf_url":"https://arxiv.org/pdf/2311.10245v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2311.10697v1","updated":"2023-11-17T18:32:17Z","published":"2023-11-17T18:32:17Z","title":"PEFT-MedAware: Large Language Model for Medical Awareness","summary":"  Chat models are capable of answering a wide range of questions, however, the\naccuracy of their responses is highly uncertain. In this research, we propose a\nspecialized PEFT-MedAware model where we utilize parameter-efficient\nfine-tuning (PEFT) to enhance the Falcon-1b large language model on specialized\nMedQuAD data consisting of 16,407 medical QA pairs, leveraging only 0.44% of\nits trainable parameters to enhance computational efficiency. The paper adopts\ndata preprocessing and PEFT to optimize model performance, complemented by a\nBitsAndBytesConfig for efficient transformer training. The resulting model was\ncapable of outperforming other LLMs in medical question-answering tasks in\nspecific domains with greater accuracy utilizing limited computational\nresources making it suitable for deployment in resource-constrained\nenvironments. We propose further improvements through expanded datasets, larger\nmodels, and feedback mechanisms for sustained medical relevancy. Our work\nhighlights the efficiency gains and specialized capabilities of PEFT in medical\nAI, outpacing standard models in precision without extensive resource demands.\nThe proposed model and data are released for research purposes only.\n","authors":["Keivalya Pandya"],"pdf_url":"https://arxiv.org/pdf/2311.10697v1.pdf","comment":"7 pages, 1 figure, submitted to the Artificial Intelligence in\n  Medicine Journal"},{"id":"http://arxiv.org/abs/2303.04689v2","updated":"2023-11-17T16:47:49Z","published":"2023-03-07T17:22:38Z","title":"A Privacy Preserving System for Movie Recommendations Using Federated\n  Learning","summary":"  Recommender systems have become ubiquitous in the past years. They solve the\ntyranny of choice problem faced by many users, and are utilized by many online\nbusinesses to drive engagement and sales. Besides other criticisms, like\ncreating filter bubbles within social networks, recommender systems are often\nreproved for collecting considerable amounts of personal data. However, to\npersonalize recommendations, personal information is fundamentally required. A\nrecent distributed learning scheme called federated learning has made it\npossible to learn from personal user data without its central collection.\nConsequently, we present a recommender system for movie recommendations, which\nprovides privacy and thus trustworthiness on multiple levels: First and\nforemost, it is trained using federated learning and thus, by its very nature,\nprivacy-preserving, while still enabling users to benefit from global insights.\nFurthermore, a novel federated learning scheme, called FedQ, is employed, which\nnot only addresses the problem of non-i.i.d.-ness and small local datasets, but\nalso prevents input data reconstruction attacks by aggregating client updates\nearly. Finally, to reduce the communication overhead, compression is applied,\nwhich significantly compresses the exchanged neural network parametrizations to\na fraction of their original size. We conjecture that this may also improve\ndata privacy through its lossy quantization stage.\n","authors":["David Neumann","Andreas Lutz","Karsten Müller","Wojciech Samek"],"pdf_url":"https://arxiv.org/pdf/2303.04689v2.pdf","comment":"Accepted by the ACM TORS Special Issue on Trustworthy Recommender\n  Systems"},{"id":"http://arxiv.org/abs/2311.10635v1","updated":"2023-11-17T16:42:57Z","published":"2023-11-17T16:42:57Z","title":"Ex2Vec: Characterizing Users and Items from the Mere Exposure Effect","summary":"  The traditional recommendation framework seeks to connect user and content,\nby finding the best match possible based on users past interaction. However, a\ngood content recommendation is not necessarily similar to what the user has\nchosen in the past. As humans, users naturally evolve, learn, forget, get\nbored, they change their perspective of the world and in consequence, of the\nrecommendable content. One well known mechanism that affects user interest is\nthe Mere Exposure Effect: when repeatedly exposed to stimuli, users' interest\ntends to rise with the initial exposures, reaching a peak, and gradually\ndecreasing thereafter, resulting in an inverted-U shape. Since previous\nresearch has shown that the magnitude of the effect depends on a number of\ninteresting factors such as stimulus complexity and familiarity, leveraging\nthis effect is a way to not only improve repeated recommendation but to gain a\nmore in-depth understanding of both users and stimuli. In this work we present\n(Mere) Exposure2Vec (Ex2Vec) our model that leverages the Mere Exposure Effect\nin repeat consumption to derive user and item characterization and track user\ninterest evolution. We validate our model through predicting future music\nconsumption based on repetition and discuss its implications for recommendation\nscenarios where repetition is common.\n","authors":["Bruno Sguerra","Viet-Anh Tran","Romain Hennequin"],"pdf_url":"https://arxiv.org/pdf/2311.10635v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10567v1","updated":"2023-11-17T15:06:59Z","published":"2023-11-17T15:06:59Z","title":"Cross-Modal Search and Exploration of Greek Painted Pottery","summary":"  This paper focuses on digitally-supported research methods for an important\ngroup of cultural heritage objects, the Greek pottery, especially with figured\ndecoration. The design, development and application of new digital methods for\nsearching, comparing, and visually exploring these vases needs an\ninterdisciplinary approach to effectively analyse the various features of the\nvases, like shape, decoration, and manufacturing techniques, and relationships\nbetween the vases. We motivate the need and opportunities by a multimodal\nrepresentation of the objects, including 3D shape, material, and painting. We\nthen illustrate a range of innovative methods for these representations,\nincluding quantified surface and capacity comparison, material analysis, image\nflattening from 3D objects, retrieval and comparison of shapes and paintings,\nand multidimensional data visualization. We also discuss challenges and future\nwork in this area.\n","authors":["Elisabeth Trinkl","Stephan Karl","Stefan Lengauer","Reinhold Preiner","Tobias Schreck"],"pdf_url":"https://arxiv.org/pdf/2311.10567v1.pdf","comment":"14 pages, 10 figures, preprint for a book chapter, supplementary\n  video available at https://youtu.be/x_Xg0vy3nJY"},{"id":"http://arxiv.org/abs/2311.10501v1","updated":"2023-11-17T13:02:25Z","published":"2023-11-17T13:02:25Z","title":"Collaborative Word-based Pre-trained Item Representation for\n  Transferable Recommendation","summary":"  Item representation learning (IRL) plays an essential role in recommender\nsystems, especially for sequential recommendation. Traditional sequential\nrecommendation models usually utilize ID embeddings to represent items, which\nare not shared across different domains and lack the transferable ability.\nRecent studies use pre-trained language models (PLM) for item text embeddings\n(text-based IRL) that are universally applicable across domains. However, the\nexisting text-based IRL is unaware of the important collaborative filtering\n(CF) information. In this paper, we propose CoWPiRec, an approach of\nCollaborative Word-based Pre-trained item representation for Recommendation. To\neffectively incorporate CF information into text-based IRL, we convert the\nitem-level interaction data to a word graph containing word-level\ncollaborations. Subsequently, we design a novel pre-training task to align the\nword-level semantic- and CF-related item representation. Extensive experimental\nresults on multiple public datasets demonstrate that compared to\nstate-of-the-art transferable sequential recommenders, CoWPiRec achieves\nsignificantly better performances in both fine-tuning and zero-shot settings\nfor cross-scenario recommendation and effectively alleviates the cold-start\nissue. The code is available at: https://github.com/ysh-1998/CoWPiRec.\n","authors":["Shenghao Yang","Chenyang Wang","Yankai Liu","Kangping Xu","Weizhi Ma","Yiqun Liu","Min Zhang","Haitao Zeng","Junlan Feng","Chao Deng"],"pdf_url":"https://arxiv.org/pdf/2311.10501v1.pdf","comment":"Accepted by ICDM 2023"},{"id":"http://arxiv.org/abs/2208.06265v3","updated":"2023-11-17T12:38:19Z","published":"2022-08-10T08:28:46Z","title":"Trustworthy Recommender Systems","summary":"  Recommender systems (RSs) aim to help users to effectively retrieve items of\ntheir interests from a large catalogue. For a quite long period of time,\nresearchers and practitioners have been focusing on developing accurate RSs.\nRecent years have witnessed an increasing number of threats to RSs, coming from\nattacks, system and user generated noise, system bias. As a result, it has\nbecome clear that a strict focus on RS accuracy is limited and the research\nmust consider other important factors, e.g., trustworthiness. For end users, a\ntrustworthy RS (TRS) should not only be accurate, but also transparent,\nunbiased and fair as well as robust to noise or attacks. These observations\nactually led to a paradigm shift of the research on RSs: from accuracy-oriented\nRSs to TRSs. However, researchers lack a systematic overview and discussion of\nthe literature in this novel and fast developing field of TRSs. To this end, in\nthis paper, we provide an overview of TRSs, including a discussion of the\nmotivation and basic concepts of TRSs, a presentation of the challenges in\nbuilding TRSs, and a perspective on the future directions in this area. We also\nprovide a novel conceptual framework to support the construction of TRSs.\n","authors":["Shoujin Wang","Xiuzhen Zhang","Yan Wang","Huan Liu","Francesco Ricci"],"pdf_url":"https://arxiv.org/pdf/2208.06265v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10348v1","updated":"2023-11-17T06:35:38Z","published":"2023-11-17T06:35:38Z","title":"A Comparative Analysis of Retrievability and PageRank Measures","summary":"  The accessibility of documents within a collection holds a pivotal role in\nInformation Retrieval, signifying the ease of locating specific content in a\ncollection of documents. This accessibility can be achieved via two distinct\navenues. The first is through some retrieval model using a keyword or other\nfeature-based search, and the other is where a document can be navigated using\nlinks associated with them, if available. Metrics such as PageRank, Hub, and\nAuthority illuminate the pathways through which documents can be discovered\nwithin the network of content while the concept of Retrievability is used to\nquantify the ease with which a document can be found by a retrieval model. In\nthis paper, we compare these two perspectives, PageRank and retrievability, as\nthey quantify the importance and discoverability of content in a corpus.\nThrough empirical experimentation on benchmark datasets, we demonstrate a\nsubtle similarity between retrievability and PageRank particularly\ndistinguishable for larger datasets.\n","authors":["Aman Sinha","Priyanshu Raj Mall","Dwaipayan Roy"],"pdf_url":"https://arxiv.org/pdf/2311.10348v1.pdf","comment":"Accepted at FIRE 2023"},{"id":"http://arxiv.org/abs/2204.06522v2","updated":"2023-11-17T05:17:45Z","published":"2022-04-03T16:50:30Z","title":"Graph Enhanced BERT for Query Understanding","summary":"  Query understanding plays a key role in exploring users' search intents and\nfacilitating users to locate their most desired information. However, it is\ninherently challenging since it needs to capture semantic information from\nshort and ambiguous queries and often requires massive task-specific labeled\ndata. In recent years, pre-trained language models (PLMs) have advanced various\nnatural language processing tasks because they can extract general semantic\ninformation from large-scale corpora. Therefore, there are unprecedented\nopportunities to adopt PLMs for query understanding. However, there is a gap\nbetween the goal of query understanding and existing pre-training strategies --\nthe goal of query understanding is to boost search performance while existing\nstrategies rarely consider this goal. Thus, directly applying them to query\nunderstanding is sub-optimal. On the other hand, search logs contain user\nclicks between queries and urls that provide rich users' search behavioral\ninformation on queries beyond their content. Therefore, in this paper, we aim\nto fill this gap by exploring search logs. In particular, to incorporate search\nlogs into pre-training, we first construct a query graph where nodes are\nqueries and two queries are connected if they lead to clicks on the same urls.\nThen we propose a novel graph-enhanced pre-training framework, GE-BERT, which\ncan leverage both query content and the query graph. In other words, GE-BERT\ncan capture both the semantic information and the users' search behavioral\ninformation of queries. Extensive experiments on various query understanding\ntasks have demonstrated the effectiveness of the proposed framework.\n","authors":["Juanhui Li","Yao Ma","Wei Zeng","Suqi Cheng","Jiliang Tang","Shuaiqiang Wang","Dawei Yin"],"pdf_url":"https://arxiv.org/pdf/2204.06522v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.10230v2","updated":"2023-11-17T04:00:09Z","published":"2023-07-15T11:49:43Z","title":"Prompt Tuning on Graph-augmented Low-resource Text Classification","summary":"  Text classification is a fundamental problem in information retrieval with\nmany real-world applications, such as predicting the topics of online articles\nand the categories of e-commerce product descriptions. However, low-resource\ntext classification, with no or few labeled samples, presents a serious concern\nfor supervised learning. Meanwhile, many text data are inherently grounded on a\nnetwork structure, such as a hyperlink/citation network for online articles,\nand a user-item purchase network for e-commerce products. These graph\nstructures capture rich semantic relationships, which can potentially augment\nlow-resource text classification. In this paper, we propose a novel model\ncalled Graph-Grounded Pre-training and Prompting (G2P2) to address low-resource\ntext classification in a two-pronged approach. During pre-training, we propose\nthree graph interaction-based contrastive strategies to jointly pre-train a\ngraph-text model; during downstream classification, we explore handcrafted\ndiscrete prompts and continuous prompt tuning for the jointly pre-trained model\nto achieve zero- and few-shot classification, respectively. Besides, for\ngeneralizing continuous prompts to unseen classes, we propose conditional\nprompt tuning on graphs (G2P2$^*$). Extensive experiments on four real-world\ndatasets demonstrate the strength of G2P2 in zero- and few-shot low-resource\ntext classification tasks, and illustrate the advantage of G2P2$^*$ in dealing\nwith unseen classes.\n","authors":["Zhihao Wen","Yuan Fang"],"pdf_url":"https://arxiv.org/pdf/2307.10230v2.pdf","comment":"26 pages, journal under review. arXiv admin note: substantial text\n  overlap with arXiv:2305.03324"},{"id":"http://arxiv.org/abs/2311.00423v4","updated":"2023-11-17T02:33:34Z","published":"2023-11-01T10:27:44Z","title":"LLMRec: Large Language Models with Graph Augmentation for Recommendation","summary":"  The problem of data sparsity has long been a challenge in recommendation\nsystems, and previous studies have attempted to address this issue by\nincorporating side information. However, this approach often introduces side\neffects such as noise, availability issues, and low data quality, which in turn\nhinder the accurate modeling of user preferences and adversely impact\nrecommendation performance. In light of the recent advancements in large\nlanguage models (LLMs), which possess extensive knowledge bases and strong\nreasoning capabilities, we propose a novel framework called LLMRec that\nenhances recommender systems by employing three simple yet effective LLM-based\ngraph augmentation strategies. Our approach leverages the rich content\navailable within online platforms (e.g., Netflix, MovieLens) to augment the\ninteraction graph in three ways: (i) reinforcing user-item interaction egde,\n(ii) enhancing the understanding of item node attributes, and (iii) conducting\nuser node profiling, intuitively from the natural language perspective. By\nemploying these strategies, we address the challenges posed by sparse implicit\nfeedback and low-quality side information in recommenders. Besides, to ensure\nthe quality of the augmentation, we develop a denoised data robustification\nmechanism that includes techniques of noisy implicit feedback pruning and\nMAE-based feature enhancement that help refine the augmented data and improve\nits reliability. Furthermore, we provide theoretical analysis to support the\neffectiveness of LLMRec and clarify the benefits of our method in facilitating\nmodel optimization. Experimental results on benchmark datasets demonstrate the\nsuperiority of our LLM-based augmentation approach over state-of-the-art\ntechniques. To ensure reproducibility, we have made our code and augmented data\npublicly available at: https://github.com/HKUDS/LLMRec.git\n","authors":["Wei Wei","Xubin Ren","Jiabin Tang","Qinyong Wang","Lixin Su","Suqi Cheng","Junfeng Wang","Dawei Yin","Chao Huang"],"pdf_url":"https://arxiv.org/pdf/2311.00423v4.pdf","comment":"WSDM 2024 Oral Presentation"},{"id":"http://arxiv.org/abs/2311.10796v1","updated":"2023-11-17T05:55:36Z","published":"2023-11-17T05:55:36Z","title":"Emotion-Aware Music Recommendation System: Enhancing User Experience\n  Through Real-Time Emotional Context","summary":"  This study addresses the deficiency in conventional music recommendation\nsystems by focusing on the vital role of emotions in shaping users music\nchoices. These systems often disregard the emotional context, relying\npredominantly on past listening behavior and failing to consider the dynamic\nand evolving nature of users emotional preferences. This gap leads to several\nlimitations. Users may receive recommendations that do not match their current\nmood, which diminishes the quality of their music experience. Furthermore,\nwithout accounting for emotions, the systems might overlook undiscovered or\nlesser-known songs that have a profound emotional impact on users. To combat\nthese limitations, this research introduces an AI model that incorporates\nemotional context into the song recommendation process. By accurately detecting\nusers real-time emotions, the model can generate personalized song\nrecommendations that align with the users emotional state. This approach aims\nto enhance the user experience by offering music that resonates with their\ncurrent mood, elicits the desired emotions, and creates a more immersive and\nmeaningful listening experience. By considering emotional context in the song\nrecommendation process, the proposed model offers an opportunity for a more\npersonalized and emotionally resonant musical journey.\n","authors":["Tina Babu","Rekha R Nair","Geetha A"],"pdf_url":"https://arxiv.org/pdf/2311.10796v1.pdf","comment":"6 pages"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2311.10710v1","updated":"2023-11-17T18:59:35Z","published":"2023-11-17T18:59:35Z","title":"Machine learning phase transitions: Connections to the Fisher\n  information","summary":"  Despite the widespread use and success of machine-learning techniques for\ndetecting phase transitions from data, their working principle and fundamental\nlimits remain elusive. Here, we explain the inner workings and identify\npotential failure modes of these techniques by rooting popular machine-learning\nindicators of phase transitions in information-theoretic concepts. Using tools\nfrom information geometry, we prove that several machine-learning indicators of\nphase transitions approximate the square root of the system's (quantum) Fisher\ninformation from below -- a quantity that is known to indicate phase\ntransitions but is often difficult to compute from data. We numerically\ndemonstrate the quality of these bounds for phase transitions in classical and\nquantum systems.\n","authors":["Julian Arnold","Niels Lörch","Flemming Holtorf","Frank Schäfer"],"pdf_url":"https://arxiv.org/pdf/2311.10710v1.pdf","comment":"7+11 pages, 2+3 figures"},{"id":"http://arxiv.org/abs/2311.10709v1","updated":"2023-11-17T18:59:04Z","published":"2023-11-17T18:59:04Z","title":"Emu Video: Factorizing Text-to-Video Generation by Explicit Image\n  Conditioning","summary":"  We present Emu Video, a text-to-video generation model that factorizes the\ngeneration into two steps: first generating an image conditioned on the text,\nand then generating a video conditioned on the text and the generated image. We\nidentify critical design decisions--adjusted noise schedules for diffusion, and\nmulti-stage training--that enable us to directly generate high quality and high\nresolution videos, without requiring a deep cascade of models as in prior work.\nIn human evaluations, our generated videos are strongly preferred in quality\ncompared to all prior work--81% vs. Google's Imagen Video, 90% vs. Nvidia's\nPYOCO, and 96% vs. Meta's Make-A-Video. Our model outperforms commercial\nsolutions such as RunwayML's Gen2 and Pika Labs. Finally, our factorizing\napproach naturally lends itself to animating images based on a user's text\nprompt, where our generations are preferred 96% over prior work.\n","authors":["Rohit Girdhar","Mannat Singh","Andrew Brown","Quentin Duval","Samaneh Azadi","Sai Saketh Rambhatla","Akbar Shah","Xi Yin","Devi Parikh","Ishan Misra"],"pdf_url":"https://arxiv.org/pdf/2311.10709v1.pdf","comment":"Project page: https://emu-video.metademolab.com"},{"id":"http://arxiv.org/abs/2311.10708v1","updated":"2023-11-17T18:58:16Z","published":"2023-11-17T18:58:16Z","title":"SelfEval: Leveraging the discriminative nature of generative models for\n  evaluation","summary":"  In this work, we show that text-to-image generative models can be 'inverted'\nto assess their own text-image understanding capabilities in a completely\nautomated manner.\n  Our method, called SelfEval, uses the generative model to compute the\nlikelihood of real images given text prompts, making the generative model\ndirectly applicable to discriminative tasks.\n  Using SelfEval, we repurpose standard datasets created for evaluating\nmultimodal text-image discriminative models to evaluate generative models in a\nfine-grained manner: assessing their performance on attribute binding, color\nrecognition, counting, shape recognition, spatial understanding.\n  To the best of our knowledge SelfEval is the first automated metric to show a\nhigh degree of agreement for measuring text-faithfulness with the gold-standard\nhuman evaluations across multiple models and benchmarks.\n  Moreover, SelfEval enables us to evaluate generative models on challenging\ntasks such as Winoground image-score where they demonstrate competitive\nperformance to discriminative models.\n  We also show severe drawbacks of standard automated metrics such as\nCLIP-score to measure text faithfulness on benchmarks such as DrawBench, and\nhow SelfEval sidesteps these issues.\n  We hope SelfEval enables easy and reliable automated evaluation for diffusion\nmodels.\n","authors":["Sai Saketh Rambhatla","Ishan Misra"],"pdf_url":"https://arxiv.org/pdf/2311.10708v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10707v1","updated":"2023-11-17T18:57:40Z","published":"2023-11-17T18:57:40Z","title":"Multimodal Representation Learning by Alternating Unimodal Adaptation","summary":"  Multimodal learning, which integrates data from diverse sensory modes, plays\na pivotal role in artificial intelligence. However, existing multimodal\nlearning methods often struggle with challenges where some modalities appear\nmore dominant than others during multimodal learning, resulting in suboptimal\nperformance. To address this challenge, we propose MLA (Multimodal Learning\nwith Alternating Unimodal Adaptation). MLA reframes the conventional joint\nmultimodal learning process by transforming it into an alternating unimodal\nlearning process, thereby minimizing interference between modalities.\nSimultaneously, it captures cross-modal interactions through a shared head,\nwhich undergoes continuous optimization across different modalities. This\noptimization process is controlled by a gradient modification mechanism to\nprevent the shared head from losing previously acquired information. During the\ninference phase, MLA utilizes a test-time uncertainty-based model fusion\nmechanism to integrate multimodal information. Extensive experiments are\nconducted on five diverse datasets, encompassing scenarios with complete\nmodalities and scenarios with missing modalities. These experiments demonstrate\nthe superiority of MLA over competing prior approaches.\n","authors":["Xiaohui Zhang","Jaehong Yoon","Mohit Bansal","Huaxiu Yao"],"pdf_url":"https://arxiv.org/pdf/2311.10707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10090v2","updated":"2023-11-17T18:49:04Z","published":"2023-11-16T18:58:43Z","title":"JaxMARL: Multi-Agent RL Environments in JAX","summary":"  Benchmarks play an important role in the development of machine learning\nalgorithms. For example, research in reinforcement learning (RL) has been\nheavily influenced by available environments and benchmarks. However, RL\nenvironments are traditionally run on the CPU, limiting their scalability with\ntypical academic compute. Recent advancements in JAX have enabled the wider use\nof hardware acceleration to overcome these computational hurdles, enabling\nmassively parallel RL training pipelines and environments. This is particularly\nuseful for multi-agent reinforcement learning (MARL) research. First of all,\nmultiple agents must be considered at each environment step, adding\ncomputational burden, and secondly, the sample complexity is increased due to\nnon-stationarity, decentralised partial observability, or other MARL\nchallenges. In this paper, we present JaxMARL, the first open-source code base\nthat combines ease-of-use with GPU enabled efficiency, and supports a large\nnumber of commonly used MARL environments as well as popular baseline\nalgorithms. When considering wall clock time, our experiments show that per-run\nour JAX-based training pipeline is up to 12500x faster than existing\napproaches. This enables efficient and thorough evaluations, with the potential\nto alleviate the evaluation crisis of the field. We also introduce and\nbenchmark SMAX, a vectorised, simplified version of the popular StarCraft\nMulti-Agent Challenge, which removes the need to run the StarCraft II game\nengine. This not only enables GPU acceleration, but also provides a more\nflexible MARL environment, unlocking the potential for self-play,\nmeta-learning, and other future applications in MARL. We provide code at\nhttps://github.com/flairox/jaxmarl.\n","authors":["Alexander Rutherford","Benjamin Ellis","Matteo Gallici","Jonathan Cook","Andrei Lupu","Gardar Ingvarsson","Timon Willi","Akbir Khan","Christian Schroeder de Witt","Alexandra Souly","Saptarashmi Bandyopadhyay","Mikayel Samvelyan","Minqi Jiang","Robert Tjarko Lange","Shimon Whiteson","Bruno Lacerda","Nick Hawes","Tim Rocktaschel","Chris Lu","Jakob Nicolaus Foerster"],"pdf_url":"https://arxiv.org/pdf/2311.10090v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10701v1","updated":"2023-11-17T18:45:00Z","published":"2023-11-17T18:45:00Z","title":"SpACNN-LDVAE: Spatial Attention Convolutional Latent Dirichlet\n  Variational Autoencoder for Hyperspectral Pixel Unmixing","summary":"  The Hyperspectral Unxming problem is to find the pure spectral signal of the\nunderlying materials (endmembers) and their proportions (abundances). The\nproposed method builds upon the recently proposed method, Latent Dirichlet\nVariational Autoencoder (LDVAE). It assumes that abundances can be encoded as\nDirichlet Distributions while mixed pixels and endmembers are represented by\nMultivariate Normal Distributions. However, LDVAE does not leverage spatial\ninformation present in an HSI; we propose an Isotropic CNN encoder with spatial\nattention to solve the hyperspectral unmixing problem. We evaluated our model\non Samson, Hydice Urban, Cuprite, and OnTech-HSI-Syn-21 datasets. Our model\nalso leverages the transfer learning paradigm for Cuprite Dataset, where we\ntrain the model on synthetic data and evaluate it on real-world data. We are\nable to observe the improvement in the results for the endmember extraction and\nabundance estimation by incorporating the spatial information. Code can be\nfound at https://github.com/faisalqureshi/cnn-ldvae\n","authors":["Soham Chitnis","Kiran Mantripragada","Faisal Z. Qureshi"],"pdf_url":"https://arxiv.org/pdf/2311.10701v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10699v1","updated":"2023-11-17T18:43:32Z","published":"2023-11-17T18:43:32Z","title":"Using linear initialisation to improve speed of convergence and\n  fully-trained error in Autoencoders","summary":"  Good weight initialisation is an important step in successful training of\nArtificial Neural Networks. Over time a number of improvements have been\nproposed to this process. In this paper we introduce a novel weight\ninitialisation technique called the Straddled Matrix Initialiser. This\ninitialisation technique is motivated by our assumption that major,\nglobal-scale relationships in data are linear with only smaller effects\nrequiring complex non-linearities. Combination of Straddled Matrix and ReLU\nactivation function initialises a Neural Network as a de facto linear model,\nwhich we postulate should be a better starting point for optimisation given our\nassumptions. We test this by training autoencoders on three datasets using\nStraddled Matrix and seven other state-of-the-art weight initialisation\ntechniques. In all our experiments the Straddeled Matrix Initialiser clearly\noutperforms all other methods.\n","authors":["Marcel Marais","Mate Hartstein","George Cevora"],"pdf_url":"https://arxiv.org/pdf/2311.10699v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10697v1","updated":"2023-11-17T18:32:17Z","published":"2023-11-17T18:32:17Z","title":"PEFT-MedAware: Large Language Model for Medical Awareness","summary":"  Chat models are capable of answering a wide range of questions, however, the\naccuracy of their responses is highly uncertain. In this research, we propose a\nspecialized PEFT-MedAware model where we utilize parameter-efficient\nfine-tuning (PEFT) to enhance the Falcon-1b large language model on specialized\nMedQuAD data consisting of 16,407 medical QA pairs, leveraging only 0.44% of\nits trainable parameters to enhance computational efficiency. The paper adopts\ndata preprocessing and PEFT to optimize model performance, complemented by a\nBitsAndBytesConfig for efficient transformer training. The resulting model was\ncapable of outperforming other LLMs in medical question-answering tasks in\nspecific domains with greater accuracy utilizing limited computational\nresources making it suitable for deployment in resource-constrained\nenvironments. We propose further improvements through expanded datasets, larger\nmodels, and feedback mechanisms for sustained medical relevancy. Our work\nhighlights the efficiency gains and specialized capabilities of PEFT in medical\nAI, outpacing standard models in precision without extensive resource demands.\nThe proposed model and data are released for research purposes only.\n","authors":["Keivalya Pandya"],"pdf_url":"https://arxiv.org/pdf/2311.10697v1.pdf","comment":"7 pages, 1 figure, submitted to the Artificial Intelligence in\n  Medicine Journal"},{"id":"http://arxiv.org/abs/2311.10680v1","updated":"2023-11-17T18:01:58Z","published":"2023-11-17T18:01:58Z","title":"Optimal Embedding Dimension for Sparse Subspace Embeddings","summary":"  A random $m\\times n$ matrix $S$ is an oblivious subspace embedding (OSE) with\nparameters $\\epsilon>0$, $\\delta\\in(0,1/3)$ and $d\\leq m\\leq n$, if for any\n$d$-dimensional subspace $W\\subseteq R^n$,\n  $P\\big(\\,\\forall_{x\\in W}\\ (1+\\epsilon)^{-1}\\|x\\|\\leq\\|Sx\\|\\leq\n(1+\\epsilon)\\|x\\|\\,\\big)\\geq 1-\\delta.$\n  It is known that the embedding dimension of an OSE must satisfy $m\\geq d$,\nand for any $\\theta > 0$, a Gaussian embedding matrix with $m\\geq (1+\\theta) d$\nis an OSE with $\\epsilon = O_\\theta(1)$. However, such optimal embedding\ndimension is not known for other embeddings. Of particular interest are sparse\nOSEs, having $s\\ll m$ non-zeros per column, with applications to problems such\nas least squares regression and low-rank approximation.\n  We show that, given any $\\theta > 0$, an $m\\times n$ random matrix $S$ with\n$m\\geq (1+\\theta)d$ consisting of randomly sparsified $\\pm1/\\sqrt s$ entries\nand having $s= O(\\log^4(d))$ non-zeros per column, is an oblivious subspace\nembedding with $\\epsilon = O_{\\theta}(1)$. Our result addresses the main open\nquestion posed by Nelson and Nguyen (FOCS 2013), who conjectured that sparse\nOSEs can achieve $m=O(d)$ embedding dimension, and it improves on\n$m=O(d\\log(d))$ shown by Cohen (SODA 2016). We use this to construct the first\noblivious subspace embedding with $O(d)$ embedding dimension that can be\napplied faster than current matrix multiplication time, and to obtain an\noptimal single-pass algorithm for least squares regression. We further extend\nour results to construct even sparser non-oblivious embeddings, leading to the\nfirst subspace embedding with low distortion $\\epsilon=o(1)$ and optimal\nembedding dimension $m=O(d/\\epsilon^2)$ that can be applied in current matrix\nmultiplication time.\n","authors":["Shabarish Chenakkod","Michał Dereziński","Xiaoyu Dong","Mark Rudelson"],"pdf_url":"https://arxiv.org/pdf/2311.10680v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10678v1","updated":"2023-11-17T18:00:20Z","published":"2023-11-17T18:00:20Z","title":"Distilling and Retrieving Generalizable Knowledge for Robot Manipulation\n  via Language Corrections","summary":"  Today's robot policies exhibit subpar performance when faced with the\nchallenge of generalizing to novel environments. Human corrective feedback is a\ncrucial form of guidance to enable such generalization. However, adapting to\nand learning from online human corrections is a non-trivial endeavor: not only\ndo robots need to remember human feedback over time to retrieve the right\ninformation in new settings and reduce the intervention rate, but also they\nwould need to be able to respond to feedback that can be arbitrary corrections\nabout high-level human preferences to low-level adjustments to skill\nparameters. In this work, we present Distillation and Retrieval of Online\nCorrections (DROC), a large language model (LLM)-based system that can respond\nto arbitrary forms of language feedback, distill generalizable knowledge from\ncorrections, and retrieve relevant past experiences based on textual and visual\nsimilarity for improving performance in novel settings. DROC is able to respond\nto a sequence of online language corrections that address failures in both\nhigh-level task plans and low-level skill primitives. We demonstrate that DROC\neffectively distills the relevant information from the sequence of online\ncorrections in a knowledge base and retrieves that knowledge in settings with\nnew task or object instances. DROC outperforms other techniques that directly\ngenerate robot code via LLMs by using only half of the total number of\ncorrections needed in the first round and requires little to no corrections\nafter two iterations. We show further results, videos, prompts and code on\nhttps://sites.google.com/stanford.edu/droc .\n","authors":["Lihan Zha","Yuchen Cui","Li-Heng Lin","Minae Kwon","Montserrat Gonzalez Arenas","Andy Zeng","Fei Xia","Dorsa Sadigh"],"pdf_url":"https://arxiv.org/pdf/2311.10678v1.pdf","comment":"8 pages, 4 figures, videos and code links on website\n  https://sites.google.com/stanford.edu/droc"},{"id":"http://arxiv.org/abs/2311.10671v1","updated":"2023-11-17T17:43:11Z","published":"2023-11-17T17:43:11Z","title":"Fuse It or Lose It: Deep Fusion for Multimodal Simulation-Based\n  Inference","summary":"  We present multimodal neural posterior estimation (MultiNPE), a method to\nintegrate heterogeneous data from different sources in simulation-based\ninference with neural networks. Inspired by advances in attention-based deep\nfusion learning, it empowers researchers to analyze data from different domains\nand infer the parameters of complex mathematical models with increased\naccuracy. We formulate different multimodal fusion approaches for MultiNPE\n(early, late, and hybrid) and evaluate their performance in three challenging\nnumerical experiments. MultiNPE not only outperforms na\\\"ive baselines on a\nbenchmark model, but also achieves superior inference on representative\nscientific models from neuroscience and cardiology. In addition, we\nsystematically investigate the impact of partially missing data on the\ndifferent fusion strategies. Across our different experiments, late and hybrid\nfusion techniques emerge as the methods of choice for practical applications of\nmultimodal simulation-based inference.\n","authors":["Marvin Schmitt","Stefan T. Radev","Paul-Christian Bürkner"],"pdf_url":"https://arxiv.org/pdf/2311.10671v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10665v1","updated":"2023-11-17T17:36:26Z","published":"2023-11-17T17:36:26Z","title":"Online Calibration of Deep Learning Sub-Models for Hybrid Numerical\n  Modeling Systems","summary":"  Artificial intelligence and deep learning are currently reshaping numerical\nsimulation frameworks by introducing new modeling capabilities. These\nframeworks are extensively investigated in the context of model correction and\nparameterization where they demonstrate great potential and often outperform\ntraditional physical models. Most of these efforts in defining hybrid dynamical\nsystems follow {offline} learning strategies in which the neural\nparameterization (called here sub-model) is trained to output an ideal\ncorrection. Yet, these hybrid models can face hard limitations when defining\nwhat should be a relevant sub-model response that would translate into a good\nforecasting performance. End-to-end learning schemes, also referred to as\nonline learning, could address such a shortcoming by allowing the deep learning\nsub-models to train on historical data. However, defining end-to-end training\nschemes for the calibration of neural sub-models in hybrid systems requires\nworking with an optimization problem that involves the solver of the physical\nequations. Online learning methodologies thus require the numerical model to be\ndifferentiable, which is not the case for most modeling systems. To overcome\nthis difficulty and bypass the differentiability challenge of physical models,\nwe present an efficient and practical online learning approach for hybrid\nsystems. The method, called EGA for Euler Gradient Approximation, assumes an\nadditive neural correction to the physical model, and an explicit Euler\napproximation of the gradients. We demonstrate that the EGA converges to the\nexact gradients in the limit of infinitely small time steps. Numerical\nexperiments are performed on various case studies, including prototypical\nocean-atmosphere dynamics. Results show significant improvements over offline\nlearning, highlighting the potential of end-to-end online learning for hybrid\nmodeling.\n","authors":["Said Ouala","Bertrand Chapron","Fabrice Collard","Lucile Gaultier","Ronan Fablet"],"pdf_url":"https://arxiv.org/pdf/2311.10665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10653v1","updated":"2023-11-17T17:14:42Z","published":"2023-11-17T17:14:42Z","title":"Learning Realistic Joint Space Boundaries for Range of Motion Analysis\n  of Healthy and Impaired Human Arms","summary":"  A realistic human kinematic model that satisfies anatomical constraints is\nessential for human-robot interaction, biomechanics and robot-assisted\nrehabilitation. Modeling realistic joint constraints, however, is challenging\nas human arm motion is constrained by joint limits, inter- and intra-joint\ndependencies, self-collisions, individual capabilities and muscular or\nneurological constraints which are difficult to represent. Hence, physicians\nand researchers have relied on simple box-constraints, ignoring important\nanatomical factors. In this paper, we propose a data-driven method to learn\nrealistic anatomically constrained upper-limb range of motion (RoM) boundaries\nfrom motion capture data. This is achieved by fitting a one-class support\nvector machine to a dataset of upper-limb joint space exploration motions with\nan efficient hyper-parameter tuning scheme. Our approach outperforms similar\nworks focused on valid RoM learning. Further, we propose an impairment index\n(II) metric that offers a quantitative assessment of capability/impairment when\ncomparing healthy and impaired arms. We validate the metric on healthy subjects\nphysically constrained to emulate hemiplegia and different disability levels as\nstroke patients.\n","authors":["Shafagh Keyvanian","Michelle J. Johnson","Nadia Figueroa"],"pdf_url":"https://arxiv.org/pdf/2311.10653v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.00690v2","updated":"2023-11-17T17:09:56Z","published":"2023-11-01T17:45:52Z","title":"What User Behaviors Make the Differences During the Process of Visual\n  Analytics?","summary":"  The understanding of visual analytics process can benefit visualization\nresearchers from multiple aspects, including improving visual designs and\ndeveloping advanced interaction functions. However, the log files of user\nbehaviors are still hard to analyze due to the complexity of sensemaking and\nour lack of knowledge on the related user behaviors. This work presents a study\non a comprehensive data collection of user behaviors, and our analysis approach\nwith time-series classification methods. We have chosen a classical\nvisualization application, Covid-19 data analysis, with common analysis tasks\ncovering geo-spatial, time-series and multi-attributes. Our user study collects\nuser behaviors on a diverse set of visualization tasks with two comparable\nsystems, desktop and immersive visualizations. We summarize the classification\nresults with three time-series machine learning algorithms at two scales, and\nexplore the influences of behavior features. Our results reveal that user\nbehaviors can be distinguished during the process of visual analytics and there\nis a potentially strong association between the physical behaviors of users and\nthe visualization tasks they perform. We also demonstrate the usage of our\nmodels by interpreting open sessions of visual analytics, which provides an\nautomatic way to study sensemaking without tedious manual annotations.\n","authors":["Shahin Doroudian","Zekun Wu","Aidong Lu"],"pdf_url":"https://arxiv.org/pdf/2311.00690v2.pdf","comment":"The authors have decided to withdraw the paper due to identified\n  critical errors. These errors were deemed substantial enough to compromise\n  the integrity and reliability of the research findings presented in the\n  paper. As a result, the authors have chosen to retract the paper to maintain\n  academic standards and transparency in the dissemination of scientific\n  knowledge"},{"id":"http://arxiv.org/abs/2311.10648v1","updated":"2023-11-17T17:06:59Z","published":"2023-11-17T17:06:59Z","title":"Self-trained Panoptic Segmentation","summary":"  Panoptic segmentation is an important computer vision task which combines\nsemantic and instance segmentation. It plays a crucial role in domains of\nmedical image analysis, self-driving vehicles, and robotics by providing a\ncomprehensive understanding of visual environments. Traditionally, deep\nlearning panoptic segmentation models have relied on dense and accurately\nannotated training data, which is expensive and time consuming to obtain.\nRecent advancements in self-supervised learning approaches have shown great\npotential in leveraging synthetic and unlabelled data to generate pseudo-labels\nusing self-training to improve the performance of instance and semantic\nsegmentation models. The three available methods for self-supervised panoptic\nsegmentation use proposal-based transformer architectures which are\ncomputationally expensive, complicated and engineered for specific tasks. The\naim of this work is to develop a framework to perform embedding-based\nself-supervised panoptic segmentation using self-training in a\nsynthetic-to-real domain adaptation problem setting.\n","authors":["Shourya Verma"],"pdf_url":"https://arxiv.org/pdf/2311.10648v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.17290v2","updated":"2023-11-17T17:05:44Z","published":"2023-09-29T14:48:24Z","title":"In search of dispersed memories: Generative diffusion models are\n  associative memory networks","summary":"  Uncovering the mechanisms behind long-term memory is one of the most\nfascinating open problems in neuroscience and artificial intelligence.\nArtificial associative memory networks have been used to formalize important\naspects of biological memory. Generative diffusion models are a type of\ngenerative machine learning techniques that have shown great performance in\nmany tasks. Like associative memory systems, these networks define a dynamical\nsystem that converges to a set of target states. In this work we show that\ngenerative diffusion models can be interpreted as energy-based models and that,\nwhen trained on discrete patterns, their energy function is (asymptotically)\nidentical to that of modern Hopfield networks. This equivalence allows us to\ninterpret the supervised training of diffusion models as a synaptic learning\nprocess that encodes the associative dynamics of a modern Hopfield network in\nthe weight structure of a deep neural network. Leveraging this connection, we\nformulate a generalized framework for understanding the formation of long-term\nmemory, where creative generation and memory recall can be seen as parts of a\nunified continuum.\n","authors":["Luca Ambrogioni"],"pdf_url":"https://arxiv.org/pdf/2309.17290v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.20654v3","updated":"2023-11-17T17:01:26Z","published":"2023-10-31T17:24:40Z","title":"Closed Drafting as a Case Study for First-Principle Interpretability,\n  Memory, and Generalizability in Deep Reinforcement Learning","summary":"  Closed drafting or \"pick and pass\" is a popular game mechanic where each\nround players select a card or other playable element from their hand and pass\nthe rest to the next player. In this paper, we establish first-principle\nmethods for studying the interpretability, generalizability, and memory of Deep\nQ-Network (DQN) models playing closed drafting games. In particular, we use a\npopular family of closed drafting games called \"Sushi Go Party\", in which we\nachieve state-of-the-art performance. We fit decision rules to interpret the\ndecision-making strategy of trained DRL agents by comparing them to the ranking\npreferences of different types of human players. As Sushi Go Party can be\nexpressed as a set of closely-related games based on the set of cards in play,\nwe quantify the generalizability of DRL models trained on various sets of\ncards, establishing a method to benchmark agent performance as a function of\nenvironment unfamiliarity. Using the explicitly calculable memory of other\nplayer's hands in closed drafting games, we create measures of the ability of\nDRL models to learn memory.\n","authors":["Ryan Rezai","Jason Wang"],"pdf_url":"https://arxiv.org/pdf/2310.20654v3.pdf","comment":"4 pages, 4 figures, equal contribution"},{"id":"http://arxiv.org/abs/2311.10642v1","updated":"2023-11-17T16:58:52Z","published":"2023-11-17T16:58:52Z","title":"Rethinking Attention: Exploring Shallow Feed-Forward Neural Networks as\n  an Alternative to Attention Layers in Transformers","summary":"  This work presents an analysis of the effectiveness of using standard shallow\nfeed-forward networks to mimic the behavior of the attention mechanism in the\noriginal Transformer model, a state-of-the-art architecture for\nsequence-to-sequence tasks. We substitute key elements of the attention\nmechanism in the Transformer with simple feed-forward networks, trained using\nthe original components via knowledge distillation. Our experiments, conducted\non the IWSLT2017 dataset, reveal the capacity of these \"attentionless\nTransformers\" to rival the performance of the original architecture. Through\nrigorous ablation studies, and experimenting with various replacement network\ntypes and sizes, we offer insights that support the viability of our approach.\nThis not only sheds light on the adaptability of shallow feed-forward networks\nin emulating attention mechanisms but also underscores their potential to\nstreamline complex architectures for sequence-to-sequence tasks.\n","authors":["Vukasin Bozic","Danilo Dordervic","Daniele Coppola","Joseph Thommes"],"pdf_url":"https://arxiv.org/pdf/2311.10642v1.pdf","comment":"Accepted at AAAI24(https://aaai.org/aaai-conference/)"},{"id":"http://arxiv.org/abs/2311.10640v1","updated":"2023-11-17T16:55:14Z","published":"2023-11-17T16:55:14Z","title":"Multi-delay arterial spin-labeled perfusion estimation with biophysics\n  simulation and deep learning","summary":"  Purpose: To develop biophysics-based method for estimating perfusion Q from\narterial spin labeling (ASL) images using deep learning. Methods: A 3D U-Net\n(QTMnet) was trained to estimate perfusion from 4D tracer propagation images.\nThe network was trained and tested on simulated 4D tracer concentration data\nbased on artificial vasculature structure generated by constrained constructive\noptimization (CCO) method. The trained network was further tested in a\nsynthetic brain ASL image based on vasculature network extracted from magnetic\nresonance (MR) angiography. The estimations from both trained network and a\nconventional kinetic model were compared in ASL images acquired from eight\nhealthy volunteers. Results: QTMnet accurately reconstructed perfusion Q from\nconcentration data. Relative error of the synthetic brain ASL image was 7.04%\nfor perfusion Q, lower than the error using single-delay ASL model: 25.15% for\nQ, and multi-delay ASL model: 12.62% for perfusion Q. Conclusion: QTMnet\nprovides accurate estimation on perfusion parameters and is a promising\napproach as a clinical ASL MRI image processing pipeline.\n","authors":["Renjiu Hu","Qihao Zhang","Pascal Spincemaille","Thanh D. Nguyen","Yi Wang"],"pdf_url":"https://arxiv.org/pdf/2311.10640v1.pdf","comment":"32 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.10638v1","updated":"2023-11-17T16:50:00Z","published":"2023-11-17T16:50:00Z","title":"Concept-free Causal Disentanglement with Variational Graph Auto-Encoder","summary":"  In disentangled representation learning, the goal is to achieve a compact\nrepresentation that consists of all interpretable generative factors in the\nobservational data. Learning disentangled representations for graphs becomes\nincreasingly important as graph data rapidly grows. Existing approaches often\nrely on Variational Auto-Encoder (VAE) or its causal structure learning-based\nrefinement, which suffer from sub-optimality in VAEs due to the independence\nfactor assumption and unavailability of concept labels, respectively. In this\npaper, we propose an unsupervised solution, dubbed concept-free causal\ndisentanglement, built on a theoretically provable tight upper bound\napproximating the optimal factor. This results in an SCM-like causal structure\nmodeling that directly learns concept structures from data. Based on this idea,\nwe propose Concept-free Causal VGAE (CCVGAE) by incorporating a novel causal\ndisentanglement layer into Variational Graph Auto-Encoder. Furthermore, we\nprove concept consistency under our concept-free causal disentanglement\nframework, hence employing it to enhance the meta-learning framework, called\nconcept-free causal Meta-Graph (CC-Meta-Graph). We conduct extensive\nexperiments to demonstrate the superiority of the proposed models: CCVGAE and\nCC-Meta-Graph, reaching up to $29\\%$ and $11\\%$ absolute improvements over\nbaselines in terms of AUC, respectively.\n","authors":["Jingyun Feng","Lin Zhang","Lili Yang"],"pdf_url":"https://arxiv.org/pdf/2311.10638v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04689v2","updated":"2023-11-17T16:47:49Z","published":"2023-03-07T17:22:38Z","title":"A Privacy Preserving System for Movie Recommendations Using Federated\n  Learning","summary":"  Recommender systems have become ubiquitous in the past years. They solve the\ntyranny of choice problem faced by many users, and are utilized by many online\nbusinesses to drive engagement and sales. Besides other criticisms, like\ncreating filter bubbles within social networks, recommender systems are often\nreproved for collecting considerable amounts of personal data. However, to\npersonalize recommendations, personal information is fundamentally required. A\nrecent distributed learning scheme called federated learning has made it\npossible to learn from personal user data without its central collection.\nConsequently, we present a recommender system for movie recommendations, which\nprovides privacy and thus trustworthiness on multiple levels: First and\nforemost, it is trained using federated learning and thus, by its very nature,\nprivacy-preserving, while still enabling users to benefit from global insights.\nFurthermore, a novel federated learning scheme, called FedQ, is employed, which\nnot only addresses the problem of non-i.i.d.-ness and small local datasets, but\nalso prevents input data reconstruction attacks by aggregating client updates\nearly. Finally, to reduce the communication overhead, compression is applied,\nwhich significantly compresses the exchanged neural network parametrizations to\na fraction of their original size. We conjecture that this may also improve\ndata privacy through its lossy quantization stage.\n","authors":["David Neumann","Andreas Lutz","Karsten Müller","Wojciech Samek"],"pdf_url":"https://arxiv.org/pdf/2303.04689v2.pdf","comment":"Accepted by the ACM TORS Special Issue on Trustworthy Recommender\n  Systems"},{"id":"http://arxiv.org/abs/2204.09603v3","updated":"2023-11-17T16:42:46Z","published":"2022-04-20T16:33:01Z","title":"Comparing Deep Reinforcement Learning Algorithms in Two-Echelon Supply\n  Chains","summary":"  In this study, we analyze and compare the performance of state-of-the-art\ndeep reinforcement learning algorithms for solving the supply chain inventory\nmanagement problem. This complex sequential decision-making problem consists of\ndetermining the optimal quantity of products to be produced and shipped across\ndifferent warehouses over a given time horizon. In particular, we present a\nmathematical formulation of a two-echelon supply chain environment with\nstochastic and seasonal demand, which allows managing an arbitrary number of\nwarehouses and product types. Through a rich set of numerical experiments, we\ncompare the performance of different deep reinforcement learning algorithms\nunder various supply chain structures, topologies, demands, capacities, and\ncosts. The results of the experimental plan indicate that deep reinforcement\nlearning algorithms outperform traditional inventory management strategies,\nsuch as the static (s, Q)-policy. Furthermore, this study provides detailed\ninsight into the design and development of an open-source software library that\nprovides a customizable environment for solving the supply chain inventory\nmanagement problem using a wide range of data-driven approaches.\n","authors":["Francesco Stranieri","Fabio Stella"],"pdf_url":"https://arxiv.org/pdf/2204.09603v3.pdf","comment":"The paper has been accepted for presentation and inclusion in the\n  proceedings of the AI for Manufacturing workshop (AI4M), co-located with the\n  ECML PKDD 2023 (European Conference on Machine Learning and Principles and\n  Practice of Knowledge Discovery in Databases). For supplementary material and\n  source code, please visit https://github.com/frenkowski/SCIMAI-Gym"},{"id":"http://arxiv.org/abs/2311.10633v1","updated":"2023-11-17T16:41:35Z","published":"2023-11-17T16:41:35Z","title":"Predicting the Probability of Collision of a Satellite with Space\n  Debris: A Bayesian Machine Learning Approach","summary":"  Space is becoming more crowded in Low Earth Orbit due to increased space\nactivity. Such a dense space environment increases the risk of collisions\nbetween space objects endangering the whole space population. Therefore, the\nneed to consider collision avoidance as part of routine operations is evident\nto satellite operators. Current procedures rely on the analysis of multiple\ncollision warnings by human analysts. However, with the continuous growth of\nthe space population, this manual approach may become unfeasible, highlighting\nthe importance of automation in risk assessment. In 2019, ESA launched a\ncompetition to study the feasibility of applying machine learning in collision\nrisk estimation and released a dataset that contained sequences of Conjunction\nData Messages (CDMs) in support of real close encounters. The competition\nresults showed that the naive forecast and its variants are strong predictors\nfor this problem, which suggests that the CDMs may follow the Markov property.\nThe proposed work investigates this theory by benchmarking Hidden Markov Models\n(HMM) in predicting the risk of collision between two resident space objects by\nusing one feature of the entire dataset: the sequence of the probability in the\nCDMs. In addition, Bayesian statistics are used to infer a joint distribution\nfor the parameters of the models, which allows the development of robust and\nreliable probabilistic predictive models that can incorporate physical or prior\nknowledge about the problem within a rigorous theoretical framework and\nprovides prediction uncertainties that nicely reflect the accuracy of the\npredicted risk. This work shows that the implemented HMM outperforms the naive\nsolution in some metrics, which further adds to the idea that the collision\nwarnings may be Markovian and suggests that this is a powerful method to be\nfurther explored.\n","authors":["João Simões Catulo","Cláudia Soares","Marta Guimarães"],"pdf_url":"https://arxiv.org/pdf/2311.10633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.01841v2","updated":"2023-11-17T16:37:44Z","published":"2023-05-03T00:56:12Z","title":"Inferential Moments of Uncertain Multivariable Systems","summary":"  This article expands the framework of Bayesian inference and provides direct\nprobabilistic methods for approaching inference tasks that are typically\nhandled with information theory. We treat Bayesian probability updating as a\nrandom process and uncover intrinsic quantitative features of joint probability\ndistributions called inferential moments. Inferential moments quantify shape\ninformation about how a prior distribution is expected to update in response to\nyet to be obtained information. Further, we quantify the unique probability\ndistribution whose statistical moments are the inferential moments in question.\nWe find a power series expansion of the mutual information in terms of\ninferential moments, which implies a connection between inferential theoretic\nlogic and elements of information theory. Of particular interest is the\ninferential deviation, which is the expected variation of the probability of\none variable in response to an inferential update of another. We explore two\napplications that analyze the inferential deviations of a Bayesian network to\nimprove decision-making. We implement simple greedy algorithms for exploring\nsensor tasking using inferential deviations that generally outperform similar\ngreedy mutual information algorithms in terms of root mean squared error\nbetween epistemic probability estimates and the ground truth probabilities they\nare estimating.\n","authors":["Kevin Vanslette"],"pdf_url":"https://arxiv.org/pdf/2305.01841v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.10436v3","updated":"2023-11-17T16:29:49Z","published":"2023-08-21T03:13:38Z","title":"Approximately Equivariant Graph Networks","summary":"  Graph neural networks (GNNs) are commonly described as being permutation\nequivariant with respect to node relabeling in the graph. This symmetry of GNNs\nis often compared to the translation equivariance of Euclidean convolution\nneural networks (CNNs). However, these two symmetries are fundamentally\ndifferent: The translation equivariance of CNNs corresponds to symmetries of\nthe fixed domain acting on the image signals (sometimes known as active\nsymmetries), whereas in GNNs any permutation acts on both the graph signals and\nthe graph domain (sometimes described as passive symmetries). In this work, we\nfocus on the active symmetries of GNNs, by considering a learning setting where\nsignals are supported on a fixed graph. In this case, the natural symmetries of\nGNNs are the automorphisms of the graph. Since real-world graphs tend to be\nasymmetric, we relax the notion of symmetries by formalizing approximate\nsymmetries via graph coarsening. We present a bias-variance formula that\nquantifies the tradeoff between the loss in expressivity and the gain in the\nregularity of the learned estimator, depending on the chosen symmetry group. To\nillustrate our approach, we conduct extensive experiments on image inpainting,\ntraffic flow prediction, and human pose estimation with different choices of\nsymmetries. We show theoretically and empirically that the best generalization\nperformance can be achieved by choosing a suitably larger group than the graph\nautomorphism, but smaller than the permutation group.\n","authors":["Ningyuan Huang","Ron Levie","Soledad Villar"],"pdf_url":"https://arxiv.org/pdf/2308.10436v3.pdf","comment":"Accepted at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.08502v2","updated":"2023-11-17T16:08:52Z","published":"2023-11-14T19:49:09Z","title":"Variational Quantum Eigensolver with Constraints (VQEC): Solving\n  Constrained Optimization Problems via VQE","summary":"  Variational quantum approaches have shown great promise in finding\nnear-optimal solutions to computationally challenging tasks. Nonetheless,\nenforcing constraints in a disciplined fashion has been largely unexplored. To\naddress this gap, this work proposes a hybrid quantum-classical algorithmic\nparadigm termed VQEC that extends the celebrated VQE to handle optimization\nwith constraints. As with the standard VQE, the vector of optimization\nvariables is captured by the state of a variational quantum circuit (VQC). To\ndeal with constraints, VQEC optimizes a Lagrangian function classically over\nboth the VQC parameters as well as the dual variables associated with\nconstraints. To comply with the quantum setup, variables are updated via a\nperturbed primal-dual method leveraging the parameter shift rule. Among a wide\ngamut of potential applications, we showcase how VQEC can approximately solve\nquadratically-constrained binary optimization (QCBO) problems, find stochastic\nbinary policies satisfying quadratic constraints on the average and in\nprobability, and solve large-scale linear programs (LP) over the probability\nsimplex. Under an assumption on the error for the VQC to approximate an\narbitrary probability mass function (PMF), we provide bounds on the optimality\ngap attained by a VQC. Numerical tests on a quantum simulator investigate the\neffect of various parameters and corroborate that VQEC can generate\nhigh-quality solutions.\n","authors":["Thinh Viet Le","Vassilis Kekatos"],"pdf_url":"https://arxiv.org/pdf/2311.08502v2.pdf","comment":"22 pages, 13 figures, 1 table"},{"id":"http://arxiv.org/abs/2311.10610v1","updated":"2023-11-17T16:04:31Z","published":"2023-11-17T16:04:31Z","title":"A Poincaré Inequality and Consistency Results for Signal Sampling on\n  Large Graphs","summary":"  Large-scale graph machine learning is challenging as the complexity of\nlearning models scales with the graph size. Subsampling the graph is a viable\nalternative, but sampling on graphs is nontrivial as graphs are non-Euclidean.\nExisting graph sampling techniques require not only computing the spectra of\nlarge matrices but also repeating these computations when the graph changes,\ne.g., grows. In this paper, we introduce a signal sampling theory for a type of\ngraph limit -- the graphon. We prove a Poincar\\'e inequality for graphon\nsignals and show that complements of node subsets satisfying this inequality\nare unique sampling sets for Paley-Wiener spaces of graphon signals. Exploiting\nconnections with spectral clustering and Gaussian elimination, we prove that\nsuch sampling sets are consistent in the sense that unique sampling sets on a\nconvergent graph sequence converge to unique sampling sets on the graphon. We\nthen propose a related graphon signal sampling algorithm for large graphs, and\ndemonstrate its good empirical performance on graph machine learning tasks.\n","authors":["Thien Le","Luana Ruiz","Stefanie Jegelka"],"pdf_url":"https://arxiv.org/pdf/2311.10610v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2311.10609v1","updated":"2023-11-17T16:04:27Z","published":"2023-11-17T16:04:27Z","title":"Scaling TabPFN: Sketching and Feature Selection for Tabular Prior-Data\n  Fitted Networks","summary":"  Tabular classification has traditionally relied on supervised algorithms,\nwhich estimate the parameters of a prediction model using its training data.\nRecently, Prior-Data Fitted Networks (PFNs) such as TabPFN have successfully\nlearned to classify tabular data in-context: the model parameters are designed\nto classify new samples based on labelled training samples given after the\nmodel training. While such models show great promise, their applicability to\nreal-world data remains limited due to the computational scale needed. Here we\nstudy the following question: given a pre-trained PFN for tabular data, what is\nthe best way to summarize the labelled training samples before feeding them to\nthe model? We conduct an initial investigation of sketching and\nfeature-selection methods for TabPFN, and note certain key differences between\nit and conventionally fitted tabular models.\n","authors":["Benjamin Feuer","Chinmay Hegde","Niv Cohen"],"pdf_url":"https://arxiv.org/pdf/2311.10609v1.pdf","comment":"2nd Table Representation Learning Workshop: 37th Conference on Neural\n  Information Processing Systems (NeurIPS 2023)"},{"id":"http://arxiv.org/abs/2311.10607v1","updated":"2023-11-17T16:03:04Z","published":"2023-11-17T16:03:04Z","title":"Active Inference on the Edge: A Design Study","summary":"  Machine Learning (ML) is a common tool to interpret and predict the behavior\nof distributed computing systems, e.g., to optimize the task distribution\nbetween devices. As more and more data is created by Internet of Things (IoT)\ndevices, data processing and ML training are carried out by edge devices in\nclose proximity. To ensure Quality of Service (QoS) throughout these\noperations, systems are supervised and dynamically adapted with the help of ML.\nHowever, as long as ML models are not retrained, they fail to capture gradual\nshifts in the variable distribution, leading to an inaccurate view of the\nsystem state. Moreover, as the prediction accuracy decreases, the reporting\ndevice should actively resolve uncertainties to improve the model's precision.\nSuch a level of self-determination could be provided by Active Inference (ACI)\n-- a concept from neuroscience that describes how the brain constantly predicts\nand evaluates sensory information to decrease long-term surprise. We\nencompassed these concepts in a single action-perception cycle, which we\nimplemented for distributed agents in a smart manufacturing use case. As a\nresult, we showed how our ACI agent was able to quickly and traceably solve an\noptimization problem while fulfilling QoS requirements.\n","authors":["Boris Sedlak","Victor Casamayor Pujol","Praveen Kumar Donta","Schahram Dustdar"],"pdf_url":"https://arxiv.org/pdf/2311.10607v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10597v1","updated":"2023-11-17T15:49:56Z","published":"2023-11-17T15:49:56Z","title":"Designing Reconfigurable Intelligent Systems with Markov Blankets","summary":"  Compute Continuum (CC) systems comprise a vast number of devices distributed\nover computational tiers. Evaluating business requirements, i.e., Service Level\nObjectives (SLOs), requires collecting data from all those devices; if SLOs are\nviolated, devices must be reconfigured to ensure correct operation. If done\ncentrally, this dramatically increases the number of devices and variables that\nmust be considered, while creating an enormous communication overhead. To\naddress this, we (1) introduce a causality filter based on Markov blankets (MB)\nthat limits the number of variables that each device must track, (2) evaluate\nSLOs decentralized on a device basis, and (3) infer optimal device\nconfiguration for fulfilling SLOs. We evaluated our methodology by analyzing\nvideo stream transformations and providing device configurations that ensure\nthe Quality of Service (QoS). The devices thus perceived their environment and\nacted accordingly -- a form of decentralized intelligence.\n","authors":["Boris Sedlak","Victor Casamayor Pujol","Praveen Kumar Donta","Schahram Dustdar"],"pdf_url":"https://arxiv.org/pdf/2311.10597v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10590v1","updated":"2023-11-17T15:45:00Z","published":"2023-11-17T15:45:00Z","title":"EduGym: An Environment Suite for Reinforcement Learning Education","summary":"  Due to the empirical success of reinforcement learning, an increasing number\nof students study the subject. However, from our practical teaching experience,\nwe see students entering the field (bachelor, master and early PhD) often\nstruggle. On the one hand, textbooks and (online) lectures provide the\nfundamentals, but students find it hard to translate between equations and\ncode. On the other hand, public codebases do provide practical examples, but\nthe implemented algorithms tend to be complex, and the underlying test\nenvironments contain multiple reinforcement learning challenges at once.\nAlthough this is realistic from a research perspective, it often hinders\neducational conceptual understanding. To solve this issue we introduce EduGym,\na set of educational reinforcement learning environments and associated\ninteractive notebooks tailored for education. Each EduGym environment is\nspecifically designed to illustrate a certain aspect/challenge of reinforcement\nlearning (e.g., exploration, partial observability, stochasticity, etc.), while\nthe associated interactive notebook explains the challenge and its possible\nsolution approaches, connecting equations and code in a single document. An\nevaluation among RL students and researchers shows 86% of them think EduGym is\na useful tool for reinforcement learning education. All notebooks are available\nfrom https://sites.google.com/view/edu-gym/home, while the full software\npackage can be installed from https://github.com/RLG-Leiden/edugym.\n","authors":["Thomas M. Moerland","Matthias Müller-Brockhausen","Zhao Yang","Andrius Bernatavicius","Koen Ponse","Tom Kouwenhoven","Andreas Sauter","Michiel van der Meer","Bram Renting","Aske Plaat"],"pdf_url":"https://arxiv.org/pdf/2311.10590v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.16047v3","updated":"2023-11-17T15:41:33Z","published":"2023-03-28T15:25:46Z","title":"Exploring and Interacting with the Set of Good Sparse Generalized\n  Additive Models","summary":"  In real applications, interaction between machine learning models and domain\nexperts is critical; however, the classical machine learning paradigm that\nusually produces only a single model does not facilitate such interaction.\nApproximating and exploring the Rashomon set, i.e., the set of all near-optimal\nmodels, addresses this practical challenge by providing the user with a\nsearchable space containing a diverse set of models from which domain experts\ncan choose. We present algorithms to efficiently and accurately approximate the\nRashomon set of sparse, generalized additive models with ellipsoids for fixed\nsupport sets and use these ellipsoids to approximate Rashomon sets for many\ndifferent support sets. The approximated Rashomon set serves as a cornerstone\nto solve practical challenges such as (1) studying the variable importance for\nthe model class; (2) finding models under user-specified constraints\n(monotonicity, direct editing); and (3) investigating sudden changes in the\nshape functions. Experiments demonstrate the fidelity of the approximated\nRashomon set and its effectiveness in solving practical challenges.\n","authors":["Chudi Zhong","Zhi Chen","Jiachang Liu","Margo Seltzer","Cynthia Rudin"],"pdf_url":"https://arxiv.org/pdf/2303.16047v3.pdf","comment":"NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.10580v1","updated":"2023-11-17T15:30:44Z","published":"2023-11-17T15:30:44Z","title":"Implicit Maximum a Posteriori Filtering via Adaptive Optimization","summary":"  Bayesian filtering approximates the true underlying behavior of a\ntime-varying system by inverting an explicit generative model to convert noisy\nmeasurements into state estimates. This process typically requires either\nstorage, inversion, and multiplication of large matrices or Monte Carlo\nestimation, neither of which are practical in high-dimensional state spaces\nsuch as the weight spaces of artificial neural networks. Here, we frame the\nstandard Bayesian filtering problem as optimization over a time-varying\nobjective. Instead of maintaining matrices for the filtering equations or\nsimulating particles, we specify an optimizer that defines the Bayesian filter\nimplicitly. In the linear-Gaussian setting, we show that every Kalman filter\nhas an equivalent formulation using K steps of gradient descent. In the\nnonlinear setting, our experiments demonstrate that our framework results in\nfilters that are effective, robust, and scalable to high-dimensional systems,\ncomparing well against the standard toolbox of Bayesian filtering solutions. We\nsuggest that it is easier to fine-tune an optimizer than it is to specify the\ncorrect filtering equations, making our framework an attractive option for\nhigh-dimensional filtering problems.\n","authors":["Gianluca M. Bencomo","Jake C. Snell","Thomas L. Griffiths"],"pdf_url":"https://arxiv.org/pdf/2311.10580v1.pdf","comment":"Under review at ICLR 2024"},{"id":"http://arxiv.org/abs/2311.10579v1","updated":"2023-11-17T15:30:12Z","published":"2023-11-17T15:30:12Z","title":"Graph Neural Networks for Pressure Estimation in Water Distribution\n  Systems","summary":"  Pressure and flow estimation in Water Distribution Networks (WDN) allows\nwater management companies to optimize their control operations. For many\nyears, mathematical simulation tools have been the most common approach to\nreconstructing an estimate of the WDN hydraulics. However, pure physics-based\nsimulations involve several challenges, e.g. partially observable data, high\nuncertainty, and extensive manual configuration. Thus, data-driven approaches\nhave gained traction to overcome such limitations. In this work, we combine\nphysics-based modeling and Graph Neural Networks (GNN), a data-driven approach,\nto address the pressure estimation problem. First, we propose a new data\ngeneration method using a mathematical simulation but not considering temporal\npatterns and including some control parameters that remain untouched in\nprevious works; this contributes to a more diverse training data. Second, our\ntraining strategy relies on random sensor placement making our GNN-based\nestimation model robust to unexpected sensor location changes. Third, a\nrealistic evaluation protocol considers real temporal patterns and additionally\ninjects the uncertainties intrinsic to real-world scenarios. Finally, a\nmulti-graph pre-training strategy allows the model to be reused for pressure\nestimation in unseen target WDNs. Our GNN-based model estimates the pressure of\na large-scale WDN in The Netherlands with a MAE of 1.94mH$_2$O and a MAPE of\n7%, surpassing the performance of previous studies. Likewise, it outperformed\nprevious approaches on other WDN benchmarks, showing a reduction of absolute\nerror up to approximately 52% in the best cases.\n","authors":["Huy Truong","Andrés Tello","Alexander Lazovik","Victoria Degeler"],"pdf_url":"https://arxiv.org/pdf/2311.10579v1.pdf","comment":"submitted to Water Resources Research. Huy Truong and Andr\\'es Tello\n  contributed equally to this work"},{"id":"http://arxiv.org/abs/2211.06302v3","updated":"2023-11-17T15:14:41Z","published":"2022-11-11T16:13:34Z","title":"GCondNet: A Novel Method for Improving Neural Networks on Small\n  High-Dimensional Tabular Data","summary":"  Neural network models often struggle with high-dimensional but small\nsample-size tabular datasets. One reason is that current weight initialisation\nmethods assume independence between weights, which can be problematic when\nthere are insufficient samples to estimate the model's parameters accurately.\nIn such small data scenarios, leveraging additional structures can improve the\nmodel's performance and training stability. To address this, we propose\nGCondNet, a general approach to enhance neural networks by leveraging implicit\nstructures present in tabular data. We create a graph between samples for each\ndata dimension, and utilise Graph Neural Networks (GNNs) for extracting this\nimplicit structure, and for conditioning the parameters of the first layer of\nan underlying predictor network. By creating many small graphs, GCondNet\nexploits the data's high-dimensionality, and thus improves the performance of\nan underlying predictor network. We demonstrate the effectiveness of our method\non 9 real-world datasets, where GCondNet outperforms 15 standard and\nstate-of-the-art methods. The results show that GCondNet is a versatile\nframework for injecting graph-regularisation into various types of neural\nnetworks, including MLPs and tabular Transformers.\n","authors":["Andrei Margeloiu","Nikola Simidjievski","Pietro Lio","Mateja Jamnik"],"pdf_url":"https://arxiv.org/pdf/2211.06302v3.pdf","comment":"Accepted at the 2nd Table Representation Learning Workshop at NeurIPS\n  2023 [selected for oral presentation]"},{"id":"http://arxiv.org/abs/2311.10572v1","updated":"2023-11-17T15:14:40Z","published":"2023-11-17T15:14:40Z","title":"SSB: Simple but Strong Baseline for Boosting Performance of Open-Set\n  Semi-Supervised Learning","summary":"  Semi-supervised learning (SSL) methods effectively leverage unlabeled data to\nimprove model generalization. However, SSL models often underperform in\nopen-set scenarios, where unlabeled data contain outliers from novel categories\nthat do not appear in the labeled set. In this paper, we study the challenging\nand realistic open-set SSL setting, where the goal is to both correctly\nclassify inliers and to detect outliers. Intuitively, the inlier classifier\nshould be trained on inlier data only. However, we find that inlier\nclassification performance can be largely improved by incorporating\nhigh-confidence pseudo-labeled data, regardless of whether they are inliers or\noutliers. Also, we propose to utilize non-linear transformations to separate\nthe features used for inlier classification and outlier detection in the\nmulti-task learning framework, preventing adverse effects between them.\nAdditionally, we introduce pseudo-negative mining, which further boosts outlier\ndetection performance. The three ingredients lead to what we call Simple but\nStrong Baseline (SSB) for open-set SSL. In experiments, SSB greatly improves\nboth inlier classification and outlier detection performance, outperforming\nexisting methods by a large margin. Our code will be released at\nhttps://github.com/YUE-FAN/SSB.\n","authors":["Yue Fan","Anna Kukleva","Dengxin Dai","Bernt Schiele"],"pdf_url":"https://arxiv.org/pdf/2311.10572v1.pdf","comment":"Paper accepted in ICCV 2023"},{"id":"http://arxiv.org/abs/2311.10571v1","updated":"2023-11-17T15:10:35Z","published":"2023-11-17T15:10:35Z","title":"Direct Amortized Likelihood Ratio Estimation","summary":"  We introduce a new amortized likelihood ratio estimator for likelihood-free\nsimulation-based inference (SBI). Our estimator is simple to train and\nestimates the likelihood ratio using a single forward pass of the neural\nestimator. Our approach directly computes the likelihood ratio between two\ncompeting parameter sets which is different from the previous approach of\ncomparing two neural network output values. We refer to our model as the direct\nneural ratio estimator (DNRE). As part of introducing the DNRE, we derive a\ncorresponding Monte Carlo estimate of the posterior. We benchmark our new ratio\nestimator and compare to previous ratio estimators in the literature. We show\nthat our new ratio estimator often outperforms these previous approaches. As a\nfurther contribution, we introduce a new derivative estimator for likelihood\nratio estimators that enables us to compare likelihood-free Hamiltonian Monte\nCarlo (HMC) with random-walk Metropolis-Hastings (MH). We show that HMC is\nequally competitive, which has not been previously shown. Finally, we include a\nnovel real-world application of SBI by using our neural ratio estimator to\ndesign a quadcopter. Code is available at https://github.com/SRI-CSL/dnre.\n","authors":["Adam D. Cobb","Brian Matejek","Daniel Elenius","Anirban Roy","Susmit Jha"],"pdf_url":"https://arxiv.org/pdf/2311.10571v1.pdf","comment":"12 Pages, 10 Figures, GitHub: https://github.com/SRI-CSL/dnre"},{"id":"http://arxiv.org/abs/2309.07383v4","updated":"2023-11-17T15:04:12Z","published":"2023-09-14T02:02:08Z","title":"Rates of Convergence in Certain Native Spaces of Approximations used in\n  Reinforcement Learning","summary":"  This paper studies convergence rates for some value function approximations\nthat arise in a collection of reproducing kernel Hilbert spaces (RKHS)\n$H(\\Omega)$. By casting an optimal control problem in a specific class of\nnative spaces, strong rates of convergence are derived for the operator\nequation that enables offline approximations that appear in policy iteration.\nExplicit upper bounds on error in value function and controller approximations\nare derived in terms of power function $\\mathcal{P}_{H,N}$ for the space of\nfinite dimensional approximants $H_N$ in the native space $H(\\Omega)$. These\nbounds are geometric in nature and refine some well-known, now classical\nresults concerning convergence of approximations of value functions.\n","authors":["Ali Bouland","Shengyuan Niu","Sai Tej Paruchuri","Andrew Kurdila","John Burns","Eugenio Schuster"],"pdf_url":"https://arxiv.org/pdf/2309.07383v4.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2007.12882v4","updated":"2023-11-17T14:44:26Z","published":"2020-07-25T08:40:29Z","title":"A finite sample analysis of the benign overfitting phenomenon for ridge\n  function estimation","summary":"  Recent extensive numerical experiments in high scale machine learning have\nallowed to uncover a quite counterintuitive phase transition, as a function of\nthe ratio between the sample size and the number of parameters in the model. As\nthe number of parameters $p$ approaches the sample size $n$, the generalisation\nerror increases, but surprisingly, it starts decreasing again past the\nthreshold $p=n$. This phenomenon, brought to the theoretical community\nattention in \\cite{belkin2019reconciling}, has been thoroughly investigated\nlately, more specifically for simpler models than deep neural networks, such as\nthe linear model when the parameter is taken to be the minimum norm solution to\nthe least-squares problem, firstly in the asymptotic regime when $p$ and $n$\ntend to infinity, see e.g. \\cite{hastie2019surprises}, and recently in the\nfinite dimensional regime and more specifically for linear models\n\\cite{bartlett2020benign}, \\cite{tsigler2020benign},\n\\cite{lecue2022geometrical}. In the present paper, we propose a finite sample\nanalysis of non-linear models of \\textit{ridge} type, where we investigate the\n\\textit{overparametrised regime} of the double descent phenomenon for both the\n\\textit{estimation problem} and the \\textit{prediction} problem. Our results\nprovide a precise analysis of the distance of the best estimator from the true\nparameter as well as a generalisation bound which complements recent works of\n\\cite{bartlett2020benign} and \\cite{chinot2020benign}. Our analysis is based on\ntools closely related to the continuous Newton method\n\\cite{neuberger2007continuous} and a refined quantitative analysis of the\nperformance in prediction of the minimum $\\ell_2$-norm solution.\n","authors":["Emmanuel Caron","Stephane Chretien"],"pdf_url":"https://arxiv.org/pdf/2007.12882v4.pdf","comment":"New section on generalisation added"},{"id":"http://arxiv.org/abs/2311.10550v1","updated":"2023-11-17T14:32:43Z","published":"2023-11-17T14:32:43Z","title":"RONAALP: Reduced-Order Nonlinear Approximation with Active Learning\n  Procedure","summary":"  Many engineering applications rely on the evaluation of expensive, non-linear\nhigh-dimensional functions. In this paper, we propose the RONAALP algorithm\n(Reduced Order Nonlinear Approximation with Active Learning Procedure) to\nincrementally learn a fast and accurate reduced-order surrogate model of a\ntarget function on-the-fly as the application progresses. First, the\ncombination of nonlinear auto-encoder, community clustering and radial basis\nfunction networks allows to learn an efficient and compact surrogate model with\nlimited training data. Secondly, the active learning procedure overcome any\nextrapolation issue when evaluating the surrogate model outside of its initial\ntraining range during the online stage. This results in generalizable, fast and\naccurate reduced-order models of high-dimensional functions. The method is\ndemonstrated on three direct numerical simulations of hypersonic flows in\nchemical nonequilibrium. Accurate simulations of these flows rely on detailed\nthermochemical gas models that dramatically increase the cost of such\ncalculations. Using RONAALP to learn a reduced-order thermodynamic model\nsurrogate on-the-fly, the cost of such simulation was reduced by up to 75%\nwhile maintaining an error of less than 10% on relevant quantities of interest.\n","authors":["Clément Scherding","Georgios Rigas","Denis Sipp","Peter J Schmid","Taraneh Sayadi"],"pdf_url":"https://arxiv.org/pdf/2311.10550v1.pdf","comment":"38 pages, 16 figures"},{"id":"http://arxiv.org/abs/2311.10525v1","updated":"2023-11-17T13:45:31Z","published":"2023-11-17T13:45:31Z","title":"Utilizing VQ-VAE for End-to-End Health Indicator Generation in\n  Predicting Rolling Bearing RUL","summary":"  The prediction of the remaining useful life (RUL) of rolling bearings is a\npivotal issue in industrial production. A crucial approach to tackling this\nissue involves transforming vibration signals into health indicators (HI) to\naid model training. This paper presents an end-to-end HI construction method,\nvector quantised variational autoencoder (VQ-VAE), which addresses the need for\ndimensionality reduction of latent variables in traditional unsupervised\nlearning methods such as autoencoder. Moreover, concerning the inadequacy of\ntraditional statistical metrics in reflecting curve fluctuations accurately,\ntwo novel statistical metrics, mean absolute distance (MAD) and mean variance\n(MV), are introduced. These metrics accurately depict the fluctuation patterns\nin the curves, thereby indicating the model's accuracy in discerning similar\nfeatures. On the PMH2012 dataset, methods employing VQ-VAE for label\nconstruction achieved lower values for MAD and MV. Furthermore, the ASTCN\nprediction model trained with VQ-VAE labels demonstrated commendable\nperformance, attaining the lowest values for MAD and MV.\n","authors":["Junliang Wang","Qinghua Zhang","Guanhua Zhu","Guoxi Sun"],"pdf_url":"https://arxiv.org/pdf/2311.10525v1.pdf","comment":"17 figures"},{"id":"http://arxiv.org/abs/2311.10517v1","updated":"2023-11-17T13:40:10Z","published":"2023-11-17T13:40:10Z","title":"Mind the map! Accounting for existing map information when estimating\n  online HDMaps from sensor data","summary":"  Online High Definition Map (HDMap) estimation from sensors offers a low-cost\nalternative to manually acquired HDMaps. As such, it promises to lighten costs\nfor already HDMap-reliant Autonomous Driving systems, and potentially even\nspread their use to new systems. In this paper, we propose to improve online\nHDMap estimation by accounting for already existing maps. We identify 3\nreasonable types of useful existing maps (minimalist, noisy, and outdated). We\nalso introduce MapEX, a novel online HDMap estimation framework that accounts\nfor existing maps. MapEX achieves this by encoding map elements into query\ntokens and by refining the matching algorithm used to train classic query based\nmap estimation models. We demonstrate that MapEX brings significant\nimprovements on the nuScenes dataset. For instance, MapEX - given noisy maps -\nimproves by 38% over the MapTRv2 detector it is based on and by 16% over the\ncurrent SOTA.\n","authors":["Rémy Sun","Li Yang","Diane Lingrand","Frédéric Precioso"],"pdf_url":"https://arxiv.org/pdf/2311.10517v1.pdf","comment":"12 pages, 4 figures, 7 tables"},{"id":"http://arxiv.org/abs/2311.10512v1","updated":"2023-11-17T13:31:19Z","published":"2023-11-17T13:31:19Z","title":"Causal Fairness-Guided Dataset Reweighting using Neural Networks","summary":"  The importance of achieving fairness in machine learning models cannot be\noverstated. Recent research has pointed out that fairness should be examined\nfrom a causal perspective, and several fairness notions based on the on Pearl's\ncausal framework have been proposed. In this paper, we construct a reweighting\nscheme of datasets to address causal fairness. Our approach aims at mitigating\nbias by considering the causal relationships among variables and incorporating\nthem into the reweighting process. The proposed method adopts two neural\nnetworks, whose structures are intentionally used to reflect the structures of\na causal graph and of an interventional graph. The two neural networks can\napproximate the causal model of the data, and the causal model of\ninterventions. Furthermore, reweighting guided by a discriminator is applied to\nachieve various fairness notions. Experiments on real-world datasets show that\nour method can achieve causal fairness on the data while remaining close to the\noriginal data for downstream tasks.\n","authors":["Xuan Zhao","Klaus Broelemann","Salvatore Ruggieri","Gjergji Kasneci"],"pdf_url":"https://arxiv.org/pdf/2311.10512v1.pdf","comment":"To be published in the proceedings of 2023 IEEE International\n  Conference on Big Data (IEEE BigData 2023)"},{"id":"http://arxiv.org/abs/2306.08984v3","updated":"2023-11-17T13:14:58Z","published":"2023-06-15T09:25:04Z","title":"Tree Variational Autoencoders","summary":"  We propose Tree Variational Autoencoder (TreeVAE), a new generative\nhierarchical clustering model that learns a flexible tree-based posterior\ndistribution over latent variables. TreeVAE hierarchically divides samples\naccording to their intrinsic characteristics, shedding light on hidden\nstructures in the data. It adapts its architecture to discover the optimal tree\nfor encoding dependencies between latent variables. The proposed tree-based\ngenerative architecture enables lightweight conditional inference and improves\ngenerative performance by utilizing specialized leaf decoders. We show that\nTreeVAE uncovers underlying clusters in the data and finds meaningful\nhierarchical relations between the different groups on a variety of datasets,\nincluding real-world imaging data. We present empirically that TreeVAE provides\na more competitive log-likelihood lower bound than the sequential counterparts.\nFinally, due to its generative nature, TreeVAE is able to generate new samples\nfrom the discovered clusters via conditional sampling.\n","authors":["Laura Manduchi","Moritz Vandenhirtz","Alain Ryser","Julia Vogt"],"pdf_url":"https://arxiv.org/pdf/2306.08984v3.pdf","comment":"Accepted as Spotlight to NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.10500v1","updated":"2023-11-17T13:01:09Z","published":"2023-11-17T13:01:09Z","title":"From Principle to Practice: Vertical Data Minimization for Machine\n  Learning","summary":"  Aiming to train and deploy predictive models, organizations collect large\namounts of detailed client data, risking the exposure of private information in\nthe event of a breach. To mitigate this, policymakers increasingly demand\ncompliance with the data minimization (DM) principle, restricting data\ncollection to only that data which is relevant and necessary for the task.\nDespite regulatory pressure, the problem of deploying machine learning models\nthat obey DM has so far received little attention. In this work, we address\nthis challenge in a comprehensive manner. We propose a novel vertical DM (vDM)\nworkflow based on data generalization, which by design ensures that no\nfull-resolution client data is collected during training and deployment of\nmodels, benefiting client privacy by reducing the attack surface in case of a\nbreach. We formalize and study the corresponding problem of finding\ngeneralizations that both maximize data utility and minimize empirical privacy\nrisk, which we quantify by introducing a diverse set of policy-aligned\nadversarial scenarios. Finally, we propose a range of baseline vDM algorithms,\nas well as Privacy-aware Tree (PAT), an especially effective vDM algorithm that\noutperforms all baselines across several settings. We plan to release our code\nas a publicly available library, helping advance the standardization of DM for\nmachine learning. Overall, we believe our work can help lay the foundation for\nfurther exploration and adoption of DM principles in real-world applications.\n","authors":["Robin Staab","Nikola Jovanović","Mislav Balunović","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2311.10500v1.pdf","comment":"Accepted at IEEE S&P 2024"},{"id":"http://arxiv.org/abs/2201.05613v3","updated":"2023-11-17T13:01:01Z","published":"2022-01-14T16:04:09Z","title":"The Dark Side of the Language: Pre-trained Transformers in the DarkNet","summary":"  Pre-trained Transformers are challenging human performances in many NLP\ntasks. The massive datasets used for pre-training seem to be the key to their\nsuccess on existing tasks. In this paper, we explore how a range of pre-trained\nNatural Language Understanding models perform on definitely unseen sentences\nprovided by classification tasks over a DarkNet corpus. Surprisingly, results\nshow that syntactic and lexical neural networks perform on par with pre-trained\nTransformers even after fine-tuning. Only after what we call extreme domain\nadaptation, that is, retraining with the masked language model task on all the\nnovel corpus, pre-trained Transformers reach their standard high results. This\nsuggests that huge pre-training corpora may give Transformers unexpected help\nsince they are exposed to many of the possible sentences.\n","authors":["Leonardo Ranaldi","Aria Nourbakhsh","Arianna Patrizi","Elena Sofia Ruzzetti","Dario Onorati","Francesca Fallucchi","Fabio Massimo Zanzotto"],"pdf_url":"https://arxiv.org/pdf/2201.05613v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01913v2","updated":"2023-11-17T12:47:26Z","published":"2023-03-03T13:27:00Z","title":"Bespoke: A Block-Level Neural Network Optimization Framework for\n  Low-Cost Deployment","summary":"  As deep learning models become popular, there is a lot of need for deploying\nthem to diverse device environments. Because it is costly to develop and\noptimize a neural network for every single environment, there is a line of\nresearch to search neural networks for multiple target environments\nefficiently. However, existing works for such a situation still suffer from\nrequiring many GPUs and expensive costs. Motivated by this, we propose a novel\nneural network optimization framework named Bespoke for low-cost deployment.\nOur framework searches for a lightweight model by replacing parts of an\noriginal model with randomly selected alternatives, each of which comes from a\npretrained neural network or the original model. In the practical sense,\nBespoke has two significant merits. One is that it requires near zero cost for\ndesigning the search space of neural networks. The other merit is that it\nexploits the sub-networks of public pretrained neural networks, so the total\ncost is minimal compared to the existing works. We conduct experiments\nexploring Bespoke's the merits, and the results show that it finds efficient\nmodels for multiple targets with meager cost.\n","authors":["Jong-Ryul Lee","Yong-Hyuk Moon"],"pdf_url":"https://arxiv.org/pdf/2303.01913v2.pdf","comment":"This is the extended version of our AAAI-2023 paper\n  (https://ojs.aaai.org/index.php/AAAI/article/view/26020)"},{"id":"http://arxiv.org/abs/2303.17245v3","updated":"2023-11-17T12:43:09Z","published":"2023-03-30T09:22:17Z","title":"Investigating and Mitigating the Side Effects of Noisy Views for\n  Self-Supervised Clustering Algorithms in Practical Multi-View Scenarios","summary":"  Multi-view clustering (MVC) aims at exploring category structures among\nmulti-view data in self-supervised manners. Multiple views provide more\ninformation than single views and thus existing MVC methods can achieve\nsatisfactory performance. However, their performance might seriously degenerate\nwhen the views are noisy in practical multi-view scenarios. In this paper, we\nfirst formally investigate the drawback of noisy views and then propose a\ntheoretically grounded deep MVC method (namely MVCAN) to address this issue.\nSpecifically, we propose a novel MVC objective that enables un-shared\nparameters and inconsistent clustering predictions across multiple views to\nreduce the side effects of noisy views. Furthermore, a two-level multi-view\niterative optimization is designed to generate robust learning targets for\nrefining individual views' representation learning. Theoretical analysis\nreveals that MVCAN works by achieving the multi-view consistency,\ncomplementarity, and noise robustness. Finally, experiments on extensive public\ndatasets demonstrate that MVCAN outperforms state-of-the-art methods and is\nrobust against the existence of noisy views.\n","authors":["Jie Xu","Yazhou Ren","Xiaolong Wang","Lei Feng","Zheng Zhang","Gang Niu","Xiaofeng Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.17245v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10489v1","updated":"2023-11-17T12:41:07Z","published":"2023-11-17T12:41:07Z","title":"Handling Overlapping Asymmetric Datasets -- A Twice Penalized P-Spline\n  Approach","summary":"  Overlapping asymmetric datasets are common in data science and pose questions\nof how they can be incorporated together into a predictive analysis. In\nhealthcare datasets there is often a small amount of information that is\navailable for a larger number of patients such as an electronic health record,\nhowever a small number of patients may have had extensive further testing.\nCommon solutions such as missing imputation can often be unwise if the smaller\ncohort is significantly different in scale to the larger sample, therefore the\naim of this research is to develop a new method which can model the smaller\ncohort against a particular response, whilst considering the larger cohort\nalso. Motivated by non-parametric models, and specifically flexible smoothing\ntechniques via generalized additive models, we model a twice penalized P-Spline\napproximation method to firstly prevent over/under-fitting of the smaller\ncohort and secondly to consider the larger cohort. This second penalty is\ncreated through discrepancies in the marginal value of covariates that exist in\nboth the smaller and larger cohorts. Through data simulations, parameter\ntunings and model adaptations to consider a continuous and binary response, we\nfind our twice penalized approach offers an enhanced fit over a linear B-Spline\nand once penalized P-Spline approximation. Applying to a real-life dataset\nrelating to a person's risk of developing Non-Alcoholic Steatohepatitis, we see\nan improved model fit performance of over 65%. Areas for future work within\nthis space include adapting our method to not require dimensionality reduction\nand also consider parametric modelling methods. However, to our knowledge this\nis the first work to propose additional marginal penalties in a flexible\nregression of which we can report a vastly improved model fit that is able to\nconsider asymmetric datasets, without the need for missing data imputation.\n","authors":["Matthew McTeer","Robin Henderson","Quentin M Anstee","Paolo Missier"],"pdf_url":"https://arxiv.org/pdf/2311.10489v1.pdf","comment":"52 pages, 17 figures, 8 tables, 34 references"},{"id":"http://arxiv.org/abs/2208.06265v3","updated":"2023-11-17T12:38:19Z","published":"2022-08-10T08:28:46Z","title":"Trustworthy Recommender Systems","summary":"  Recommender systems (RSs) aim to help users to effectively retrieve items of\ntheir interests from a large catalogue. For a quite long period of time,\nresearchers and practitioners have been focusing on developing accurate RSs.\nRecent years have witnessed an increasing number of threats to RSs, coming from\nattacks, system and user generated noise, system bias. As a result, it has\nbecome clear that a strict focus on RS accuracy is limited and the research\nmust consider other important factors, e.g., trustworthiness. For end users, a\ntrustworthy RS (TRS) should not only be accurate, but also transparent,\nunbiased and fair as well as robust to noise or attacks. These observations\nactually led to a paradigm shift of the research on RSs: from accuracy-oriented\nRSs to TRSs. However, researchers lack a systematic overview and discussion of\nthe literature in this novel and fast developing field of TRSs. To this end, in\nthis paper, we provide an overview of TRSs, including a discussion of the\nmotivation and basic concepts of TRSs, a presentation of the challenges in\nbuilding TRSs, and a perspective on the future directions in this area. We also\nprovide a novel conceptual framework to support the construction of TRSs.\n","authors":["Shoujin Wang","Xiuzhen Zhang","Yan Wang","Huan Liu","Francesco Ricci"],"pdf_url":"https://arxiv.org/pdf/2208.06265v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10471v1","updated":"2023-11-17T11:55:11Z","published":"2023-11-17T11:55:11Z","title":"Regions are Who Walk Them: a Large Pre-trained Spatiotemporal Model\n  Based on Human Mobility for Ubiquitous Urban Sensing","summary":"  User profiling and region analysis are two tasks of significant commercial\nvalue. However, in practical applications, modeling different features\ntypically involves four main steps: data preparation, data processing, model\nestablishment, evaluation, and optimization. This process is time-consuming and\nlabor-intensive. Repeating this workflow for each feature results in abundant\ndevelopment time for tasks and a reduced overall volume of task development.\nIndeed, human mobility data contains a wealth of information. Several\nsuccessful cases suggest that conducting in-depth analysis of population\nmovement data could potentially yield meaningful profiles about users and\nareas. Nonetheless, most related works have not thoroughly utilized the\nsemantic information within human mobility data and trained on a fixed number\nof the regions. To tap into the rich information within population movement,\nbased on the perspective that Regions Are Who walk them, we propose a large\nspatiotemporal model based on trajectories (RAW). It possesses the following\ncharacteristics: 1) Tailored for trajectory data, introducing a GPT-like\nstructure with a parameter count of up to 1B; 2) Introducing a spatiotemporal\nfine-tuning module, interpreting trajectories as collection of users to derive\narbitrary region embedding. This framework allows rapid task development based\non the large spatiotemporal model. We conducted extensive experiments to\nvalidate the effectiveness of our proposed large spatiotemporal model. It's\nevident that our proposed method, relying solely on human mobility data without\nadditional features, exhibits a certain level of relevance in user profiling\nand region analysis. Moreover, our model showcases promising predictive\ncapabilities in trajectory generation tasks based on the current state,\noffering the potential for further innovative work utilizing this large\nspatiotemporal model.\n","authors":["Ruixing Zhang","Liangzhe Han","Leilei Sun","Yunqi Liu","Jibin Wang","Weifeng Lv"],"pdf_url":"https://arxiv.org/pdf/2311.10471v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2311.08149v2","updated":"2023-11-17T11:51:18Z","published":"2023-11-14T13:25:41Z","title":"Modeling Complex Disease Trajectories using Deep Generative Models with\n  Semi-Supervised Latent Processes","summary":"  In this paper, we propose a deep generative time series approach using latent\ntemporal processes for modeling and holistically analyzing complex disease\ntrajectories. We aim to find meaningful temporal latent representations of an\nunderlying generative process that explain the observed disease trajectories in\nan interpretable and comprehensive way. To enhance the interpretability of\nthese latent temporal processes, we develop a semi-supervised approach for\ndisentangling the latent space using established medical concepts. By combining\nthe generative approach with medical knowledge, we leverage the ability to\ndiscover novel aspects of the disease while integrating medical concepts into\nthe model. We show that the learned temporal latent processes can be utilized\nfor further data analysis and clinical hypothesis testing, including finding\nsimilar patients and clustering the disease into new sub-types. Moreover, our\nmethod enables personalized online monitoring and prediction of multivariate\ntime series including uncertainty quantification. We demonstrate the\neffectiveness of our approach in modeling systemic sclerosis, showcasing the\npotential of our machine learning model to capture complex disease trajectories\nand acquire new medical knowledge.\n","authors":["Cécile Trottet","Manuel Schürch","Ahmed Allam","Imon Barua","Liubov Petelytska","Oliver Distler","Anna-Maria Hoffmann-Vold","Michael Krauthammer","the EUSTAR collaborators"],"pdf_url":"https://arxiv.org/pdf/2311.08149v2.pdf","comment":"Extended Abstract presented at Machine Learning for Health (ML4H)\n  symposium 2023, December 10th, 2023, New Orleans, United States, 23 pages"},{"id":"http://arxiv.org/abs/2311.10468v1","updated":"2023-11-17T11:48:10Z","published":"2023-11-17T11:48:10Z","title":"Using Cooperative Game Theory to Prune Neural Networks","summary":"  We show how solution concepts from cooperative game theory can be used to\ntackle the problem of pruning neural networks.\n  The ever-growing size of deep neural networks (DNNs) increases their\nperformance, but also their computational requirements. We introduce a method\ncalled Game Theory Assisted Pruning (GTAP), which reduces the neural network's\nsize while preserving its predictive accuracy. GTAP is based on eliminating\nneurons in the network based on an estimation of their joint impact on the\nprediction quality through game theoretic solutions. Specifically, we use a\npower index akin to the Shapley value or Banzhaf index, tailored using a\nprocedure similar to Dropout (commonly used to tackle overfitting problems in\nmachine learning).\n  Empirical evaluation of both feedforward networks and convolutional neural\nnetworks shows that this method outperforms existing approaches in the achieved\ntradeoff between the number of parameters and model accuracy.\n","authors":["Mauricio Diaz-Ortiz Jr","Benjamin Kempinski","Daphne Cornelisse","Yoram Bachrach","Tal Kachman"],"pdf_url":"https://arxiv.org/pdf/2311.10468v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.11247v2","updated":"2023-11-17T11:28:29Z","published":"2023-04-21T20:49:29Z","title":"Hybrid quantum physics-informed neural networks for simulating\n  computational fluid dynamics in complex shapes","summary":"  Finding the distribution of the velocities and pressures of a fluid (by\nsolving the Navier-Stokes equations) is a principal task in the chemical,\nenergy, and pharmaceutical industries, as well as in mechanical engineering and\nthe design of pipeline systems. With existing solvers, such as OpenFOAM and\nAnsys, simulations of fluid dynamics in intricate geometries are\ncomputationally expensive and require re-simulation whenever the geometric\nparameters or the initial and boundary conditions are altered. Physics-informed\nneural networks are a promising tool for simulating fluid flows in complex\ngeometries, as they can adapt to changes in the geometry and mesh definitions,\nallowing for generalization across different shapes. We present a hybrid\nquantum physics-informed neural network that simulates laminar fluid flows in\n3D Y-shaped mixers. Our approach combines the expressive power of a quantum\nmodel with the flexibility of a physics-informed neural network, resulting in a\n21% higher accuracy compared to a purely classical neural network. Our findings\nhighlight the potential of machine learning approaches, and in particular\nhybrid quantum physics-informed neural network, for complex shape optimization\ntasks in computational fluid dynamics. By improving the accuracy of fluid\nsimulations in complex geometries, our research using hybrid quantum models\ncontributes to the development of more efficient and reliable fluid dynamics\nsolvers.\n","authors":["Alexandr Sedykh","Maninadh Podapaka","Asel Sagingalieva","Karan Pinto","Markus Pflitsch","Alexey Melnikov"],"pdf_url":"https://arxiv.org/pdf/2304.11247v2.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2311.10456v1","updated":"2023-11-17T11:21:09Z","published":"2023-11-17T11:21:09Z","title":"Accurate and Fast Fischer-Tropsch Reaction Microkinetics using PINNs","summary":"  Microkinetics allows detailed modelling of chemical transformations occurring\nin many industrially relevant reactions. Traditional way of solving the\nmicrokinetics model for Fischer-Tropsch synthesis (FTS) becomes inefficient\nwhen it comes to more advanced real-time applications. In this work, we address\nthese challenges by using physics-informed neural networks(PINNs) for modelling\nFTS microkinetics. We propose a computationally efficient and accurate method,\nenabling the ultra-fast solution of the existing microkinetics models in\nrealistic process conditions. The proposed PINN model computes the fraction of\nvacant catalytic sites, a key quantity in FTS microkinetics, with median\nrelative error (MRE) of 0.03%, and the FTS product formation rates with MRE of\n0.1%. Compared to conventional equation solvers, the model achieves up to 1E+06\ntimes speed-up when running on GPUs, thus being fast enough for multi-scale and\nmulti-physics reactor modelling and enabling its applications in real-time\nprocess control and optimization.\n","authors":["Harshil Patel","Aniruddha Panda","Tymofii Nikolaienko","Stanislav Jaso","Alejandro Lopez","Kaushic Kalyanaraman"],"pdf_url":"https://arxiv.org/pdf/2311.10456v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.14889v2","updated":"2023-11-17T11:18:51Z","published":"2023-03-27T02:55:56Z","title":"Model-Based Reinforcement Learning with Isolated Imaginations","summary":"  World models learn the consequences of actions in vision-based interactive\nsystems. However, in practical scenarios like autonomous driving,\nnoncontrollable dynamics that are independent or sparsely dependent on action\nsignals often exist, making it challenging to learn effective world models. To\naddress this issue, we propose Iso-Dream++, a model-based reinforcement\nlearning approach that has two main contributions. First, we optimize the\ninverse dynamics to encourage the world model to isolate controllable state\ntransitions from the mixed spatiotemporal variations of the environment.\nSecond, we perform policy optimization based on the decoupled latent\nimaginations, where we roll out noncontrollable states into the future and\nadaptively associate them with the current controllable state. This enables\nlong-horizon visuomotor control tasks to benefit from isolating mixed dynamics\nsources in the wild, such as self-driving cars that can anticipate the movement\nof other vehicles, thereby avoiding potential risks. On top of our previous\nwork, we further consider the sparse dependencies between controllable and\nnoncontrollable states, address the training collapse problem of state\ndecoupling, and validate our approach in transfer learning setups. Our\nempirical study demonstrates that Iso-Dream++ outperforms existing\nreinforcement learning models significantly on CARLA and DeepMind Control.\n","authors":["Minting Pan","Xiangming Zhu","Yitao Zheng","Yunbo Wang","Xiaokang Yang"],"pdf_url":"https://arxiv.org/pdf/2303.14889v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2205.13817"},{"id":"http://arxiv.org/abs/2311.01404v2","updated":"2023-11-17T11:06:52Z","published":"2023-11-02T17:17:03Z","title":"Normalizing flows as approximations of optimal transport maps via\n  linear-control neural ODEs","summary":"  The term \"Normalizing Flows\" is related to the task of constructing\ninvertible transport maps between probability measures by means of deep neural\nnetworks. In this paper, we consider the problem of recovering the\n$W_2$-optimal transport map $T$ between absolutely continuous measures\n$\\mu,\\nu\\in\\mathcal{P}(\\mathbb{R}^n)$ as the flow of a linear-control neural\nODE. We first show that, under suitable assumptions on $\\mu,\\nu$ and on the\ncontrolled vector fields, the optimal transport map is contained in the\n$C^0_c$-closure of the flows generated by the system. Assuming that discrete\napproximations $\\mu_N,\\nu_N$ of the original measures $\\mu,\\nu$ are available,\nwe use a discrete optimal coupling $\\gamma_N$ to define an optimal control\nproblem. With a $\\Gamma$-convergence argument, we prove that its solutions\ncorrespond to flows that approximate the optimal transport map $T$. Finally,\ntaking advantage of the Pontryagin Maximum Principle, we propose an iterative\nnumerical scheme for the resolution of the optimal control problem, resulting\nin an algorithm for the practical computation of the approximated optimal\ntransport map.\n","authors":["Alessandro Scagliotti","Sara Farinelli"],"pdf_url":"https://arxiv.org/pdf/2311.01404v2.pdf","comment":"Correction of typos and new bibliographical references. 32 pages, 1\n  figure"},{"id":"http://arxiv.org/abs/2311.10448v1","updated":"2023-11-17T11:03:13Z","published":"2023-11-17T11:03:13Z","title":"DeepClean: Machine Unlearning on the Cheap by Resetting Privacy\n  Sensitive Weights using the Fisher Diagonal","summary":"  Machine learning models trained on sensitive or private data can\ninadvertently memorize and leak that information. Machine unlearning seeks to\nretroactively remove such details from model weights to protect privacy. We\ncontribute a lightweight unlearning algorithm that leverages the Fisher\nInformation Matrix (FIM) for selective forgetting. Prior work in this area\nrequires full retraining or large matrix inversions, which are computationally\nexpensive. Our key insight is that the diagonal elements of the FIM, which\nmeasure the sensitivity of log-likelihood to changes in weights, contain\nsufficient information for effective forgetting. Specifically, we compute the\nFIM diagonal over two subsets -- the data to retain and forget -- for all\ntrainable weights. This diagonal representation approximates the complete FIM\nwhile dramatically reducing computation. We then use it to selectively update\nweights to maximize forgetting of the sensitive subset while minimizing impact\non the retained subset. Experiments show that our algorithm can successfully\nforget any randomly selected subsets of training data across neural network\narchitectures. By leveraging the FIM diagonal, our approach provides an\ninterpretable, lightweight, and efficient solution for machine unlearning with\npractical privacy benefits.\n","authors":["Jiaeli Shi","Najah Ghalyan","Kostis Gourgoulias","John Buford","Sean Moran"],"pdf_url":"https://arxiv.org/pdf/2311.10448v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.10865v2","updated":"2023-11-17T10:48:43Z","published":"2023-07-20T13:34:11Z","title":"Addressing caveats of neural persistence with deep graph persistence","summary":"  Neural Persistence is a prominent measure for quantifying neural network\ncomplexity, proposed in the emerging field of topological data analysis in deep\nlearning. In this work, however, we find both theoretically and empirically\nthat the variance of network weights and spatial concentration of large weights\nare the main factors that impact neural persistence. Whilst this captures\nuseful information for linear classifiers, we find that no relevant spatial\nstructure is present in later layers of deep neural networks, making neural\npersistence roughly equivalent to the variance of weights. Additionally, the\nproposed averaging procedure across layers for deep neural networks does not\nconsider interaction between layers. Based on our analysis, we propose an\nextension of the filtration underlying neural persistence to the whole neural\nnetwork instead of single layers, which is equivalent to calculating neural\npersistence on one particular matrix. This yields our deep graph persistence\nmeasure, which implicitly incorporates persistent paths through the network and\nalleviates variance-related issues through standardisation. Code is available\nat https://github.com/ExplainableML/Deep-Graph-Persistence .\n","authors":["Leander Girrbach","Anders Christensen","Ole Winther","Zeynep Akata","A. Sophia Koepke"],"pdf_url":"https://arxiv.org/pdf/2307.10865v2.pdf","comment":"Transactions on Machine Learning Research (TMLR), 2023"},{"id":"http://arxiv.org/abs/2310.14858v2","updated":"2023-11-17T10:35:48Z","published":"2023-10-23T12:28:21Z","title":"Dynamically Weighted Federated k-Means","summary":"  Federated clustering, an integral aspect of federated machine learning,\nenables multiple data sources to collaboratively cluster their data,\nmaintaining decentralization and preserving privacy. In this paper, we\nintroduce a novel federated clustering algorithm named Dynamically Weighted\nFederated k-means (DWF k-means) based on Lloyd's method for k-means clustering,\nto address the challenges associated with distributed data sources and\nheterogeneous data. Our proposed algorithm combines the benefits of traditional\nclustering techniques with the privacy and scalability benefits offered by\nfederated learning. The algorithm facilitates collaborative clustering among\nmultiple data owners, allowing them to cluster their local data collectively\nwhile exchanging minimal information with the central coordinator. The\nalgorithm optimizes the clustering process by adaptively aggregating cluster\nassignments and centroids from each data source, thereby learning a global\nclustering solution that reflects the collective knowledge of the entire\nfederated network. We address the issue of empty clusters, which commonly\narises in the context of federated clustering. We conduct experiments on\nmultiple datasets and data distribution settings to evaluate the performance of\nour algorithm in terms of clustering score, accuracy, and v-measure. The\nresults demonstrate that our approach can match the performance of the\ncentralized classical k-means baseline, and outperform existing federated\nclustering methods like k-FED in realistic scenarios.\n","authors":["Patrick Holzer","Tania Jacob","Shubham Kavane"],"pdf_url":"https://arxiv.org/pdf/2310.14858v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.09790v2","updated":"2023-11-17T10:21:44Z","published":"2023-11-16T11:10:38Z","title":"Breaking Boundaries: Balancing Performance and Robustness in Deep\n  Wireless Traffic Forecasting","summary":"  Balancing the trade-off between accuracy and robustness is a long-standing\nchallenge in time series forecasting. While most of existing robust algorithms\nhave achieved certain suboptimal performance on clean data, sustaining the same\nperformance level in the presence of data perturbations remains extremely hard.\nIn this paper, we study a wide array of perturbation scenarios and propose\nnovel defense mechanisms against adversarial attacks using real-world telecom\ndata. We compare our strategy against two existing adversarial training\nalgorithms under a range of maximal allowed perturbations, defined using\n$\\ell_{\\infty}$-norm, $\\in [0.1,0.4]$. Our findings reveal that our hybrid\nstrategy, which is composed of a classifier to detect adversarial examples, a\ndenoiser to eliminate noise from the perturbed data samples, and a standard\nforecaster, achieves the best performance on both clean and perturbed data. Our\noptimal model can retain up to $92.02\\%$ the performance of the original\nforecasting model in terms of Mean Squared Error (MSE) on clean data, while\nbeing more robust than the standard adversarially trained models on perturbed\ndata. Its MSE is 2.71$\\times$ and 2.51$\\times$ lower than those of comparing\nmethods on normal and perturbed data, respectively. In addition, the components\nof our models can be trained in parallel, resulting in better computational\nefficiency. Our results indicate that we can optimally balance the trade-off\nbetween the performance and robustness of forecasting models by improving the\nclassifier and denoiser, even in the presence of sophisticated and destructive\npoisoning attacks.\n","authors":["Romain Ilbert","Thai V. Hoang","Zonghua Zhang","Themis Palpanas"],"pdf_url":"https://arxiv.org/pdf/2311.09790v2.pdf","comment":"Accepted for presentation at the ARTMAN workshop, part of the ACM\n  Conference on Computer and Communications Security (CCS), 2023"},{"id":"http://arxiv.org/abs/2311.10430v1","updated":"2023-11-17T10:05:10Z","published":"2023-11-17T10:05:10Z","title":"Deep Residual CNN for Multi-Class Chest Infection Diagnosis","summary":"  The advent of deep learning has significantly propelled the capabilities of\nautomated medical image diagnosis, providing valuable tools and resources in\nthe realm of healthcare and medical diagnostics. This research delves into the\ndevelopment and evaluation of a Deep Residual Convolutional Neural Network\n(CNN) for the multi-class diagnosis of chest infections, utilizing chest X-ray\nimages. The implemented model, trained and validated on a dataset amalgamated\nfrom diverse sources, demonstrated a robust overall accuracy of 93%. However,\nnuanced disparities in performance across different classes, particularly\nFibrosis, underscored the complexity and challenges inherent in automated\nmedical image diagnosis. The insights derived pave the way for future research,\nfocusing on enhancing the model's proficiency in classifying conditions that\npresent more subtle and nuanced visual features in the images, as well as\noptimizing and refining the model architecture and training process. This paper\nprovides a comprehensive exploration into the development, implementation, and\nevaluation of the model, offering insights and directions for future research\nand development in the field.\n","authors":["Ryan Donghan Kwon","Dohyun Lim","Yoonha Lee","Seung Won Lee"],"pdf_url":"https://arxiv.org/pdf/2311.10430v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.03574v5","updated":"2023-11-17T10:01:56Z","published":"2022-02-04T12:30:49Z","title":"Structured Prediction Problem Archive","summary":"  Structured prediction problems are one of the fundamental tools in machine\nlearning. In order to facilitate algorithm development for their numerical\nsolution, we collect in one place a large number of datasets in easy to read\nformats for a diverse set of problem classes. We provide archival links to\ndatasets, description of the considered problems and problem formats, and a\nshort summary of problem characteristics including size, number of instances\netc. For reference we also give a non-exhaustive selection of algorithms\nproposed in the literature for their solution. We hope that this central\nrepository will make benchmarking and comparison to established works easier.\nWe welcome submission of interesting new datasets and algorithms for inclusion\nin our archive.\n","authors":["Paul Swoboda","Bjoern Andres","Andrea Hornakova","Florian Bernard","Jannik Irmai","Paul Roetzer","Bogdan Savchynskyy","David Stein","Ahmed Abbas"],"pdf_url":"https://arxiv.org/pdf/2202.03574v5.pdf","comment":"Added multicast instances from Andres group"},{"id":"http://arxiv.org/abs/2311.10421v1","updated":"2023-11-17T09:54:35Z","published":"2023-11-17T09:54:35Z","title":"Maintenance Techniques for Anomaly Detection AIOps Solutions","summary":"  Anomaly detection techniques are essential in automating the monitoring of IT\nsystems and operations. These techniques imply that machine learning algorithms\nare trained on operational data corresponding to a specific period of time and\nthat they are continuously evaluated on newly emerging data. Operational data\nis constantly changing over time, which affects the performance of deployed\nanomaly detection models. Therefore, continuous model maintenance is required\nto preserve the performance of anomaly detectors over time. In this work, we\nanalyze two different anomaly detection model maintenance techniques in terms\nof the model update frequency, namely blind model retraining and informed model\nretraining. We further investigate the effects of updating the model by\nretraining it on all the available data (full-history approach) and on only the\nnewest data (sliding window approach). Moreover, we investigate whether a data\nchange monitoring tool is capable of determining when the anomaly detection\nmodel needs to be updated through retraining.\n","authors":["Lorena Poenaru-Olaru","Natalia Karpova","Luis Cruz","Jan Rellermeyer","Arie van Deursen"],"pdf_url":"https://arxiv.org/pdf/2311.10421v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10418v1","updated":"2023-11-17T09:48:45Z","published":"2023-11-17T09:48:45Z","title":"DynaPipe: Optimizing Multi-task Training through Dynamic Pipelines","summary":"  Multi-task model training has been adopted to enable a single deep neural\nnetwork model (often a large language model) to handle multiple tasks (e.g.,\nquestion answering and text summarization). Multi-task training commonly\nreceives input sequences of highly different lengths due to the diverse\ncontexts of different tasks. Padding (to the same sequence length) or packing\n(short examples into long sequences of the same length) is usually adopted to\nprepare input samples for model training, which is nonetheless not space or\ncomputation efficient. This paper proposes a dynamic micro-batching approach to\ntackle sequence length variation and enable efficient multi-task model\ntraining. We advocate pipeline-parallel training of the large model with\nvariable-length micro-batches, each of which potentially comprises a different\nnumber of samples. We optimize micro-batch construction using a dynamic\nprogramming-based approach, and handle micro-batch execution time variation\nthrough dynamic pipeline and communication scheduling, enabling highly\nefficient pipeline training. Extensive evaluation on the FLANv2 dataset\ndemonstrates up to 4.39x higher training throughput when training T5, and 3.25x\nwhen training GPT, as compared with packing-based baselines. DynaPipe's source\ncode is publicly available at\nhttps://github.com/awslabs/optimizing-multitask-training-through-dynamic-pipelines.\n","authors":["Chenyu Jiang","Zhen Jia","Shuai Zheng","Yida Wang","Chuan Wu"],"pdf_url":"https://arxiv.org/pdf/2311.10418v1.pdf","comment":"18 pages, 18 figures"},{"id":"http://arxiv.org/abs/2306.16058v3","updated":"2023-11-17T09:26:40Z","published":"2023-06-28T09:40:03Z","title":"DUET: 2D Structured and Approximately Equivariant Representations","summary":"  Multiview Self-Supervised Learning (MSSL) is based on learning invariances\nwith respect to a set of input transformations. However, invariance partially\nor totally removes transformation-related information from the representations,\nwhich might harm performance for specific downstream tasks that require such\ninformation. We propose 2D strUctured and EquivarianT representations (coined\nDUET), which are 2d representations organized in a matrix structure, and\nequivariant with respect to transformations acting on the input data. DUET\nrepresentations maintain information about an input transformation, while\nremaining semantically expressive. Compared to SimCLR (Chen et al., 2020)\n(unstructured and invariant) and ESSL (Dangovski et al., 2022) (unstructured\nand equivariant), the structured and equivariant nature of DUET representations\nenables controlled generation with lower reconstruction error, while\ncontrollability is not possible with SimCLR or ESSL. DUET also achieves higher\naccuracy for several discriminative tasks, and improves transfer learning.\n","authors":["Xavier Suau","Federico Danieli","T. Anderson Keller","Arno Blaas","Chen Huang","Jason Ramapuram","Dan Busbridge","Luca Zappella"],"pdf_url":"https://arxiv.org/pdf/2306.16058v3.pdf","comment":"Accepted at ICML 2023"},{"id":"http://arxiv.org/abs/2311.09930v2","updated":"2023-11-17T09:23:20Z","published":"2023-11-16T14:32:18Z","title":"A Framework for Monitoring and Retraining Language Models in Real-World\n  Applications","summary":"  In the Machine Learning (ML) model development lifecycle, training candidate\nmodels using an offline holdout dataset and identifying the best model for the\ngiven task is only the first step. After the deployment of the selected model,\ncontinuous model monitoring and model retraining is required in many real-world\napplications. There are multiple reasons for retraining, including data or\nconcept drift, which may be reflected on the model performance as monitored by\nan appropriate metric. Another motivation for retraining is the acquisition of\nincreasing amounts of data over time, which may be used to retrain and improve\nthe model performance even in the absence of drifts. We examine the impact of\nvarious retraining decision points on crucial factors, such as model\nperformance and resource utilization, in the context of Multilabel\nClassification models. We explain our key decision points and propose a\nreference framework for designing an effective model retraining strategy.\n","authors":["Jaykumar Kasundra","Claudia Schulz","Melicaalsadat Mirsafian","Stavroula Skylaki"],"pdf_url":"https://arxiv.org/pdf/2311.09930v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10406v1","updated":"2023-11-17T09:15:43Z","published":"2023-11-17T09:15:43Z","title":"Decentralized Energy Marketplace via NFTs and AI-based Agents","summary":"  The paper introduces an advanced Decentralized Energy Marketplace (DEM)\nintegrating blockchain technology and artificial intelligence to manage energy\nexchanges among smart homes with energy storage systems. The proposed framework\nuses Non-Fungible Tokens (NFTs) to represent unique energy profiles in a\ntransparent and secure trading environment. Leveraging Federated Deep\nReinforcement Learning (FDRL), the system promotes collaborative and adaptive\nenergy management strategies, maintaining user privacy. A notable innovation is\nthe use of smart contracts, ensuring high efficiency and integrity in energy\ntransactions. Extensive evaluations demonstrate the system's scalability and\nthe effectiveness of the FDRL method in optimizing energy distribution. This\nresearch significantly contributes to developing sophisticated decentralized\nsmart grid infrastructures. Our approach broadens potential blockchain and AI\napplications in sustainable energy systems and addresses incentive alignment\nand transparency challenges in traditional energy trading mechanisms. The\nimplementation of this paper is publicly accessible at\n\\url{https://github.com/RasoulNik/DEM}.\n","authors":["Rasoul Nikbakht","Farhana Javed","Farhad Rezazadeh","Nikolaos Bartzoudis","Josep Mangues-Bafalluy"],"pdf_url":"https://arxiv.org/pdf/2311.10406v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2308.00273v2","updated":"2023-11-17T08:37:18Z","published":"2023-08-01T04:11:19Z","title":"Neural approximation of Wasserstein distance via a universal\n  architecture for symmetric and factorwise group invariant functions","summary":"  Learning distance functions between complex objects, such as the Wasserstein\ndistance to compare point sets, is a common goal in machine learning\napplications. However, functions on such complex objects (e.g., point sets and\ngraphs) are often required to be invariant to a wide variety of group actions\ne.g. permutation or rigid transformation. Therefore, continuous and symmetric\nproduct functions (such as distance functions) on such complex objects must\nalso be invariant to the product of such group actions. We call these functions\nsymmetric and factor-wise group invariant (or SFGI functions in short). In this\npaper, we first present a general neural network architecture for approximating\nSFGI functions. The main contribution of this paper combines this general\nneural network with a sketching idea to develop a specific and efficient neural\nnetwork which can approximate the $p$-th Wasserstein distance between point\nsets. Very importantly, the required model complexity is independent of the\nsizes of input point sets. On the theoretical front, to the best of our\nknowledge, this is the first result showing that there exists a neural network\nwith the capacity to approximate Wasserstein distance with bounded model\ncomplexity. Our work provides an interesting integration of sketching ideas for\ngeometric problems with universal approximation of symmetric functions. On the\nempirical front, we present a range of results showing that our newly proposed\nneural network architecture performs comparatively or better than other models\n(including a SOTA Siamese Autoencoder based approach). In particular, our\nneural network generalizes significantly better and trains much faster than the\nSOTA Siamese AE. Finally, this line of investigation could be useful in\nexploring effective neural network design for solving a broad range of\ngeometric optimization problems (e.g., $k$-means in a metric space).\n","authors":["Samantha Chen","Yusu Wang"],"pdf_url":"https://arxiv.org/pdf/2308.00273v2.pdf","comment":"Accepted to NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.10387v1","updated":"2023-11-17T08:30:41Z","published":"2023-11-17T08:30:41Z","title":"A Bridge between Dynamical Systems and Machine Learning: Engineered\n  Ordinary Differential Equations as Classification Algorithm (EODECA)","summary":"  In a world increasingly reliant on machine learning, the interpretability of\nthese models remains a substantial challenge, with many equating their\nfunctionality to an enigmatic black box. This study seeks to bridge machine\nlearning and dynamical systems. Recognizing the deep parallels between dense\nneural networks and dynamical systems, particularly in the light of\nnon-linearities and successive transformations, this manuscript introduces the\nEngineered Ordinary Differential Equations as Classification Algorithms\n(EODECAs). Uniquely designed as neural networks underpinned by continuous\nordinary differential equations, EODECAs aim to capitalize on the\nwell-established toolkit of dynamical systems. Unlike traditional deep learning\nmodels, which often suffer from opacity, EODECAs promise both high\nclassification performance and intrinsic interpretability. They are naturally\ninvertible, granting them an edge in understanding and transparency over their\ncounterparts. By bridging these domains, we hope to usher in a new era of\nmachine learning models where genuine comprehension of data processes\ncomplements predictive prowess.\n","authors":["Raffaele Marino","Lorenzo Giambagli","Lorenzo Chicchi","Lorenzo Buffoni","Duccio Fanelli"],"pdf_url":"https://arxiv.org/pdf/2311.10387v1.pdf","comment":"24 pages"},{"id":"http://arxiv.org/abs/2311.02058v2","updated":"2023-11-17T08:26:16Z","published":"2023-11-03T17:38:35Z","title":"LOTUS: Continual Imitation Learning for Robot Manipulation Through\n  Unsupervised Skill Discovery","summary":"  We introduce LOTUS, a continual imitation learning algorithm that empowers a\nphysical robot to continuously and efficiently learn to solve new manipulation\ntasks throughout its lifespan. The core idea behind LOTUS is constructing an\never-growing skill library from a sequence of new tasks with a small number of\nhuman demonstrations. LOTUS starts with a continual skill discovery process\nusing an open-vocabulary vision model, which extracts skills as recurring\npatterns presented in unsegmented demonstrations. Continual skill discovery\nupdates existing skills to avoid catastrophic forgetting of previous tasks and\nadds new skills to solve novel tasks. LOTUS trains a meta-controller that\nflexibly composes various skills to tackle vision-based manipulation tasks in\nthe lifelong learning process. Our comprehensive experiments show that LOTUS\noutperforms state-of-the-art baselines by over 11% in success rate, showing its\nsuperior knowledge transfer ability compared to prior methods. More results and\nvideos can be found on the project website:\nhttps://ut-austin-rpl.github.io/Lotus/.\n","authors":["Weikang Wan","Yifeng Zhu","Rutav Shah","Yuke Zhu"],"pdf_url":"https://arxiv.org/pdf/2311.02058v2.pdf","comment":"Submitted to ICRA 2024"},{"id":"http://arxiv.org/abs/2311.10385v1","updated":"2023-11-17T08:23:17Z","published":"2023-11-17T08:23:17Z","title":"Delete My Account: Impact of Data Deletion on Machine Learning\n  Classifiers","summary":"  Users are more aware than ever of the importance of their own data, thanks to\nreports about security breaches and leaks of private, often sensitive data in\nrecent years. Additionally, the GDPR has been in effect in the European Union\nfor over three years and many people have encountered its effects in one way or\nanother. Consequently, more and more users are actively protecting their\npersonal data. One way to do this is to make of the right to erasure guaranteed\nin the GDPR, which has potential implications for a number of different fields,\nsuch as big data and machine learning.\n  Our paper presents an in-depth analysis about the impact of the use of the\nright to erasure on the performance of machine learning models on\nclassification tasks. We conduct various experiments utilising different\ndatasets as well as different machine learning algorithms to analyse a variety\nof deletion behaviour scenarios. Due to the lack of credible data on actual\nuser behaviour, we make reasonable assumptions for various deletion modes and\nbiases and provide insight into the effects of different plausible scenarios\nfor right to erasure usage on data quality of machine learning. Our results\nshow that the impact depends strongly on the amount of data deleted, the\nparticular characteristics of the dataset and the bias chosen for deletion and\nassumptions on user behaviour.\n","authors":["Tobias Dam","Maximilian Henzl","Lukas Daniel Klausner"],"pdf_url":"https://arxiv.org/pdf/2311.10385v1.pdf","comment":"14 pages, 14 figures"},{"id":"http://arxiv.org/abs/2311.09690v2","updated":"2023-11-17T08:23:11Z","published":"2023-11-16T09:05:52Z","title":"CDMPP: A Device-Model Agnostic Framework for Latency Prediction of\n  Tensor Programs","summary":"  Deep Neural Networks (DNNs) have shown excellent performance in a wide range\nof machine learning applications. Knowing the latency of running a DNN model or\ntensor program on a specific device is useful in various tasks, such as DNN\ngraph- or tensor-level optimization and device selection. Considering the large\nspace of DNN models and devices that impede direct profiling of all\ncombinations, recent efforts focus on building a predictor to model the\nperformance of DNN models on different devices. However, none of the existing\nattempts have achieved a cost model that can accurately predict the performance\nof various tensor programs while supporting both training and inference\naccelerators. We propose CDMPP, an efficient tensor program latency prediction\nframework for both cross-model and cross-device prediction. We design an\ninformative but efficient representation of tensor programs, called compact\nASTs, and a pre-order-based positional encoding method, to capture the internal\nstructure of tensor programs. We develop a domain-adaption-inspired method to\nlearn domain-invariant representations and devise a KMeans-based sampling\nalgorithm, for the predictor to learn from different domains (i.e., different\nDNN operators and devices). Our extensive experiments on a diverse range of DNN\nmodels and devices demonstrate that CDMPP significantly outperforms\nstate-of-the-art baselines with 14.03% and 10.85% prediction error for\ncross-model and cross-device prediction, respectively, and one order of\nmagnitude higher training efficiency. The implementation and the expanded\ndataset are available at https://github.com/joapolarbear/cdmpp.\n","authors":["Hanpeng Hu","Junwei Su","Juntao Zhao","Yanghua Peng","Yibo Zhu","Haibin Lin","Chuan Wu"],"pdf_url":"https://arxiv.org/pdf/2311.09690v2.pdf","comment":"Accepted by EuroSys 2024"},{"id":"http://arxiv.org/abs/2306.04226v2","updated":"2023-11-17T08:23:05Z","published":"2023-06-07T08:05:46Z","title":"Normalization Layers Are All That Sharpness-Aware Minimization Needs","summary":"  Sharpness-aware minimization (SAM) was proposed to reduce sharpness of minima\nand has been shown to enhance generalization performance in various settings.\nIn this work we show that perturbing only the affine normalization parameters\n(typically comprising 0.1% of the total parameters) in the adversarial step of\nSAM can outperform perturbing all of the parameters.This finding generalizes to\ndifferent SAM variants and both ResNet (Batch Normalization) and Vision\nTransformer (Layer Normalization) architectures. We consider alternative sparse\nperturbation approaches and find that these do not achieve similar performance\nenhancement at such extreme sparsity levels, showing that this behaviour is\nunique to the normalization layers. Although our findings reaffirm the\neffectiveness of SAM in improving generalization performance, they cast doubt\non whether this is solely caused by reduced sharpness.\n","authors":["Maximilian Mueller","Tiffany Vlaar","David Rolnick","Matthias Hein"],"pdf_url":"https://arxiv.org/pdf/2306.04226v2.pdf","comment":"camera ready version"},{"id":"http://arxiv.org/abs/2310.14710v2","updated":"2023-11-17T08:01:34Z","published":"2023-10-23T08:49:39Z","title":"Random Forest Kernel for High-Dimension Low Sample Size Classification","summary":"  High dimension, low sample size (HDLSS) problems are numerous among\nreal-world applications of machine learning. From medical images to text\nprocessing, traditional machine learning algorithms are usually unsuccessful in\nlearning the best possible concept from such data. In a previous work, we\nproposed a dissimilarity-based approach for multi-view classification, the\nRandom Forest Dissimilarity (RFD), that perfoms state-of-the-art results for\nsuch problems. In this work, we transpose the core principle of this approach\nto solving HDLSS classification problems, by using the RF similarity measure as\na learned precomputed SVM kernel (RFSVM). We show that such a learned\nsimilarity measure is particularly suited and accurate for this classification\ncontext. Experiments conducted on 40 public HDLSS classification datasets,\nsupported by rigorous statistical analyses, show that the RFSVM method\noutperforms existing methods for the majority of HDLSS problems and remains at\nthe same time very competitive for low or non-HDLSS problems.\n","authors":["Lucca Portes Cavalheiro","Simon Bernard","Jean Paul Barddal","Laurent Heutte"],"pdf_url":"https://arxiv.org/pdf/2310.14710v2.pdf","comment":"23 pages. To be published in statistics and computing (accepted\n  September 26, 2023)"},{"id":"http://arxiv.org/abs/2311.02818v2","updated":"2023-11-17T07:58:45Z","published":"2023-11-06T01:41:46Z","title":"Signal Processing Meets SGD: From Momentum to Filter","summary":"  In the field of deep learning, Stochastic Gradient Descent (SGD) and its\nmomentum-based variants are the predominant choices for optimization\nalgorithms. Despite all that, these momentum strategies, which accumulate\nhistorical gradients by using a fixed $\\beta$ hyperparameter to smooth the\noptimization processing, often neglect the potential impact of the variance of\nhistorical gradients on the current gradient estimation. In the gradient\nvariance during training, fluctuation indicates the objective function does not\nmeet the Lipschitz continuity condition at all time, which raises the\ntroublesome optimization problem. This paper aims to explore the potential\nbenefits of reducing the variance of historical gradients to make optimizer\nconverge to flat solutions. Moreover, we proposed a new optimization method\nbased on reducing the variance. We employed the Wiener filter theory to enhance\nthe first moment estimation of SGD, notably introducing an adaptive weight to\noptimizer. Specifically, the adaptive weight dynamically changes along with\ntemporal fluctuation of gradient variance during deep learning model training.\nExperimental results demonstrated our proposed adaptive weight optimizer, SGDF\n(Stochastic Gradient Descent With Filter), can achieve satisfactory performance\ncompared with state-of-the-art optimizers.\n","authors":["Zhipeng Yao","Guisong Chang","Jiaqi Zhang","Qi Zhang","Yu Zhang","Dazhou Li"],"pdf_url":"https://arxiv.org/pdf/2311.02818v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2010.07468 by other authors"},{"id":"http://arxiv.org/abs/2309.08835v3","updated":"2023-11-17T07:54:42Z","published":"2023-09-16T01:45:13Z","title":"Intelligent machines work in unstructured environments by differential\n  neuromorphic computing","summary":"  Efficient operation of intelligent machines in the real world requires\nmethods that allow them to understand and predict the uncertainties presented\nby the unstructured environments with good accuracy, scalability and\ngeneralization, similar to humans. Current methods rely on pretrained networks\ninstead of continuously learning from the dynamic signal properties of working\nenvironments and suffer inherent limitations, such as data-hungry procedures,\nand limited generalization capabilities. Herein, we present a memristor-based\ndifferential neuromorphic computing, perceptual signal processing and learning\nmethod for intelligent machines. The main features of environmental information\nsuch as amplification (>720%) and adaptation (<50%) of mechanical stimuli\nencoded in memristors, are extracted to obtain human-like processing in\nunstructured environments. The developed method takes advantage of the\nintrinsic multi-state property of memristors and exhibits good scalability and\ngeneralization, as confirmed by validation in two different application\nscenarios: object grasping and autonomous driving. In the former, a robot hand\nexperimentally realizes safe and stable grasping through fast learning (in ~1\nms) the unknown object features (e.g., sharp corner and smooth surface) with a\nsingle memristor. In the latter, the decision-making information of 10\nunstructured environments in autonomous driving (e.g., overtaking cars,\npedestrians) is accurately (94%) extracted with a 40*25 memristor array. By\nmimicking the intrinsic nature of human low-level perception mechanisms, the\nelectronic memristive neuromorphic circuit-based method, presented here shows\nthe potential for adapting to diverse sensing technologies and helping\nintelligent machines generate smart high-level decisions in the real world.\n","authors":["Shengbo Wang","Shuo Gao","Chenyu Tang","Edoardo Occhipinti","Cong Li","Shurui Wang","Jiaqi Wang","Hubin Zhao","Guohua Hu","Arokia Nathan","Ravinder Dahiya","Luigi Occhipinti"],"pdf_url":"https://arxiv.org/pdf/2309.08835v3.pdf","comment":"16 pages, 5 figures"},{"id":"http://arxiv.org/abs/2304.13860v2","updated":"2023-11-17T07:54:27Z","published":"2023-04-26T23:05:57Z","title":"Enhancing Inverse Problem Solutions with Accurate Surrogate Simulators\n  and Promising Candidates","summary":"  Deep-learning inverse techniques have attracted significant attention in\nrecent years. Among them, the neural adjoint (NA) method, which employs a\nneural network surrogate simulator, has demonstrated impressive performance in\nthe design tasks of artificial electromagnetic materials (AEM). However, the\nimpact of the surrogate simulators' accuracy on the solutions in the NA method\nremains uncertain. Furthermore, achieving sufficient optimization becomes\nchallenging in this method when the surrogate simulator is large, and\ncomputational resources are limited. Additionally, the behavior under\nconstraints has not been studied, despite its importance from the engineering\nperspective. In this study, we investigated the impact of surrogate simulators'\naccuracy on the solutions and discovered that the more accurate the surrogate\nsimulator is, the better the solutions become. We then developed an extension\nof the NA method, named Neural Lagrangian (NeuLag) method, capable of\nefficiently optimizing a sufficient number of solution candidates. We then\ndemonstrated that the NeuLag method can find optimal solutions even when\nhandling sufficient candidates is difficult due to the use of a large and\naccurate surrogate simulator. The resimulation errors of the NeuLag method were\napproximately 1/50 compared to previous methods for three AEM tasks. Finally,\nwe performed optimization under constraint using NA and NeuLag, and confirmed\ntheir potential in optimization with soft or hard constraints. We believe our\nmethod holds potential in areas that require large and accurate surrogate\nsimulators.\n","authors":["Akihiro Fujii","Hideki Tsunashima","Yoshihiro Fukuhara","Koji Shimizu","Satoshi Watanabe"],"pdf_url":"https://arxiv.org/pdf/2304.13860v2.pdf","comment":"20 pages, 8 figures"},{"id":"http://arxiv.org/abs/2311.10370v1","updated":"2023-11-17T07:49:20Z","published":"2023-11-17T07:49:20Z","title":"Few-shot Message-Enhanced Contrastive Learning for Graph Anomaly\n  Detection","summary":"  Graph anomaly detection plays a crucial role in identifying exceptional\ninstances in graph data that deviate significantly from the majority. It has\ngained substantial attention in various domains of information security,\nincluding network intrusion, financial fraud, and malicious comments, et al.\nExisting methods are primarily developed in an unsupervised manner due to the\nchallenge in obtaining labeled data. For lack of guidance from prior knowledge\nin unsupervised manner, the identified anomalies may prove to be data noise or\nindividual data instances. In real-world scenarios, a limited batch of labeled\nanomalies can be captured, making it crucial to investigate the few-shot\nproblem in graph anomaly detection. Taking advantage of this potential, we\npropose a novel few-shot Graph Anomaly Detection model called FMGAD (Few-shot\nMessage-Enhanced Contrastive-based Graph Anomaly Detector). FMGAD leverages a\nself-supervised contrastive learning strategy within and across views to\ncapture intrinsic and transferable structural representations. Furthermore, we\npropose the Deep-GNN message-enhanced reconstruction module, which extensively\nexploits the few-shot label information and enables long-range propagation to\ndisseminate supervision signals to deeper unlabeled nodes. This module in turn\nassists in the training of self-supervised contrastive learning. Comprehensive\nexperimental results on six real-world datasets demonstrate that FMGAD can\nachieve better performance than other state-of-the-art methods, regardless of\nartificially injected anomalies or domain-organic anomalies.\n","authors":["Fan Xu","Nan Wang","Xuezhi Wen","Meiqi Gao","Chaoqun Guo","Xibin Zhao"],"pdf_url":"https://arxiv.org/pdf/2311.10370v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10359v1","updated":"2023-11-17T07:25:18Z","published":"2023-11-17T07:25:18Z","title":"FIKIT: Priority-Based Real-time GPU Multi-tasking Scheduling with Kernel\n  Identification","summary":"  Highly parallelized workloads like machine learning training, inferences and\ngeneral HPC tasks are greatly accelerated using GPU devices. In a cloud\ncomputing cluster, serving a GPU's computation power through multi-tasks\nsharing is highly demanded since there are always more task requests than the\nnumber of GPU available. Existing GPU sharing solutions focus on reducing\ntask-level waiting time or task-level switching costs when multiple jobs\ncompeting for a single GPU. Non-stopped computation requests come with\ndifferent priorities, having non-symmetric impact on QoS for sharing a GPU\ndevice. Existing work missed the kernel-level optimization opportunity brought\nby this setting. To address this problem, we present a novel kernel-level\nscheduling strategy called FIKIT: Filling Inter-kernel Idle Time. FIKIT\nincorporates task-level priority information, fine-grained kernel\nidentification, and kernel measurement, allowing low priorities task's\nexecution during high priority task's inter-kernel idle time. Thereby, filling\nthe GPU's device runtime fully, and reduce overall GPU sharing impact to cloud\nservices. Across a set of ML models, the FIKIT based inference system\naccelerated high priority tasks by 1.33 to 14.87 times compared to the JCT in\nGPU sharing mode, and more than half of the cases are accelerated by more than\n3.5 times. Alternatively, under preemptive sharing, the low-priority tasks have\na comparable to default GPU sharing mode JCT, with a 0.84 to 1 times ratio. We\nfurther limit the kernel measurement and runtime fine-grained kernel scheduling\noverhead to less than 10%.\n","authors":["Wenqing Wu"],"pdf_url":"https://arxiv.org/pdf/2311.10359v1.pdf","comment":"19 pages, 18 figures"},{"id":"http://arxiv.org/abs/2306.06048v2","updated":"2023-11-17T07:22:04Z","published":"2023-06-09T17:16:50Z","title":"How Does Fine-Tuning Impact Out-of-Distribution Detection for\n  Vision-Language Models?","summary":"  Recent large vision-language models such as CLIP have shown remarkable\nout-of-distribution (OOD) detection and generalization performance. However,\ntheir zero-shot in-distribution (ID) accuracy is often limited for downstream\ndatasets. Recent CLIP-based fine-tuning methods such as prompt learning have\ndemonstrated significant improvements in ID classification and OOD\ngeneralization where OOD labels are available. Nonetheless, it remains unclear\nwhether the model is reliable to semantic shifts without OOD labels. In this\npaper, we aim to bridge the gap and present a comprehensive study to understand\nhow fine-tuning impact OOD detection for few-shot downstream tasks. By framing\nOOD detection as multi-modal concept matching, we establish a connection\nbetween fine-tuning methods and various OOD scores. Our results suggest that a\nproper choice of OOD scores is essential for CLIP-based fine-tuning. In\nparticular, the maximum concept matching (MCM) score provides a promising\nsolution consistently. We also show that prompt learning demonstrates the\nstate-of-the-art OOD detection performance over the zero-shot counterpart.\n","authors":["Yifei Ming","Yixuan Li"],"pdf_url":"https://arxiv.org/pdf/2306.06048v2.pdf","comment":"Accepted to IJCV 2023"},{"id":"http://arxiv.org/abs/2311.10349v1","updated":"2023-11-17T06:36:43Z","published":"2023-11-17T06:36:43Z","title":"Pseudo Label-Guided Data Fusion and Output Consistency for\n  Semi-Supervised Medical Image Segmentation","summary":"  Supervised learning algorithms based on Convolutional Neural Networks have\nbecome the benchmark for medical image segmentation tasks, but their\neffectiveness heavily relies on a large amount of labeled data. However,\nannotating medical image datasets is a laborious and time-consuming process.\nInspired by semi-supervised algorithms that use both labeled and unlabeled data\nfor training, we propose the PLGDF framework, which builds upon the mean\nteacher network for segmenting medical images with less annotation. We propose\na novel pseudo-label utilization scheme, which combines labeled and unlabeled\ndata to augment the dataset effectively. Additionally, we enforce the\nconsistency between different scales in the decoder module of the segmentation\nnetwork and propose a loss function suitable for evaluating the consistency.\nMoreover, we incorporate a sharpening operation on the predicted results,\nfurther enhancing the accuracy of the segmentation.\n  Extensive experiments on three publicly available datasets demonstrate that\nthe PLGDF framework can largely improve performance by incorporating the\nunlabeled data. Meanwhile, our framework yields superior performance compared\nto six state-of-the-art semi-supervised learning methods. The codes of this\nstudy are available at https://github.com/ortonwang/PLGDF.\n","authors":["Tao Wang","Yuanbin Chen","Xinlin Zhang","Yuanbo Zhou","Junlin Lan","Bizhe Bai","Tao Tan","Min Du","Qinquan Gao","Tong Tong"],"pdf_url":"https://arxiv.org/pdf/2311.10349v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10341v1","updated":"2023-11-17T06:03:56Z","published":"2023-11-17T06:03:56Z","title":"Federated Knowledge Graph Completion via Latent Embedding Sharing and\n  Tensor Factorization","summary":"  Knowledge graphs (KGs), which consist of triples, are inherently incomplete\nand always require completion procedure to predict missing triples. In\nreal-world scenarios, KGs are distributed across clients, complicating\ncompletion tasks due to privacy restrictions. Many frameworks have been\nproposed to address the issue of federated knowledge graph completion. However,\nthe existing frameworks, including FedE, FedR, and FEKG, have certain\nlimitations. = FedE poses a risk of information leakage, FedR's optimization\nefficacy diminishes when there is minimal overlap among relations, and FKGE\nsuffers from computational costs and mode collapse issues. To address these\nissues, we propose a novel method, i.e., Federated Latent Embedding Sharing\nTensor factorization (FLEST), which is a novel approach using federated tensor\nfactorization for KG completion. FLEST decompose the embedding matrix and\nenables sharing of latent dictionary embeddings to lower privacy risks.\nEmpirical results demonstrate FLEST's effectiveness and efficiency, offering a\nbalanced solution between performance and privacy. FLEST expands the\napplication of federated tensor factorization in KG completion tasks.\n","authors":["Maolin Wang","Dun Zeng","Zenglin Xu","Ruocheng Guo","Xiangyu Zhao"],"pdf_url":"https://arxiv.org/pdf/2311.10341v1.pdf","comment":"Accepted by ICDM 2023"},{"id":"http://arxiv.org/abs/2309.16397v2","updated":"2023-11-17T05:41:45Z","published":"2023-09-28T12:44:51Z","title":"Uncertainty-Aware Decision Transformer for Stochastic Driving\n  Environments","summary":"  Offline Reinforcement Learning (RL) has emerged as a promising framework for\nlearning policies without active interactions, making it especially appealing\nfor autonomous driving tasks. Recent successes of Transformers inspire casting\noffline RL as sequence modeling, which performs well in long-horizon tasks.\nHowever, they are overly optimistic in stochastic environments with incorrect\nassumptions that the same goal can be consistently achieved by identical\nactions. In this paper, we introduce an UNcertainty-awaRE deciSion Transformer\n(UNREST) for planning in stochastic driving environments without introducing\nadditional transition or complex generative models. Specifically, UNREST\nestimates state uncertainties by the conditional mutual information between\ntransitions and returns, and segments sequences accordingly. Discovering the\n`uncertainty accumulation' and `temporal locality' properties of driving\nenvironments, UNREST replaces the global returns in decision transformers with\nless uncertain truncated returns, to learn from true outcomes of agent actions\nrather than environment transitions. We also dynamically evaluate environmental\nuncertainty during inference for cautious planning. Extensive experimental\nresults demonstrate UNREST's superior performance in various driving scenarios\nand the power of our uncertainty estimation strategy.\n","authors":["Zenan Li","Fan Nie","Qiao Sun","Fang Da","Hang Zhao"],"pdf_url":"https://arxiv.org/pdf/2309.16397v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.05433v2","updated":"2023-11-17T05:27:43Z","published":"2023-05-09T13:22:13Z","title":"Tomography of Quantum States from Structured Measurements via\n  quantum-aware transformer","summary":"  Quantum state tomography (QST) is the process of reconstructing the state of\na quantum system (mathematically described as a density matrix) through a\nseries of different measurements, which can be solved by learning a\nparameterized function to translate experimentally measured statistics into\nphysical density matrices. However, the specific structure of quantum\nmeasurements for characterizing a quantum state has been neglected in previous\nwork. In this paper, we explore the similarity between highly structured\nsentences in natural language and intrinsically structured measurements in QST.\nTo fully leverage the intrinsic quantum characteristics involved in QST, we\ndesign a quantum-aware transformer (QAT) model to capture the complex\nrelationship between measured frequencies and density matrices. In particular,\nwe query quantum operators in the architecture to facilitate informative\nrepresentations of quantum data and integrate the Bures distance into the loss\nfunction to evaluate quantum state fidelity, thereby enabling the\nreconstruction of quantum states from measured data with high fidelity.\nExtensive simulations and experiments (on IBM quantum computers) demonstrate\nthe superiority of the QAT in reconstructing quantum states with favorable\nrobustness against experimental noise.\n","authors":["Hailan Ma","Zhenhong Sun","Daoyi Dong","Chunlin Chen","Herschel Rabitz"],"pdf_url":"https://arxiv.org/pdf/2305.05433v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10328v1","updated":"2023-11-17T04:59:08Z","published":"2023-11-17T04:59:08Z","title":"TransONet: Automatic Segmentation of Vasculature in Computed Tomographic\n  Angiograms Using Deep Learning","summary":"  Pathological alterations in the human vascular system underlie many chronic\ndiseases, such as atherosclerosis and aneurysms. However, manually analyzing\ndiagnostic images of the vascular system, such as computed tomographic\nangiograms (CTAs) is a time-consuming and tedious process. To address this\nissue, we propose a deep learning model to segment the vascular system in CTA\nimages of patients undergoing surgery for peripheral arterial disease (PAD).\nOur study focused on accurately segmenting the vascular system (1) from the\ndescending thoracic aorta to the iliac bifurcation and (2) from the descending\nthoracic aorta to the knees in CTA images using deep learning techniques. Our\napproach achieved average Dice accuracies of 93.5% and 80.64% in test dataset\nfor (1) and (2), respectively, highlighting its high accuracy and potential\nclinical utility. These findings demonstrate the use of deep learning\ntechniques as a valuable tool for medical professionals to analyze the health\nof the vascular system efficiently and accurately. Please visit the GitHub page\nfor this paper at https://github.com/pip-alireza/TransOnet.\n","authors":["Alireza Bagheri Rajeoni","Breanna Pederson","Ali Firooz","Hamed Abdollahi","Andrew K. Smith","Daniel G. Clair","Susan M. Lessner","Homayoun Valafar"],"pdf_url":"https://arxiv.org/pdf/2311.10328v1.pdf","comment":"Accepted for the 2023 International Conference on Computational\n  Science and Computational Intelligence (CSCI), Las Vegas, USA"},{"id":"http://arxiv.org/abs/2311.10322v1","updated":"2023-11-17T04:24:52Z","published":"2023-11-17T04:24:52Z","title":"Clustering Techniques for Stable Linear Dynamical Systems with\n  applications to Hard Disk Drives","summary":"  In Robust Control and Data Driven Robust Control design methodologies,\nmultiple plant transfer functions or a family of transfer functions are\nconsidered and a common controller is designed such that all the plants that\nfall into this family are stabilized. Though the plants are stabilized, the\ncontroller might be sub-optimal for each of the plants when the variations in\nthe plants are large. This paper presents a way of clustering stable linear\ndynamical systems for the design of robust controllers within each of the\nclusters such that the controllers are optimal for each of the clusters. First\na k-medoids algorithm for hard clustering will be presented for stable Linear\nTime Invariant (LTI) systems and then a Gaussian Mixture Models (GMM)\nclustering for a special class of LTI systems, common for Hard Disk Drive\nplants, will be presented.\n","authors":["Nikhil Potu Surya Prakash","Joohwan Seo","Jongeun Choi","Roberto Horowitz"],"pdf_url":"https://arxiv.org/pdf/2311.10322v1.pdf","comment":"6 pages, 4 figures"},{"id":"http://arxiv.org/abs/2306.11719v2","updated":"2023-11-17T04:17:34Z","published":"2023-06-20T17:53:00Z","title":"Diffusion with Forward Models: Solving Stochastic Inverse Problems\n  Without Direct Supervision","summary":"  Denoising diffusion models are a powerful type of generative models used to\ncapture complex distributions of real-world signals. However, their\napplicability is limited to scenarios where training samples are readily\navailable, which is not always the case in real-world applications. For\nexample, in inverse graphics, the goal is to generate samples from a\ndistribution of 3D scenes that align with a given image, but ground-truth 3D\nscenes are unavailable and only 2D images are accessible. To address this\nlimitation, we propose a novel class of denoising diffusion probabilistic\nmodels that learn to sample from distributions of signals that are never\ndirectly observed. Instead, these signals are measured indirectly through a\nknown differentiable forward model, which produces partial observations of the\nunknown signal. Our approach involves integrating the forward model directly\ninto the denoising process. This integration effectively connects the\ngenerative modeling of observations with the generative modeling of the\nunderlying signals, allowing for end-to-end training of a conditional\ngenerative model over signals. During inference, our approach enables sampling\nfrom the distribution of underlying signals that are consistent with a given\npartial observation. We demonstrate the effectiveness of our method on three\nchallenging computer vision tasks. For instance, in the context of inverse\ngraphics, our model enables direct sampling from the distribution of 3D scenes\nthat align with a single 2D input image.\n","authors":["Ayush Tewari","Tianwei Yin","George Cazenavette","Semon Rezchikov","Joshua B. Tenenbaum","Frédo Durand","William T. Freeman","Vincent Sitzmann"],"pdf_url":"https://arxiv.org/pdf/2306.11719v2.pdf","comment":"Project page: https://diffusion-with-forward-models.github.io/"},{"id":"http://arxiv.org/abs/2311.10321v1","updated":"2023-11-17T04:15:27Z","published":"2023-11-17T04:15:27Z","title":"Towards Machine Learning-based Quantitative Hyperspectral Image Guidance\n  for Brain Tumor Resection","summary":"  Complete resection of malignant gliomas is hampered by the difficulty in\ndistinguishing tumor cells at the infiltration zone. Fluorescence guidance with\n5-ALA assists in reaching this goal. Using hyperspectral imaging, previous work\ncharacterized five fluorophores' emission spectra in most human brain tumors.\nIn this paper, the effectiveness of these five spectra was explored for\ndifferent tumor and tissue classification tasks in 184 patients (891\nhyperspectral measurements) harboring low- (n=30) and high-grade gliomas\n(n=115), non-glial primary brain tumors (n=19), radiation necrosis (n=2),\nmiscellaneous (n=10) and metastases (n=8). Four machine learning models were\ntrained to classify tumor type, grade, glioma margins and IDH mutation. Using\nrandom forests and multi-layer perceptrons, the classifiers achieved average\ntest accuracies of 74-82%, 79%, 81%, and 93% respectively. All five fluorophore\nabundances varied between tumor margin types and tumor grades (p < 0.01). For\ntissue type, at least four of the five fluorophore abundances were found to be\nsignificantly different (p < 0.01) between all classes. These results\ndemonstrate the fluorophores' differing abundances in different tissue classes,\nas well as the value of the five fluorophores as potential optical biomarkers,\nopening new opportunities for intraoperative classification systems in\nfluorescence-guided neurosurgery.\n","authors":["David Black","Declan Byrne","Anna Walke","Sidong Liu","Antonio Di leva","Sadahiro Kaneko","Walter Stummer","Septimiu Salcudean","Eric Suero Molina"],"pdf_url":"https://arxiv.org/pdf/2311.10321v1.pdf","comment":"22 pages, 8 figures"},{"id":"http://arxiv.org/abs/2310.07958v3","updated":"2023-11-17T04:07:41Z","published":"2023-10-12T00:51:06Z","title":"Towards Causal Deep Learning for Vulnerability Detection","summary":"  Deep learning vulnerability detection has shown promising results in recent\nyears. However, an important challenge that still blocks it from being very\nuseful in practice is that the model is not robust under perturbation and it\ncannot generalize well over the out-of-distribution (OOD) data, e.g., applying\na trained model to unseen projects in real world. We hypothesize that this is\nbecause the model learned non-robust features, e.g., variable names, that have\nspurious correlations with labels. When the perturbed and OOD datasets no\nlonger have the same spurious features, the model prediction fails. To address\nthe challenge, in this paper, we introduced causality into deep learning\nvulnerability detection. Our approach CausalVul consists of two phases. First,\nwe designed novel perturbations to discover spurious features that the model\nmay use to make predictions. Second, we applied the causal learning algorithms,\nspecifically, do-calculus, on top of existing deep learning models to\nsystematically remove the use of spurious features and thus promote causal\nbased prediction. Our results show that CausalVul consistently improved the\nmodel accuracy, robustness and OOD performance for all the state-of-the-art\nmodels and datasets we experimented. To the best of our knowledge, this is the\nfirst work that introduces do calculus based causal learning to software\nengineering models and shows it's indeed useful for improving the model\naccuracy, robustness and generalization. Our replication package is located at\nhttps://figshare.com/s/0ffda320dcb96c249ef2.\n","authors":["Md Mahbubur Rahman","Ira Ceka","Chengzhi Mao","Saikat Chakraborty","Baishakhi Ray","Wei Le"],"pdf_url":"https://arxiv.org/pdf/2310.07958v3.pdf","comment":"Accepted at ICSE 2024 (not camera-ready version)"},{"id":"http://arxiv.org/abs/2311.10318v1","updated":"2023-11-17T04:04:11Z","published":"2023-11-17T04:04:11Z","title":"Nonparametric Teaching for Multiple Learners","summary":"  We study the problem of teaching multiple learners simultaneously in the\nnonparametric iterative teaching setting, where the teacher iteratively\nprovides examples to the learner for accelerating the acquisition of a target\nconcept. This problem is motivated by the gap between current single-learner\nteaching setting and the real-world scenario of human instruction where a\nteacher typically imparts knowledge to multiple students. Under the new problem\nformulation, we introduce a novel framework -- Multi-learner Nonparametric\nTeaching (MINT). In MINT, the teacher aims to instruct multiple learners, with\neach learner focusing on learning a scalar-valued target model. To achieve\nthis, we frame the problem as teaching a vector-valued target model and extend\nthe target model space from a scalar-valued reproducing kernel Hilbert space\nused in single-learner scenarios to a vector-valued space. Furthermore, we\ndemonstrate that MINT offers significant teaching speed-up over repeated\nsingle-learner teaching, particularly when the multiple learners can\ncommunicate with each other. Lastly, we conduct extensive experiments to\nvalidate the practicality and efficiency of MINT.\n","authors":["Chen Zhang","Xiaofeng Cao","Weiyang Liu","Ivor Tsang","James Kwok"],"pdf_url":"https://arxiv.org/pdf/2311.10318v1.pdf","comment":"NeurIPS 2023 (31 pages, 20 figures)"},{"id":"http://arxiv.org/abs/2301.12829v2","updated":"2023-11-17T04:01:17Z","published":"2023-01-27T13:12:21Z","title":"Identifying the Key Attributes in an Unlabeled Event Log for Automated\n  Process Discovery","summary":"  Process mining discovers and analyzes a process model from historical event\nlogs. The prior art methods use the key attributes of case-id, activity, and\ntimestamp hidden in an event log as clues to discover a process model. However,\na user needs to specify them manually, and this can be an exhaustive task. In\nthis paper, we propose a two-stage key attribute identification method to avoid\nsuch a manual investigation, and thus this is a step toward fully automated\nprocess discovery. One of the challenging tasks is how to avoid exhaustive\ncomputation due to combinatorial explosion. For this, we narrow down candidates\nfor each key attribute by using supervised machine learning in the first stage\nand identify the best combination of the key attributes by discovering process\nmodels and evaluating them in the second stage. Our computational complexity\ncan be reduced from $\\mathcal{O}(N^3)$ to $\\mathcal{O}(k^3)$ where $N$ and $k$\nare the numbers of columns and candidates we keep in the first stage,\nrespectively, and usually $k$ is much smaller than $N$. We evaluated our method\nwith 14 open datasets and showed that our method could identify the key\nattributes even with $k = 2$ for about 20 seconds for many datasets.\n","authors":["Kentaroh Toyoda","Rachel Gan Kai Ying","Allan NengSheng Zhang","Tan Puay Siew"],"pdf_url":"https://arxiv.org/pdf/2301.12829v2.pdf","comment":"IEEE Transactions on Services Computing (Early Access version)"},{"id":"http://arxiv.org/abs/2311.10316v1","updated":"2023-11-17T03:59:50Z","published":"2023-11-17T03:59:50Z","title":"Graph Sparsifications using Neural Network Assisted Monte Carlo Tree\n  Search","summary":"  Graph neural networks have been successful for machine learning, as well as\nfor combinatorial and graph problems such as the Subgraph Isomorphism Problem\nand the Traveling Salesman Problem. We describe an approach for computing graph\nsparsifiers by combining a graph neural network and Monte Carlo Tree Search. We\nfirst train a graph neural network that takes as input a partial solution and\nproposes a new node to be added as output. This neural network is then used in\na Monte Carlo search to compute a sparsifier. The proposed method consistently\noutperforms several standard approximation algorithms on different types of\ngraphs and often finds the optimal solution.\n","authors":["Alvin Chiu","Mithun Ghosh","Reyan Ahmed","Kwang-Sung Jun","Stephen Kobourov","Michael T. Goodrich"],"pdf_url":"https://arxiv.org/pdf/2311.10316v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2305.00535"},{"id":"http://arxiv.org/abs/2311.10315v1","updated":"2023-11-17T03:58:59Z","published":"2023-11-17T03:58:59Z","title":"Interpretable Modeling of Single-cell perturbation Responses to Novel\n  Drugs Using Cycle Consistence Learning","summary":"  Phenotype-based screening has attracted much attention for identifying\ncell-active compounds. Transcriptional and proteomic profiles of cell\npopulation or single cells are informative phenotypic measures of cellular\nresponses to perturbations. In this paper, we proposed a deep learning\nframework based on encoder-decoder architecture that maps the initial cellular\nstates to a latent space, in which we assume the effects of drug perturbation\non cellular states follow linear additivity. Next, we introduced the cycle\nconsistency constraints to enforce that initial cellular state subjected to\ndrug perturbations would produce the perturbed cellular responses, and,\nconversely, removal of drug perturbation from the perturbed cellular states\nwould restore the initial cellular states. The cycle consistency constraints\nand linear modeling in latent space enable to learn interpretable and\ntransferable drug perturbation representations, so that our model can predict\ncellular response to unseen drugs. We validated our model on three different\ntypes of datasets, including bulk transcriptional responses, bulk proteomic\nresponses, and single-cell transcriptional responses to drug perturbations. The\nexperimental results show that our model achieves better performance than\nexisting state-of-the-art methods.\n","authors":["Wei Huang","Aichun Zhu","Hui Liu"],"pdf_url":"https://arxiv.org/pdf/2311.10315v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10309v1","updated":"2023-11-17T03:41:22Z","published":"2023-11-17T03:41:22Z","title":"Imagination-augmented Hierarchical Reinforcement Learning for Safe and\n  Interactive Autonomous Driving in Urban Environments","summary":"  Hierarchical reinforcement learning (HRL) has led to remarkable achievements\nin diverse fields. However, existing HRL algorithms still cannot be applied to\nreal-world navigation tasks. These tasks require an agent to perform\nsafety-aware behaviors and interact with surrounding objects in dynamic\nenvironments. In addition, an agent in these tasks should perform consistent\nand structured exploration as they are long-horizon and have complex structures\nwith diverse objects and task-specific rules. Designing HRL agents that can\nhandle these challenges in real-world navigation tasks is an open problem. In\nthis paper, we propose imagination-augmented HRL (IAHRL), a new and general\nnavigation algorithm that allows an agent to learn safe and interactive\nbehaviors in real-world navigation tasks. Our key idea is to train a\nhierarchical agent in which a high-level policy infers interactions by\ninterpreting behaviors imagined with low-level policies. Specifically, the\nhigh-level policy is designed with a permutation-invariant attention mechanism\nto determine which low-level policy generates the most interactive behavior,\nand the low-level policies are implemented with an optimization-based behavior\nplanner to generate safe and structured behaviors following task-specific\nrules. To evaluate our algorithm, we introduce five complex urban driving\ntasks, which are among the most challenging real-world navigation tasks. The\nexperimental results indicate that our hierarchical agent performs safety-aware\nbehaviors and properly interacts with surrounding vehicles, achieving higher\nsuccess rates and lower average episode steps than baselines in urban driving\ntasks.\n","authors":["Sang-Hyun Lee","Yoonjae Jung","Seung-Woo Seo"],"pdf_url":"https://arxiv.org/pdf/2311.10309v1.pdf","comment":"11 pages, 8 figures"},{"id":"http://arxiv.org/abs/2210.12723v2","updated":"2023-11-17T03:37:18Z","published":"2022-10-23T13:10:12Z","title":"A Faithful Deep Sensitivity Estimation for Accelerated Magnetic\n  Resonance Imaging","summary":"  Magnetic resonance imaging (MRI) is an essential diagnostic tool that suffers\nfrom prolonged scan time. To alleviate this limitation, advanced fast MRI\ntechnology attracts extensive research interests. Recent deep learning has\nshown its great potential in improving image quality and reconstruction speed.\nFaithful coil sensitivity estimation is vital for MRI reconstruction. However,\nmost deep learning methods still rely on pre-estimated sensitivity maps and\nignore their inaccuracy, resulting in the significant quality degradation of\nreconstructed images. In this work, we propose a Joint Deep Sensitivity\nestimation and Image reconstruction network, called JDSI. During the image\nartifacts removal, it gradually provides more faithful sensitivity maps with\nhigh-frequency information, leading to improved image reconstructions. To\nunderstand the behavior of the network, the mutual promotion of sensitivity\nestimation and image reconstruction is revealed through the visualization of\nnetwork intermediate results. Results on in vivo datasets and radiologist\nreader study demonstrate that, for both calibration-based and calibrationless\nreconstruction, the proposed JDSI achieves the state-of-the-art performance\nvisually and quantitatively, especially when the acceleration factor is high.\nAdditionally, JDSI owns nice robustness to patients and autocalibration\nsignals.\n","authors":["Zi Wang","Haoming Fang","Chen Qian","Boxuan Shi","Lijun Bao","Liuhong Zhu","Jianjun Zhou","Wenping Wei","Jianzhong Lin","Di Guo","Xiaobo Qu"],"pdf_url":"https://arxiv.org/pdf/2210.12723v2.pdf","comment":"11 pages, 12 figures, 7 tables"},{"id":"http://arxiv.org/abs/2311.10306v1","updated":"2023-11-17T03:33:09Z","published":"2023-11-17T03:33:09Z","title":"MPSeg : Multi-Phase strategy for coronary artery Segmentation","summary":"  Accurate segmentation of coronary arteries is a pivotal process in assessing\ncardiovascular diseases. However, the intricate structure of the cardiovascular\nsystem presents significant challenges for automatic segmentation, especially\nwhen utilizing methodologies like the SYNTAX Score, which relies extensively on\ndetailed structural information for precise risk stratification. To address\nthese difficulties and cater to this need, we present MPSeg, an innovative\nmulti-phase strategy designed for coronary artery segmentation. Our approach\nspecifically accommodates these structural complexities and adheres to the\nprinciples of the SYNTAX Score. Initially, our method segregates vessels into\ntwo categories based on their unique morphological characteristics: Left\nCoronary Artery (LCA) and Right Coronary Artery (RCA). Specialized ensemble\nmodels are then deployed for each category to execute the challenging\nsegmentation task. Due to LCA's higher complexity over RCA, a refinement model\nis utilized to scrutinize and correct initial class predictions on segmented\nareas. Notably, our approach demonstrated exceptional effectiveness when\nevaluated in the Automatic Region-based Coronary Artery Disease diagnostics\nusing x-ray angiography imagEs (ARCADE) Segmentation Detection Algorithm\nchallenge at MICCAI 2023.\n","authors":["Jonghoe Ku","Yong-Hee Lee","Junsup Shin","In Kyu Lee","Hyun-Woo Kim"],"pdf_url":"https://arxiv.org/pdf/2311.10306v1.pdf","comment":"MICCAI 2023 Conference ARCADE Challenge"},{"id":"http://arxiv.org/abs/2310.15479v2","updated":"2023-11-17T03:24:50Z","published":"2023-10-24T03:15:19Z","title":"AutoDiff: combining Auto-encoder and Diffusion model for tabular data\n  synthesizing","summary":"  Diffusion model has become a main paradigm for synthetic data generation in\nmany subfields of modern machine learning, including computer vision, language\nmodel, or speech synthesis. In this paper, we leverage the power of diffusion\nmodel for generating synthetic tabular data. The heterogeneous features in\ntabular data have been main obstacles in tabular data synthesis, and we tackle\nthis problem by employing the auto-encoder architecture. When compared with the\nstate-of-the-art tabular synthesizers, the resulting synthetic tables from our\nmodel show nice statistical fidelities to the real data, and perform well in\ndownstream tasks for machine learning utilities. We conducted the experiments\nover $15$ publicly available datasets. Notably, our model adeptly captures the\ncorrelations among features, which has been a long-standing challenge in\ntabular data synthesis. Our code is available at\nhttps://github.com/UCLA-Trustworthy-AI-Lab/AutoDiffusion.\n","authors":["Namjoon Suh","Xiaofeng Lin","Din-Yin Hsieh","Merhdad Honarkhah","Guang Cheng"],"pdf_url":"https://arxiv.org/pdf/2310.15479v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10300v1","updated":"2023-11-17T03:18:55Z","published":"2023-11-17T03:18:55Z","title":"Supervised structure learning","summary":"  This paper concerns structure learning or discovery of discrete generative\nmodels. It focuses on Bayesian model selection and the assimilation of training\ndata or content, with a special emphasis on the order in which data are\ningested. A key move - in the ensuing schemes - is to place priors on the\nselection of models, based upon expected free energy. In this setting, expected\nfree energy reduces to a constrained mutual information, where the constraints\ninherit from priors over outcomes (i.e., preferred outcomes). The resulting\nscheme is first used to perform image classification on the MNIST dataset to\nillustrate the basic idea, and then tested on a more challenging problem of\ndiscovering models with dynamics, using a simple sprite-based visual\ndisentanglement paradigm and the Tower of Hanoi (cf., blocks world) problem. In\nthese examples, generative models are constructed autodidactically to recover\n(i.e., disentangle) the factorial structure of latent states - and their\ncharacteristic paths or dynamics.\n","authors":["Karl J. Friston","Lancelot Da Costa","Alexander Tschantz","Alex Kiefer","Tommaso Salvatori","Victorita Neacsu","Magnus Koudahl","Conor Heins","Noor Sajid","Dimitrije Markovic","Thomas Parr","Tim Verbelen","Christopher L Buckley"],"pdf_url":"https://arxiv.org/pdf/2311.10300v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.09299v2","updated":"2023-11-17T03:00:26Z","published":"2023-10-07T09:09:19Z","title":"Digital Twin Accelerated Deep Reinforcement Learning for Online\n  Admission Control of Network Slicing","summary":"  The proliferation of diverse wireless services in 5G and beyond has led to\nthe emergence of network slicing technologies. Among these, admission control\nplays a crucial role in achieving service-oriented optimization goals through\nthe selective acceptance of service requests. Although deep reinforcement\nlearning (DRL) forms the foundation in many admission control approaches thanks\nto its effectiveness and flexibility, initial instability with excessive\nconvergence delay of DRL models hinders their deployment in real-world\nnetworks. We propose a digital twin (DT) accelerated DRL solution to address\nthis issue. Specifically, we first formulate the admission decision-making\nprocess as a semi-Markov decision process, which is subsequently simplified\ninto an equivalent discrete-time Markov decision process to facilitate the\nimplementation of DRL methods. A neural network-based DT is established with a\ncustomized output layer for queuing systems, trained through supervised\nlearning, and then employed to assist the training phase of the DRL model.\nExtensive simulations show that the DT-accelerated DRL improves resource\nutilization by over 40% compared to the directly trained state-of-the-art\ndueling deep Q-learning model. This improvement is achieved while preserving\nthe model's capability to optimize the long-term rewards of the admission\nprocess.\n","authors":["Zhenyu Tao","Wei Xu","Xiaohu You"],"pdf_url":"https://arxiv.org/pdf/2310.09299v2.pdf","comment":"13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2310.11248v2","updated":"2023-11-17T02:51:39Z","published":"2023-10-17T13:18:01Z","title":"CrossCodeEval: A Diverse and Multilingual Benchmark for Cross-File Code\n  Completion","summary":"  Code completion models have made significant progress in recent years, yet\ncurrent popular evaluation datasets, such as HumanEval and MBPP, predominantly\nfocus on code completion tasks within a single file. This over-simplified\nsetting falls short of representing the real-world software development\nscenario where repositories span multiple files with numerous cross-file\ndependencies, and accessing and understanding cross-file context is often\nrequired to complete the code correctly.\n  To fill in this gap, we propose CrossCodeEval, a diverse and multilingual\ncode completion benchmark that necessitates an in-depth cross-file contextual\nunderstanding to complete the code accurately. CrossCodeEval is built on a\ndiverse set of real-world, open-sourced, permissively-licensed repositories in\nfour popular programming languages: Python, Java, TypeScript, and C#. To create\nexamples that strictly require cross-file context for accurate completion, we\npropose a straightforward yet efficient static-analysis-based approach to\npinpoint the use of cross-file context within the current file.\n  Extensive experiments on state-of-the-art code language models like CodeGen\nand StarCoder demonstrate that CrossCodeEval is extremely challenging when the\nrelevant cross-file context is absent, and we see clear improvements when\nadding these context into the prompt. However, despite such improvements, the\npinnacle of performance remains notably unattained even with the\nhighest-performing model, indicating that CrossCodeEval is also capable of\nassessing model's capability in leveraging extensive context to make better\ncode completion. Finally, we benchmarked various methods in retrieving\ncross-file context, and show that CrossCodeEval can also be used to measure the\ncapability of code retrievers.\n","authors":["Yangruibo Ding","Zijian Wang","Wasi Uddin Ahmad","Hantian Ding","Ming Tan","Nihal Jain","Murali Krishna Ramanathan","Ramesh Nallapati","Parminder Bhatia","Dan Roth","Bing Xiang"],"pdf_url":"https://arxiv.org/pdf/2310.11248v2.pdf","comment":"To appear at NeurIPS 2023 (Datasets and Benchmarks Track)"},{"id":"http://arxiv.org/abs/2311.10293v1","updated":"2023-11-17T02:48:20Z","published":"2023-11-17T02:48:20Z","title":"Hierarchical Pruning of Deep Ensembles with Focal Diversity","summary":"  Deep neural network ensembles combine the wisdom of multiple deep neural\nnetworks to improve the generalizability and robustness over individual\nnetworks. It has gained increasing popularity to study deep ensemble techniques\nin the deep learning community. Some mission-critical applications utilize a\nlarge number of deep neural networks to form deep ensembles to achieve desired\naccuracy and resilience, which introduces high time and space costs for\nensemble execution. However, it still remains a critical challenge whether a\nsmall subset of the entire deep ensemble can achieve the same or better\ngeneralizability and how to effectively identify these small deep ensembles for\nimproving the space and time efficiency of ensemble execution. This paper\npresents a novel deep ensemble pruning approach, which can efficiently identify\nsmaller deep ensembles and provide higher ensemble accuracy than the entire\ndeep ensemble of a large number of member networks. Our hierarchical ensemble\npruning approach (HQ) leverages three novel ensemble pruning techniques. First,\nwe show that the focal diversity metrics can accurately capture the\ncomplementary capacity of the member networks of an ensemble, which can guide\nensemble pruning. Second, we design a focal diversity based hierarchical\npruning approach, which will iteratively find high quality deep ensembles with\nlow cost and high accuracy. Third, we develop a focal diversity consensus\nmethod to integrate multiple focal diversity metrics to refine ensemble pruning\nresults, where smaller deep ensembles can be effectively identified to offer\nhigh accuracy, high robustness and high efficiency. Evaluated using popular\nbenchmark datasets, we demonstrate that the proposed hierarchical ensemble\npruning approach can effectively identify high quality deep ensembles with\nbetter generalizability while being more time and space efficient in ensemble\ndecision making.\n","authors":["Yanzhao Wu","Ka-Ho Chow","Wenqi Wei","Ling Liu"],"pdf_url":"https://arxiv.org/pdf/2311.10293v1.pdf","comment":"To appear on ACM Transactions on Intelligent Systems and Technology"},{"id":"http://arxiv.org/abs/2311.10291v1","updated":"2023-11-17T02:37:10Z","published":"2023-11-17T02:37:10Z","title":"Leveraging Function Space Aggregation for Federated Learning at Scale","summary":"  The federated learning paradigm has motivated the development of methods for\naggregating multiple client updates into a global server model, without sharing\nclient data. Many federated learning algorithms, including the canonical\nFederated Averaging (FedAvg), take a direct (possibly weighted) average of the\nclient parameter updates, motivated by results in distributed optimization. In\nthis work, we adopt a function space perspective and propose a new algorithm,\nFedFish, that aggregates local approximations to the functions learned by\nclients, using an estimate based on their Fisher information. We evaluate\nFedFish on realistic, large-scale cross-device benchmarks. While the\nperformance of FedAvg can suffer as client models drift further apart, we\ndemonstrate that FedFish is more robust to longer local training. Our\nevaluation across several settings in image and language benchmarks shows that\nFedFish outperforms FedAvg as local training epochs increase. Further, FedFish\nresults in global networks that are more amenable to efficient personalization\nvia local fine-tuning on the same or shifted data distributions. For instance,\nfederated pretraining on the C4 dataset, followed by few-shot personalization\non Stack Overflow, results in a 7% improvement in next-token prediction by\nFedFish over FedAvg.\n","authors":["Nikita Dhawan","Nicole Mitchell","Zachary Charles","Zachary Garrett","Gintare Karolina Dziugaite"],"pdf_url":"https://arxiv.org/pdf/2311.10291v1.pdf","comment":"20 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.05836v3","updated":"2023-11-17T02:35:52Z","published":"2023-11-10T02:47:15Z","title":"UMedNeRF: Uncertainty-aware Single View Volumetric Rendering for Medical\n  Neural Radiance Fields","summary":"  In the field of clinical medicine, computed tomography (CT) is an effective\nmedical imaging modality for the diagnosis of various pathologies. Compared\nwith X-ray images, CT images can provide more information, including\nmulti-planar slices and three-dimensional structures for clinical diagnosis.\nHowever, CT imaging requires patients to be exposed to large doses of ionizing\nradiation for a long time, which may cause irreversible physical harm. In this\npaper, we propose an Uncertainty-aware MedNeRF (UMedNeRF) network based on\ngenerated radiation fields. The network can learn a continuous representation\nof CT projections from 2D X-ray images by obtaining the internal structure and\ndepth information and using adaptive loss weights to ensure the quality of the\ngenerated images. Our model is trained on publicly available knee and chest\ndatasets, and we show the results of CT projection rendering with a single\nX-ray and compare our method with other methods based on generated radiation\nfields.\n","authors":["Jing Hu","Qinrui Fan","Shu Hu","Siwei Lyu","Xi Wu","Xin Wang"],"pdf_url":"https://arxiv.org/pdf/2311.05836v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.05439v3","updated":"2023-11-17T02:20:40Z","published":"2021-09-12T06:13:33Z","title":"Concave Utility Reinforcement Learning with Zero-Constraint Violations","summary":"  We consider the problem of tabular infinite horizon concave utility\nreinforcement learning (CURL) with convex constraints. For this, we propose a\nmodel-based learning algorithm that also achieves zero constraint violations.\nAssuming that the concave objective and the convex constraints have a solution\ninterior to the set of feasible occupation measures, we solve a tighter\noptimization problem to ensure that the constraints are never violated despite\nthe imprecise model knowledge and model stochasticity. We use Bellman\nerror-based analysis for tabular infinite-horizon setups which allows analyzing\nstochastic policies. Combining the Bellman error-based analysis and tighter\noptimization equation, for $T$ interactions with the environment, we obtain a\nhigh-probability regret guarantee for objective which grows as\n$\\Tilde{O}(1/\\sqrt{T})$, excluding other factors. The proposed method can be\napplied for optimistic algorithms to obtain high-probability regret bounds and\nalso be used for posterior sampling algorithms to obtain a loose Bayesian\nregret bounds but with significant improvement in computational complexity.\n","authors":["Mridul Agarwal","Qinbo Bai","Vaneet Aggarwal"],"pdf_url":"https://arxiv.org/pdf/2109.05439v3.pdf","comment":"Transactions on Machine Learning Research, Dec 2022"},{"id":"http://arxiv.org/abs/2311.10278v1","updated":"2023-11-17T01:55:15Z","published":"2023-11-17T01:55:15Z","title":"Physics-Enhanced Multi-fidelity Learning for Optical Surface Imprint","summary":"  Human fingerprints serve as one unique and powerful characteristic for each\nperson, from which policemen can recognize the identity. Similar to humans,\nmany natural bodies and intrinsic mechanical qualities can also be uniquely\nidentified from surface characteristics. To measure the elasto-plastic\nproperties of one material, one formally sharp indenter is pushed into the\nmeasured body under constant force and retracted, leaving a unique residual\nimprint of the minute size from several micrometers to nanometers. However, one\ngreat challenge is how to map the optical image of this residual imprint into\nthe real wanted mechanical properties, i.e., the tensile force curve. In this\npaper, we propose a novel method to use multi-fidelity neural networks (MFNN)\nto solve this inverse problem. We first actively train the NN model via pure\nsimulation data, and then bridge the sim-to-real gap via transfer learning. The\nmost innovative part is that we use NN to dig out the unknown physics and also\nimplant the known physics into the transfer learning framework, thus highly\nimproving the model stability and decreasing the data requirement. This work\nserves as one great example of applying machine learning into the real\nexperimental research, especially under the constraints of data limitation and\nfidelity variance.\n","authors":["Yongchao Chen"],"pdf_url":"https://arxiv.org/pdf/2311.10278v1.pdf","comment":"8 pages, 4 figures, NeurIPS 2023 Workshop on Adaptive Experimental\n  Design and Active Learning in the Real World"},{"id":"http://arxiv.org/abs/2303.17807v2","updated":"2023-11-17T01:49:57Z","published":"2023-03-31T05:43:21Z","title":"GPT-4 can pass the Korean National Licensing Examination for Korean\n  Medicine Doctors","summary":"  Traditional Korean medicine (TKM) emphasizes individualized diagnosis and\ntreatment. This uniqueness makes AI modeling difficult due to limited data and\nimplicit processes. Large language models (LLMs) have demonstrated impressive\nmedical inference, even without advanced training in medical texts. This study\nassessed the capabilities of GPT-4 in TKM, using the Korean National Licensing\nExamination for Korean Medicine Doctors (K-NLEKMD) as a benchmark. The\nK-NLEKMD, administered by a national organization, encompasses 12 major\nsubjects in TKM. We optimized prompts with Chinese-term annotation, English\ntranslation for questions and instruction, exam-optimized instruction, and\nself-consistency. GPT-4 with optimized prompts achieved 66.18% accuracy,\nsurpassing both the examination's average pass mark of 60% and the 40% minimum\nfor each subject. The gradual introduction of language-related prompts and\nprompting techniques enhanced the accuracy from 51.82% to its maximum accuracy.\nGPT-4 showed low accuracy in subjects including public health &\nmedicine-related law, internal medicine (2) which are localized in Korea and\nTKM. The model's accuracy was lower for questions requiring TKM-specialized\nknowledge. It exhibited higher accuracy in diagnosis-based and recall-based\nquestions than in intervention-based questions. A positive correlation was\nobserved between the consistency and accuracy of GPT-4's responses. This study\nunveils both the potential and challenges of applying LLMs to TKM. These\nfindings underline the potential of LLMs like GPT-4 in culturally adapted\nmedicine, especially TKM, for tasks such as clinical assistance, medical\neducation, and research. But they also point towards the necessity for the\ndevelopment of methods to mitigate cultural bias inherent in large language\nmodels and validate their efficacy in real-world clinical settings.\n","authors":["Dongyeop Jang","Tae-Rim Yun","Choong-Yeol Lee","Young-Kyu Kwon","Chang-Eop Kim"],"pdf_url":"https://arxiv.org/pdf/2303.17807v2.pdf","comment":"23 pages, 4 figures"},{"id":"http://arxiv.org/abs/2311.10277v1","updated":"2023-11-17T01:48:07Z","published":"2023-11-17T01:48:07Z","title":"Sobol Sequence Optimization for Hardware-Efficient Vector Symbolic\n  Architectures","summary":"  Hyperdimensional computing (HDC) is an emerging computing paradigm with\nsignificant promise for efficient and robust learning. In HDC, objects are\nencoded with high-dimensional vector symbolic sequences called hypervectors.\nThe quality of hypervectors, defined by their distribution and independence,\ndirectly impacts the performance of HDC systems. Despite a large body of work\non the processing parts of HDC systems, little to no attention has been paid to\ndata encoding and the quality of hypervectors. Most prior studies have\ngenerated hypervectors using inherent random functions, such as MATLAB`s or\nPython`s random function. This work introduces an optimization technique for\ngenerating hypervectors by employing quasi-random sequences. These sequences\nhave recently demonstrated their effectiveness in achieving accurate and\nlow-discrepancy data encoding in stochastic computing systems. The study\noutlines the optimization steps for utilizing Sobol sequences to produce\nhigh-quality hypervectors in HDC systems. An optimization algorithm is proposed\nto select the most suitable Sobol sequences for generating minimally correlated\nhypervectors, particularly in applications related to symbol-oriented\narchitectures. The performance of the proposed technique is evaluated in\ncomparison to two traditional approaches of generating hypervectors based on\nlinear-feedback shift registers and MATLAB random function. The evaluation is\nconducted for two applications: (i) language and (ii) headline classification.\nOur experimental results demonstrate accuracy improvements of up to 10.79%,\ndepending on the vector size. Additionally, the proposed encoding hardware\nexhibits reduced energy consumption and a superior area-delay product.\n","authors":["Sercan Aygun","M. Hassan Najafi"],"pdf_url":"https://arxiv.org/pdf/2311.10277v1.pdf","comment":"9 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.10270v1","updated":"2023-11-17T01:30:43Z","published":"2023-11-17T01:30:43Z","title":"Multiscale Hodge Scattering Networks for Data Analysis","summary":"  We propose new scattering networks for signals measured on simplicial\ncomplexes, which we call \\emph{Multiscale Hodge Scattering Networks} (MHSNs).\nOur construction is based on multiscale basis dictionaries on simplicial\ncomplexes, i.e., the $\\kappa$-GHWT and $\\kappa$-HGLET, which we recently\ndeveloped for simplices of dimension $\\kappa \\in \\N$ in a given simplicial\ncomplex by generalizing the node-based Generalized Haar-Walsh Transform (GHWT)\nand Hierarchical Graph Laplacian Eigen Transform (HGLET). The $\\kappa$-GHWT and\nthe $\\kk$-HGLET both form redundant sets (i.e., dictionaries) of multiscale\nbasis vectors and the corresponding expansion coefficients of a given signal.\nOur MHSNs use a layered structure analogous to a convolutional neural network\n(CNN) to cascade the moments of the modulus of the dictionary coefficients. The\nresulting features are invariant to reordering of the simplices (i.e., node\npermutation of the underlying graphs). Importantly, the use of multiscale basis\ndictionaries in our MHSNs admits a natural pooling operation that is akin to\nlocal pooling in CNNs, and which may be performed either locally or per-scale.\nThese pooling operations are harder to define in both traditional scattering\nnetworks based on Morlet wavelets, and geometric scattering networks based on\nDiffusion Wavelets. As a result, we are able to extract a rich set of\ndescriptive yet robust features that can be used along with very simple machine\nlearning methods (i.e., logistic regression or support vector machines) to\nachieve high-accuracy classification systems with far fewer parameters to train\nthan most modern graph neural networks. Finally, we demonstrate the usefulness\nof our MHSNs in three distinct types of problems: signal classification, domain\n(i.e., graph/simplex) classification, and molecular dynamics prediction.\n","authors":["Naoki Saito","Stefan C. Schonsheck","Eugene Shvarts"],"pdf_url":"https://arxiv.org/pdf/2311.10270v1.pdf","comment":"20 Pages, Comments Welcome"},{"id":"http://arxiv.org/abs/2311.10267v1","updated":"2023-11-17T01:27:01Z","published":"2023-11-17T01:27:01Z","title":"Energy and Carbon Considerations of Fine-Tuning BERT","summary":"  Despite the popularity of the `pre-train then fine-tune' paradigm in the NLP\ncommunity, existing work quantifying energy costs and associated carbon\nemissions has largely focused on language model pre-training. Although a single\npre-training run draws substantially more energy than fine-tuning, fine-tuning\nis performed more frequently by many more individual actors, and thus must be\naccounted for when considering the energy and carbon footprint of NLP. In order\nto better characterize the role of fine-tuning in the landscape of energy and\ncarbon emissions in NLP, we perform a careful empirical study of the\ncomputational costs of fine-tuning across tasks, datasets, hardware\ninfrastructure and measurement modalities. Our experimental results allow us to\nplace fine-tuning energy and carbon costs into perspective with respect to\npre-training and inference, and outline recommendations to NLP researchers and\npractitioners who wish to improve their fine-tuning energy efficiency.\n","authors":["Xiaorong Wang","Clara Na","Emma Strubell","Sorelle Friedler","Sasha Luccioni"],"pdf_url":"https://arxiv.org/pdf/2311.10267v1.pdf","comment":"EMNLP 2023 Findings; First two authors contributed equally; 12 pages"},{"id":"http://arxiv.org/abs/2311.09574v2","updated":"2023-11-17T01:24:47Z","published":"2023-11-16T05:17:14Z","title":"LymphoML: An interpretable artificial intelligence-based method\n  identifies morphologic features that correlate with lymphoma subtype","summary":"  The accurate classification of lymphoma subtypes using hematoxylin and eosin\n(H&E)-stained tissue is complicated by the wide range of morphological features\nthese cancers can exhibit. We present LymphoML - an interpretable machine\nlearning method that identifies morphologic features that correlate with\nlymphoma subtypes. Our method applies steps to process H&E-stained tissue\nmicroarray cores, segment nuclei and cells, compute features encompassing\nmorphology, texture, and architecture, and train gradient-boosted models to\nmake diagnostic predictions. LymphoML's interpretable models, developed on a\nlimited volume of H&E-stained tissue, achieve non-inferior diagnostic accuracy\nto pathologists using whole-slide images and outperform black box deep-learning\non a dataset of 670 cases from Guatemala spanning 8 lymphoma subtypes. Using\nSHapley Additive exPlanation (SHAP) analysis, we assess the impact of each\nfeature on model prediction and find that nuclear shape features are most\ndiscriminative for DLBCL (F1-score: 78.7%) and classical Hodgkin lymphoma\n(F1-score: 74.5%). Finally, we provide the first demonstration that a model\ncombining features from H&E-stained tissue with features from a standardized\npanel of 6 immunostains results in a similar diagnostic accuracy (85.3%) to a\n46-stain panel (86.1%).\n","authors":["Vivek Shankar","Xiaoli Yang","Vrishab Krishna","Brent Tan","Oscar Silva","Rebecca Rojansky","Andrew Ng","Fabiola Valvert","Edward Briercheck","David Weinstock","Yasodha Natkunam","Sebastian Fernandez-Pol","Pranav Rajpurkar"],"pdf_url":"https://arxiv.org/pdf/2311.09574v2.pdf","comment":"To be published in Proceedings of the 3rd Machine Learning for Health\n  symposium, Proceedings of Machine Learning Research (PMLR)"},{"id":"http://arxiv.org/abs/2309.09969v2","updated":"2023-11-17T01:24:26Z","published":"2023-09-18T17:50:17Z","title":"Prompt a Robot to Walk with Large Language Models","summary":"  Large language models (LLMs) pre-trained on vast internet-scale data have\nshowcased remarkable capabilities across diverse domains. Recently, there has\nbeen escalating interest in deploying LLMs for robotics, aiming to harness the\npower of foundation models in real-world settings. However, this approach faces\nsignificant challenges, particularly in grounding these models in the physical\nworld and in generating dynamic robot motions. To address these issues, we\nintroduce a novel paradigm in which we use few-shot prompts collected from the\nphysical environment, enabling the LLM to autoregressively generate low-level\ncontrol commands for robots without task-specific fine-tuning. Experiments\nacross various robots and environments validate that our method can effectively\nprompt a robot to walk. We thus illustrate how LLMs can proficiently function\nas low-level feedback controllers for dynamic motion control even in\nhigh-dimensional robotic systems. The project website and source code can be\nfound at: https://prompt2walk.github.io/ .\n","authors":["Yen-Jen Wang","Bike Zhang","Jianyu Chen","Koushil Sreenath"],"pdf_url":"https://arxiv.org/pdf/2309.09969v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10263v1","updated":"2023-11-17T01:14:24Z","published":"2023-11-17T01:14:24Z","title":"Stable Differentiable Causal Discovery","summary":"  Inferring causal relationships as directed acyclic graphs (DAGs) is an\nimportant but challenging problem. Differentiable Causal Discovery (DCD) is a\npromising approach to this problem, framing the search as a continuous\noptimization. But existing DCD methods are numerically unstable, with poor\nperformance beyond tens of variables. In this paper, we propose Stable\nDifferentiable Causal Discovery (SDCD), a new method that improves previous DCD\nmethods in two ways: (1) It employs an alternative constraint for acyclicity;\nthis constraint is more stable, both theoretically and empirically, and fast to\ncompute. (2) It uses a training procedure tailored for sparse causal graphs,\nwhich are common in real-world scenarios. We first derive SDCD and prove its\nstability and correctness. We then evaluate it with both observational and\ninterventional data and on both small-scale and large-scale settings. We find\nthat SDCD outperforms existing methods in both convergence speed and accuracy\nand can scale to thousands of variables.\n","authors":["Achille Nazaret","Justin Hong","Elham Azizi","David Blei"],"pdf_url":"https://arxiv.org/pdf/2311.10263v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10255v1","updated":"2023-11-17T00:53:09Z","published":"2023-11-17T00:53:09Z","title":"FREE: The Foundational Semantic Recognition for Modeling Environmental\n  Ecosystems","summary":"  Modeling environmental ecosystems is critical for the sustainability of our\nplanet, but is extremely challenging due to the complex underlying processes\ndriven by interactions amongst a large number of physical variables. As many\nvariables are difficult to measure at large scales, existing works often\nutilize a combination of observable features and locally available measurements\nor modeled values as input to build models for a specific study region and time\nperiod. This raises a fundamental question in advancing the modeling of\nenvironmental ecosystems: how to build a general framework for modeling the\ncomplex relationships amongst various environmental data over space and time?\nIn this paper, we introduce a new framework, FREE, which maps available\nenvironmental data into a text space and then converts the traditional\npredictive modeling task in environmental science to the semantic recognition\nproblem. The proposed FREE framework leverages recent advances in Large\nLanguage Models (LLMs) to supplement the original input features with natural\nlanguage descriptions. This facilitates capturing the data semantics and also\nallows harnessing the irregularities of input features. When used for long-term\nprediction, FREE has the flexibility to incorporate newly collected\nobservations to enhance future prediction. The efficacy of FREE is evaluated in\nthe context of two societally important real-world applications, predicting\nstream water temperature in the Delaware River Basin and predicting annual corn\nyield in Illinois and Iowa. Beyond the superior predictive performance over\nmultiple baseline methods, FREE is shown to be more data- and\ncomputation-efficient as it can be pre-trained on simulated data generated by\nphysics-based models.\n","authors":["Shiyuan Luo","Juntong Ni","Shengyu Chen","Runlong Yu","Yiqun Xie","Licheng Liu","Zhenong Jin","Huaxiu Yao","Xiaowei Jia"],"pdf_url":"https://arxiv.org/pdf/2311.10255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10251v1","updated":"2023-11-17T00:44:56Z","published":"2023-11-17T00:44:56Z","title":"UniMOS: A Universal Framework For Multi-Organ Segmentation Over\n  Label-Constrained Datasets","summary":"  Machine learning models for medical images can help physicians diagnose and\nmanage diseases. However, due to the fact that medical image annotation\nrequires a great deal of manpower and expertise, as well as the fact that\nclinical departments perform image annotation based on task orientation, there\nis the problem of having fewer medical image annotation data with more\nunlabeled data and having many datasets that annotate only a single organ. In\nthis paper, we present UniMOS, the first universal framework for achieving the\nutilization of fully and partially labeled images as well as unlabeled images.\nSpecifically, we construct a Multi-Organ Segmentation (MOS) module over\nfully/partially labeled data as the basenet and designed a new target adaptive\nloss. Furthermore, we incorporate a semi-supervised training module that\ncombines consistent regularization and pseudolabeling techniques on unlabeled\ndata, which significantly improves the segmentation of unlabeled data.\nExperiments show that the framework exhibits excellent performance in several\nmedical image segmentation tasks compared to other advanced methods, and also\nsignificantly improves data utilization and reduces annotation cost. Code and\nmodels are available at: https://github.com/lw8807001/UniMOS.\n","authors":["Can Li","Sheng Shao","Junyi Qu","Shuchao Pang","Mehmet A. Orgun"],"pdf_url":"https://arxiv.org/pdf/2311.10251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10248v1","updated":"2023-11-17T00:39:59Z","published":"2023-11-17T00:39:59Z","title":"FedTruth: Byzantine-Robust and Backdoor-Resilient Federated Learning\n  Framework","summary":"  Federated Learning (FL) enables collaborative machine learning model training\nacross multiple parties without sharing raw data. However, FL's distributed\nnature allows malicious clients to impact model training through Byzantine or\nbackdoor attacks, using erroneous model updates. Existing defenses measure the\ndeviation of each update from a 'ground-truth model update.' They often rely on\na benign root dataset on the server or use trimmed mean or median for clipping,\nboth methods having limitations.\n  We introduce FedTruth, a robust defense against model poisoning in FL.\nFedTruth doesn't assume specific data distributions nor requires a benign root\ndataset. It estimates a global model update with dynamic aggregation weights,\nconsidering contributions from all benign clients. Empirical studies\ndemonstrate FedTruth's efficacy in mitigating the impacts of poisoned updates\nfrom both Byzantine and backdoor attacks.\n","authors":["Sheldon C. Ebron Jr.","Kan Yang"],"pdf_url":"https://arxiv.org/pdf/2311.10248v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10246v1","updated":"2023-11-17T00:35:38Z","published":"2023-11-17T00:35:38Z","title":"Surprisal Driven $k$-NN for Robust and Interpretable Nonparametric\n  Learning","summary":"  Nonparametric learning is a fundamental concept in machine learning that aims\nto capture complex patterns and relationships in data without making strong\nassumptions about the underlying data distribution. Owing to simplicity and\nfamiliarity, one of the most well-known algorithms under this paradigm is the\n$k$-nearest neighbors ($k$-NN) algorithm. Driven by the usage of machine\nlearning in safety-critical applications, in this work, we shed new light on\nthe traditional nearest neighbors algorithm from the perspective of information\ntheory and propose a robust and interpretable framework for tasks such as\nclassification, regression, and anomaly detection using a single model. Instead\nof using a traditional distance measure which needs to be scaled and\ncontextualized, we use a novel formulation of \\textit{surprisal} (amount of\ninformation required to explain the difference between the observed and\nexpected result). Finally, we demonstrate this architecture's capability to\nperform at-par or above the state-of-the-art on classification, regression, and\nanomaly detection tasks using a single model with enhanced interpretability by\nproviding novel concepts for characterizing data and predictions.\n","authors":["Amartya Banerjee","Christopher J. Hazard","Jacob Beel","Cade Mack","Jack Xia","Michael Resnick","Will Goddin"],"pdf_url":"https://arxiv.org/pdf/2311.10246v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.06233v2","updated":"2023-11-17T00:20:44Z","published":"2023-11-10T18:48:58Z","title":"Data Contamination Quiz: A Tool to Detect and Estimate Contamination in\n  Large Language Models","summary":"  We propose the Data Contamination Quiz, a simple and effective approach to\ndetect data contamination in large language models (LLMs) and estimate the\namount of it. Specifically, we frame data contamination detection as a series\nof multiple-choice questions. We devise a quiz format wherein three perturbed\nversions of each dataset instance are created. These changes only include\nword-level perturbations, replacing words with their contextual synonyms,\nensuring both the semantic and sentence structure remain exactly the same as\nthe original instance. Together with the original instance, these perturbed\nversions constitute the choices in the quiz. Given that the only distinguishing\nsignal among these choices is the exact wording, an LLM, when tasked with\nidentifying the original instance from the choices, opts for the original if it\nhas memorized it in its pre-training phase--a trait intrinsic to LLMs. A\ndataset partition is then marked as contaminated if the LLM's performance on\nthe quiz surpasses what random chance suggests. Our evaluation spans seven\ndatasets and their respective splits (train and test/validation) on two\nstate-of-the-art LLMs: GPT-4 and GPT-3.5. While lacking access to the\npre-training data, our results suggest that our approach not only enhances the\ndetection of data contamination but also provides an accurate estimation of its\nextent, even when the contamination signal is weak.\n","authors":["Shahriar Golchin","Mihai Surdeanu"],"pdf_url":"https://arxiv.org/pdf/2311.06233v2.pdf","comment":"v1.1 preprint"},{"id":"http://arxiv.org/abs/2311.10242v1","updated":"2023-11-17T00:08:19Z","published":"2023-11-17T00:08:19Z","title":"Advancements in Generative AI: A Comprehensive Review of GANs, GPT,\n  Autoencoders, Diffusion Model, and Transformers","summary":"  The launch of ChatGPT has garnered global attention, marking a significant\nmilestone in the field of Generative Artificial Intelligence. While Generative\nAI has been in effect for the past decade, the introduction of ChatGPT has\nignited a new wave of research and innovation in the AI domain. This surge in\ninterest has led to the development and release of numerous cutting-edge tools,\nsuch as Bard, Stable Diffusion, DALL-E, Make-A-Video, Runway ML, and Jukebox,\namong others. These tools exhibit remarkable capabilities, encompassing tasks\nranging from text generation and music composition, image creation, video\nproduction, code generation, and even scientific work. They are built upon\nvarious state-of-the-art models, including Stable Diffusion, transformer models\nlike GPT-3 (recent GPT-4), variational autoencoders, and generative adversarial\nnetworks. This advancement in Generative AI presents a wealth of exciting\nopportunities and, simultaneously, unprecedented challenges. Throughout this\npaper, we have explored these state-of-the-art models, the diverse array of\ntasks they can accomplish, the challenges they pose, and the promising future\nof Generative Artificial Intelligence.\n","authors":["Staphord Bengesi","Hoda El-Sayed","Md Kamruzzaman Sarker","Yao Houkpati","John Irungu","Timothy Oladunni"],"pdf_url":"https://arxiv.org/pdf/2311.10242v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2311.10709v1","updated":"2023-11-17T18:59:04Z","published":"2023-11-17T18:59:04Z","title":"Emu Video: Factorizing Text-to-Video Generation by Explicit Image\n  Conditioning","summary":"  We present Emu Video, a text-to-video generation model that factorizes the\ngeneration into two steps: first generating an image conditioned on the text,\nand then generating a video conditioned on the text and the generated image. We\nidentify critical design decisions--adjusted noise schedules for diffusion, and\nmulti-stage training--that enable us to directly generate high quality and high\nresolution videos, without requiring a deep cascade of models as in prior work.\nIn human evaluations, our generated videos are strongly preferred in quality\ncompared to all prior work--81% vs. Google's Imagen Video, 90% vs. Nvidia's\nPYOCO, and 96% vs. Meta's Make-A-Video. Our model outperforms commercial\nsolutions such as RunwayML's Gen2 and Pika Labs. Finally, our factorizing\napproach naturally lends itself to animating images based on a user's text\nprompt, where our generations are preferred 96% over prior work.\n","authors":["Rohit Girdhar","Mannat Singh","Andrew Brown","Quentin Duval","Samaneh Azadi","Sai Saketh Rambhatla","Akbar Shah","Xi Yin","Devi Parikh","Ishan Misra"],"pdf_url":"https://arxiv.org/pdf/2311.10709v1.pdf","comment":"Project page: https://emu-video.metademolab.com"},{"id":"http://arxiv.org/abs/2311.10645v1","updated":"2023-11-17T17:01:09Z","published":"2023-11-17T17:01:09Z","title":"User Dynamics-Aware Edge Caching and Computing for Mobile Virtual\n  Reality","summary":"  In this paper, we present a novel content caching and delivery approach for\nmobile virtual reality (VR) video streaming. The proposed approach aims to\nmaximize VR video streaming performance, i.e., minimizing video frame missing\nrate, by proactively caching popular VR video chunks and adaptively scheduling\ncomputing resources at an edge server based on user and network dynamics.\nFirst, we design a scalable content placement scheme for deciding which video\nchunks to cache at the edge server based on tradeoffs between computing and\ncaching resource consumption. Second, we propose a machine learning-assisted VR\nvideo delivery scheme, which allocates computing resources at the edge server\nto satisfy video delivery requests from multiple VR headsets. A Whittle\nindex-based method is adopted to reduce the video frame missing rate by\nidentifying network and user dynamics with low signaling overhead. Simulation\nresults demonstrate that the proposed approach can significantly improve VR\nvideo streaming performance over conventional caching and computing resource\nscheduling strategies.\n","authors":["Mushu Li","Jie Gao","Conghao Zhou","Xuemin Shen","Weihua Zhuang"],"pdf_url":"https://arxiv.org/pdf/2311.10645v1.pdf","comment":"38 pages, 13 figures, single column double spaced, published in IEEE\n  Journal of Selected Topics in Signal Processing"},{"id":"http://arxiv.org/abs/2311.10256v1","updated":"2023-11-17T00:56:55Z","published":"2023-11-17T00:56:55Z","title":"Exploring User Perceptions of Virtual Reality Scene Design in Metaverse\n  Learning Environments","summary":"  Metaverse learning environments allow for a seamless and intuitive transition\nbetween activities compared to Virtual Reality (VR) learning environments, due\nto their interconnected design. The design of VR scenes is important for\ncreating effective learning experiences in the Metaverse. However, there is\nlimited research on the impact of different design elements on user's learning\nexperiences in VR scenes. To address this, a study was conducted with 16\nparticipants who interacted with two VR scenes, each with varying design\nelements such as style, color, texture, object, and background, while watching\na short tutorial. Participant rankings of the scenes for learning were obtained\nusing a seven-point Likert scale, and the Mann-Whitney U test was used to\nvalidate differences in preference between the scenes. The results showed a\nsignificant difference in preference between the scenes. Further analysis using\nthe NASA TLX questionnaire was conducted to examine the impact of this\ndifference on cognitive load, and participant feedback was also considered. The\nstudy emphasizes the importance of careful VR scene design to improve the\nuser's learning experience.\n","authors":["Rahatara Ferdousi","Mohammed Faisal","Fedwa Laamarti","Chunsheng Yang","Abdulmotaleb El Saddik"],"pdf_url":"https://arxiv.org/pdf/2311.10256v1.pdf","comment":"6 pages,3 figures, accepted to present at IEEE 42nd International\n  Conference on Consumer Electronics"},{"id":"http://arxiv.org/abs/2211.09124v3","updated":"2023-11-17T13:11:53Z","published":"2022-11-16T13:43:16Z","title":"A Review of Intelligent Music Generation Systems","summary":"  With the introduction of ChatGPT, the public's perception of AI-generated\ncontent (AIGC) has begun to reshape. Artificial intelligence has significantly\nreduced the barrier to entry for non-professionals in creative endeavors,\nenhancing the efficiency of content creation. Recent advancements have seen\nsignificant improvements in the quality of symbolic music generation, which is\nenabled by the use of modern generative algorithms to extract patterns implicit\nin a piece of music based on rule constraints or a musical corpus.\nNevertheless, existing literature reviews tend to present a conventional and\nconservative perspective on future development trajectories, with a notable\nabsence of thorough benchmarking of generative models. This paper provides a\nsurvey and analysis of recent intelligent music generation techniques,\noutlining their respective characteristics and discussing existing methods for\nevaluation. Additionally, the paper compares the different characteristics of\nmusic generation techniques in the East and West as well as analysing the\nfield's development prospects.\n","authors":["Lei Wang","Ziyi Zhao","Hanwei Liu","Junwei Pang","Yi Qin","Qidi Wu"],"pdf_url":"https://arxiv.org/pdf/2211.09124v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10791v1","updated":"2023-11-17T02:22:01Z","published":"2023-11-17T02:22:01Z","title":"Modality-invariant and Specific Prompting for Multimodal Human\n  Perception Understanding","summary":"  Understanding human perceptions presents a formidable multimodal challenge\nfor computers, encompassing aspects such as sentiment tendencies and sense of\nhumor. While various methods have recently been introduced to extract\nmodality-invariant and specific information from diverse modalities, with the\ngoal of enhancing the efficacy of multimodal learning, few works emphasize this\naspect in large language models. In this paper, we introduce a novel multimodal\nprompt strategy tailored for tuning large language models. Our method assesses\nthe correlation among different modalities and isolates the modality-invariant\nand specific components, which are then utilized for prompt tuning. This\napproach enables large language models to efficiently and effectively\nassimilate information from various modalities. Furthermore, our strategy is\ndesigned with scalability in mind, allowing the integration of features from\nany modality into pretrained large language models. Experimental results on\npublic datasets demonstrate that our proposed method significantly improves\nperformance compared to previous methods.\n","authors":["Hao Sun","Ziwei Niu","Xinyao Yu","Jiaqing Liu","Yen-Wei Chen","Lanfen Lin"],"pdf_url":"https://arxiv.org/pdf/2311.10791v1.pdf","comment":null}]},"2023-11-20T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2311.12023v1","updated":"2023-11-20T18:57:41Z","published":"2023-11-20T18:57:41Z","title":"LQ-LoRA: Low-rank Plus Quantized Matrix Decomposition for Efficient\n  Language Model Finetuning","summary":"  We propose a simple approach for memory-efficient adaptation of pretrained\nlanguage models. Our approach uses an iterative algorithm to decompose each\npretrained matrix into a high-precision low-rank component and a\nmemory-efficient quantized component. During finetuning, the quantized\ncomponent remains fixed and only the low-rank component is updated. We present\nan integer linear programming formulation of the quantization component which\nenables dynamic configuration of quantization parameters (e.g., bit-width,\nblock size) for each matrix given an overall target memory budget. We further\nexplore a data-aware version of the algorithm which uses an approximation of\nthe Fisher information matrix to weight the reconstruction objective during\nmatrix decomposition. Experiments on adapting RoBERTa and LLaMA-2 (7B and 70B)\ndemonstrate that our low-rank plus quantized matrix decomposition approach\n(LQ-LoRA) outperforms strong QLoRA and GPTQ-LoRA baselines and moreover enables\nmore aggressive quantization. For example, on the OpenAssistant benchmark\nLQ-LoRA is able to learn a 2.5-bit LLaMA-2 model that is competitive with a\nmodel finetuned with 4-bit QLoRA. When finetuned on a language modeling\ncalibration dataset, LQ-LoRA can also be used for model compression; in this\nsetting our 2.75-bit LLaMA-2-70B model (which has 2.85 bits on average when\nincluding the low-rank components and requires 27GB of GPU memory) is\ncompetitive with the original model in full precision.\n","authors":["Han Guo","Philip Greengard","Eric P. Xing","Yoon Kim"],"pdf_url":"https://arxiv.org/pdf/2311.12023v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12022v1","updated":"2023-11-20T18:57:34Z","published":"2023-11-20T18:57:34Z","title":"GPQA: A Graduate-Level Google-Proof Q&A Benchmark","summary":"  We present GPQA, a challenging dataset of 448 multiple-choice questions\nwritten by domain experts in biology, physics, and chemistry. We ensure that\nthe questions are high-quality and extremely difficult: experts who have or are\npursuing PhDs in the corresponding domains reach 65% accuracy (74% when\ndiscounting clear mistakes the experts identified in retrospect), while highly\nskilled non-expert validators only reach 34% accuracy, despite spending on\naverage over 30 minutes with unrestricted access to the web (i.e., the\nquestions are \"Google-proof\"). The questions are also difficult for\nstate-of-the-art AI systems, with our strongest GPT-4 based baseline achieving\n39% accuracy. If we are to use future AI systems to help us answer very hard\nquestions, for example, when developing new scientific knowledge, we need to\ndevelop scalable oversight methods that enable humans to supervise their\noutputs, which may be difficult even if the supervisors are themselves skilled\nand knowledgeable. The difficulty of GPQA both for skilled non-experts and\nfrontier AI systems should enable realistic scalable oversight experiments,\nwhich we hope can help devise ways for human experts to reliably get truthful\ninformation from AI systems that surpass human capabilities.\n","authors":["David Rein","Betty Li Hou","Asa Cooper Stickland","Jackson Petty","Richard Yuanzhe Pang","Julien Dirani","Julian Michael","Samuel R. Bowman"],"pdf_url":"https://arxiv.org/pdf/2311.12022v1.pdf","comment":"28 pages, 5 figures, 7 tables"},{"id":"http://arxiv.org/abs/2311.12015v1","updated":"2023-11-20T18:54:39Z","published":"2023-11-20T18:54:39Z","title":"GPT-4V(ision) for Robotics: Multimodal Task Planning from Human\n  Demonstration","summary":"  We introduce a pipeline that enhances a general-purpose Vision Language\nModel, GPT-4V(ision), by integrating observations of human actions to\nfacilitate robotic manipulation. This system analyzes videos of humans\nperforming tasks and creates executable robot programs that incorporate\naffordance insights. The computation starts by analyzing the videos with GPT-4V\nto convert environmental and action details into text, followed by a\nGPT-4-empowered task planner. In the following analyses, vision systems\nreanalyze the video with the task plan. Object names are grounded using an\nopen-vocabulary object detector, while focus on the hand-object relation helps\nto detect the moment of grasping and releasing. This spatiotemporal grounding\nallows the vision systems to further gather affordance data (e.g., grasp type,\nway points, and body postures). Experiments across various scenarios\ndemonstrate this method's efficacy in achieving real robots' operations from\nhuman demonstrations in a zero-shot manner. The prompts of GPT-4V/GPT-4 are\navailable at this project page:\nhttps://microsoft.github.io/GPT4Vision-Robot-Manipulation-Prompts/\n","authors":["Naoki Wake","Atsushi Kanehira","Kazuhiro Sasabuchi","Jun Takamatsu","Katsushi Ikeuchi"],"pdf_url":"https://arxiv.org/pdf/2311.12015v1.pdf","comment":"8 pages, 10 figures, 1 table. Last updated on November 20th, 2023"},{"id":"http://arxiv.org/abs/2310.15127v2","updated":"2023-11-20T18:51:29Z","published":"2023-10-23T17:31:55Z","title":"Open-Ended Instructable Embodied Agents with Memory-Augmented Large\n  Language Models","summary":"  Pre-trained and frozen large language models (LLMs) can effectively map\nsimple scene rearrangement instructions to programs over a robot's visuomotor\nfunctions through appropriate few-shot example prompting. To parse open-domain\nnatural language and adapt to a user's idiosyncratic procedures, not known\nduring prompt engineering time, fixed prompts fall short. In this paper, we\nintroduce HELPER, an embodied agent equipped with an external memory of\nlanguage-program pairs that parses free-form human-robot dialogue into action\nprograms through retrieval-augmented LLM prompting: relevant memories are\nretrieved based on the current dialogue, instruction, correction, or VLM\ndescription, and used as in-context prompt examples for LLM querying. The\nmemory is expanded during deployment to include pairs of user's language and\naction plans, to assist future inferences and personalize them to the user's\nlanguage and routines. HELPER sets a new state-of-the-art in the TEACh\nbenchmark in both Execution from Dialog History (EDH) and Trajectory from\nDialogue (TfD), with a 1.7x improvement over the previous state-of-the-art for\nTfD. Our models, code, and video results can be found in our project's website:\nhttps://helper-agent-llm.github.io.\n","authors":["Gabriel Sarch","Yue Wu","Michael J. Tarr","Katerina Fragkiadaki"],"pdf_url":"https://arxiv.org/pdf/2310.15127v2.pdf","comment":"Project page with code & videos: https://helper-agent-llm.github.io"},{"id":"http://arxiv.org/abs/2311.11981v1","updated":"2023-11-20T18:16:27Z","published":"2023-11-20T18:16:27Z","title":"H-COAL: Human Correction of AI-Generated Labels for Biomedical Named\n  Entity Recognition","summary":"  With the rapid advancement of machine learning models for NLP tasks,\ncollecting high-fidelity labels from AI models is a realistic possibility.\nFirms now make AI available to customers via predictions as a service (PaaS).\nThis includes PaaS products for healthcare. It is unclear whether these labels\ncan be used for training a local model without expensive annotation checking by\nin-house experts. In this work, we propose a new framework for Human Correction\nof AI-Generated Labels (H-COAL). By ranking AI-generated outputs, one can\nselectively correct labels and approach gold standard performance (100% human\nlabeling) with significantly less human effort. We show that correcting 5% of\nlabels can close the AI-human performance gap by up to 64% relative\nimprovement, and correcting 20% of labels can close the performance gap by up\nto 86% relative improvement.\n","authors":["Xiaojing Duan","John P. Lalor"],"pdf_url":"https://arxiv.org/pdf/2311.11981v1.pdf","comment":"Presented at Conference on Information Systems and Technology (CIST)\n  2023"},{"id":"http://arxiv.org/abs/2311.11979v1","updated":"2023-11-20T18:12:28Z","published":"2023-11-20T18:12:28Z","title":"On the Potential and Limitations of Few-Shot In-Context Learning to\n  Generate Metamorphic Specifications for Tax Preparation Software","summary":"  Due to the ever-increasing complexity of income tax laws in the United\nStates, the number of US taxpayers filing their taxes using tax preparation\nsoftware (henceforth, tax software) continues to increase. According to the\nU.S. Internal Revenue Service (IRS), in FY22, nearly 50% of taxpayers filed\ntheir individual income taxes using tax software. Given the legal consequences\nof incorrectly filing taxes for the taxpayer, ensuring the correctness of tax\nsoftware is of paramount importance. Metamorphic testing has emerged as a\nleading solution to test and debug legal-critical tax software due to the\nabsence of correctness requirements and trustworthy datasets. The key idea\nbehind metamorphic testing is to express the properties of a system in terms of\nthe relationship between one input and its slightly metamorphosed twinned\ninput. Extracting metamorphic properties from IRS tax publications is a tedious\nand time-consuming process. As a response, this paper formulates the task of\ngenerating metamorphic specifications as a translation task between properties\nextracted from tax documents - expressed in natural language - to a contrastive\nfirst-order logic form. We perform a systematic analysis on the potential and\nlimitations of in-context learning with Large Language Models(LLMs) for this\ntask, and outline a research agenda towards automating the generation of\nmetamorphic specifications for tax preparation software.\n","authors":["Dananjay Srinivas","Rohan Das","Saeid Tizpaz-Niari","Ashutosh Trivedi","Maria Leonor Pacheco"],"pdf_url":"https://arxiv.org/pdf/2311.11979v1.pdf","comment":"Accepted to the Proceedings of the Natural Legal Language Processing\n  Workshop, EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.11976v1","updated":"2023-11-20T18:06:03Z","published":"2023-11-20T18:06:03Z","title":"Context-aware Neural Machine Translation for English-Japanese Business\n  Scene Dialogues","summary":"  Despite the remarkable advancements in machine translation, the current\nsentence-level paradigm faces challenges when dealing with highly-contextual\nlanguages like Japanese. In this paper, we explore how context-awareness can\nimprove the performance of the current Neural Machine Translation (NMT) models\nfor English-Japanese business dialogues translation, and what kind of context\nprovides meaningful information to improve translation. As business dialogue\ninvolves complex discourse phenomena but offers scarce training resources, we\nadapted a pretrained mBART model, finetuning on multi-sentence dialogue data,\nwhich allows us to experiment with different contexts. We investigate the\nimpact of larger context sizes and propose novel context tokens encoding\nextra-sentential information, such as speaker turn and scene type. We make use\nof Conditional Cross-Mutual Information (CXMI) to explore how much of the\ncontext the model uses and generalise CXMI to study the impact of the\nextra-sentential context. Overall, we find that models leverage both preceding\nsentences and extra-sentential context (with CXMI increasing with context size)\nand we provide a more focused analysis on honorifics translation. Regarding\ntranslation quality, increased source-side context paired with scene and\nspeaker information improves the model performance compared to previous work\nand our context-agnostic baselines, measured in BLEU and COMET metrics.\n","authors":["Sumire Honda","Patrick Fernandes","Chrysoula Zerva"],"pdf_url":"https://arxiv.org/pdf/2311.11976v1.pdf","comment":"MT Summit 2023, research track, link to paper in proceedings:\n  https://aclanthology.org/2023.mtsummit-research.23/"},{"id":"http://arxiv.org/abs/2311.11973v1","updated":"2023-11-20T18:01:29Z","published":"2023-11-20T18:01:29Z","title":"Adaptive Training Distributions with Scalable Online Bilevel\n  Optimization","summary":"  Large neural networks pretrained on web-scale corpora are central to modern\nmachine learning. In this paradigm, the distribution of the large,\nheterogeneous pretraining data rarely matches that of the application domain.\nThis work considers modifying the pretraining distribution in the case where\none has a small sample of data reflecting the targeted test conditions. We\npropose an algorithm motivated by a recent formulation of this setting as an\nonline, bilevel optimization problem. With scalability in mind, our algorithm\nprioritizes computing gradients at training points which are likely to most\nimprove the loss on the targeted distribution. Empirically, we show that in\nsome cases this approach is beneficial over existing strategies from the domain\nadaptation literature but may not succeed in other cases. We propose a simple\ntest to evaluate when our approach can be expected to work well and point\ntowards further research to address current limitations.\n","authors":["David Grangier","Pierre Ablin","Awni Hannun"],"pdf_url":"https://arxiv.org/pdf/2311.11973v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11967v1","updated":"2023-11-20T17:47:37Z","published":"2023-11-20T17:47:37Z","title":"Automatic Analysis of Substantiation in Scientific Peer Reviews","summary":"  With the increasing amount of problematic peer reviews in top AI conferences,\nthe community is urgently in need of automatic quality control measures. In\nthis paper, we restrict our attention to substantiation -- one popular quality\naspect indicating whether the claims in a review are sufficiently supported by\nevidence -- and provide a solution automatizing this evaluation process. To\nachieve this goal, we first formulate the problem as claim-evidence pair\nextraction in scientific peer reviews, and collect SubstanReview, the first\nannotated dataset for this task. SubstanReview consists of 550 reviews from NLP\nconferences annotated by domain experts. On the basis of this dataset, we train\nan argument mining system to automatically analyze the level of substantiation\nin peer reviews. We also perform data analysis on the SubstanReview dataset to\nobtain meaningful insights on peer reviewing quality in NLP conferences over\nrecent years.\n","authors":["Yanzhu Guo","Guokan Shang","Virgile Rennard","Michalis Vazirgiannis","Chloé Clavel"],"pdf_url":"https://arxiv.org/pdf/2311.11967v1.pdf","comment":"Accepted to EMNLP 2023 Findings"},{"id":"http://arxiv.org/abs/2311.11944v1","updated":"2023-11-20T17:28:02Z","published":"2023-11-20T17:28:02Z","title":"FinanceBench: A New Benchmark for Financial Question Answering","summary":"  FinanceBench is a first-of-its-kind test suite for evaluating the performance\nof LLMs on open book financial question answering (QA). It comprises 10,231\nquestions about publicly traded companies, with corresponding answers and\nevidence strings. The questions in FinanceBench are ecologically valid and\ncover a diverse set of scenarios. They are intended to be clear-cut and\nstraightforward to answer to serve as a minimum performance standard. We test\n16 state of the art model configurations (including GPT-4-Turbo, Llama2 and\nClaude2, with vector stores and long context prompts) on a sample of 150 cases\nfrom FinanceBench, and manually review their answers (n=2,400). The cases are\navailable open-source. We show that existing LLMs have clear limitations for\nfinancial QA. Notably, GPT-4-Turbo used with a retrieval system incorrectly\nanswered or refused to answer 81% of questions. While augmentation techniques\nsuch as using longer context window to feed in relevant evidence improve\nperformance, they are unrealistic for enterprise settings due to increased\nlatency and cannot support larger financial documents. We find that all models\nexamined exhibit weaknesses, such as hallucinations, that limit their\nsuitability for use by enterprises.\n","authors":["Pranab Islam","Anand Kannappan","Douwe Kiela","Rebecca Qian","Nino Scherrer","Bertie Vidgen"],"pdf_url":"https://arxiv.org/pdf/2311.11944v1.pdf","comment":"Dataset is available at:\n  https://huggingface.co/datasets/PatronusAI/financebench"},{"id":"http://arxiv.org/abs/2311.10217v2","updated":"2023-11-20T17:08:11Z","published":"2023-11-16T22:15:15Z","title":"A Language and Its Dimensions: Intrinsic Dimensions of Language Fractal\n  Structures","summary":"  The present paper introduces a novel object of study - a language fractal\nstructure. We hypothesize that a set of embeddings of all $n$-grams of a\nnatural language constitutes a representative sample of this fractal set. (We\nuse the term Hailonakea to refer to the sum total of all language fractal\nstructures, over all $n$). The paper estimates intrinsic (genuine) dimensions\nof language fractal structures for the Russian and English languages. To this\nend, we employ methods based on (1) topological data analysis and (2) a minimum\nspanning tree of a data graph for a cloud of points considered (Steele\ntheorem). For both languages, for all $n$, the intrinsic dimensions appear to\nbe non-integer values (typical for fractal sets), close to 9 for both of the\nRussian and English language.\n","authors":["Vasilii A. Gromov","Nikita S. Borodin","Asel S. Yerbolova"],"pdf_url":"https://arxiv.org/pdf/2311.10217v2.pdf","comment":"Preprint. Under review"},{"id":"http://arxiv.org/abs/2209.09757v2","updated":"2023-11-20T16:54:55Z","published":"2022-09-20T14:39:12Z","title":"Language Varieties of Italy: Technology Challenges and Opportunities","summary":"  Italy is characterized by a one-of-a-kind linguistic diversity landscape in\nEurope, which implicitly encodes local knowledge, cultural traditions, artistic\nexpressions and history of its speakers. However, most local languages and\ndialects in Italy are at risk of disappearing within few generations. The NLP\ncommunity has recently begun to engage with endangered languages, including\nthose of Italy. Yet, most efforts assume that these varieties are\nunder-resourced language monoliths with an established written form and\nhomogeneous functions and needs, and thus highly interchangeable with each\nother and with high-resource, standardized languages. In this paper, we\nintroduce the linguistic context of Italy and challenge the default\nmachine-centric assumptions of NLP for Italy's language varieties. We advocate\nfor a shift in the paradigm from machine-centric to speaker-centric NLP, and\nprovide recommendations and opportunities for work that prioritizes languages\nand their speakers over technological advances. To facilitate the process, we\nfinally propose building a local community towards responsible, participatory\nefforts aimed at supporting vitality of languages and dialects of Italy.\n","authors":["Alan Ramponi"],"pdf_url":"https://arxiv.org/pdf/2209.09757v2.pdf","comment":"Accepted to TACL. This arXiv version is a pre-MIT Press publication\n  version"},{"id":"http://arxiv.org/abs/2311.11904v1","updated":"2023-11-20T16:37:45Z","published":"2023-11-20T16:37:45Z","title":"LLMs as Visual Explainers: Advancing Image Classification with Evolving\n  Visual Descriptions","summary":"  Vision-language models (VLMs) offer a promising paradigm for image\nclassification by comparing the similarity between images and class embeddings.\nA critical challenge lies in crafting precise textual representations for class\nnames. While previous studies have leveraged recent advancements in large\nlanguage models (LLMs) to enhance these descriptors, their outputs often suffer\nfrom ambiguity and inaccuracy. We identify two primary causes: 1) The prevalent\nreliance on textual interactions with LLMs, leading to a mismatch between the\ngenerated text and the visual content in VLMs' latent space - a phenomenon we\nterm the \"explain without seeing\" dilemma. 2) The oversight of the inter-class\nrelationships, resulting in descriptors that fail to differentiate similar\nclasses effectively. To address these issues, we propose a novel image\nclassification framework combining VLMs with LLMs, named Iterative Optimization\nwith Visual Feedback. In particular, our method develops an LLM-based agent,\nemploying an evolutionary optimization strategy to refine class descriptors.\nCrucially, we incorporate visual feedback from VLM classification metrics,\nthereby guiding the optimization process with concrete visual data. Our method\nleads to improving accuracy on a wide range of image classification benchmarks,\nwith 3.47\\% average gains over state-of-the-art methods. We also highlight the\nresulting descriptions serve as explainable and robust features that can\nconsistently improve the performance across various backbone models.\n","authors":["Songhao Han","Le Zhuo","Yue Liao","Si Liu"],"pdf_url":"https://arxiv.org/pdf/2311.11904v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.07496v3","updated":"2023-11-20T15:57:43Z","published":"2022-09-15T17:37:08Z","title":"Unsupervised Opinion Summarization Using Approximate Geodesics","summary":"  Opinion summarization is the task of creating summaries capturing popular\nopinions from user reviews. In this paper, we introduce Geodesic Summarizer\n(GeoSumm), a novel system to perform unsupervised extractive opinion\nsummarization. GeoSumm involves an encoder-decoder based representation\nlearning model, that generates representations of text as a distribution over\nlatent semantic units. GeoSumm generates these representations by performing\ndictionary learning over pre-trained text representations at multiple decoder\nlayers. We then use these representations to quantify the relevance of review\nsentences using a novel approximate geodesic distance based scoring mechanism.\nWe use the relevance scores to identify popular opinions in order to compose\ngeneral and aspect-specific summaries. Our proposed model, GeoSumm, achieves\nstate-of-the-art performance on three opinion summarization datasets. We\nperform additional experiments to analyze the functioning of our model and\nshowcase the generalization ability of {\\X} across different domains.\n","authors":["Somnath Basu Roy Chowdhury","Nicholas Monath","Avinava Dubey","Amr Ahmed","Snigdha Chaturvedi"],"pdf_url":"https://arxiv.org/pdf/2209.07496v3.pdf","comment":"Findings of EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.11861v1","updated":"2023-11-20T15:57:04Z","published":"2023-11-20T15:57:04Z","title":"Generating Valid and Natural Adversarial Examples with Large Language\n  Models","summary":"  Deep learning-based natural language processing (NLP) models, particularly\npre-trained language models (PLMs), have been revealed to be vulnerable to\nadversarial attacks. However, the adversarial examples generated by many\nmainstream word-level adversarial attack models are neither valid nor natural,\nleading to the loss of semantic maintenance, grammaticality, and human\nimperceptibility. Based on the exceptional capacity of language understanding\nand generation of large language models (LLMs), we propose LLM-Attack, which\naims at generating both valid and natural adversarial examples with LLMs. The\nmethod consists of two stages: word importance ranking (which searches for the\nmost vulnerable words) and word synonym replacement (which substitutes them\nwith their synonyms obtained from LLMs). Experimental results on the Movie\nReview (MR), IMDB, and Yelp Review Polarity datasets against the baseline\nadversarial attack models illustrate the effectiveness of LLM-Attack, and it\noutperforms the baselines in human and GPT-4 evaluation by a significant\nmargin. The model can generate adversarial examples that are typically valid\nand natural, with the preservation of semantic meaning, grammaticality, and\nhuman imperceptibility.\n","authors":["Zimu Wang","Wei Wang","Qi Chen","Qiufeng Wang","Anh Nguyen"],"pdf_url":"https://arxiv.org/pdf/2311.11861v1.pdf","comment":"Submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2311.11855v1","updated":"2023-11-20T15:50:09Z","published":"2023-11-20T15:50:09Z","title":"Evil Geniuses: Delving into the Safety of LLM-based Agents","summary":"  The rapid advancements in large language models (LLMs) have led to a\nresurgence in LLM-based agents, which demonstrate impressive human-like\nbehaviors and cooperative capabilities in various interactions and strategy\nformulations. However, evaluating the safety of LLM-based agents remains a\ncomplex challenge. This paper elaborately conducts a series of manual jailbreak\nprompts along with a virtual chat-powered evil plan development team, dubbed\nEvil Geniuses, to thoroughly probe the safety aspects of these agents. Our\ninvestigation reveals three notable phenomena: 1) LLM-based agents exhibit\nreduced robustness against malicious attacks. 2) the attacked agents could\nprovide more nuanced responses. 3) the detection of the produced improper\nresponses is more challenging. These insights prompt us to question the\neffectiveness of LLM-based attacks on agents, highlighting vulnerabilities at\nvarious levels and within different role specializations within the\nsystem/agent of LLM-based agents. Extensive evaluation and discussion reveal\nthat LLM-based agents face significant challenges in safety and yield insights\nfor future research. Our code is available at\nhttps://github.com/T1aNS1R/Evil-Geniuses.\n","authors":["Yu Tian","Xiao Yang","Jingyuan Zhang","Yinpeng Dong","Hang Su"],"pdf_url":"https://arxiv.org/pdf/2311.11855v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2311.11846v1","updated":"2023-11-20T15:37:33Z","published":"2023-11-20T15:37:33Z","title":"Deepparse : An Extendable, and Fine-Tunable State-Of-The-Art Library for\n  Parsing Multinational Street Addresses","summary":"  Segmenting an address into meaningful components, also known as address\nparsing, is an essential step in many applications from record linkage to\ngeocoding and package delivery. Consequently, a lot of work has been dedicated\nto develop accurate address parsing techniques, with machine learning and\nneural network methods leading the state-of-the-art scoreboard. However, most\nof the work on address parsing has been confined to academic endeavours with\nlittle availability of free and easy-to-use open-source solutions.\n  This paper presents Deepparse, a Python open-source, extendable, fine-tunable\naddress parsing solution under LGPL-3.0 licence to parse multinational\naddresses using state-of-the-art deep learning algorithms and evaluated on over\n60 countries. It can parse addresses written in any language and use any\naddress standard. The pre-trained model achieves average $99~\\%$ parsing\naccuracies on the countries used for training with no pre-processing nor\npost-processing needed. Moreover, the library supports fine-tuning with new\ndata to generate a custom address parser.\n","authors":["David Beauchemin","Marouane Yassine"],"pdf_url":"https://arxiv.org/pdf/2311.11846v1.pdf","comment":"Accepted in EMNLP 2024 NLP-OSS workshop. arXiv admin note: text\n  overlap with arXiv:2006.16152, arXiv:2112.04008"},{"id":"http://arxiv.org/abs/2311.11844v1","updated":"2023-11-20T15:34:45Z","published":"2023-11-20T15:34:45Z","title":"How to Use Large Language Models for Text Coding: The Case of Fatherhood\n  Roles in Public Policy Documents","summary":"  Recent advances in large language models (LLMs) like GPT-3 and GPT-4 have\nopened up new opportunities for text analysis in political science. They\npromise automation with better results and less programming. In this study, we\nevaluate LLMs on three original coding tasks of non-English political science\ntexts, and we provide a detailed description of a general workflow for using\nLLMs for text coding in political science research. Our use case offers a\npractical guide for researchers looking to incorporate LLMs into their research\non text analysis. We find that, when provided with detailed label definitions\nand coding examples, an LLM can be as good as or even better than a human\nannotator while being much faster (up to hundreds of times), considerably\ncheaper (costing up to 60% less than human coding), and much easier to scale to\nlarge amounts of text. Overall, LLMs present a viable option for most text\ncoding projects.\n","authors":["Lorenzo Lupo","Oscar Magnusson","Dirk Hovy","Elin Naurin","Lena Wängnerud"],"pdf_url":"https://arxiv.org/pdf/2311.11844v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11829v1","updated":"2023-11-20T15:04:50Z","published":"2023-11-20T15:04:50Z","title":"System 2 Attention (is something you might need too)","summary":"  Soft attention in Transformer-based Large Language Models (LLMs) is\nsusceptible to incorporating irrelevant information from the context into its\nlatent representations, which adversely affects next token generations. To help\nrectify these issues, we introduce System 2 Attention (S2A), which leverages\nthe ability of LLMs to reason in natural language and follow instructions in\norder to decide what to attend to. S2A regenerates the input context to only\ninclude the relevant portions, before attending to the regenerated context to\nelicit the final response. In experiments, S2A outperforms standard\nattention-based LLMs on three tasks containing opinion or irrelevant\ninformation, QA, math word problems and longform generation, where S2A\nincreases factuality and objectivity, and decreases sycophancy.\n","authors":["Jason Weston","Sainbayar Sukhbaatar"],"pdf_url":"https://arxiv.org/pdf/2311.11829v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08358v3","updated":"2023-11-20T14:52:43Z","published":"2022-11-15T18:06:53Z","title":"MEAL: Stable and Active Learning for Few-Shot Prompting","summary":"  Few-shot classification has made great strides due to foundation models that,\nthrough priming and prompting, are highly effective few-shot learners. However,\nthis approach has high variance both across different sets of few shots (data\nselection) and across different finetuning runs (run variability). This is\nproblematic not only because it impedes the fair comparison of different\napproaches, but especially because it makes few-shot learning too unreliable\nfor many real-world applications. To alleviate these issues, we make two\ncontributions for more stable and effective few-shot learning: First, we\npropose novel ensembling methods and show that they substantially reduce run\nvariability. Second, we introduce a new active learning (AL) criterion for data\nselection and present the first AL-based approach specifically tailored towards\nprompt-based learning. In our experiments, we show that our combined method,\nMEAL (Multiprompt finetuning and prediction Ensembling with Active Learning),\nimproves overall performance of prompt-based finetuning by 2.3 points on five\ndiverse tasks. We publicly share our code and data splits in\nhttps://github.com/akoksal/MEAL.\n","authors":["Abdullatif Köksal","Timo Schick","Hinrich Schütze"],"pdf_url":"https://arxiv.org/pdf/2211.08358v3.pdf","comment":"EMNLP 2023 Findings"},{"id":"http://arxiv.org/abs/2311.11813v1","updated":"2023-11-20T14:50:12Z","published":"2023-11-20T14:50:12Z","title":"Efficient Grammatical Error Correction Via Multi-Task Training and\n  Optimized Training Schedule","summary":"  Progress in neural grammatical error correction (GEC) is hindered by the lack\nof annotated training data. Sufficient amounts of high-quality manually\nannotated data are not available, so recent research has relied on generating\nsynthetic data, pretraining on it, and then fine-tuning on real datasets;\nperformance gains have been achieved either by ensembling or by using huge\npretrained models such as XXL-T5 as the backbone. In this work, we explore an\northogonal direction: how to use available data more efficiently. First, we\npropose auxiliary tasks that exploit the alignment between the original and\ncorrected sentences, such as predicting a sequence of corrections. We formulate\neach task as a sequence-to-sequence problem and perform multi-task training.\nSecond, we discover that the order of datasets used for training and even\nindividual instances within a dataset may have important effects on the final\nperformance, so we set out to find the best training schedule. Together, these\ntwo ideas lead to significant improvements, producing results that improve\nstate of the art with much smaller models; in particular, we outperform the\nbest models based on T5-XXL (11B parameters) with a BART-based model (400M\nparameters).\n","authors":["Andrey Bout","Alexander Podolskiy","Sergey Nikolenko","Irina Piontkovskaya"],"pdf_url":"https://arxiv.org/pdf/2311.11813v1.pdf","comment":"EMNLP 2023"},{"id":"http://arxiv.org/abs/2305.13302v2","updated":"2023-11-20T14:31:26Z","published":"2023-05-22T17:58:01Z","title":"Language-Agnostic Bias Detection in Language Models with Bias Probing","summary":"  Pretrained language models (PLMs) are key components in NLP, but they contain\nstrong social biases. Quantifying these biases is challenging because current\nmethods focusing on fill-the-mask objectives are sensitive to slight changes in\ninput. To address this, we propose a bias probing technique called LABDet, for\nevaluating social bias in PLMs with a robust and language-agnostic method. For\nnationality as a case study, we show that LABDet `surfaces' nationality bias by\ntraining a classifier on top of a frozen PLM on non-nationality sentiment\ndetection. We find consistent patterns of nationality bias across monolingual\nPLMs in six languages that align with historical and political context. We also\nshow for English BERT that bias surfaced by LABDet correlates well with bias in\nthe pretraining data; thus, our work is one of the few studies that directly\nlinks pretraining data to PLM behavior. Finally, we verify LABDet's reliability\nand applicability to different templates and languages through an extensive set\nof robustness checks. We publicly share our code and dataset in\nhttps://github.com/akoksal/LABDet.\n","authors":["Abdullatif Köksal","Omer Faruk Yalcin","Ahmet Akbiyik","M. Tahir Kilavuz","Anna Korhonen","Hinrich Schütze"],"pdf_url":"https://arxiv.org/pdf/2305.13302v2.pdf","comment":"EMNLP 2023 Findings"},{"id":"http://arxiv.org/abs/2311.11797v1","updated":"2023-11-20T14:30:55Z","published":"2023-11-20T14:30:55Z","title":"Igniting Language Intelligence: The Hitchhiker's Guide From\n  Chain-of-Thought Reasoning to Language Agents","summary":"  Large language models (LLMs) have dramatically enhanced the field of language\nintelligence, as demonstrably evidenced by their formidable empirical\nperformance across a spectrum of complex reasoning tasks. Additionally,\ntheoretical proofs have illuminated their emergent reasoning capabilities,\nproviding a compelling showcase of their advanced cognitive abilities in\nlinguistic contexts. Critical to their remarkable efficacy in handling complex\nreasoning tasks, LLMs leverage the intriguing chain-of-thought (CoT) reasoning\ntechniques, obliging them to formulate intermediate steps en route to deriving\nan answer. The CoT reasoning approach has not only exhibited proficiency in\namplifying reasoning performance but also in enhancing interpretability,\ncontrollability, and flexibility. In light of these merits, recent research\nendeavors have extended CoT reasoning methodologies to nurture the development\nof autonomous language agents, which adeptly adhere to language instructions\nand execute actions within varied environments. This survey paper orchestrates\na thorough discourse, penetrating vital research dimensions, encompassing: (i)\nthe foundational mechanics of CoT techniques, with a focus on elucidating the\ncircumstances and justification behind its efficacy; (ii) the paradigm shift in\nCoT; and (iii) the burgeoning of language agents fortified by CoT approaches.\nProspective research avenues envelop explorations into generalization,\nefficiency, customization, scaling, and safety. This paper caters to a wide\naudience, including beginners seeking comprehensive knowledge of CoT reasoning\nand language agents, as well as experienced researchers interested in\nfoundational mechanics and engaging in cutting-edge discussions on these\ntopics. A repository for the related papers is available at\nhttps://github.com/Zoeyyao27/CoT-Igniting-Agent.\n","authors":["Zhuosheng Zhang","Yao Yao","Aston Zhang","Xiangru Tang","Xinbei Ma","Zhiwei He","Yiming Wang","Mark Gerstein","Rui Wang","Gongshen Liu","Hai Zhao"],"pdf_url":"https://arxiv.org/pdf/2311.11797v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11796v1","updated":"2023-11-20T14:29:45Z","published":"2023-11-20T14:29:45Z","title":"Beyond Boundaries: A Comprehensive Survey of Transferable Attacks on AI\n  Systems","summary":"  Artificial Intelligence (AI) systems such as autonomous vehicles, facial\nrecognition, and speech recognition systems are increasingly integrated into\nour daily lives. However, despite their utility, these AI systems are\nvulnerable to a wide range of attacks such as adversarial, backdoor, data\npoisoning, membership inference, model inversion, and model stealing attacks.\nIn particular, numerous attacks are designed to target a particular model or\nsystem, yet their effects can spread to additional targets, referred to as\ntransferable attacks. Although considerable efforts have been directed toward\ndeveloping transferable attacks, a holistic understanding of the advancements\nin transferable attacks remains elusive. In this paper, we comprehensively\nexplore learning-based attacks from the perspective of transferability,\nparticularly within the context of cyber-physical security. We delve into\ndifferent domains -- the image, text, graph, audio, and video domains -- to\nhighlight the ubiquitous and pervasive nature of transferable attacks. This\npaper categorizes and reviews the architecture of existing attacks from various\nviewpoints: data, process, model, and system. We further examine the\nimplications of transferable attacks in practical scenarios such as autonomous\ndriving, speech recognition, and large language models (LLMs). Additionally, we\noutline the potential research directions to encourage efforts in exploring the\nlandscape of transferable attacks. This survey offers a holistic understanding\nof the prevailing transferable attacks and their impacts across different\ndomains.\n","authors":["Guangjing Wang","Ce Zhou","Yuanda Wang","Bocheng Chen","Hanqing Guo","Qiben Yan"],"pdf_url":"https://arxiv.org/pdf/2311.11796v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.15363v4","updated":"2023-11-20T13:59:16Z","published":"2023-08-29T14:59:54Z","title":"Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation","summary":"  Large language models (LLMs) have emerged as a new paradigm for Text-to-SQL\ntask. However, the absence of a systematical benchmark inhibits the development\nof designing effective, efficient and economic LLM-based Text-to-SQL solutions.\nTo address this challenge, in this paper, we first conduct a systematical and\nextensive comparison over existing prompt engineering methods, including\nquestion representation, example selection and example organization, and with\nthese experimental results, we elaborate their pros and cons. Based on these\nfindings, we propose a new integrated solution, named DAIL-SQL, which refreshes\nthe Spider leaderboard with 86.6% execution accuracy and sets a new bar. To\nexplore the potential of open-source LLM, we investigate them in various\nscenarios, and further enhance their performance with supervised fine-tuning.\nOur explorations highlight open-source LLMs' potential in Text-to-SQL, as well\nas the advantages and disadvantages of the supervised fine-tuning.\nAdditionally, towards an efficient and economic LLM-based Text-to-SQL solution,\nwe emphasize the token efficiency in prompt engineering and compare the prior\nstudies under this metric. We hope that our work provides a deeper\nunderstanding of Text-to-SQL with LLMs, and inspires further investigations and\nbroad applications.\n","authors":["Dawei Gao","Haibin Wang","Yaliang Li","Xiuyu Sun","Yichen Qian","Bolin Ding","Jingren Zhou"],"pdf_url":"https://arxiv.org/pdf/2308.15363v4.pdf","comment":"We have released code on https://github.com/BeachWang/DAIL-SQL"},{"id":"http://arxiv.org/abs/2309.10003v3","updated":"2023-11-20T13:31:47Z","published":"2023-09-17T16:50:07Z","title":"A novel approach to measuring patent claim scope based on probabilities\n  obtained from (large) language models","summary":"  This work proposes to measure the scope of a patent claim as the reciprocal\nof the self-information contained in this claim. A probability of occurrence of\nthe claim is obtained from a language model and this probability is used to\ncompute the self-information. Grounded in information theory, this approach is\nbased on the assumption that an unlikely concept is more informative than a\nusual concept, insofar as it is more surprising. In turn, the more surprising\nthe information required to defined the claim, the narrower its scope. Five\nlanguage models are considered, ranging from simplest models (each word or\ncharacter is assigned an identical probability) to intermediate models (using\naverage word or character frequencies), to a large language model (GPT2).\nInterestingly, the scope resulting from the simplest language models is\nproportional to the reciprocal of the number of words or characters involved in\nthe claim, a metric already used in previous works. Application is made to\nmultiple series of patent claims directed to distinct inventions, where each\nseries consists of claims devised to have a gradually decreasing scope. The\nperformance of the language models is assessed with respect to several ad hoc\ntests. The more sophisticated the model, the better the results. I.e., the GPT2\nprobability model outperforms models based on word and character frequencies,\nwhich themselves outdo the simplest models based on word or character counts.\nStill, the character count appears to be a more reliable indicator than the\nword count.\n","authors":["Sébastien Ragot"],"pdf_url":"https://arxiv.org/pdf/2309.10003v3.pdf","comment":"58 pages, 8 tables, 6 figures. Substantial changes made to version 2:\n  New section 4.1 added (including a new table); Minor normalization issue\n  corrected in values listed in Appendix B; Content of former appendix C now\n  moved to Section 3; and new Appendix C added. Minor changes made to version 3\n  (style, typos, language)"},{"id":"http://arxiv.org/abs/2311.11745v1","updated":"2023-11-20T13:13:24Z","published":"2023-11-20T13:13:24Z","title":"Encoding Speaker-Specific Latent Speech Feature for Speech Synthesis","summary":"  In this work, we propose a novel method for modeling numerous speakers, which\nenables expressing the overall characteristics of speakers in detail like a\ntrained multi-speaker model without additional training on the target speaker's\ndataset. Although various works with similar purposes have been actively\nstudied, their performance has not yet reached that of trained multi-speaker\nmodels due to their fundamental limitations. To overcome previous limitations,\nwe propose effective methods for feature learning and representing target\nspeakers' speech characteristics by discretizing the features and conditioning\nthem to a speech synthesis model. Our method obtained a significantly higher\nsimilarity mean opinion score (SMOS) in subjective similarity evaluation than\nseen speakers of a best-performing multi-speaker model, even with unseen\nspeakers. The proposed method also outperforms a zero-shot method by\nsignificant margins. Furthermore, our method shows remarkable performance in\ngenerating new artificial speakers. In addition, we demonstrate that the\nencoded latent features are sufficiently informative to reconstruct an original\nspeaker's speech completely. It implies that our method can be used as a\ngeneral methodology to encode and reconstruct speakers' characteristics in\nvarious tasks.\n","authors":["Jungil Kong","Junmo Lee","Jeongmin Kim","Beomjeong Kim","Jihoon Park","Dohee Kong","Changheon Lee","Sangjin Kim"],"pdf_url":"https://arxiv.org/pdf/2311.11745v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.19130v2","updated":"2023-11-20T12:15:19Z","published":"2023-10-29T19:39:03Z","title":"Women Wearing Lipstick: Measuring the Bias Between an Object and Its\n  Related Gender","summary":"  In this paper, we investigate the impact of objects on gender bias in image\ncaptioning systems. Our results show that only gender-specific objects have a\nstrong gender bias (e.g., women-lipstick). In addition, we propose a visual\nsemantic-based gender score that measures the degree of bias and can be used as\na plug-in for any image captioning system. Our experiments demonstrate the\nutility of the gender score, since we observe that our score can measure the\nbias relation between a caption and its related gender; therefore, our score\ncan be used as an additional metric to the existing Object Gender Co-Occ\napproach. Code and data are publicly available at\n\\url{https://github.com/ahmedssabir/GenderScore}.\n","authors":["Ahmed Sabir","Lluís Padró"],"pdf_url":"https://arxiv.org/pdf/2310.19130v2.pdf","comment":"EMNLP Findings 2023"},{"id":"http://arxiv.org/abs/2311.11701v1","updated":"2023-11-20T12:08:32Z","published":"2023-11-20T12:08:32Z","title":"Control in Hybrid Chatbots","summary":"  Customer data typically is held in database systems, which can be seen as\nrule-based knowledge base, whereas businesses increasingly want to benefit from\nthe capabilities of large, pre-trained language models.\n  In this technical report, we describe a case study of how a commercial rule\nengine and an integrated neural chatbot may be integrated, and what level of\ncontrol that particular integration mode leads to. We also discuss alternative\nways (including past ways realized in other systems) how researchers strive to\nmaintain control and avoid what has recently been called model \"hallucination\".\n","authors":["Thomas Rüdel","Jochen L. Leidner"],"pdf_url":"https://arxiv.org/pdf/2311.11701v1.pdf","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.11696v1","updated":"2023-11-20T11:56:25Z","published":"2023-11-20T11:56:25Z","title":"Sparse Low-rank Adaptation of Pre-trained Language Models","summary":"  Fine-tuning pre-trained large language models in a parameter-efficient manner\nis widely studied for its effectiveness and efficiency. The popular method of\nlow-rank adaptation (LoRA) offers a notable approach, hypothesizing that the\nadaptation process is intrinsically low-dimensional. Although LoRA has\ndemonstrated commendable performance, it is implemented with a fixed and\nunalterable intrinsic rank that might not always be the ideal choice.\nRecognizing the need for more flexible adaptation, we extend the methodology of\nLoRA to an innovative approach we call sparse low-rank adaptation (SoRA) that\nenables dynamic adjustments to the intrinsic rank during the adaptation\nprocess. We achieve this through the incorporation of a gate unit optimized\nwith proximal gradient method in the training stage, controlling the\ncardinality of rank under the sparsity of the gate. In the subsequent inference\nstage, we eliminate the parameter blocks corresponding to the zeroed-out ranks,\nto reduce each SoRA module back to a concise yet rank-optimal LoRA. Our\napproach strengthens the representation power of LoRA by initializing it with a\nhigher rank, while efficiently taming a temporarily increased number of\nparameters via updating in a sparse way. We further introduce a sparsifying\nscheduler for SoRA, aiming to examine the impact of the number of non-zero\nparameters on the model's memorization and generalization. Our experimental\nresults demonstrate that SoRA can outperform other baselines even with 70%\nretained parameters and 70% training time.\n","authors":["Ning Ding","Xingtai Lv","Qiaosen Wang","Yulin Chen","Bowen Zhou","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2311.11696v1.pdf","comment":"Accepted to EMNLP 2023 (Main Conference)"},{"id":"http://arxiv.org/abs/2311.11690v1","updated":"2023-11-20T11:43:45Z","published":"2023-11-20T11:43:45Z","title":"Refactoring Programs Using Large Language Models with Few-Shot Examples","summary":"  A less complex and more straightforward program is a crucial factor that\nenhances its maintainability and makes writing secure and bug-free programs\neasier. However, due to its heavy workload and the risks of breaking the\nworking programs, programmers are reluctant to do code refactoring, and thus,\nit also causes the loss of potential learning experiences. To mitigate this, we\ndemonstrate the application of using a large language model (LLM), GPT-3.5, to\nsuggest less complex versions of the user-written Python program, aiming to\nencourage users to learn how to write better programs. We propose a method to\nleverage the prompting with few-shot examples of the LLM by selecting the\nbest-suited code refactoring examples for each target programming problem based\non the prior evaluation of prompting with the one-shot example. The\nquantitative evaluation shows that 95.68% of programs can be refactored by\ngenerating 10 candidates each, resulting in a 17.35% reduction in the average\ncyclomatic complexity and a 25.84% decrease in the average number of lines\nafter filtering only generated programs that are semantically correct.\nFurthermore, the qualitative evaluation shows outstanding capability in code\nformatting, while unnecessary behaviors such as deleting or translating\ncomments are also observed.\n","authors":["Atsushi Shirafuji","Yusuke Oda","Jun Suzuki","Makoto Morishita","Yutaka Watanobe"],"pdf_url":"https://arxiv.org/pdf/2311.11690v1.pdf","comment":"10 pages, 10 figures, accepted to the 30th Asia-Pacific Software\n  Engineering Conference (APSEC 2023)"},{"id":"http://arxiv.org/abs/2310.10348v2","updated":"2023-11-20T11:31:16Z","published":"2023-10-16T12:34:43Z","title":"Attribution Patching Outperforms Automated Circuit Discovery","summary":"  Automated interpretability research has recently attracted attention as a\npotential research direction that could scale explanations of neural network\nbehavior to large models. Existing automated circuit discovery work applies\nactivation patching to identify subnetworks responsible for solving specific\ntasks (circuits). In this work, we show that a simple method based on\nattribution patching outperforms all existing methods while requiring just two\nforward passes and a backward pass. We apply a linear approximation to\nactivation patching to estimate the importance of each edge in the\ncomputational subgraph. Using this approximation, we prune the least important\nedges of the network. We survey the performance and limitations of this method,\nfinding that averaged over all tasks our method has greater AUC from circuit\nrecovery than other methods.\n","authors":["Aaquib Syed","Can Rager","Arthur Conmy"],"pdf_url":"https://arxiv.org/pdf/2310.10348v2.pdf","comment":"6 main paper pages, 6 additional pages. NeurIPS 2023 ATTRIB Workshop"},{"id":"http://arxiv.org/abs/2311.11608v1","updated":"2023-11-20T08:51:30Z","published":"2023-11-20T08:51:30Z","title":"Taiyi: A Bilingual Fine-Tuned Large Language Model for Diverse\n  Biomedical Tasks","summary":"  Recent advancements in large language models (LLMs) have shown promising\nresults across a variety of natural language processing (NLP) tasks. The\napplication of LLMs to specific domains, such as biomedicine, has achieved\nincreased attention. However, most biomedical LLMs focus on enhancing\nperformance in monolingual biomedical question answering and conversation\ntasks. To further investigate the effectiveness of the LLMs on diverse\nbiomedical NLP tasks in different languages, we present Taiyi, a bilingual\n(English and Chinese) fine-tuned LLM for diverse biomedical tasks. In this\nwork, we first curated a comprehensive collection of 140 existing biomedical\ntext mining datasets across over 10 task types. Subsequently, a two-stage\nstrategy is proposed for supervised fine-tuning to optimize the model\nperformance across varied tasks. Experimental results on 13 test sets covering\nnamed entity recognition, relation extraction, text classification, question\nanswering tasks demonstrate Taiyi achieves superior performance compared to\ngeneral LLMs. The case study involving additional biomedical NLP tasks further\nshows Taiyi's considerable potential for bilingual biomedical multi-tasking.\nThe source code, datasets, and model for Taiyi are freely available at\nhttps://github.com/DUTIR-BioNLP/Taiyi-LLM.\n","authors":["Ling Luo","Jinzhong Ning","Yingwen Zhao","Zhijun Wang","Zeyuan Ding","Peng Chen","Weiru Fu","Qinyu Han","Guangtao Xu","Yunzhi Qiu","Dinghao Pan","Jiru Li","Hao Li","Wenduo Feng","Senbo Tu","Yuqi Liu","Zhihao Yang","Jian Wang","Yuanyuan Sun","Hongfei Lin"],"pdf_url":"https://arxiv.org/pdf/2311.11608v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11601v1","updated":"2023-11-20T08:29:52Z","published":"2023-11-20T08:29:52Z","title":"Addressing the Length Bias Problem in Document-Level Neural Machine\n  Translation","summary":"  Document-level neural machine translation (DNMT) has shown promising results\nby incorporating more context information. However, this approach also\nintroduces a length bias problem, whereby DNMT suffers from significant\ntranslation quality degradation when decoding documents that are much shorter\nor longer than the maximum sequence length during training. %i.e., the length\nbias problem. To solve the length bias problem, we propose to improve the DNMT\nmodel in training method, attention mechanism, and decoding strategy. Firstly,\nwe propose to sample the training data dynamically to ensure a more uniform\ndistribution across different sequence lengths. Then, we introduce a\nlength-normalized attention mechanism to aid the model in focusing on target\ninformation, mitigating the issue of attention divergence when processing\nlonger sequences. Lastly, we propose a sliding window strategy during decoding\nthat integrates as much context information as possible without exceeding the\nmaximum sequence length. The experimental results indicate that our method can\nbring significant improvements on several open datasets, and further analysis\nshows that our method can significantly alleviate the length bias problem.\n","authors":["Zhuocheng Zhang","Shuhao Gu","Min Zhang","Yang Feng"],"pdf_url":"https://arxiv.org/pdf/2311.11601v1.pdf","comment":"Accepted by EMNLP2023 Findings"},{"id":"http://arxiv.org/abs/2311.11598v1","updated":"2023-11-20T08:23:39Z","published":"2023-11-20T08:23:39Z","title":"Filling the Image Information Gap for VQA: Prompting Large Language\n  Models to Proactively Ask Questions","summary":"  Large Language Models (LLMs) demonstrate impressive reasoning ability and the\nmaintenance of world knowledge not only in natural language tasks, but also in\nsome vision-language tasks such as open-domain knowledge-based visual question\nanswering (OK-VQA). As images are invisible to LLMs, researchers convert images\nto text to engage LLMs into the visual question reasoning procedure. This leads\nto discrepancies between images and their textual representations presented to\nLLMs, which consequently impedes final reasoning performance. To fill the\ninformation gap and better leverage the reasoning capability, we design a\nframework that enables LLMs to proactively ask relevant questions to unveil\nmore details in the image, along with filters for refining the generated\ninformation. We validate our idea on OK-VQA and A-OKVQA. Our method\ncontinuously boosts the performance of baselines methods by an average gain of\n2.15% on OK-VQA, and achieves consistent improvements across different LLMs.\n","authors":["Ziyue Wang","Chi Chen","Peng Li","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2311.11598v1.pdf","comment":"Accepted to EMNLP2023 Findings"},{"id":"http://arxiv.org/abs/2311.11583v1","updated":"2023-11-20T07:41:30Z","published":"2023-11-20T07:41:30Z","title":"How well ChatGPT understand Malaysian English? An Evaluation on Named\n  Entity Recognition and Relation Extraction","summary":"  Recently, ChatGPT has attracted a lot of interest from both researchers and\nthe general public. While the performance of ChatGPT in named entity\nrecognition and relation extraction from Standard English texts is\nsatisfactory, it remains to be seen if it can perform similarly for Malaysian\nEnglish. Malaysian English is unique as it exhibits morphosyntactic and\nsemantical adaptation from local contexts. In this study, we assess ChatGPT's\ncapability in extracting entities and relations from the Malaysian English News\n(MEN) dataset. We propose a three-step methodology referred to as\n\\textbf{\\textit{educate-predict-evaluate}}. The performance of ChatGPT is\nassessed using F1-Score across 18 unique prompt settings, which were carefully\nengineered for a comprehensive review. From our evaluation, we found that\nChatGPT does not perform well in extracting entities from Malaysian English\nnews articles, with the highest F1-Score of 0.497. Further analysis shows that\nthe morphosyntactic adaptation in Malaysian English caused the limitation.\nHowever, interestingly, this morphosyntactic adaptation does not impact the\nperformance of ChatGPT for relation extraction.\n","authors":["Mohan Raj Chanthran","Lay-Ki Soon","Huey Fang Ong","Bhawani Selvaretnam"],"pdf_url":"https://arxiv.org/pdf/2311.11583v1.pdf","comment":"Accepted in Generation, Evaluation & Metrics (GEM) Workshop at EMNLP\n  2023"},{"id":"http://arxiv.org/abs/2311.11564v1","updated":"2023-11-20T07:02:35Z","published":"2023-11-20T07:02:35Z","title":"KBioXLM: A Knowledge-anchored Biomedical Multilingual Pretrained\n  Language Model","summary":"  Most biomedical pretrained language models are monolingual and cannot handle\nthe growing cross-lingual requirements. The scarcity of non-English domain\ncorpora, not to mention parallel data, poses a significant hurdle in training\nmultilingual biomedical models. Since knowledge forms the core of\ndomain-specific corpora and can be translated into various languages\naccurately, we propose a model called KBioXLM, which transforms the\nmultilingual pretrained model XLM-R into the biomedical domain using a\nknowledge-anchored approach. We achieve a biomedical multilingual corpus by\nincorporating three granularity knowledge alignments (entity, fact, and passage\nlevels) into monolingual corpora. Then we design three corresponding training\ntasks (entity masking, relation masking, and passage relation prediction) and\ncontinue training on top of the XLM-R model to enhance its domain cross-lingual\nability. To validate the effectiveness of our model, we translate the English\nbenchmarks of multiple tasks into Chinese. Experimental results demonstrate\nthat our model significantly outperforms monolingual and multilingual\npretrained models in cross-lingual zero-shot and few-shot scenarios, achieving\nimprovements of up to 10+ points. Our code is publicly available at\nhttps://github.com/ngwlh-gl/KBioXLM.\n","authors":["Lei Geng","Xu Yan","Ziqiang Cao","Juntao Li","Wenjie Li","Sujian Li","Xinjie Zhou","Yang Yang","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.11564v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11552v1","updated":"2023-11-20T06:06:22Z","published":"2023-11-20T06:06:22Z","title":"Exploring Prompting Large Language Models as Explainable Metrics","summary":"  This paper describes the IUST NLP Lab submission to the Prompting Large\nLanguage Models as Explainable Metrics Shared Task at the Eval4NLP 2023\nWorkshop on Evaluation & Comparison of NLP Systems. We have proposed a\nzero-shot prompt-based strategy for explainable evaluation of the summarization\ntask using Large Language Models (LLMs). The conducted experiments demonstrate\nthe promising potential of LLMs as evaluation metrics in Natural Language\nProcessing (NLP), particularly in the field of summarization. Both few-shot and\nzero-shot approaches are employed in these experiments. The performance of our\nbest provided prompts achieved a Kendall correlation of 0.477 with human\nevaluations in the text summarization task on the test data. Code and results\nare publicly available on GitHub.\n","authors":["Ghazaleh Mahmoudi"],"pdf_url":"https://arxiv.org/pdf/2311.11552v1.pdf","comment":"9 pages, Eval4NLP 2023"},{"id":"http://arxiv.org/abs/2311.11551v1","updated":"2023-11-20T06:06:20Z","published":"2023-11-20T06:06:20Z","title":"Adapt in Contexts: Retrieval-Augmented Domain Adaptation via In-Context\n  Learning","summary":"  Large language models (LLMs) have showcased their capability with few-shot\ninference known as in-context learning. However, in-domain demonstrations are\nnot always readily available in real scenarios, leading to cross-domain\nin-context learning. Besides, LLMs are still facing challenges in long-tail\nknowledge in unseen and unfamiliar domains. The above limitations demonstrate\nthe necessity of Unsupervised Domain Adaptation (UDA). In this paper, we study\nthe UDA problem under an in-context learning setting to adapt language models\nfrom the source domain to the target domain without any target labels. The core\nidea is to retrieve a subset of cross-domain elements that are the most similar\nto the query, and elicit language model to adapt in an in-context manner by\nlearning both target domain distribution and the discriminative task signal\nsimultaneously with the augmented cross-domain in-context examples. We devise\ndifferent prompting and training strategies, accounting for different LM\narchitectures to learn the target distribution via language modeling. With\nextensive experiments on Sentiment Analysis (SA) and Named Entity Recognition\n(NER) tasks, we thoroughly study the effectiveness of ICL for domain transfer\nand demonstrate significant improvements over baseline models.\n","authors":["Quanyu Long","Wenya Wang","Sinno Jialin Pan"],"pdf_url":"https://arxiv.org/pdf/2311.11551v1.pdf","comment":"EMNLP 2023"},{"id":"http://arxiv.org/abs/2205.15439v2","updated":"2023-11-20T04:31:13Z","published":"2022-05-30T21:34:40Z","title":"StyleTTS: A Style-Based Generative Model for Natural and Diverse\n  Text-to-Speech Synthesis","summary":"  Text-to-Speech (TTS) has recently seen great progress in synthesizing\nhigh-quality speech owing to the rapid development of parallel TTS systems, but\nproducing speech with naturalistic prosodic variations, speaking styles and\nemotional tones remains challenging. Moreover, since duration and speech are\ngenerated separately, parallel TTS models still have problems finding the best\nmonotonic alignments that are crucial for naturalistic speech synthesis. Here,\nwe propose StyleTTS, a style-based generative model for parallel TTS that can\nsynthesize diverse speech with natural prosody from a reference speech\nutterance. With novel Transferable Monotonic Aligner (TMA) and\nduration-invariant data augmentation schemes, our method significantly\noutperforms state-of-the-art models on both single and multi-speaker datasets\nin subjective tests of speech naturalness and speaker similarity. Through\nself-supervised learning of the speaking styles, our model can synthesize\nspeech with the same prosodic and emotional tone as any given reference speech\nwithout the need for explicitly labeling these categories.\n","authors":["Yinghao Aaron Li","Cong Han","Nima Mesgarani"],"pdf_url":"https://arxiv.org/pdf/2205.15439v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.07691v2","updated":"2023-11-20T04:23:08Z","published":"2023-06-13T11:04:43Z","title":"StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion\n  and Adversarial Training with Large Speech Language Models","summary":"  In this paper, we present StyleTTS 2, a text-to-speech (TTS) model that\nleverages style diffusion and adversarial training with large speech language\nmodels (SLMs) to achieve human-level TTS synthesis. StyleTTS 2 differs from its\npredecessor by modeling styles as a latent random variable through diffusion\nmodels to generate the most suitable style for the text without requiring\nreference speech, achieving efficient latent diffusion while benefiting from\nthe diverse speech synthesis offered by diffusion models. Furthermore, we\nemploy large pre-trained SLMs, such as WavLM, as discriminators with our novel\ndifferentiable duration modeling for end-to-end training, resulting in improved\nspeech naturalness. StyleTTS 2 surpasses human recordings on the single-speaker\nLJSpeech dataset and matches it on the multispeaker VCTK dataset as judged by\nnative English speakers. Moreover, when trained on the LibriTTS dataset, our\nmodel outperforms previous publicly available models for zero-shot speaker\nadaptation. This work achieves the first human-level TTS on both single and\nmultispeaker datasets, showcasing the potential of style diffusion and\nadversarial training with large SLMs. The audio demos and source code are\navailable at https://styletts2.github.io/.\n","authors":["Yinghao Aaron Li","Cong Han","Vinay S. Raghavan","Gavin Mischler","Nima Mesgarani"],"pdf_url":"https://arxiv.org/pdf/2306.07691v2.pdf","comment":"NeurIPS 2023"},{"id":"http://arxiv.org/abs/2304.13867v3","updated":"2023-11-20T04:09:25Z","published":"2023-04-26T23:24:50Z","title":"Transferring Procedural Knowledge across Commonsense Tasks","summary":"  Stories about everyday situations are an essential part of human\ncommunication, motivating the need to develop AI agents that can reliably\nunderstand these stories. Despite the long list of supervised methods for story\ncompletion and procedural understanding, current AI has no mechanisms to\nautomatically track and explain procedures in unseen stories. To bridge this\ngap, we study the ability of AI models to transfer procedural knowledge to\nnovel narrative tasks in a transparent manner. We design LEAP: a comprehensive\nframework that integrates state-of-the-art modeling architectures, training\nregimes, and augmentation strategies based on both natural and synthetic\nstories. To address the lack of densely annotated training data, we devise a\nrobust automatic labeler based on few-shot prompting to enhance the augmented\ndata. Our experiments with in- and out-of-domain tasks reveal insights into the\ninterplay of different architectures, training regimes, and augmentation\nstrategies. LEAP's labeler has a clear positive impact on out-of-domain\ndatasets, while the resulting dense annotation provides native explainability.\n","authors":["Yifan Jiang","Filip Ilievski","Kaixin Ma"],"pdf_url":"https://arxiv.org/pdf/2304.13867v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11518v1","updated":"2023-11-20T03:44:32Z","published":"2023-11-20T03:44:32Z","title":"Multi-teacher Distillation for Multilingual Spelling Correction","summary":"  Accurate spelling correction is a critical step in modern search interfaces,\nespecially in an era of mobile devices and speech-to-text interfaces. For\nservices that are deployed around the world, this poses a significant challenge\nfor multilingual NLP: spelling errors need to be caught and corrected in all\nlanguages, and even in queries that use multiple languages. In this paper, we\ntackle this challenge using multi-teacher distillation. On our approach, a\nmonolingual teacher model is trained for each language/locale, and these\nindividual models are distilled into a single multilingual student model\nintended to serve all languages/locales. In experiments using open-source data\nas well as user data from a worldwide search service, we show that this leads\nto highly effective spelling correction models that can meet the tight latency\nrequirements of deployed services.\n","authors":["Jingfen Zhang","Xuan Guo","Sravan Bodapati","Christopher Potts"],"pdf_url":"https://arxiv.org/pdf/2311.11518v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11516v1","updated":"2023-11-20T03:42:24Z","published":"2023-11-20T03:42:24Z","title":"GPT in Data Science: A Practical Exploration of Model Selection","summary":"  There is an increasing interest in leveraging Large Language Models (LLMs)\nfor managing structured data and enhancing data science processes. Despite the\npotential benefits, this integration poses significant questions regarding\ntheir reliability and decision-making methodologies. It highlights the\nimportance of various factors in the model selection process, including the\nnature of the data, problem type, performance metrics, computational resources,\ninterpretability vs accuracy, assumptions about data, and ethical\nconsiderations. Our objective is to elucidate and express the factors and\nassumptions guiding GPT-4's model selection recommendations. We employ a\nvariability model to depict these factors and use toy datasets to evaluate both\nthe model and the implementation of the identified heuristics. By contrasting\nthese outcomes with heuristics from other platforms, our aim is to determine\nthe effectiveness and distinctiveness of GPT-4's methodology. This research is\ncommitted to advancing our comprehension of AI decision-making processes,\nespecially in the realm of model selection within data science. Our efforts are\ndirected towards creating AI systems that are more transparent and\ncomprehensible, contributing to a more responsible and efficient practice in\ndata science.\n","authors":["Nathalia Nascimento","Cristina Tavares","Paulo Alencar","Donald Cowan"],"pdf_url":"https://arxiv.org/pdf/2311.11516v1.pdf","comment":"11 pages. To appear in IEEE BigData 2023"},{"id":"http://arxiv.org/abs/2310.09590v2","updated":"2023-11-20T03:29:23Z","published":"2023-10-14T14:23:44Z","title":"Solving Math Word Problems with Reexamination","summary":"  Math word problem (MWP) solving aims to understand the descriptive math\nproblem and calculate the result, for which previous efforts are mostly devoted\nto upgrade different technical modules. This paper brings a different\nperspective of \\textit{reexamination process} during training by introducing a\npseudo-dual task to enhance the MWP solving. We propose a pseudo-dual (PseDual)\nlearning scheme to model such process, which is model-agnostic thus can be\nadapted to any existing MWP solvers. The pseudo-dual task is specifically\ndefined as filling the numbers in the expression back into the original word\nproblem with numbers masked. To facilitate the effective joint learning of the\ntwo tasks, we further design a scheduled fusion strategy for the number\ninfilling task, which smoothly switches the input from the ground-truth math\nexpressions to the predicted ones. Our pseudo-dual learning scheme has been\ntested and proven effective when being equipped in several representative MWP\nsolvers through empirical studies. \\textit{The codes and trained models are\navailable at:} \\url{https://github.com/steven640pixel/PsedualMWP}.\n\\end{abstract}\n","authors":["Yi Bin","Wenhao Shi","Yujuan Ding","Yang Yang","See-Kiong Ng"],"pdf_url":"https://arxiv.org/pdf/2310.09590v2.pdf","comment":"To be appeared at NeurIPS2023 Workshop on MATH-AI"},{"id":"http://arxiv.org/abs/2311.11509v1","updated":"2023-11-20T03:17:21Z","published":"2023-11-20T03:17:21Z","title":"Token-Level Adversarial Prompt Detection Based on Perplexity Measures\n  and Contextual Information","summary":"  In recent years, Large Language Models (LLM) have emerged as pivotal tools in\nvarious applications. However, these models are susceptible to adversarial\nprompt attacks, where attackers can carefully curate input strings that lead to\nundesirable outputs. The inherent vulnerability of LLMs stems from their\ninput-output mechanisms, especially when presented with intensely\nout-of-distribution (OOD) inputs. This paper proposes a token-level detection\nmethod to identify adversarial prompts, leveraging the LLM's capability to\npredict the next token's probability. We measure the degree of the model's\nperplexity and incorporate neighboring token information to encourage the\ndetection of contiguous adversarial prompt sequences. As a result, we propose\ntwo methods: one that identifies each token as either being part of an\nadversarial prompt or not, and another that estimates the probability of each\ntoken being part of an adversarial prompt.\n","authors":["Zhengmian Hu","Gang Wu","Saayan Mitra","Ruiyi Zhang","Tong Sun","Heng Huang","Vishy Swaminathan"],"pdf_url":"https://arxiv.org/pdf/2311.11509v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10702v2","updated":"2023-11-20T02:01:33Z","published":"2023-11-17T18:45:45Z","title":"Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2","summary":"  Since the release of T\\\"ULU [Wang et al., 2023b], open resources for\ninstruction tuning have developed quickly, from better base models to new\nfinetuning techniques. We test and incorporate a number of these advances into\nT\\\"ULU, resulting in T\\\"ULU 2, a suite of improved T\\\"ULU models for advancing\nthe understanding and best practices of adapting pretrained language models to\ndownstream tasks and user preferences. Concretely, we release: (1)\nT\\\"ULU-V2-mix, an improved collection of high-quality instruction datasets; (2)\nT\\\"ULU 2, LLAMA-2 models finetuned on the V2 mixture; (3) T\\\"ULU 2+DPO, T\\\"ULU\n2 models trained with direct preference optimization (DPO), including the\nlargest DPO-trained model to date (T\\\"ULU 2+DPO 70B); (4) CODE T\\\"ULU 2, CODE\nLLAMA models finetuned on our V2 mix that outperform CODE LLAMA and its\ninstruction-tuned variant, CODE LLAMA-Instruct. Our evaluation from multiple\nperspectives shows that the T\\\"ULU 2 suite achieves state-of-the-art\nperformance among open models and matches or exceeds the performance of\nGPT-3.5-turbo-0301 on several benchmarks. We release all the checkpoints, data,\ntraining and evaluation code to facilitate future open efforts on adapting\nlarge language models.\n","authors":["Hamish Ivison","Yizhong Wang","Valentina Pyatkin","Nathan Lambert","Matthew Peters","Pradeep Dasigi","Joel Jang","David Wadden","Noah A. Smith","Iz Beltagy","Hannaneh Hajishirzi"],"pdf_url":"https://arxiv.org/pdf/2311.10702v2.pdf","comment":"technical report; fixed zephyr numbers"},{"id":"http://arxiv.org/abs/2311.11482v1","updated":"2023-11-20T01:51:13Z","published":"2023-11-20T01:51:13Z","title":"Meta Prompting for AGI Systems","summary":"  This paper presents an in-depth exploration of Meta Prompting, a novel\ntechnique that revolutionizes the way large language models (LLMs), multi-modal\nfoundation models, and AI systems approach problem-solving and data\ninterpretation. Meta Prompting, rooted in type theory and category theory,\nprioritizes the structure and syntax of information, providing a unique\nframework that transcends traditional content-focused methods. We delve into\nthe formal definitions of Meta Prompting, contrasting it with Few-Shot\nPrompting, and highlight its applicability and superiority in various AI\napplications.\n  Key to this exploration is the expansion of Meta Prompting into the realm of\ncomplex reasoning. Here, we demonstrate how this technique adeptly breaks down\nintricate problems into manageable sub-problems, facilitating a step-by-step,\ndetailed approach to problem-solving. This method proves especially\nadvantageous in terms of token efficiency and offering a fair comparison in\nproblem-solving scenarios, standing out against few-shot example approaches.\n  Furthermore, the paper breaks new ground by extending Meta Prompting into\nmulti-modal foundation model settings. This extension addresses the integration\nof diverse data types, such as images, audio, and video, within the structured\nframework of Meta Prompting, highlighting both the challenges and the vast\npotential of this approach in handling complex, multi-faceted data (The code is\navailable at https://github.com/meta-prompting/meta-prompting).\n","authors":["Yifan Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.11482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.05619v2","updated":"2023-11-20T01:24:40Z","published":"2023-09-11T17:07:01Z","title":"Effective Proxy for Human Labeling: Ensemble Disagreement Scores in\n  Large Language Models for Industrial NLP","summary":"  Large language models (LLMs) have demonstrated significant capability to\ngeneralize across a large number of NLP tasks. For industry applications, it is\nimperative to assess the performance of the LLM on unlabeled production data\nfrom time to time to validate for a real-world setting. Human labeling to\nassess model error requires considerable expense and time delay. Here we\ndemonstrate that ensemble disagreement scores work well as a proxy for human\nlabeling for language models in zero-shot, few-shot, and fine-tuned settings,\nper our evaluation on keyphrase extraction (KPE) task. We measure fidelity of\nthe results by comparing to true error measured from human labeled ground\ntruth. We contrast with the alternative of using another LLM as a source of\nmachine labels, or silver labels. Results across various languages and domains\nshow disagreement scores provide a better estimation of model performance with\nmean average error (MAE) as low as 0.4% and on average 13.8% better than using\nsilver labels.\n","authors":["Wei Du","Laksh Advani","Yashmeet Gambhir","Daniel J Perry","Prashant Shiralkar","Zhengzheng Xing","Aaron Colak"],"pdf_url":"https://arxiv.org/pdf/2309.05619v2.pdf","comment":"Camera ready version for 2023 EMNLP (The Third Workshop on Natural\n  Language Generation, Evaluation, and Metrics (GEM))"},{"id":"http://arxiv.org/abs/2305.16300v2","updated":"2023-11-20T01:16:17Z","published":"2023-05-25T17:53:42Z","title":"Landmark Attention: Random-Access Infinite Context Length for\n  Transformers","summary":"  While Transformers have shown remarkable success in natural language\nprocessing, their attention mechanism's large memory requirements have limited\ntheir ability to handle longer contexts. Prior approaches, such as recurrent\nmemory or retrieval-based augmentation, have either compromised the\nrandom-access flexibility of attention (i.e., the capability to select any\ntoken in the entire context) or relied on separate mechanisms for relevant\ncontext retrieval, which may not be compatible with the model's attention. In\nthis paper, we present a novel approach that allows access to the complete\ncontext while retaining random-access flexibility, closely resembling running\nattention on the entire context. Our method uses a landmark token to represent\neach block of the input and trains the attention to use it for selecting\nrelevant blocks, enabling retrieval of blocks directly through the attention\nmechanism instead of by relying on a separate mechanism. Our approach\nseamlessly integrates with specialized data structures and the system's memory\nhierarchy, enabling processing of arbitrarily long context lengths. We\ndemonstrate that our method can obtain comparable performance with\nTransformer-XL while significantly reducing the number of retrieved tokens in\neach step. Finally, we show that fine-tuning LLaMA 7B with our method\nsuccessfully extends its context length capacity to over 32k tokens, allowing\nfor inference at the context lengths of GPT-4. We release the implementation of\nlandmark attention and the code to reproduce our experiments at\nhttps://github.com/epfml/landmark-attention/.\n","authors":["Amirkeivan Mohtashami","Martin Jaggi"],"pdf_url":"https://arxiv.org/pdf/2305.16300v2.pdf","comment":"Published as a conference paper at NeurIPS 2023 - 37th Conference on\n  Neural Information Processing Systems"},{"id":"http://arxiv.org/abs/2311.11477v1","updated":"2023-11-20T01:07:30Z","published":"2023-11-20T01:07:30Z","title":"What's left can't be right -- The remaining positional incompetence of\n  contrastive vision-language models","summary":"  Contrastive vision-language models like CLIP have been found to lack spatial\nunderstanding capabilities. In this paper we discuss the possible causes of\nthis phenomenon by analysing both datasets and embedding space. By focusing on\nsimple left-right positional relations, we show that this behaviour is entirely\npredictable, even with large-scale datasets, demonstrate that these relations\ncan be taught using synthetic data and show that this approach can generalise\nwell to natural images - improving the performance on left-right relations on\nVisual Genome Relations.\n","authors":["Nils Hoehing","Ellen Rushe","Anthony Ventresque"],"pdf_url":"https://arxiv.org/pdf/2311.11477v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12233v1","updated":"2023-11-20T23:17:20Z","published":"2023-11-20T23:17:20Z","title":"Unifying Corroborative and Contributive Attributions in Large Language\n  Models","summary":"  As businesses, products, and services spring up around large language models,\nthe trustworthiness of these models hinges on the verifiability of their\noutputs. However, methods for explaining language model outputs largely fall\nacross two distinct fields of study which both use the term \"attribution\" to\nrefer to entirely separate techniques: citation generation and training data\nattribution. In many modern applications, such as legal document generation and\nmedical question answering, both types of attributions are important. In this\nwork, we argue for and present a unified framework of large language model\nattributions. We show how existing methods of different types of attribution\nfall under the unified framework. We also use the framework to discuss\nreal-world use cases where one or both types of attributions are required. We\nbelieve that this unified framework will guide the use case driven development\nof systems that leverage both types of attribution, as well as the\nstandardization of their evaluation.\n","authors":["Theodora Worledge","Judy Hanwen Shen","Nicole Meister","Caleb Winston","Carlos Guestrin"],"pdf_url":"https://arxiv.org/pdf/2311.12233v1.pdf","comment":"NeurIPS ATTRIB Workshop 2023"},{"id":"http://arxiv.org/abs/2307.03172v3","updated":"2023-11-20T23:09:34Z","published":"2023-07-06T17:54:11Z","title":"Lost in the Middle: How Language Models Use Long Contexts","summary":"  While recent language models have the ability to take long contexts as input,\nrelatively little is known about how well they use longer context. We analyze\nthe performance of language models on two tasks that require identifying\nrelevant information in their input contexts: multi-document question answering\nand key-value retrieval. We find that performance can degrade significantly\nwhen changing the position of relevant information, indicating that current\nlanguage models do not robustly make use of information in long input contexts.\nIn particular, we observe that performance is often highest when relevant\ninformation occurs at the beginning or end of the input context, and\nsignificantly degrades when models must access relevant information in the\nmiddle of long contexts, even for explicitly long-context models. Our analysis\nprovides a better understanding of how language models use their input context\nand provides new evaluation protocols for future long-context language models.\n","authors":["Nelson F. Liu","Kevin Lin","John Hewitt","Ashwin Paranjape","Michele Bevilacqua","Fabio Petroni","Percy Liang"],"pdf_url":"https://arxiv.org/pdf/2307.03172v3.pdf","comment":"18 pages, 16 figures. Accepted for publication in Transactions of the\n  Association for Computational Linguistics (TACL), 2023"},{"id":"http://arxiv.org/abs/2311.12179v1","updated":"2023-11-20T20:48:25Z","published":"2023-11-20T20:48:25Z","title":"Leveraging Closed-Access Multilingual Embedding for Automatic Sentence\n  Alignment in Low Resource Languages","summary":"  The importance of qualitative parallel data in machine translation has long\nbeen determined but it has always been very difficult to obtain such in\nsufficient quantity for the majority of world languages, mainly because of the\nassociated cost and also the lack of accessibility to these languages. Despite\nthe potential for obtaining parallel datasets from online articles using\nautomatic approaches, forensic investigations have found a lot of\nquality-related issues such as misalignment, and wrong language codes. In this\nwork, we present a simple but qualitative parallel sentence aligner that\ncarefully leveraged the closed-access Cohere multilingual embedding, a solution\nthat ranked second in the just concluded #CoHereAIHack 2023 Challenge (see\nhttps://ai6lagos.devpost.com). The proposed approach achieved $94.96$ and\n$54.83$ f1 scores on FLORES and MAFAND-MT, compared to $3.64$ and $0.64$ of\nLASER respectively. Our method also achieved an improvement of more than 5 BLEU\nscores over LASER, when the resulting datasets were used with MAFAND-MT dataset\nto train translation models. Our code and data are available for research\npurposes here (https://github.com/abumafrim/Cohere-Align).\n","authors":["Idris Abdulmumin","Auwal Abubakar Khalid","Shamsuddeen Hassan Muhammad","Ibrahim Said Ahmad","Lukman Jibril Aliyu","Babangida Sani","Bala Mairiga Abduljalil","Sani Ahmad Hassan"],"pdf_url":"https://arxiv.org/pdf/2311.12179v1.pdf","comment":"To appear in the proceedings of ICCAIT 2023. 6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2311.06233v3","updated":"2023-11-20T20:43:10Z","published":"2023-11-10T18:48:58Z","title":"Data Contamination Quiz: A Tool to Detect and Estimate Contamination in\n  Large Language Models","summary":"  We propose the Data Contamination Quiz, a simple and effective approach to\ndetect data contamination in large language models (LLMs) and estimate the\namount of it. Specifically, we frame data contamination detection as a series\nof multiple-choice questions. We devise a quiz format wherein three perturbed\nversions of each dataset instance are created. These changes only include\nword-level perturbations, replacing words with their contextual synonyms,\nensuring both the semantic and sentence structure remain exactly the same as\nthe original instance. Together with the original instance, these perturbed\nversions constitute the choices in the quiz. Given that the only distinguishing\nsignal among these choices is the exact wording, an LLM, when tasked with\nidentifying the original instance from the choices, opts for the original if it\nhas memorized it in its pre-training phase--a trait intrinsic to LLMs. A\ndataset partition is then marked as contaminated if the LLM's performance on\nthe quiz surpasses what random chance suggests. Our evaluation spans seven\ndatasets and their respective splits (train and test/validation) on two\nstate-of-the-art LLMs: GPT-4 and GPT-3.5. While lacking access to the\npre-training data, our results suggest that our approach not only enhances the\ndetection of data contamination but also provides an accurate estimation of its\nextent, even when the contamination signal is weak.\n","authors":["Shahriar Golchin","Mihai Surdeanu"],"pdf_url":"https://arxiv.org/pdf/2311.06233v3.pdf","comment":"v1.2 preprint"},{"id":"http://arxiv.org/abs/2301.02748v4","updated":"2023-11-20T19:45:49Z","published":"2023-01-06T23:34:52Z","title":"Generative Antibody Design for Complementary Chain Pairing Sequences\n  through Encoder-Decoder Language Model","summary":"  Current protein language models (pLMs) predominantly focus on single-chain\nprotein sequences and often have not accounted for constraints on generative\ndesign imposed by protein-protein interactions. To address this gap, we present\npaired Antibody T5 (pAbT5), an encoder-decoder model to generate complementary\nheavy or light chain from its pairing partner. We show that our model respects\nconservation in framework regions and variability in hypervariable domains,\ndemonstrated by agreement with sequence alignment and variable-length CDR\nloops. We also show that our model captures chain pairing preferences through\nthe recovery of ground-truth chain type and gene families. Our results showcase\nthe potential of pAbT5 in generative antibody design, incorporating biological\nconstraints from chain pairing preferences.\n","authors":["Simon K. S. Chu","Kathy Y. Wei"],"pdf_url":"https://arxiv.org/pdf/2301.02748v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12131v1","updated":"2023-11-20T19:28:52Z","published":"2023-11-20T19:28:52Z","title":"Human Learning by Model Feedback: The Dynamics of Iterative Prompting\n  with Midjourney","summary":"  Generating images with a Text-to-Image model often requires multiple trials,\nwhere human users iteratively update their prompt based on feedback, namely the\noutput image. Taking inspiration from cognitive work on reference games and\ndialogue alignment, this paper analyzes the dynamics of the user prompts along\nsuch iterations. We compile a dataset of iterative interactions of human users\nwith Midjourney. Our analysis then reveals that prompts predictably converge\ntoward specific traits along these iterations. We further study whether this\nconvergence is due to human users, realizing they missed important details, or\ndue to adaptation to the model's ``preferences'', producing better images for a\nspecific language style. We show initial evidence that both possibilities are\nat play. The possibility that users adapt to the model's preference raises\nconcerns about reusing user data for further training. The prompts may be\nbiased towards the preferences of a specific model, rather than align with\nhuman intentions and natural manner of expression.\n","authors":["Shachar Don-Yehiya","Leshem Choshen","Omri Abend"],"pdf_url":"https://arxiv.org/pdf/2311.12131v1.pdf","comment":"EMNLP23"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2311.12028v1","updated":"2023-11-20T18:59:51Z","published":"2023-11-20T18:59:51Z","title":"Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose\n  Estimation","summary":"  Transformers have been successfully applied in the field of video-based 3D\nhuman pose estimation. However, the high computational costs of these video\npose transformers (VPTs) make them impractical on resource-constrained devices.\nIn this paper, we present a plug-and-play pruning-and-recovering framework,\ncalled Hourglass Tokenizer (HoT), for efficient transformer-based 3D human pose\nestimation from videos. Our HoT begins with pruning pose tokens of redundant\nframes and ends with recovering full-length tokens, resulting in a few pose\ntokens in the intermediate transformer blocks and thus improving the model\nefficiency. To effectively achieve this, we propose a token pruning cluster\n(TPC) that dynamically selects a few representative tokens with high semantic\ndiversity while eliminating the redundancy of video frames. In addition, we\ndevelop a token recovering attention (TRA) to restore the detailed\nspatio-temporal information based on the selected tokens, thereby expanding the\nnetwork output to the original full-length temporal resolution for fast\ninference. Extensive experiments on two benchmark datasets (i.e., Human3.6M and\nMPI-INF-3DHP) demonstrate that our method can achieve both high efficiency and\nestimation accuracy compared to the original VPT models. For instance, applying\nto MotionBERT and MixSTE on Human3.6M, our HoT can save nearly 50% FLOPs\nwithout sacrificing accuracy and nearly 40% FLOPs with only 0.2% accuracy drop,\nrespectively. Our source code will be open-sourced.\n","authors":["Wenhao Li","Mengyuan Liu","Hong Liu","Pichao Wang","Jialun Cai","Nicu Sebe"],"pdf_url":"https://arxiv.org/pdf/2311.12028v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12024v1","updated":"2023-11-20T18:57:55Z","published":"2023-11-20T18:57:55Z","title":"PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape\n  Prediction","summary":"  We propose a Pose-Free Large Reconstruction Model (PF-LRM) for reconstructing\na 3D object from a few unposed images even with little visual overlap, while\nsimultaneously estimating the relative camera poses in ~1.3 seconds on a single\nA100 GPU. PF-LRM is a highly scalable method utilizing the self-attention\nblocks to exchange information between 3D object tokens and 2D image tokens; we\npredict a coarse point cloud for each view, and then use a differentiable\nPerspective-n-Point (PnP) solver to obtain camera poses. When trained on a huge\namount of multi-view posed data of ~1M objects, PF-LRM shows strong\ncross-dataset generalization ability, and outperforms baseline methods by a\nlarge margin in terms of pose prediction accuracy and 3D reconstruction quality\non various unseen evaluation datasets. We also demonstrate our model's\napplicability in downstream text/image-to-3D task with fast feed-forward\ninference. Our project website is at: https://totoro97.github.io/pf-lrm .\n","authors":["Peng Wang","Hao Tan","Sai Bi","Yinghao Xu","Fujun Luan","Kalyan Sunkavalli","Wenping Wang","Zexiang Xu","Kai Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12024v1.pdf","comment":"Project website: https://totoro97.github.io/pf-lrm"},{"id":"http://arxiv.org/abs/2311.12015v1","updated":"2023-11-20T18:54:39Z","published":"2023-11-20T18:54:39Z","title":"GPT-4V(ision) for Robotics: Multimodal Task Planning from Human\n  Demonstration","summary":"  We introduce a pipeline that enhances a general-purpose Vision Language\nModel, GPT-4V(ision), by integrating observations of human actions to\nfacilitate robotic manipulation. This system analyzes videos of humans\nperforming tasks and creates executable robot programs that incorporate\naffordance insights. The computation starts by analyzing the videos with GPT-4V\nto convert environmental and action details into text, followed by a\nGPT-4-empowered task planner. In the following analyses, vision systems\nreanalyze the video with the task plan. Object names are grounded using an\nopen-vocabulary object detector, while focus on the hand-object relation helps\nto detect the moment of grasping and releasing. This spatiotemporal grounding\nallows the vision systems to further gather affordance data (e.g., grasp type,\nway points, and body postures). Experiments across various scenarios\ndemonstrate this method's efficacy in achieving real robots' operations from\nhuman demonstrations in a zero-shot manner. The prompts of GPT-4V/GPT-4 are\navailable at this project page:\nhttps://microsoft.github.io/GPT4Vision-Robot-Manipulation-Prompts/\n","authors":["Naoki Wake","Atsushi Kanehira","Kazuhiro Sasabuchi","Jun Takamatsu","Katsushi Ikeuchi"],"pdf_url":"https://arxiv.org/pdf/2311.12015v1.pdf","comment":"8 pages, 10 figures, 1 table. Last updated on November 20th, 2023"},{"id":"http://arxiv.org/abs/2311.11992v1","updated":"2023-11-20T18:23:41Z","published":"2023-11-20T18:23:41Z","title":"Exploring Lip Segmentation Techniques in Computer Vision: A Comparative\n  Analysis","summary":"  Lip segmentation is crucial in computer vision, especially for lip reading.\nDespite extensive face segmentation research, lip segmentation has received\nlimited attention. The aim of this study is to compare state-of-the-art lip\nsegmentation models using a standardized setting and a publicly available\ndataset. Five techniques, namely EHANet, Mask2Former, BiSeNet V2, PIDNet, and\nSTDC1, are qualitatively selected based on their reported performance,\ninference time, code availability, recency, and popularity. The CelebAMask-HQ\ndataset, comprising manually annotated face images, is used to fairly assess\nthe lip segmentation performance of the selected models. Inference experiments\nare conducted on a Raspberry Pi4 to emulate limited computational resources.\nThe results show that Mask2Former and EHANet have the best performances in\nterms of mIoU score. BiSeNet V2 demonstrate competitive performance, while\nPIDNet excels in recall but has lower precision. Most models present inference\ntime ranging from 1000 to around 3000 milliseconds on a Raspberry Pi4, with\nPIDNet having the lowest mean inference time. This study provides a\ncomprehensive evaluation of lip segmentation models, highlighting their\nperformance and inference times. The findings contribute to the development of\nlightweight techniques and establish benchmarks for future advances in lip\nsegmentation, especially in IoT and edge computing scenarios.\n","authors":["Pietro B. S. Masur","Francisco Braulio Oliveira","Lucas Moreira Medino","Emanuel Huber","Milene Haraguchi Padilha","Cassio de Alcantara","Renata Sellaro"],"pdf_url":"https://arxiv.org/pdf/2311.11992v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11988v1","updated":"2023-11-20T18:21:18Z","published":"2023-11-20T18:21:18Z","title":"Categorizing the Visual Environment and Analyzing the Visual Attention\n  of Dogs","summary":"  Dogs have a unique evolutionary relationship with humans and serve many\nimportant roles e.g. search and rescue, blind assistance, emotional support.\nHowever, few datasets exist to categorize visual features and objects available\nto dogs, as well as how dogs direct their visual attention within their\nenvironment. We collect and study a dataset with over 11,698 gazes to\ncategorize the objects available to be gazed at by 11 dogs in everyday outdoor\nenvironments i.e. a walk around a college campus and urban area. We explore the\navailability of these object categories and the visual attention of dogs over\nthese categories using a head mounted eye tracking apparatus. A small portion\n(approx. 600 images or < 20% of total dataset) of the collected data is used to\nfine tune a MaskRCNN for the novel image domain to segment objects present in\nthe scene, enabling further statistical analysis on the visual gaze tendencies\nof dogs. The MaskRCNN, with eye tracking apparatus, serves as an end to end\nmodel for automatically classifying the visual fixations of dogs. The fine\ntuned MaskRCNN performs far better than chance. There are few individual\ndifferences between the 11 dogs and we observe greater visual fixations on\nbuses, plants, pavement, and construction equipment. This work takes a step\ntowards understanding visual behavior of dogs and their interaction with the\nphysical world.\n","authors":["Shreyas Sundara Raman","Madeline H. Pelgrim","Daphna Buchsbaum","Thomas Serre"],"pdf_url":"https://arxiv.org/pdf/2311.11988v1.pdf","comment":"13 pages, 11 figures, 1 table, WACV CV4Smalls Workshop"},{"id":"http://arxiv.org/abs/2311.11980v1","updated":"2023-11-20T18:14:53Z","published":"2023-11-20T18:14:53Z","title":"Leveraging Previous Facial Action Units Knowledge for Emotion\n  Recognition on Faces","summary":"  People naturally understand emotions, thus permitting a machine to do the\nsame could open new paths for human-computer interaction. Facial expressions\ncan be very useful for emotion recognition techniques, as these are the biggest\ntransmitters of non-verbal cues capable of being correlated with emotions.\nSeveral techniques are based on Convolutional Neural Networks (CNNs) to extract\ninformation in a machine learning process. However, simple CNNs are not always\nsufficient to locate points of interest on the face that can be correlated with\nemotions. In this work, we intend to expand the capacity of emotion recognition\ntechniques by proposing the usage of Facial Action Units (AUs) recognition\ntechniques to recognize emotions. This recognition will be based on the Facial\nAction Coding System (FACS) and computed by a machine learning system. In\nparticular, our method expands over EmotiRAM, an approach for multi-cue emotion\nrecognition, in which we improve over their facial encoding module.\n","authors":["Pietro B. S. Masur","Willams Costa","Lucas S. Figueredo","Veronica Teichrieb"],"pdf_url":"https://arxiv.org/pdf/2311.11980v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11974v1","updated":"2023-11-20T18:02:20Z","published":"2023-11-20T18:02:20Z","title":"Evaluating Supervision Levels Trade-Offs for Infrared-Based People\n  Counting","summary":"  Object detection models are commonly used for people counting (and\nlocalization) in many applications but require a dataset with costly bounding\nbox annotations for training. Given the importance of privacy in people\ncounting, these models rely more and more on infrared images, making the task\neven harder. In this paper, we explore how weaker levels of supervision can\naffect the performance of deep person counting architectures for image\nclassification and point-level localization. Our experiments indicate that\ncounting people using a CNN Image-Level model achieves competitive results with\nYOLO detectors and point-level models, yet provides a higher frame rate and a\nsimilar amount of model parameters.\n","authors":["David Latortue","Moetez Kdayem","Fidel A Guerrero Peña","Eric Granger","Marco Pedersoli"],"pdf_url":"https://arxiv.org/pdf/2311.11974v1.pdf","comment":"Accepted in IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV) 2024"},{"id":"http://arxiv.org/abs/2311.11971v1","updated":"2023-11-20T17:59:28Z","published":"2023-11-20T17:59:28Z","title":"LiDAR-HMR: 3D Human Mesh Recovery from LiDAR","summary":"  In recent years, point cloud perception tasks have been garnering increasing\nattention. This paper presents the first attempt to estimate 3D human body mesh\nfrom sparse LiDAR point clouds. We found that the major challenge in estimating\nhuman pose and mesh from point clouds lies in the sparsity, noise, and\nincompletion of LiDAR point clouds. Facing these challenges, we propose an\neffective sparse-to-dense reconstruction scheme to reconstruct 3D human mesh.\nThis involves estimating a sparse representation of a human (3D human pose) and\ngradually reconstructing the body mesh. To better leverage the 3D structural\ninformation of point clouds, we employ a cascaded graph transformer\n(graphormer) to introduce point cloud features during sparse-to-dense\nreconstruction. Experimental results on three publicly available databases\ndemonstrate the effectiveness of the proposed approach. Code:\nhttps://github.com/soullessrobot/LiDAR-HMR/\n","authors":["Bohao Fan","Wenzhao Zheng","Jianjiang Feng","Jie Zhou"],"pdf_url":"https://arxiv.org/pdf/2311.11971v1.pdf","comment":"Code is available at: https://github.com/soullessrobot/LiDAR-HMR/"},{"id":"http://arxiv.org/abs/2311.11969v1","updated":"2023-11-20T17:59:03Z","published":"2023-11-20T17:59:03Z","title":"SA-Med2D-20M Dataset: Segment Anything in 2D Medical Imaging with 20\n  Million masks","summary":"  Segment Anything Model (SAM) has achieved impressive results for natural\nimage segmentation with input prompts such as points and bounding boxes. Its\nsuccess largely owes to massive labeled training data. However, directly\napplying SAM to medical image segmentation cannot perform well because SAM\nlacks medical knowledge -- it does not use medical images for training. To\nincorporate medical knowledge into SAM, we introduce SA-Med2D-20M, a\nlarge-scale segmentation dataset of 2D medical images built upon numerous\npublic and private datasets. It consists of 4.6 million 2D medical images and\n19.7 million corresponding masks, covering almost the whole body and showing\nsignificant diversity. This paper describes all the datasets collected in\nSA-Med2D-20M and details how to process these datasets. Furthermore,\ncomprehensive statistics of SA-Med2D-20M are presented to facilitate the better\nuse of our dataset, which can help the researchers build medical vision\nfoundation models or apply their models to downstream medical applications. We\nhope that the large scale and diversity of SA-Med2D-20M can be leveraged to\ndevelop medical artificial intelligence for enhancing diagnosis, medical image\nanalysis, knowledge sharing, and education. The data with the redistribution\nlicense is publicly available at https://github.com/OpenGVLab/SAM-Med2D.\n","authors":["Jin Ye","Junlong Cheng","Jianpin Chen","Zhongying Deng","Tianbin Li","Haoyu Wang","Yanzhou Su","Ziyan Huang","Jilong Chen","Lei Jiang","Hui Sun","Min Zhu","Shaoting Zhang","Junjun He","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2311.11969v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11963v1","updated":"2023-11-20T17:43:09Z","published":"2023-11-20T17:43:09Z","title":"What Can AutoML Do For Continual Learning?","summary":"  This position paper outlines the potential of AutoML for incremental\n(continual) learning to encourage more research in this direction. Incremental\nlearning involves incorporating new data from a stream of tasks and\ndistributions to learn enhanced deep representations and adapt better to new\ntasks. However, a significant limitation of incremental learners is that most\ncurrent techniques freeze the backbone architecture, hyperparameters, and the\norder & structure of the learning tasks throughout the learning and adaptation\nprocess. We strongly believe that AutoML offers promising solutions to address\nthese limitations, enabling incremental learning to adapt to more diverse\nreal-world tasks. Therefore, instead of directly proposing a new method, this\npaper takes a step back by posing the question: \"What can AutoML do for\nincremental learning?\" We outline three key areas of research that can\ncontribute to making incremental learners more dynamic, highlighting concrete\nopportunities to apply AutoML methods in novel ways as well as entirely new\nchallenges for AutoML research.\n","authors":["Mert Kilickaya","Joaquin Vanschoren"],"pdf_url":"https://arxiv.org/pdf/2311.11963v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11961v1","updated":"2023-11-20T17:38:35Z","published":"2023-11-20T17:38:35Z","title":"NNG-Mix: Improving Semi-supervised Anomaly Detection with Pseudo-anomaly\n  Generation","summary":"  Anomaly detection (AD) is essential in identifying rare and often critical\nevents in complex systems, finding applications in fields such as network\nintrusion detection, financial fraud detection, and fault detection in\ninfrastructure and industrial systems. While AD is typically treated as an\nunsupervised learning task due to the high cost of label annotation, it is more\npractical to assume access to a small set of labeled anomaly samples from\ndomain experts, as is the case for semi-supervised anomaly detection.\nSemi-supervised and supervised approaches can leverage such labeled data,\nresulting in improved performance. In this paper, rather than proposing a new\nsemi-supervised or supervised approach for AD, we introduce a novel algorithm\nfor generating additional pseudo-anomalies on the basis of the limited labeled\nanomalies and a large volume of unlabeled data. This serves as an augmentation\nto facilitate the detection of new anomalies. Our proposed algorithm, named\nNearest Neighbor Gaussian Mixup (NNG-Mix), efficiently integrates information\nfrom both labeled and unlabeled data to generate pseudo-anomalies. We compare\nthe performance of this novel algorithm with commonly applied augmentation\ntechniques, such as Mixup and Cutout. We evaluate NNG-Mix by training various\nexisting semi-supervised and supervised anomaly detection algorithms on the\noriginal training data along with the generated pseudo-anomalies. Through\nextensive experiments on 57 benchmark datasets in ADBench, reflecting different\ndata types, we demonstrate that NNG-Mix outperforms other data augmentation\nmethods. It yields significant performance improvements compared to the\nbaselines trained exclusively on the original training data. Notably, NNG-Mix\nyields up to 16.4%, 8.8%, and 8.0% improvements on Classical, CV, and NLP\ndatasets in ADBench. Our source code will be available at\nhttps://github.com/donghao51/NNG-Mix.\n","authors":["Hao Dong","Gaëtan Frusque","Yue Zhao","Eleni Chatzi","Olga Fink"],"pdf_url":"https://arxiv.org/pdf/2311.11961v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.13849v2","updated":"2023-11-20T17:23:17Z","published":"2023-10-20T22:47:40Z","title":"A Dual-Stream Neural Network Explains the Functional Segregation of\n  Dorsal and Ventral Visual Pathways in Human Brains","summary":"  The human visual system uses two parallel pathways for spatial processing and\nobject recognition. In contrast, computer vision systems tend to use a single\nfeedforward pathway, rendering them less robust, adaptive, or efficient than\nhuman vision. To bridge this gap, we developed a dual-stream vision model\ninspired by the human eyes and brain. At the input level, the model samples two\ncomplementary visual patterns to mimic how the human eyes use magnocellular and\nparvocellular retinal ganglion cells to separate retinal inputs to the brain.\nAt the backend, the model processes the separate input patterns through two\nbranches of convolutional neural networks (CNN) to mimic how the human brain\nuses the dorsal and ventral cortical pathways for parallel visual processing.\nThe first branch (WhereCNN) samples a global view to learn spatial attention\nand control eye movements. The second branch (WhatCNN) samples a local view to\nrepresent the object around the fixation. Over time, the two branches interact\nrecurrently to build a scene representation from moving fixations. We compared\nthis model with the human brains processing the same movie and evaluated their\nfunctional alignment by linear transformation. The WhereCNN and WhatCNN\nbranches were found to differentially match the dorsal and ventral pathways of\nthe visual cortex, respectively, primarily due to their different learning\nobjectives. These model-based results lead us to speculate that the distinct\nresponses and representations of the ventral and dorsal streams are more\ninfluenced by their distinct goals in visual attention and object recognition\nthan by their specific bias or selectivity in retinal inputs. This dual-stream\nmodel takes a further step in brain-inspired computer vision, enabling parallel\nneural networks to actively explore and understand the visual surroundings.\n","authors":["Minkyu Choi","Kuan Han","Xiaokai Wang","Yizhen Zhang","Zhongming Liu"],"pdf_url":"https://arxiv.org/pdf/2310.13849v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11919v1","updated":"2023-11-20T16:54:07Z","published":"2023-11-20T16:54:07Z","title":"An Image is Worth Multiple Words: Multi-attribute Inversion for\n  Constrained Text-to-Image Synthesis","summary":"  We consider the problem of constraining diffusion model outputs with a\nuser-supplied reference image. Our key objective is to extract multiple\nattributes (e.g., color, object, layout, style) from this single reference\nimage, and then generate new samples with them. One line of existing work\nproposes to invert the reference images into a single textual conditioning\nvector, enabling generation of new samples with this learned token. These\nmethods, however, do not learn multiple tokens that are necessary to condition\nmodel outputs on the multiple attributes noted above. Another line of\ntechniques expand the inversion space to learn multiple embeddings but they do\nthis only along the layer dimension (e.g., one per layer of the DDPM model) or\nthe timestep dimension (one for a set of timesteps in the denoising process),\nleading to suboptimal attribute disentanglement. To address the aforementioned\ngaps, the first contribution of this paper is an extensive analysis to\ndetermine which attributes are captured in which dimension of the denoising\nprocess. As noted above, we consider both the time-step dimension (in reverse\ndenoising) as well as the DDPM model layer dimension. We observe that often a\nsubset of these attributes are captured in the same set of model layers and/or\nacross same denoising timesteps. For instance, color and style are captured\nacross same U-Net layers, whereas layout and color are captured across same\ntimestep stages. Consequently, an inversion process that is designed only for\nthe time-step dimension or the layer dimension is insufficient to disentangle\nall attributes. This leads to our second contribution where we design a new\nmulti-attribute inversion algorithm, MATTE, with associated\ndisentanglement-enhancing regularization losses, that operates across both\ndimensions and explicitly leads to four disentangled tokens (color, style,\nlayout, and object).\n","authors":["Aishwarya Agarwal","Srikrishna Karanam","Tripti Shukla","Balaji Vasan Srinivasan"],"pdf_url":"https://arxiv.org/pdf/2311.11919v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11910v1","updated":"2023-11-20T16:40:48Z","published":"2023-11-20T16:40:48Z","title":"Generalization of Fitness Exercise Recognition from Doppler Measurements\n  by Domain-adaption and Few-Shot Learning","summary":"  In previous works, a mobile application was developed using an unmodified\ncommercial off-the-shelf smartphone to recognize whole-body exercises. The\nworking principle was based on the ultrasound Doppler sensing with the device\nbuilt-in hardware. Applying such a lab-environment trained model on realistic\napplication variations causes a significant drop in performance, and thus\ndecimate its applicability. The reason of the reduced performance can be\nmanifold. It could be induced by the user, environment, and device variations\nin realistic scenarios. Such scenarios are often more complex and diverse,\nwhich can be challenging to anticipate in the initial training data. To study\nand overcome this issue, this paper presents a database with controlled and\nuncontrolled subsets of fitness exercises. We propose two concepts to utilize\nsmall adaption data to successfully improve model generalization in an\nuncontrolled environment, increasing the recognition accuracy by two to six\nfolds compared to the baseline for different users.\n","authors":["Biying Fu","Naser Damer","Florian Kirchbuchner","Arjan Kuijper"],"pdf_url":"https://arxiv.org/pdf/2311.11910v1.pdf","comment":"accepted at International Conference on Pattern Recognition (ICPR)\n  workshop 2021"},{"id":"http://arxiv.org/abs/2311.11908v1","updated":"2023-11-20T16:40:29Z","published":"2023-11-20T16:40:29Z","title":"Continual Learning: Applications and the Road Forward","summary":"  Continual learning is a sub-field of machine learning, which aims to allow\nmachine learning models to continuously learn on new data, by accumulating\nknowledge without forgetting what was learned in the past. In this work, we\ntake a step back, and ask: \"Why should one care about continual learning in the\nfirst place?\". We set the stage by surveying recent continual learning papers\npublished at three major machine learning conferences, and show that\nmemory-constrained settings dominate the field. Then, we discuss five open\nproblems in machine learning, and even though they seem unrelated to continual\nlearning at first sight, we show that continual learning will inevitably be\npart of their solution. These problems are model-editing, personalization,\non-device learning, faster (re-)training and reinforcement learning. Finally,\nby comparing the desiderata from these unsolved problems and the current\nassumptions in continual learning, we highlight and discuss four future\ndirections for continual learning research. We hope that this work offers an\ninteresting perspective on the future of continual learning, while displaying\nits potential value and the paths we have to pursue in order to make it\nsuccessful. This work is the result of the many discussions the authors had at\nthe Dagstuhl seminar on Deep Continual Learning, in March 2023.\n","authors":["Eli Verwimp","Shai Ben-David","Matthias Bethge","Andrea Cossu","Alexander Gepperth","Tyler L. Hayes","Eyke Hüllermeier","Christopher Kanan","Dhireesha Kudithipudi","Christoph H. Lampert","Martin Mundt","Razvan Pascanu","Adrian Popescu","Andreas S. Tolias","Joost van de Weijer","Bing Liu","Vincenzo Lomonaco","Tinne Tuytelaars","Gido M. van de Ven"],"pdf_url":"https://arxiv.org/pdf/2311.11908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11904v1","updated":"2023-11-20T16:37:45Z","published":"2023-11-20T16:37:45Z","title":"LLMs as Visual Explainers: Advancing Image Classification with Evolving\n  Visual Descriptions","summary":"  Vision-language models (VLMs) offer a promising paradigm for image\nclassification by comparing the similarity between images and class embeddings.\nA critical challenge lies in crafting precise textual representations for class\nnames. While previous studies have leveraged recent advancements in large\nlanguage models (LLMs) to enhance these descriptors, their outputs often suffer\nfrom ambiguity and inaccuracy. We identify two primary causes: 1) The prevalent\nreliance on textual interactions with LLMs, leading to a mismatch between the\ngenerated text and the visual content in VLMs' latent space - a phenomenon we\nterm the \"explain without seeing\" dilemma. 2) The oversight of the inter-class\nrelationships, resulting in descriptors that fail to differentiate similar\nclasses effectively. To address these issues, we propose a novel image\nclassification framework combining VLMs with LLMs, named Iterative Optimization\nwith Visual Feedback. In particular, our method develops an LLM-based agent,\nemploying an evolutionary optimization strategy to refine class descriptors.\nCrucially, we incorporate visual feedback from VLM classification metrics,\nthereby guiding the optimization process with concrete visual data. Our method\nleads to improving accuracy on a wide range of image classification benchmarks,\nwith 3.47\\% average gains over state-of-the-art methods. We also highlight the\nresulting descriptions serve as explainable and robust features that can\nconsistently improve the performance across various backbone models.\n","authors":["Songhao Han","Le Zhuo","Yue Liao","Si Liu"],"pdf_url":"https://arxiv.org/pdf/2311.11904v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.13677v3","updated":"2023-11-20T16:37:05Z","published":"2021-11-26T18:59:38Z","title":"SWAT: Spatial Structure Within and Among Tokens","summary":"  Modeling visual data as tokens (i.e., image patches) using attention\nmechanisms, feed-forward networks or convolutions has been highly effective in\nrecent years. Such methods usually have a common pipeline: a tokenization\nmethod, followed by a set of layers/blocks for information mixing, both within\nand among tokens. When image patches are converted into tokens, they are often\nflattened, discarding the spatial structure within each patch. As a result, any\nprocessing that follows (eg: multi-head self-attention) may fail to recover\nand/or benefit from such information. In this paper, we argue that models can\nhave significant gains when spatial structure is preserved during tokenization,\nand is explicitly used during the mixing stage. We propose two key\ncontributions: (1) Structure-aware Tokenization and, (2) Structure-aware\nMixing, both of which can be combined with existing models with minimal effort.\nWe introduce a family of models (SWAT), showing improvements over the likes of\nDeiT, MLP-Mixer and Swin Transformer, across multiple benchmarks including\nImageNet classification and ADE20K segmentation. Our code is available at\nhttps://github.com/kkahatapitiya/SWAT.\n","authors":["Kumara Kahatapitiya","Michael S. Ryoo"],"pdf_url":"https://arxiv.org/pdf/2111.13677v3.pdf","comment":"Accepted to be published at IJCAI23"},{"id":"http://arxiv.org/abs/2311.11901v1","updated":"2023-11-20T16:35:16Z","published":"2023-11-20T16:35:16Z","title":"Identifying the Defective: Detecting Damaged Grains for Cereal\n  Appearance Inspection","summary":"  Cereal grain plays a crucial role in the human diet as a major source of\nessential nutrients. Grain Appearance Inspection (GAI) serves as an essential\nprocess to determine grain quality and facilitate grain circulation and\nprocessing. However, GAI is routinely performed manually by inspectors with\ncumbersome procedures, which poses a significant bottleneck in smart\nagriculture.\n  In this paper, we endeavor to develop an automated GAI system:AI4GrainInsp.\nBy analyzing the distinctive characteristics of grain kernels, we formulate GAI\nas a ubiquitous problem: Anomaly Detection (AD), in which healthy and edible\nkernels are considered normal samples while damaged grains or unknown objects\nare regarded as anomalies. We further propose an AD model, called AD-GAI, which\nis trained using only normal samples yet can identify anomalies during\ninference. Moreover, we customize a prototype device for data acquisition and\ncreate a large-scale dataset including 220K high-quality images of wheat and\nmaize kernels. Through extensive experiments, AD-GAI achieves considerable\nperformance in comparison with advanced AD methods, and AI4GrainInsp has highly\nconsistent performance compared to human experts and excels at inspection\nefficiency over 20x speedup. The dataset, code and models will be released at\nhttps://github.com/hellodfan/AI4GrainInsp.\n","authors":["Lei Fan","Yiwen Ding","Dongdong Fan","Yong Wu","Maurice Pagnucco","Yang Song"],"pdf_url":"https://arxiv.org/pdf/2311.11901v1.pdf","comment":"Accepted by ECAI2023. https://github.com/hellodfan/AI4GrainInsp"},{"id":"http://arxiv.org/abs/2311.11888v1","updated":"2023-11-20T16:21:37Z","published":"2023-11-20T16:21:37Z","title":"SniffyArt: The Dataset of Smelling Persons","summary":"  Smell gestures play a crucial role in the investigation of past smells in the\nvisual arts yet their automated recognition poses significant challenges. This\npaper introduces the SniffyArt dataset, consisting of 1941 individuals\nrepresented in 441 historical artworks. Each person is annotated with a tightly\nfitting bounding box, 17 pose keypoints, and a gesture label. By integrating\nthese annotations, the dataset enables the development of hybrid classification\napproaches for smell gesture recognition. The datasets high-quality human pose\nestimation keypoints are achieved through the merging of five separate sets of\nkeypoint annotations per person. The paper also presents a baseline analysis,\nevaluating the performance of representative algorithms for detection, keypoint\nestimation, and classification tasks, showcasing the potential of combining\nkeypoint estimation with smell gesture classification. The SniffyArt dataset\nlays a solid foundation for future research and the exploration of multi-task\napproaches leveraging pose keypoints and person boxes to advance human gesture\nand olfactory dimension analysis in historical artworks.\n","authors":["Mathias Zinnen","Azhar Hussian","Hang Tran","Prathmesh Madhu","Andreas Maier","Vincent Christlein"],"pdf_url":"https://arxiv.org/pdf/2311.11888v1.pdf","comment":"10 pages, 8 figures"},{"id":"http://arxiv.org/abs/2311.11882v1","updated":"2023-11-20T16:19:46Z","published":"2023-11-20T16:19:46Z","title":"Multi-Task Faces (MTF) Data Set: A Legally and Ethically Compliant\n  Collection of Face Images for Various Classification Tasks","summary":"  Human facial data hold tremendous potential to address a variety of\nclassification problems, including face recognition, age estimation, gender\nidentification, emotion analysis, and race classification. However, recent\nprivacy regulations, such as the EU General Data Protection Regulation and\nothers, have restricted the ways in which human images may be collected and\nused for research. As a result, several previously published data sets\ncontaining human faces have been removed from the internet due to inadequate\ndata collection methods that failed to meet privacy regulations. Data sets\nconsisting of synthetic data have been proposed as an alternative, but they\nfall short of accurately representing the real data distribution. On the other\nhand, most available data sets are labeled for just a single task, which limits\ntheir applicability. To address these issues, we present the Multi-Task Faces\n(MTF) image data set, a meticulously curated collection of face images designed\nfor various classification tasks, including face recognition, as well as race,\ngender, and age classification. The MTF data set has been ethically gathered by\nleveraging publicly available images of celebrities and strictly adhering to\ncopyright regulations. In this paper, we present this data set and provide\ndetailed descriptions of the followed data collection and processing\nprocedures. Furthermore, we evaluate the performance of five deep learning (DL)\nmodels on the MTF data set across the aforementioned classification tasks.\nAdditionally, we compare the performance of DL models over the processed MTF\ndata and over raw data crawled from the internet. The reported results\nconstitute a baseline for further research employing these data. The MTF data\nset can be accessed through the following link (please cite the present paper\nif you use the data set): https://github.com/RamiHaf/MTF_data_set\n","authors":["Rami Haffar","David Sánchez","Josep Domingo-Ferrer"],"pdf_url":"https://arxiv.org/pdf/2311.11882v1.pdf","comment":"21 pages, 2 figures, 9 Tables,"},{"id":"http://arxiv.org/abs/2310.04741v3","updated":"2023-11-20T16:09:07Z","published":"2023-10-07T08:54:43Z","title":"Balancing stability and plasticity in continual learning: the\n  readout-decomposition of activation change (RDAC) framework","summary":"  Continual learning (CL) algorithms strive to acquire new knowledge while\npreserving prior information. However, this stability-plasticity trade-off\nremains a central challenge. This paper introduces a framework that dissects\nthis trade-off, offering valuable insights into CL algorithms. The\nReadout-Decomposition of Activation Change (RDAC) framework first addresses the\nstability-plasticity dilemma and its relation to catastrophic forgetting. It\nrelates learning-induced activation changes in the range of prior readouts to\nthe degree of stability and changes in the null space to the degree of\nplasticity. In deep non-linear networks tackling split-CIFAR-110 tasks, the\nframework clarifies the stability-plasticity trade-offs of the popular\nregularization algorithms Synaptic intelligence (SI), Elastic-weight\nconsolidation (EWC), and learning without Forgetting (LwF), and replay-based\nalgorithms Gradient episodic memory (GEM), and data replay. GEM and data replay\npreserved stability and plasticity, while SI, EWC, and LwF traded off\nplasticity for stability. The inability of the regularization algorithms to\nmaintain plasticity was linked to them restricting the change of activations in\nthe null space of the prior readout. Additionally, for one-hidden-layer linear\nneural networks, we derived a gradient decomposition algorithm to restrict\nactivation change only in the range of the prior readouts, to maintain high\nstability while not further sacrificing plasticity. Results demonstrate that\nthe algorithm maintained stability without significant plasticity loss. The\nRDAC framework informs the behavior of existing CL algorithms and paves the way\nfor novel CL approaches. Finally, it sheds light on the connection between\nlearning-induced activation/representation changes and the stability-plasticity\ndilemma, also offering insights into representational drift in biological\nsystems.\n","authors":["Daniel Anthes","Sushrut Thorat","Peter König","Tim C. Kietzmann"],"pdf_url":"https://arxiv.org/pdf/2310.04741v3.pdf","comment":"15 pages, 5 figures, Revision"},{"id":"http://arxiv.org/abs/2311.11865v1","updated":"2023-11-20T16:02:10Z","published":"2023-11-20T16:02:10Z","title":"VLM-Eval: A General Evaluation on Video Large Language Models","summary":"  Despite the rapid development of video Large Language Models (LLMs), a\ncomprehensive evaluation is still absent. In this paper, we introduce a unified\nevaluation that encompasses multiple video tasks, including captioning,\nquestion and answering, retrieval, and action recognition. In addition to\nconventional metrics, we showcase how GPT-based evaluation can match human-like\nperformance in assessing response quality across multiple aspects. We propose a\nsimple baseline: Video-LLaVA, which uses a single linear projection and\noutperforms existing video LLMs. Finally, we evaluate video LLMs beyond\nacademic datasets, which show encouraging recognition and reasoning\ncapabilities in driving scenarios with only hundreds of video-instruction pairs\nfor fine-tuning. We hope our work can serve as a unified evaluation for video\nLLMs, and help expand more practical scenarios. The evaluation code will be\navailable soon.\n","authors":["Shuailin Li","Yuang Zhang","Yucheng Zhao","Qiuyue Wang","Fan Jia","Yingfei Liu","Tiancai Wang"],"pdf_url":"https://arxiv.org/pdf/2311.11865v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.15778v2","updated":"2023-11-20T15:59:42Z","published":"2023-10-24T12:25:37Z","title":"Preserving Patient Privacy in MRI Scans: A Comprehensive Approach with\n  3D Masked Autoencoders","summary":"  MRI scans provide valuable medical information, however they also contain\nsensitive and personally identifiable information (PII) that needs to be\nprotected. Whereas MRI metadata is easily sanitized, MRI image data is a\nprivacy risk because it contains information to render highly-realistic 3D\nvisualizations of a patient's head, enabling malicious actors to possibly\nidentify the subject by cross-referencing a database. Data anonymization and\nde-identification is concerned with ensuring the privacy and confidentiality of\nindividuals' personal information. Traditional MRI de-identification methods\nremove privacy-sensitive parts (e.g. eyes, nose etc.) from a given scan. This\ncomes at the expense of introducing a domain shift that can throw off\ndownstream analyses. Recently, a GAN-based approach was proposed to de-identify\na patient's scan by remodeling it (\\eg changing the face) rather than by\nremoving parts. In this work, we propose CP-MAE, a model that de-identifies the\nface using masked autoencoders and that outperforms all previous approaches in\nterms of downstream task performance as well as de-identification. With our\nmethod we are able to synthesize scans of resolution up to $256^3$ (previously\n$128^3$) which constitutes an eight-fold increase in the number of voxels.\nUsing our construction we were able to design a system that exhibits a highly\nrobust training stage, making it easy to fit the network on novel data.\n","authors":["Lennart Alexander Van der Goten","Kevin Smith"],"pdf_url":"https://arxiv.org/pdf/2310.15778v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11863v1","updated":"2023-11-20T15:59:41Z","published":"2023-11-20T15:59:41Z","title":"GP-NeRF: Generalized Perception NeRF for Context-Aware 3D Scene\n  Understanding","summary":"  Applying NeRF to downstream perception tasks for scene understanding and\nrepresentation is becoming increasingly popular. Most existing methods treat\nsemantic prediction as an additional rendering task, \\textit{i.e.}, the \"label\nrendering\" task, to build semantic NeRFs. However, by rendering\nsemantic/instance labels per pixel without considering the contextual\ninformation of the rendered image, these methods usually suffer from unclear\nboundary segmentation and abnormal segmentation of pixels within an object. To\nsolve this problem, we propose Generalized Perception NeRF (GP-NeRF), a novel\npipeline that makes the widely used segmentation model and NeRF work compatibly\nunder a unified framework, for facilitating context-aware 3D scene perception.\nTo accomplish this goal, we introduce transformers to aggregate radiance as\nwell as semantic embedding fields jointly for novel views and facilitate the\njoint volumetric rendering of both fields. In addition, we propose two\nself-distillation mechanisms, i.e., the Semantic Distill Loss and the\nDepth-Guided Semantic Distill Loss, to enhance the discrimination and quality\nof the semantic field and the maintenance of geometric consistency. In\nevaluation, we conduct experimental comparisons under two perception tasks\n(\\textit{i.e.} semantic and instance segmentation) using both synthetic and\nreal-world datasets. Notably, our method outperforms SOTA approaches by 6.94\\%,\n11.76\\%, and 8.47\\% on generalized semantic segmentation, finetuning semantic\nsegmentation, and instance segmentation, respectively.\n","authors":["Hao Li","Dingwen Zhang","Yalun Dai","Nian Liu","Lechao Cheng","Jingfeng Li","Jingdong Wang","Junwei Han"],"pdf_url":"https://arxiv.org/pdf/2311.11863v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11860v1","updated":"2023-11-20T15:56:44Z","published":"2023-11-20T15:56:44Z","title":"LION : Empowering Multimodal Large Language Model with Dual-Level Visual\n  Knowledge","summary":"  Multimodal Large Language Models (MLLMs) have endowed LLMs with the ability\nto perceive and understand multi-modal signals. However, most of the existing\nMLLMs mainly adopt vision encoders pretrained on coarsely aligned image-text\npairs, leading to insufficient extraction and reasoning of visual knowledge. To\naddress this issue, we devise a dual-Level vIsual knOwledge eNhanced Multimodal\nLarge Language Model (LION), which empowers the MLLM by injecting visual\nknowledge in two levels. 1) Progressive incorporation of fine-grained\nspatial-aware visual knowledge. We design a vision aggregator cooperated with\nregion-level vision-language (VL) tasks to incorporate fine-grained\nspatial-aware visual knowledge into the MLLM. To alleviate the conflict between\nimage-level and region-level VL tasks during incorporation, we devise a\ndedicated stage-wise instruction-tuning strategy with mixture-of-adapters. This\nprogressive incorporation scheme contributes to the mutual promotion between\nthese two kinds of VL tasks. 2) Soft prompting of high-level semantic visual\nevidence. We facilitate the MLLM with high-level semantic visual evidence by\nleveraging diverse image tags. To mitigate the potential influence caused by\nimperfect predicted tags, we propose a soft prompting method by embedding a\nlearnable token into the tailored text instruction. Comprehensive experiments\non several multi-modal benchmarks demonstrate the superiority of our model\n(e.g., improvement of 5% accuracy on VSR and 3% CIDEr on TextCaps over\nInstructBLIP, 5% accuracy on RefCOCOg over Kosmos-2).\n","authors":["Gongwei Chen","Leyang Shen","Rui Shao","Xiang Deng","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2311.11860v1.pdf","comment":"Technical Report. Project page:\n  https://rshaojimmy.github.io/Projects/JiuTian-LION Code:\n  https://github.com/rshaojimmy/JiuTian"},{"id":"http://arxiv.org/abs/2311.11856v1","updated":"2023-11-20T15:51:14Z","published":"2023-11-20T15:51:14Z","title":"FATURA: A Multi-Layout Invoice Image Dataset for Document Analysis and\n  Understanding","summary":"  Document analysis and understanding models often require extensive annotated\ndata to be trained. However, various document-related tasks extend beyond mere\ntext transcription, requiring both textual content and precise bounding-box\nannotations to identify different document elements. Collecting such data\nbecomes particularly challenging, especially in the context of invoices, where\nprivacy concerns add an additional layer of complexity. In this paper, we\nintroduce FATURA, a pivotal resource for researchers in the field of document\nanalysis and understanding. FATURA is a highly diverse dataset featuring\nmulti-layout, annotated invoice document images. Comprising $10,000$ invoices\nwith $50$ distinct layouts, it represents the largest openly accessible image\ndataset of invoice documents known to date. We also provide comprehensive\nbenchmarks for various document analysis and understanding tasks and conduct\nexperiments under diverse training and evaluation scenarios. The dataset is\nfreely accessible at https://zenodo.org/record/8261508, empowering researchers\nto advance the field of document analysis and understanding.\n","authors":["Mahmoud Limam","Marwa Dhiaf","Yousri Kessentini"],"pdf_url":"https://arxiv.org/pdf/2311.11856v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11853v1","updated":"2023-11-20T15:45:16Z","published":"2023-11-20T15:45:16Z","title":"Asynchronous Bioplausible Neuron for Spiking Neural Networks for\n  Event-Based Vision","summary":"  Spiking Neural Networks (SNNs) offer a biologically inspired approach to\ncomputer vision that can lead to more efficient processing of visual data with\nreduced energy consumption. However, maintaining homeostasis within these\nnetworks is challenging, as it requires continuous adjustment of neural\nresponses to preserve equilibrium and optimal processing efficiency amidst\ndiverse and often unpredictable input signals. In response to these challenges,\nwe propose the Asynchronous Bioplausible Neuron (ABN), a dynamic spike firing\nmechanism to auto-adjust the variations in the input signal. Comprehensive\nevaluation across various datasets demonstrates ABN's enhanced performance in\nimage classification and segmentation, maintenance of neural equilibrium, and\nenergy efficiency.\n","authors":["Sanket Kachole","Hussain Sajwani","Fariborz Baghaei Naeini","Dimitrios Makris","Yahya Zweiri"],"pdf_url":"https://arxiv.org/pdf/2311.11853v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2311.11845v1","updated":"2023-11-20T15:35:00Z","published":"2023-11-20T15:35:00Z","title":"Entangled View-Epipolar Information Aggregation for Generalizable Neural\n  Radiance Fields","summary":"  Generalizable NeRF can directly synthesize novel views across new scenes,\neliminating the need for scene-specific retraining in vanilla NeRF. A critical\nenabling factor in these approaches is the extraction of a generalizable 3D\nrepresentation by aggregating source-view features. In this paper, we propose\nan Entangled View-Epipolar Information Aggregation method dubbed EVE-NeRF.\nDifferent from existing methods that consider cross-view and along-epipolar\ninformation independently, EVE-NeRF conducts the view-epipolar feature\naggregation in an entangled manner by injecting the scene-invariant appearance\ncontinuity and geometry consistency priors to the aggregation process. Our\napproach effectively mitigates the potential lack of inherent geometric and\nappearance constraint resulting from one-dimensional interactions, thus further\nboosting the 3D representation generalizablity. EVE-NeRF attains\nstate-of-the-art performance across various evaluation scenarios. Extensive\nexperiments demonstate that, compared to prevailing single-dimensional\naggregation, the entangled network excels in the accuracy of 3D scene geometry\nand appearance reconstruction.Our project page is\nhttps://github.com/tatakai1/EVENeRF.\n","authors":["Zhiyuan Min","Yawei Luo","Wei Yang","Yuesong Wang","Yi Yang"],"pdf_url":"https://arxiv.org/pdf/2311.11845v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11837v1","updated":"2023-11-20T15:11:31Z","published":"2023-11-20T15:11:31Z","title":"Kandinsky Conformal Prediction: Efficient Calibration of Image\n  Segmentation Algorithms","summary":"  Image segmentation algorithms can be understood as a collection of pixel\nclassifiers, for which the outcomes of nearby pixels are correlated. Classifier\nmodels can be calibrated using Inductive Conformal Prediction, but this\nrequires holding back a sufficiently large calibration dataset for computing\nthe distribution of non-conformity scores of the model's predictions. If one\nonly requires only marginal calibration on the image level, this calibration\nset consists of all individual pixels in the images available for calibration.\nHowever, if the goal is to attain proper calibration for each individual pixel\nclassifier, the calibration set consists of individual images. In a scenario\nwhere data are scarce (such as the medical domain), it may not always be\npossible to set aside sufficiently many images for this pixel-level\ncalibration. The method we propose, dubbed ``Kandinsky calibration'', makes use\nof the spatial structure present in the distribution of natural images to\nsimultaneously calibrate the classifiers of ``similar'' pixels. This can be\nseen as an intermediate approach between marginal (imagewise) and conditional\n(pixelwise) calibration, where non-conformity scores are aggregated over\nsimilar image regions, thereby making more efficient use of the images\navailable for calibration. We run experiments on segmentation algorithms\ntrained and calibrated on subsets of the public MS-COCO and Medical Decathlon\ndatasets, demonstrating that Kandinsky calibration method can significantly\nimprove the coverage. When compared to both pixelwise and imagewise calibration\non little data, the Kandinsky method achieves much lower coverage errors,\nindicating the data efficiency of the Kandinsky calibration.\n","authors":["Joren Brunekreef","Eric Marcus","Ray Sheombarsing","Jan-Jakob Sonke","Jonas Teuwen"],"pdf_url":"https://arxiv.org/pdf/2311.11837v1.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2311.11827v1","updated":"2023-11-20T15:04:16Z","published":"2023-11-20T15:04:16Z","title":"Few-shot Multispectral Segmentation with Representations Generated by\n  Reinforcement Learning","summary":"  The task of multispectral image segmentation (segmentation of images with\nnumerous channels/bands, each capturing a specific range of wavelengths of\nelectromagnetic radiation) has been previously explored in contexts with large\namounts of labeled data. However, these models tend not to generalize well to\ndatasets of smaller size. In this paper, we propose a novel approach for\nimproving few-shot segmentation performance on multispectral images using\nreinforcement learning to generate representations. These representations are\ngenerated in the form of mathematical expressions between channels and are\ntailored to the specific class being segmented. Our methodology involves\ntraining an agent to identify the most informative expressions, updating the\ndataset using these expressions, and then using the updated dataset to perform\nsegmentation. Due to the limited length of the expressions, the model receives\nuseful representations without any added risk of overfitting. We evaluate the\neffectiveness of our approach on several multispectral datasets and demonstrate\nits effectiveness in boosting the performance of segmentation algorithms.\n","authors":["Dilith Jayakody","Thanuja Ambegoda"],"pdf_url":"https://arxiv.org/pdf/2311.11827v1.pdf","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2311.11825v1","updated":"2023-11-20T15:03:56Z","published":"2023-11-20T15:03:56Z","title":"Holistic Inverse Rendering of Complex Facade via Aerial 3D Scanning","summary":"  In this work, we use multi-view aerial images to reconstruct the geometry,\nlighting, and material of facades using neural signed distance fields (SDFs).\nWithout the requirement of complex equipment, our method only takes simple RGB\nimages captured by a drone as inputs to enable physically based and\nphotorealistic novel-view rendering, relighting, and editing. However, a\nreal-world facade usually has complex appearances ranging from diffuse rocks\nwith subtle details to large-area glass windows with specular reflections,\nmaking it hard to attend to everything. As a result, previous methods can\npreserve the geometry details but fail to reconstruct smooth glass windows or\nverse vise. In order to address this challenge, we introduce three spatial- and\nsemantic-adaptive optimization strategies, including a semantic regularization\napproach based on zero-shot segmentation techniques to improve material\nconsistency, a frequency-aware geometry regularization to balance surface\nsmoothness and details in different surfaces, and a visibility probe-based\nscheme to enable efficient modeling of the local lighting in large-scale\noutdoor environments. In addition, we capture a real-world facade aerial 3D\nscanning image set and corresponding point clouds for training and\nbenchmarking. The experiment demonstrates the superior quality of our method on\nfacade holistic inverse rendering, novel view synthesis, and scene editing\ncompared to state-of-the-art baselines.\n","authors":["Zixuan Xie","Rengan Xie","Rong Li","Kai Huang","Pengju Qiao","Jingsen Zhu","Xu Yin","Qi Ye","Wei Hua","Yuchi Huo","Hujun Bao"],"pdf_url":"https://arxiv.org/pdf/2311.11825v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07750v2","updated":"2023-11-20T15:01:19Z","published":"2023-11-13T21:07:07Z","title":"SynthEnsemble: A Fusion of CNN, Vision Transformer, and Hybrid Models\n  for Multi-Label Chest X-Ray Classification","summary":"  Chest X-rays are widely used to diagnose thoracic diseases, but the lack of\ndetailed information about these abnormalities makes it challenging to develop\naccurate automated diagnosis systems, which is crucial for early detection and\neffective treatment. To address this challenge, we employed deep learning\ntechniques to identify patterns in chest X-rays that correspond to different\ndiseases. We conducted experiments on the \"ChestX-ray14\" dataset using various\npre-trained CNNs, transformers, hybrid(CNN+Transformer) models and classical\nmodels. The best individual model was the CoAtNet, which achieved an area under\nthe receiver operating characteristic curve (AUROC) of 84.2%. By combining the\npredictions of all trained models using a weighted average ensemble where the\nweight of each model was determined using differential evolution, we further\nimproved the AUROC to 85.4%, outperforming other state-of-the-art methods in\nthis field. Our findings demonstrate the potential of deep learning techniques,\nparticularly ensemble deep learning, for improving the accuracy of automatic\ndiagnosis of thoracic diseases from chest X-rays.\n","authors":["S. M. Nabil Ashraf","Md. Adyelullahil Mamun","Hasnat Md. Abdullah","Md. Golam Rabiul Alam"],"pdf_url":"https://arxiv.org/pdf/2311.07750v2.pdf","comment":"Accepted in International Conference on Computer and Information\n  Technology (ICCIT) 2023"},{"id":"http://arxiv.org/abs/2311.11821v1","updated":"2023-11-20T14:58:47Z","published":"2023-11-20T14:58:47Z","title":"Cross-View Graph Consistency Learning for Invariant Graph\n  Representations","summary":"  Graph representation learning is fundamental for analyzing graph-structured\ndata. Exploring invariant graph representations remains a challenge for most\nexisting graph representation learning methods. In this paper, we propose a\ncross-view graph consistency learning (CGCL) method that learns invariant graph\nrepresentations for link prediction. First, two complementary augmented views\nare derived from an incomplete graph structure through a bidirectional graph\nstructure augmentation scheme. This augmentation scheme mitigates the potential\ninformation loss that is commonly associated with various data augmentation\ntechniques involving raw graph data, such as edge perturbation, node removal,\nand attribute masking. Second, we propose a CGCL model that can learn invariant\ngraph representations. A cross-view training scheme is proposed to train the\nproposed CGCL model. This scheme attempts to maximize the consistency\ninformation between one augmented view and the graph structure reconstructed\nfrom the other augmented view. Furthermore, we offer a comprehensive\ntheoretical CGCL analysis. This paper empirically and experimentally\ndemonstrates the effectiveness of the proposed CGCL method, achieving\ncompetitive results on graph datasets in comparisons with several\nstate-of-the-art algorithms.\n","authors":["Jie Chen","Zhiming Li","Hua Mao","Wai Lok Woo","Xi Peng"],"pdf_url":"https://arxiv.org/pdf/2311.11821v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2311.11819v1","updated":"2023-11-20T14:55:40Z","published":"2023-11-20T14:55:40Z","title":"Generalized super-resolution 4D Flow MRI -- using ensemble learning to\n  extend across the cardiovascular system","summary":"  4D Flow Magnetic Resonance Imaging (4D Flow MRI) is a non-invasive\nmeasurement technique capable of quantifying blood flow across the\ncardiovascular system. While practical use is limited by spatial resolution and\nimage noise, incorporation of trained super-resolution (SR) networks has\npotential to enhance image quality post-scan. However, these efforts have\npredominantly been restricted to narrowly defined cardiovascular domains, with\nlimited exploration of how SR performance extends across the cardiovascular\nsystem; a task aggravated by contrasting hemodynamic conditions apparent across\nthe cardiovasculature. The aim of our study was to explore the generalizability\nof SR 4D Flow MRI using a combination of heterogeneous training sets and\ndedicated ensemble learning. With synthetic training data generated across\nthree disparate domains (cardiac, aortic, cerebrovascular), varying\nconvolutional base and ensemble learners were evaluated as a function of domain\nand architecture, quantifying performance on both in-silico and acquired\nin-vivo data from the same three domains. Results show that both bagging and\nstacking ensembling enhance SR performance across domains, accurately\npredicting high-resolution velocities from low-resolution input data in-silico.\nLikewise, optimized networks successfully recover native resolution velocities\nfrom downsampled in-vivo data, as well as show qualitative potential in\ngenerating denoised SR-images from clinical level input data. In conclusion,\nour work presents a viable approach for generalized SR 4D Flow MRI, with\nensemble learning extending utility across various clinical areas of interest.\n","authors":["Leon Ericsson","Adam Hjalmarsson","Muhammad Usman Akbar","Edward Ferdian","Mia Bonini","Brandon Hardy","Jonas Schollenberger","Maria Aristova","Patrick Winter","Nicholas Burris","Alexander Fyrdahl","Andreas Sigfridsson","Susanne Schnell","C. Alberto Figueroa","David Nordsletten","Alistair A. Young","David Marlevi"],"pdf_url":"https://arxiv.org/pdf/2311.11819v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.11815v1","updated":"2023-11-20T14:52:48Z","published":"2023-11-20T14:52:48Z","title":"CrackCLF: Automatic Pavement Crack Detection based on Closed-Loop\n  Feedback","summary":"  Automatic pavement crack detection is an important task to ensure the\nfunctional performances of pavements during their service life. Inspired by\ndeep learning (DL), the encoder-decoder framework is a powerful tool for crack\ndetection. However, these models are usually open-loop (OL) systems that tend\nto treat thin cracks as the background. Meanwhile, these models can not\nautomatically correct errors in the prediction, nor can it adapt to the changes\nof the environment to automatically extract and detect thin cracks. To tackle\nthis problem, we embed closed-loop feedback (CLF) into the neural network so\nthat the model could learn to correct errors on its own, based on generative\nadversarial networks (GAN). The resulting model is called CrackCLF and includes\nthe front and back ends, i.e. segmentation and adversarial network. The front\nend with U-shape framework is employed to generate crack maps, and the back end\nwith a multi-scale loss function is used to correct higher-order\ninconsistencies between labels and crack maps (generated by the front end) to\naddress open-loop system issues. Empirical results show that the proposed\nCrackCLF outperforms others methods on three public datasets. Moreover, the\nproposed CLF can be defined as a plug and play module, which can be embedded\ninto different neural network models to improve their performances.\n","authors":["Chong Li","Zhun Fan","Ying Chen","Huibiao Lin","Laura Moretti","Giuseppe Loprencipe","Weihua Sheng","Kelvin C. P. Wang"],"pdf_url":"https://arxiv.org/pdf/2311.11815v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11810v1","updated":"2023-11-20T14:42:25Z","published":"2023-11-20T14:42:25Z","title":"DocPedia: Unleashing the Power of Large Multimodal Model in the\n  Frequency Domain for Versatile Document Understanding","summary":"  This work presents DocPedia, a novel large multimodal model (LMM) for\nversatile OCR-free document understanding, capable of parsing images up to\n2,560$\\times$2,560 resolution. Unlike existing work either struggle with\nhigh-resolution documents or give up the large language model thus vision or\nlanguage ability constrained, our DocPedia directly processes visual input in\nthe frequency domain rather than the pixel space. The unique characteristic\nenables DocPedia to capture a greater amount of visual and textual information\nusing a limited number of visual tokens. To consistently enhance both\nperception and comprehension abilities of our model, we develop a dual-stage\ntraining strategy and enrich instructions/annotations of all training tasks\ncovering multiple document types. Extensive quantitative and qualitative\nexperiments conducted on various publicly available benchmarks confirm the\nmutual benefits of jointly learning perception and comprehension tasks. The\nresults provide further evidence of the effectiveness and superior performance\nof our DocPedia over other methods.\n","authors":["Hao Feng","Qi Liu","Hao Liu","Wengang Zhou","Houqiang Li","Can Huang"],"pdf_url":"https://arxiv.org/pdf/2311.11810v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11808v1","updated":"2023-11-20T14:41:44Z","published":"2023-11-20T14:41:44Z","title":"Robot Hand-Eye Calibration using Structure-from-Motion","summary":"  In this paper we propose a new flexible method for hand-eye calibration. The\nvast majority of existing hand-eye calibration techniques requires a\ncalibration rig which is used in conjunction with camera pose estimation\nmethods. Instead, we combine structure-from-motion with known robot motions and\nwe show that the solution can be obtained in linear form. The latter solves for\nboth the hand-eye parameters and for the unknown scale factor inherent with\nstructure-from-motion methods. The algebraic analysis that is made possible\nwith such a linear formulation allows to investigate not only the well known\ncase of general screw motions but also such singular motions as pure\ntranslations, pure rotations, and planar motions. In essence, the robot-mounted\ncamera looks to an unknown rigid layout, tracks points over an image sequence\nand estimates the camera-to-robot relationship. Such a self calibration process\nis relevant for unmanned vehicles, robots working in remote places, and so\nforth. We conduct a large number of experiments which validate the quality of\nthe method by comparing it with existing ones.\n","authors":["Nicolas Andreff","Bernard Espiau","Radu Horaud"],"pdf_url":"https://arxiv.org/pdf/2311.11808v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11797v1","updated":"2023-11-20T14:30:55Z","published":"2023-11-20T14:30:55Z","title":"Igniting Language Intelligence: The Hitchhiker's Guide From\n  Chain-of-Thought Reasoning to Language Agents","summary":"  Large language models (LLMs) have dramatically enhanced the field of language\nintelligence, as demonstrably evidenced by their formidable empirical\nperformance across a spectrum of complex reasoning tasks. Additionally,\ntheoretical proofs have illuminated their emergent reasoning capabilities,\nproviding a compelling showcase of their advanced cognitive abilities in\nlinguistic contexts. Critical to their remarkable efficacy in handling complex\nreasoning tasks, LLMs leverage the intriguing chain-of-thought (CoT) reasoning\ntechniques, obliging them to formulate intermediate steps en route to deriving\nan answer. The CoT reasoning approach has not only exhibited proficiency in\namplifying reasoning performance but also in enhancing interpretability,\ncontrollability, and flexibility. In light of these merits, recent research\nendeavors have extended CoT reasoning methodologies to nurture the development\nof autonomous language agents, which adeptly adhere to language instructions\nand execute actions within varied environments. This survey paper orchestrates\na thorough discourse, penetrating vital research dimensions, encompassing: (i)\nthe foundational mechanics of CoT techniques, with a focus on elucidating the\ncircumstances and justification behind its efficacy; (ii) the paradigm shift in\nCoT; and (iii) the burgeoning of language agents fortified by CoT approaches.\nProspective research avenues envelop explorations into generalization,\nefficiency, customization, scaling, and safety. This paper caters to a wide\naudience, including beginners seeking comprehensive knowledge of CoT reasoning\nand language agents, as well as experienced researchers interested in\nfoundational mechanics and engaging in cutting-edge discussions on these\ntopics. A repository for the related papers is available at\nhttps://github.com/Zoeyyao27/CoT-Igniting-Agent.\n","authors":["Zhuosheng Zhang","Yao Yao","Aston Zhang","Xiangru Tang","Xinbei Ma","Zhiwei He","Yiming Wang","Mark Gerstein","Rui Wang","Gongshen Liu","Hai Zhao"],"pdf_url":"https://arxiv.org/pdf/2311.11797v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11796v1","updated":"2023-11-20T14:29:45Z","published":"2023-11-20T14:29:45Z","title":"Beyond Boundaries: A Comprehensive Survey of Transferable Attacks on AI\n  Systems","summary":"  Artificial Intelligence (AI) systems such as autonomous vehicles, facial\nrecognition, and speech recognition systems are increasingly integrated into\nour daily lives. However, despite their utility, these AI systems are\nvulnerable to a wide range of attacks such as adversarial, backdoor, data\npoisoning, membership inference, model inversion, and model stealing attacks.\nIn particular, numerous attacks are designed to target a particular model or\nsystem, yet their effects can spread to additional targets, referred to as\ntransferable attacks. Although considerable efforts have been directed toward\ndeveloping transferable attacks, a holistic understanding of the advancements\nin transferable attacks remains elusive. In this paper, we comprehensively\nexplore learning-based attacks from the perspective of transferability,\nparticularly within the context of cyber-physical security. We delve into\ndifferent domains -- the image, text, graph, audio, and video domains -- to\nhighlight the ubiquitous and pervasive nature of transferable attacks. This\npaper categorizes and reviews the architecture of existing attacks from various\nviewpoints: data, process, model, and system. We further examine the\nimplications of transferable attacks in practical scenarios such as autonomous\ndriving, speech recognition, and large language models (LLMs). Additionally, we\noutline the potential research directions to encourage efforts in exploring the\nlandscape of transferable attacks. This survey offers a holistic understanding\nof the prevailing transferable attacks and their impacts across different\ndomains.\n","authors":["Guangjing Wang","Ce Zhou","Yuanda Wang","Bocheng Chen","Hanqing Guo","Qiben Yan"],"pdf_url":"https://arxiv.org/pdf/2311.11796v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.04514v2","updated":"2023-11-20T14:28:02Z","published":"2020-12-08T16:02:16Z","title":"Human Motion Tracking by Registering an Articulated Surface to 3-D\n  Points and Normals","summary":"  We address the problem of human motion tracking by registering a surface to\n3-D data. We propose a method that iteratively computes two things: Maximum\nlikelihood estimates for both the kinematic and free-motion parameters of a\nkinematic human-body representation, as well as probabilities that the data are\nassigned either to a body part, or to an outlier cluster. We introduce a new\nmetric between observed points and normals on one side, and a parameterized\nsurface on the other side, the latter being defined as a blending over a set of\nellipsoids. We claim that this metric is well suited when one deals with either\nvisual-hull or visual-shape observations. We illustrate the method by tracking\nhuman motions using sparse visual-shape data (3-D surface points and normals)\ngathered from imperfect silhouettes.\n","authors":["Radu Horaud","Matti Niskanen","Guillaume Dewaele","Edmond Boyer"],"pdf_url":"https://arxiv.org/pdf/2012.04514v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.05582v2","updated":"2023-11-20T14:17:15Z","published":"2020-12-10T11:03:25Z","title":"Image Matching with Scale Adjustment","summary":"  In this paper we address the problem of matching two images with two\ndifferent resolutions: a high-resolution image and a low-resolution one. The\ndifference in resolution between the two images is not known and without loss\nof generality one of the images is assumed to be the high-resolution one. On\nthe premise that changes in resolution act as a smoothing equivalent to changes\nin scale, a scale-space representation of the high-resolution image is\nproduced. Hence the one-to-one classical image matching paradigm becomes\none-to-many because the low-resolution image is compared with all the\nscale-space representations of the high-resolution one. Key to the success of\nsuch a process is the proper representation of the features to be matched in\nscale-space. We show how to represent and extract interest points at variable\nscales and we devise a method allowing the comparison of two images at two\ndifferent resolutions. The method comprises the use of photometric- and\nrotation-invariant descriptors, a geometric model mapping the high-resolution\nimage onto a low-resolution image region, and an image matching strategy based\non local constraints and on the robust estimation of this geometric model.\nExtensive experiments show that our matching method can be used for scale\nchanges up to a factor of 6.\n","authors":["Yves Dufournaud","Cordelia Schmid","Radu Horaud"],"pdf_url":"https://arxiv.org/pdf/2012.05582v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11782v1","updated":"2023-11-20T14:07:38Z","published":"2023-11-20T14:07:38Z","title":"Robust Tumor Segmentation with Hyperspectral Imaging and Graph Neural\n  Networks","summary":"  Segmenting the boundary between tumor and healthy tissue during surgical\ncancer resection poses a significant challenge. In recent years, Hyperspectral\nImaging (HSI) combined with Machine Learning (ML) has emerged as a promising\nsolution. However, due to the extensive information contained within the\nspectral domain, most ML approaches primarily classify individual HSI\n(super-)pixels, or tiles, without taking into account their spatial context. In\nthis paper, we propose an improved methodology that leverages the spatial\ncontext of tiles for more robust and smoother segmentation. To address the\nirregular shapes of tiles, we utilize Graph Neural Networks (GNNs) to propagate\ncontext information across neighboring regions. The features for each tile\nwithin the graph are extracted using a Convolutional Neural Network (CNN),\nwhich is trained simultaneously with the subsequent GNN. Moreover, we\nincorporate local image quality metrics into the loss function to enhance the\ntraining procedure's robustness against low-quality regions in the training\nimages. We demonstrate the superiority of our proposed method using a clinical\nex vivo dataset consisting of 51 HSI images from 30 patients. Despite the\nlimited dataset, the GNN-based model significantly outperforms context-agnostic\napproaches, accurately distinguishing between healthy and tumor tissues, even\nin images from previously unseen patients. Furthermore, we show that our\ncarefully designed loss function, accounting for local image quality, results\nin additional improvements. Our findings demonstrate that context-aware GNN\nalgorithms can robustly find tumor demarcations on HSI images, ultimately\ncontributing to better surgery success and patient outcome.\n","authors":["Mayar Lotfy","Anna Alperovich","Tommaso Giannantonio","Bjorn Barz","Xiaohan Zhang","Felix Holm","Nassir Navab","Felix Boehm","Carolin Schwamborn","Thomas K. Hoffmann","Patrick J. Schuler"],"pdf_url":"https://arxiv.org/pdf/2311.11782v1.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.11777v1","updated":"2023-11-20T14:02:50Z","published":"2023-11-20T14:02:50Z","title":"Multimodal deep learning for mapping forest dominant height by fusing\n  GEDI with earth observation data","summary":"  The integration of multisource remote sensing data and deep learning models\noffers new possibilities for accurately mapping high spatial resolution forest\nheight. We found that GEDI relative heights (RH) metrics exhibited strong\ncorrelation with the mean of the top 10 highest trees (dominant height)\nmeasured in situ at the corresponding footprint locations. Consequently, we\nproposed a novel deep learning framework termed the multi-modal attention\nremote sensing network (MARSNet) to estimate forest dominant height by\nextrapolating dominant height derived from GEDI, using Setinel-1 data, ALOS-2\nPALSAR-2 data, Sentinel-2 optical data and ancillary data. MARSNet comprises\nseparate encoders for each remote sensing data modality to extract multi-scale\nfeatures, and a shared decoder to fuse the features and estimate height. Using\nindividual encoders for each remote sensing imagery avoids interference across\nmodalities and extracts distinct representations. To focus on the efficacious\ninformation from each dataset, we reduced the prevalent spatial and band\nredundancies in each remote sensing data by incorporating the extended spatial\nand band reconstruction convolution modules in the encoders. MARSNet achieved\ncommendable performance in estimating dominant height, with an R2 of 0.62 and\nRMSE of 2.82 m, outperforming the widely used random forest approach which\nattained an R2 of 0.55 and RMSE of 3.05 m. Finally, we applied the trained\nMARSNet model to generate wall-to-wall maps at 10 m resolution for Jilin,\nChina. Through independent validation using field measurements, MARSNet\ndemonstrated an R2 of 0.58 and RMSE of 3.76 m, compared to 0.41 and 4.37 m for\nthe random forest baseline. Our research demonstrates the effectiveness of a\nmultimodal deep learning approach fusing GEDI with SAR and passive optical\nimagery for enhancing the accuracy of high resolution dominant height\nestimation.\n","authors":["Man Chen","Wenquan Dong","Hao Yu","Iain Woodhouse","Casey M. Ryan","Haoyu Liu","Selena Georgiou","Edward T. A. Mitchard"],"pdf_url":"https://arxiv.org/pdf/2311.11777v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11773v1","updated":"2023-11-20T13:58:59Z","published":"2023-11-20T13:58:59Z","title":"Practical cross-sensor color constancy using a dual-mapping strategy","summary":"  Deep Neural Networks (DNNs) have been widely used for illumination\nestimation, which is time-consuming and requires sensor-specific data\ncollection. Our proposed method uses a dual-mapping strategy and only requires\na simple white point from a test sensor under a D65 condition. This allows us\nto derive a mapping matrix, enabling the reconstructions of image data and\nilluminants. In the second mapping phase, we transform the re-constructed image\ndata into sparse features, which are then optimized with a lightweight\nmulti-layer perceptron (MLP) model using the re-constructed illuminants as\nground truths. This approach effectively reduces sensor discrepancies and\ndelivers performance on par with leading cross-sensor methods. It only requires\na small amount of memory (~0.003 MB), and takes ~1 hour training on an\nRTX3070Ti GPU. More importantly, the method can be implemented very fast, with\n~0.3 ms and ~1 ms on a GPU or CPU respectively, and is not sensitive to the\ninput image resolution. Therefore, it offers a practical solution to the great\nchallenges of data recollection that is faced by the industry.\n","authors":["Shuwei Yue","Minchen Wei"],"pdf_url":"https://arxiv.org/pdf/2311.11773v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11772v1","updated":"2023-11-20T13:58:26Z","published":"2023-11-20T13:58:26Z","title":"A Good Feature Extractor Is All You Need for Weakly Supervised Learning\n  in Histopathology","summary":"  Deep learning is revolutionising pathology, offering novel opportunities in\ndisease prognosis and personalised treatment. Historically, stain normalisation\nhas been a crucial preprocessing step in computational pathology pipelines, and\npersists into the deep learning era. Yet, with the emergence of feature\nextractors trained using self-supervised learning (SSL) on diverse pathology\ndatasets, we call this practice into question. In an empirical evaluation of\npublicly available feature extractors, we find that omitting stain\nnormalisation and image augmentations does not compromise downstream\nperformance, while incurring substantial savings in memory and compute.\nFurther, we show that the top-performing feature extractors are remarkably\nrobust to variations in stain and augmentations like rotation in their latent\nspace. Contrary to previous patch-level benchmarking studies, our approach\nemphasises clinical relevance by focusing on slide-level prediction tasks in a\nweakly supervised setting with external validation cohorts. This work\nrepresents the most comprehensive robustness evaluation of public pathology SSL\nfeature extractors to date, involving more than 6,000 training runs across nine\ntasks, five datasets, three downstream architectures, and various preprocessing\nsetups. Our findings stand to streamline digital pathology workflows by\nminimising preprocessing needs and informing the selection of feature\nextractors.\n","authors":["Georg Wölflein","Dyke Ferber","Asier Rabasco Meneghetti","Omar S. M. El Nahhas","Daniel Truhn","Zunamys I. Carrero","David J. Harrison","Ognjen Arandjelović","Jakob N. Kather"],"pdf_url":"https://arxiv.org/pdf/2311.11772v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11757v1","updated":"2023-11-20T13:34:51Z","published":"2023-11-20T13:34:51Z","title":"Non-Contact NIR PPG Sensing through Large Sequence Signal Regression","summary":"  Non-Contact sensing is an emerging technology with applications across many\nindustries from driver monitoring in vehicles to patient monitoring in\nhealthcare. Current state-of-the-art implementations focus on RGB video, but\nthis struggles in varying/noisy light conditions and is almost completely\nunfeasible in the dark. Near Infra-Red (NIR) video, however, does not suffer\nfrom these constraints. This paper aims to demonstrate the effectiveness of an\nalternative Convolution Attention Network (CAN) architecture, to regress\nphotoplethysmography (PPG) signal from a sequence of NIR frames. A combination\nof two publicly available datasets, which is split into train and test sets, is\nused for training the CAN. This combined dataset is augmented to reduce\noverfitting to the 'normal' 60 - 80 bpm heart rate range by providing the full\nrange of heart rates along with corresponding videos for each subject. This\nCAN, when implemented over video cropped to the subject's head, achieved a Mean\nAverage Error (MAE) of just 0.99 bpm, proving its effectiveness on NIR video\nand the architecture's feasibility to regress an accurate signal output.\n","authors":["Timothy Hanley","Dara Golden","Robyn Maxwell","Ashkan Parsi","Joseph Lemley"],"pdf_url":"https://arxiv.org/pdf/2311.11757v1.pdf","comment":"4 pages, 3 figures, 3 tables, Irish Machine Vision and Image\n  Processing Conference 2023"},{"id":"http://arxiv.org/abs/2309.08402v3","updated":"2023-11-20T13:31:42Z","published":"2023-09-15T13:54:48Z","title":"3D SA-UNet: 3D Spatial Attention UNet with 3D ASPP for White Matter\n  Hyperintensities Segmentation","summary":"  White Matter Hyperintensity (WMH) is an imaging feature related to various\ndiseases such as dementia and stroke. Accurately segmenting WMH using computer\ntechnology is crucial for early disease diagnosis. However, this task remains\nchallenging due to the small lesions with low contrast and high discontinuity\nin the images, which contain limited contextual and spatial information. To\naddress this challenge, we propose a deep learning model called 3D Spatial\nAttention U-Net (3D SA-UNet) for automatic WMH segmentation using only Fluid\nAttenuation Inversion Recovery (FLAIR) scans. The 3D SA-UNet introduces a 3D\nSpatial Attention Module that highlights important lesion features, such as\nWMH, while suppressing unimportant regions. Additionally, to capture features\nat different scales, we extend the Atrous Spatial Pyramid Pooling (ASPP) module\nto a 3D version, enhancing the segmentation performance of the network. We\nevaluate our method on publicly available dataset and demonstrate the\neffectiveness of 3D spatial attention module and 3D ASPP in WMH segmentation.\nThrough experimental results, it has been demonstrated that our proposed 3D\nSA-UNet model achieves higher accuracy compared to other state-of-the-art 3D\nconvolutional neural networks.\n","authors":["Changlu Guo"],"pdf_url":"https://arxiv.org/pdf/2309.08402v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11754v1","updated":"2023-11-20T13:30:42Z","published":"2023-11-20T13:30:42Z","title":"A Large-Scale Car Parts (LSCP) Dataset for Lightweight Fine-Grained\n  Detection","summary":"  Automotive related datasets have previously been used for training autonomous\ndriving systems or vehicle classification tasks. However, there is a lack of\ndatasets in the field of automotive AI for car parts detection, and most\navailable datasets are limited in size and scope, struggling to cover diverse\nscenarios. To address this gap, this paper presents a large-scale and\nfine-grained automotive dataset consisting of 84,162 images for detecting 12\ndifferent types of car parts. This dataset was collected from natural cameras\nand online websites which covers various car brands, scenarios, and shooting\nangles. To alleviate the burden of manual annotation, we propose a novel\nsemi-supervised auto-labeling method that leverages state-of-the-art\npre-trained detectors. Moreover, we study the limitations of the Grounding DINO\napproach for zero-shot labeling. Finally, we evaluate the effectiveness of our\nproposed dataset through fine-grained car parts detection by training several\nlightweight YOLO-series detectors.\n","authors":["Wang Jie","Zhong Yilin","Cao Qianqian"],"pdf_url":"https://arxiv.org/pdf/2311.11754v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11753v1","updated":"2023-11-20T13:28:42Z","published":"2023-11-20T13:28:42Z","title":"AdvGen: Physical Adversarial Attack on Face Presentation Attack\n  Detection Systems","summary":"  Evaluating the risk level of adversarial images is essential for safely\ndeploying face authentication models in the real world. Popular approaches for\nphysical-world attacks, such as print or replay attacks, suffer from some\nlimitations, like including physical and geometrical artifacts. Recently,\nadversarial attacks have gained attraction, which try to digitally deceive the\nlearning strategy of a recognition system using slight modifications to the\ncaptured image. While most previous research assumes that the adversarial image\ncould be digitally fed into the authentication systems, this is not always the\ncase for systems deployed in the real world. This paper demonstrates the\nvulnerability of face authentication systems to adversarial images in physical\nworld scenarios. We propose AdvGen, an automated Generative Adversarial\nNetwork, to simulate print and replay attacks and generate adversarial images\nthat can fool state-of-the-art PADs in a physical domain attack setting. Using\nthis attack strategy, the attack success rate goes up to 82.01%. We test AdvGen\nextensively on four datasets and ten state-of-the-art PADs. We also demonstrate\nthe effectiveness of our attack by conducting experiments in a realistic,\nphysical environment.\n","authors":["Sai Amrit Patnaik","Shivali Chansoriya","Anil K. Jain","Anoop M. Namboodiri"],"pdf_url":"https://arxiv.org/pdf/2311.11753v1.pdf","comment":"10 pages, 9 figures, Accepted to the International Joint Conference\n  on Biometrics (IJCB 2023)"},{"id":"http://arxiv.org/abs/2311.11742v1","updated":"2023-11-20T13:09:11Z","published":"2023-11-20T13:09:11Z","title":"Fuzzy Information Seeded Region Growing for Automated Lesions After\n  Stroke Segmentation in MR Brain Images","summary":"  In the realm of medical imaging, precise segmentation of stroke lesions from\nbrain MRI images stands as a critical challenge with significant implications\nfor patient diagnosis and treatment. Addressing this, our study introduces an\ninnovative approach using a Fuzzy Information Seeded Region Growing (FISRG)\nalgorithm. Designed to effectively delineate the complex and irregular\nboundaries of stroke lesions, the FISRG algorithm combines fuzzy logic with\nSeeded Region Growing (SRG) techniques, aiming to enhance segmentation\naccuracy.\n  The research involved three experiments to optimize the FISRG algorithm's\nperformance, each focusing on different parameters to improve the accuracy of\nstroke lesion segmentation. The highest Dice score achieved in these\nexperiments was 94.2\\%, indicating a high degree of similarity between the\nalgorithm's output and the expert-validated ground truth. Notably, the best\naverage Dice score, amounting to 88.1\\%, was recorded in the third experiment,\nhighlighting the efficacy of the algorithm in consistently segmenting stroke\nlesions across various slices.\n  Our findings reveal the FISRG algorithm's strengths in handling the\nheterogeneity of stroke lesions. However, challenges remain in areas of abrupt\nlesion topology changes and in distinguishing lesions from similar intensity\nbrain regions. The results underscore the potential of the FISRG algorithm in\ncontributing significantly to advancements in medical imaging analysis for\nstroke diagnosis and treatment.\n","authors":["Mario Pascual González"],"pdf_url":"https://arxiv.org/pdf/2311.11742v1.pdf","comment":"10 pages, 14 figures. Associated code and data available at:\n  https://github.com/Mawio02/FISRG-for-Automated-Lesion-After-Stroke-Segmentation-in-MRI"},{"id":"http://arxiv.org/abs/2311.01310v2","updated":"2023-11-20T13:08:27Z","published":"2023-11-02T15:24:23Z","title":"Scattering Vision Transformer: Spectral Mixing Matters","summary":"  Vision transformers have gained significant attention and achieved\nstate-of-the-art performance in various computer vision tasks, including image\nclassification, instance segmentation, and object detection. However,\nchallenges remain in addressing attention complexity and effectively capturing\nfine-grained information within images. Existing solutions often resort to\ndown-sampling operations, such as pooling, to reduce computational cost.\nUnfortunately, such operations are non-invertible and can result in information\nloss. In this paper, we present a novel approach called Scattering Vision\nTransformer (SVT) to tackle these challenges. SVT incorporates a spectrally\nscattering network that enables the capture of intricate image details. SVT\novercomes the invertibility issue associated with down-sampling operations by\nseparating low-frequency and high-frequency components. Furthermore, SVT\nintroduces a unique spectral gating network utilizing Einstein multiplication\nfor token and channel mixing, effectively reducing complexity. We show that SVT\nachieves state-of-the-art performance on the ImageNet dataset with a\nsignificant reduction in a number of parameters and FLOPS. SVT shows 2\\%\nimprovement over LiTv2 and iFormer. SVT-H-S reaches 84.2\\% top-1 accuracy,\nwhile SVT-H-B reaches 85.2\\% (state-of-art for base versions) and SVT-H-L\nreaches 85.7\\% (again state-of-art for large versions). SVT also shows\ncomparable results in other vision tasks such as instance segmentation. SVT\nalso outperforms other transformers in transfer learning on standard datasets\nsuch as CIFAR10, CIFAR100, Oxford Flower, and Stanford Car datasets. The\nproject page is available on this\nwebpage.\\url{https://badripatro.github.io/svt/}.\n","authors":["Badri N. Patro","Vijay Srinivas Agneeswaran"],"pdf_url":"https://arxiv.org/pdf/2311.01310v2.pdf","comment":"Accepted @NeurIPS 2023"},{"id":"http://arxiv.org/abs/2306.02850v2","updated":"2023-11-20T13:04:59Z","published":"2023-06-05T13:00:44Z","title":"TRACE: 5D Temporal Regression of Avatars with Dynamic Cameras in 3D\n  Environments","summary":"  Although the estimation of 3D human pose and shape (HPS) is rapidly\nprogressing, current methods still cannot reliably estimate moving humans in\nglobal coordinates, which is critical for many applications. This is\nparticularly challenging when the camera is also moving, entangling human and\ncamera motion. To address these issues, we adopt a novel 5D representation\n(space, time, and identity) that enables end-to-end reasoning about people in\nscenes. Our method, called TRACE, introduces several novel architectural\ncomponents. Most importantly, it uses two new \"maps\" to reason about the 3D\ntrajectory of people over time in camera, and world, coordinates. An additional\nmemory unit enables persistent tracking of people even during long occlusions.\nTRACE is the first one-stage method to jointly recover and track 3D humans in\nglobal coordinates from dynamic cameras. By training it end-to-end, and using\nfull image information, TRACE achieves state-of-the-art performance on tracking\nand HPS benchmarks. The code and dataset are released for research purposes.\n","authors":["Yu Sun","Qian Bao","Wu Liu","Tao Mei","Michael J. Black"],"pdf_url":"https://arxiv.org/pdf/2306.02850v2.pdf","comment":"Project page: https://www.yusun.work/TRACE/TRACE.html"},{"id":"http://arxiv.org/abs/2311.11722v1","updated":"2023-11-20T12:37:58Z","published":"2023-11-20T12:37:58Z","title":"Sparse4D v3: Advancing End-to-End 3D Detection and Tracking","summary":"  In autonomous driving perception systems, 3D detection and tracking are the\ntwo fundamental tasks. This paper delves deeper into this field, building upon\nthe Sparse4D framework. We introduce two auxiliary training tasks (Temporal\nInstance Denoising and Quality Estimation) and propose decoupled attention to\nmake structural improvements, leading to significant enhancements in detection\nperformance. Additionally, we extend the detector into a tracker using a\nstraightforward approach that assigns instance ID during inference, further\nhighlighting the advantages of query-based algorithms. Extensive experiments\nconducted on the nuScenes benchmark validate the effectiveness of the proposed\nimprovements. With ResNet50 as the backbone, we witnessed enhancements of\n3.0\\%, 2.2\\%, and 7.6\\% in mAP, NDS, and AMOTA, achieving 46.9\\%, 56.1\\%, and\n49.0\\%, respectively. Our best model achieved 71.9\\% NDS and 67.7\\% AMOTA on\nthe nuScenes test set. Code will be released at\n\\url{https://github.com/linxuewu/Sparse4D}.\n","authors":["Xuewu Lin","Zixiang Pei","Tianwei Lin","Lichao Huang","Zhizhong Su"],"pdf_url":"https://arxiv.org/pdf/2311.11722v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.18936v2","updated":"2023-11-20T12:35:55Z","published":"2023-10-29T08:50:27Z","title":"Adversarial Examples Are Not Real Features","summary":"  The existence of adversarial examples has been a mystery for years and\nattracted much interest. A well-known theory by \\citet{ilyas2019adversarial}\nexplains adversarial vulnerability from a data perspective by showing that one\ncan extract non-robust features from adversarial examples and these features\nalone are useful for classification. However, the explanation remains quite\ncounter-intuitive since non-robust features are mostly noise features to\nhumans. In this paper, we re-examine the theory from a larger context by\nincorporating multiple learning paradigms. Notably, we find that contrary to\ntheir good usefulness under supervised learning, non-robust features attain\npoor usefulness when transferred to other self-supervised learning paradigms,\nsuch as contrastive learning, masked image modeling, and diffusion models. It\nreveals that non-robust features are not really as useful as robust or natural\nfeatures that enjoy good transferability between these paradigms. Meanwhile,\nfor robustness, we also show that naturally trained encoders from robust\nfeatures are largely non-robust under AutoAttack. Our cross-paradigm\nexamination suggests that the non-robust features are not really useful but\nmore like paradigm-wise shortcuts, and robust features alone might be\ninsufficient to attain reliable model robustness. Code is available at\n\\url{https://github.com/PKU-ML/AdvNotRealFeatures}.\n","authors":["Ang Li","Yifei Wang","Yiwen Guo","Yisen Wang"],"pdf_url":"https://arxiv.org/pdf/2310.18936v2.pdf","comment":"NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.11714v1","updated":"2023-11-20T12:32:32Z","published":"2023-11-20T12:32:32Z","title":"On the Importance of Large Objects in CNN Based Object Detection\n  Algorithms","summary":"  Object detection models, a prominent class of machine learning algorithms,\naim to identify and precisely locate objects in images or videos. However, this\ntask might yield uneven performances sometimes caused by the objects sizes and\nthe quality of the images and labels used for training. In this paper, we\nhighlight the importance of large objects in learning features that are\ncritical for all sizes. Given these findings, we propose to introduce a\nweighting term into the training loss. This term is a function of the object\narea size. We show that giving more weight to large objects leads to improved\ndetection scores across all object sizes and so an overall improvement in\nObject Detectors performances (+2 p.p. of mAP on small objects, +2 p.p. on\nmedium and +4 p.p. on large on COCO val 2017 with InternImage-T). Additional\nexperiments and ablation studies with different models and on a different\ndataset further confirm the robustness of our findings.\n","authors":["Ahmed Ben Saad","Gabriele Facciolo","Axel Davy"],"pdf_url":"https://arxiv.org/pdf/2311.11714v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.19130v2","updated":"2023-11-20T12:15:19Z","published":"2023-10-29T19:39:03Z","title":"Women Wearing Lipstick: Measuring the Bias Between an Object and Its\n  Related Gender","summary":"  In this paper, we investigate the impact of objects on gender bias in image\ncaptioning systems. Our results show that only gender-specific objects have a\nstrong gender bias (e.g., women-lipstick). In addition, we propose a visual\nsemantic-based gender score that measures the degree of bias and can be used as\na plug-in for any image captioning system. Our experiments demonstrate the\nutility of the gender score, since we observe that our score can measure the\nbias relation between a caption and its related gender; therefore, our score\ncan be used as an additional metric to the existing Object Gender Co-Occ\napproach. Code and data are publicly available at\n\\url{https://github.com/ahmedssabir/GenderScore}.\n","authors":["Ahmed Sabir","Lluís Padró"],"pdf_url":"https://arxiv.org/pdf/2310.19130v2.pdf","comment":"EMNLP Findings 2023"},{"id":"http://arxiv.org/abs/2311.11700v1","updated":"2023-11-20T12:08:23Z","published":"2023-11-20T12:08:23Z","title":"GS-SLAM: Dense Visual SLAM with 3D Gaussian Splatting","summary":"  In this paper, we introduce $\\textbf{GS-SLAM}$ that first utilizes 3D\nGaussian representation in the Simultaneous Localization and Mapping (SLAM)\nsystem. It facilitates a better balance between efficiency and accuracy.\nCompared to recent SLAM methods employing neural implicit representations, our\nmethod utilizes a real-time differentiable splatting rendering pipeline that\noffers significant speedup to map optimization and RGB-D re-rendering.\nSpecifically, we propose an adaptive expansion strategy that adds new or\ndeletes noisy 3D Gaussian in order to efficiently reconstruct new observed\nscene geometry and improve the mapping of previously observed areas. This\nstrategy is essential to extend 3D Gaussian representation to reconstruct the\nwhole scene rather than synthesize a static object in existing methods.\nMoreover, in the pose tracking process, an effective coarse-to-fine technique\nis designed to select reliable 3D Gaussian representations to optimize camera\npose, resulting in runtime reduction and robust estimation. Our method achieves\ncompetitive performance compared with existing state-of-the-art real-time\nmethods on the Replica, TUM-RGBD datasets. The source code will be released\nupon acceptance.\n","authors":["Chi Yan","Delin Qu","Dong Wang","Dan Xu","Zhigang Wang","Bin Zhao","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2311.11700v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11697v1","updated":"2023-11-20T12:00:06Z","published":"2023-11-20T12:00:06Z","title":"Cut-and-Paste: Subject-Driven Video Editing with Attention Control","summary":"  This paper presents a novel framework termed Cut-and-Paste for real-word\nsemantic video editing under the guidance of text prompt and additional\nreference image. While the text-driven video editing has demonstrated\nremarkable ability to generate highly diverse videos following given text\nprompts, the fine-grained semantic edits are hard to control by plain textual\nprompt only in terms of object details and edited region, and cumbersome long\ntext descriptions are usually needed for the task. We therefore investigate\nsubject-driven video editing for more precise control of both edited regions\nand background preservation, and fine-grained semantic generation. We achieve\nthis goal by introducing an reference image as supplementary input to the\ntext-driven video editing, which avoids racking your brain to come up with a\ncumbersome text prompt describing the detailed appearance of the object. To\nlimit the editing area, we refer to a method of cross attention control in\nimage editing and successfully extend it to video editing by fusing the\nattention map of adjacent frames, which strikes a balance between maintaining\nvideo background and spatio-temporal consistency. Compared with current\nmethods, the whole process of our method is like ``cut\" the source object to be\nedited and then ``paste\" the target object provided by reference image. We\ndemonstrate that our method performs favorably over prior arts for video\nediting under the guidance of text prompt and extra reference image, as\nmeasured by both quantitative and subjective evaluations.\n","authors":["Zhichao Zuo","Zhao Zhang","Yan Luo","Yang Zhao","Haijun Zhang","Yi Yang","Meng Wang"],"pdf_url":"https://arxiv.org/pdf/2311.11697v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11695v1","updated":"2023-11-20T11:51:13Z","published":"2023-11-20T11:51:13Z","title":"Clarity ChatGPT: An Interactive and Adaptive Processing System for Image\n  Restoration and Enhancement","summary":"  The generalization capability of existing image restoration and enhancement\n(IRE) methods is constrained by the limited pre-trained datasets, making it\ndifficult to handle agnostic inputs such as different degradation levels and\nscenarios beyond their design scopes. Moreover, they are not equipped with\ninteractive mechanisms to consider user preferences or feedback, and their\nend-to-end settings cannot provide users with more choices. Faced with the\nabove-mentioned IRE method's limited performance and insufficient\ninteractivity, we try to solve it from the engineering and system framework\nlevels. Specifically, we propose Clarity ChatGPT-a transformative system that\ncombines the conversational intelligence of ChatGPT with multiple IRE methods.\nClarity ChatGPT can automatically detect image degradation types and select\nappropriate IRE methods to restore images, or iteratively generate satisfactory\nresults based on user feedback. Its innovative features include a CLIP-powered\ndetector for accurate degradation classification, no-reference image quality\nevaluation for performance evaluation, region-specific processing for precise\nenhancements, and advanced fusion techniques for optimal restoration results.\nClarity ChatGPT marks a significant advancement in integrating language and\nvision, enhancing image-text interactions, and providing a robust,\nhigh-performance IRE solution. Our case studies demonstrate that Clarity\nChatGPT effectively improves the generalization and interaction capabilities in\nthe IRE, and also fills the gap in the low-level domain of the existing\nvision-language model.\n","authors":["Yanyan Wei","Zhao Zhang","Jiahuan Ren","Xiaogang Xu","Richang Hong","Yi Yang","Shuicheng Yan","Meng Wang"],"pdf_url":"https://arxiv.org/pdf/2311.11695v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11686v1","updated":"2023-11-20T11:35:52Z","published":"2023-11-20T11:35:52Z","title":"Segment Together: A Versatile Paradigm for Semi-Supervised Medical Image\n  Segmentation","summary":"  Annotation scarcity has become a major obstacle for training powerful\ndeep-learning models for medical image segmentation, restricting their\ndeployment in clinical scenarios. To address it, semi-supervised learning by\nexploiting abundant unlabeled data is highly desirable to boost the model\ntraining. However, most existing works still focus on limited medical tasks and\nunderestimate the potential of learning across diverse tasks and multiple\ndatasets. Therefore, in this paper, we introduce a \\textbf{Ver}satile\n\\textbf{Semi}-supervised framework (VerSemi) to point out a new perspective\nthat integrates various tasks into a unified model with a broad label space, to\nexploit more unlabeled data for semi-supervised medical image segmentation.\nSpecifically, we introduce a dynamic task-prompted design to segment various\ntargets from different datasets. Next, this unified model is used to identify\nthe foreground regions from all labeled data, to capture cross-dataset\nsemantics. Particularly, we create a synthetic task with a cutmix strategy to\naugment foreground targets within the expanded label space. To effectively\nutilize unlabeled data, we introduce a consistency constraint. This involves\naligning aggregated predictions from various tasks with those from the\nsynthetic task, further guiding the model in accurately segmenting foreground\nregions during training. We evaluated our VerSemi model on four public\nbenchmarking datasets. Extensive experiments demonstrated that VerSemi can\nconsistently outperform the second-best method by a large margin (e.g., an\naverage 2.69\\% Dice gain on four datasets), setting new SOTA performance for\nsemi-supervised medical image segmentation. The code will be released.\n","authors":["Qingjie Zeng","Yutong Xie","Zilin Lu","Mengkang Lu","Yicheng Wu","Yong Xia"],"pdf_url":"https://arxiv.org/pdf/2311.11686v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11683v1","updated":"2023-11-20T11:28:18Z","published":"2023-11-20T11:28:18Z","title":"ViP-Mixer: A Convolutional Mixer for Video Prediction","summary":"  Video prediction aims to predict future frames from a video's previous\ncontent. Existing methods mainly process video data where the time dimension\nmingles with the space and channel dimensions from three distinct angles: as a\nsequence of individual frames, as a 3D volume in spatiotemporal coordinates, or\nas a stacked image where frames are treated as separate channels. Most of them\ngenerally focus on one of these perspectives and may fail to fully exploit the\nrelationships across different dimensions. To address this issue, this paper\nintroduces a convolutional mixer for video prediction, termed ViP-Mixer, to\nmodel the spatiotemporal evolution in the latent space of an autoencoder. The\nViP-Mixers are stacked sequentially and interleave feature mixing at three\nlevels: frames, channels, and locations. Extensive experiments demonstrate that\nour proposed method achieves new state-of-the-art prediction performance on\nthree benchmark video datasets covering both synthetic and real-world\nscenarios.\n","authors":["Xin Zheng","Ziang Peng","Yuan Cao","Hongming Shan","Junping Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.11683v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2311.11669v1","updated":"2023-11-20T11:09:09Z","published":"2023-11-20T11:09:09Z","title":"PMP-Swin: Multi-Scale Patch Message Passing Swin Transformer for Retinal\n  Disease Classification","summary":"  Retinal disease is one of the primary causes of visual impairment, and early\ndiagnosis is essential for preventing further deterioration. Nowadays, many\nworks have explored Transformers for diagnosing diseases due to their strong\nvisual representation capabilities. However, retinal diseases exhibit milder\nforms and often present with overlapping signs, which pose great difficulties\nfor accurate multi-class classification. Therefore, we propose a new framework\nnamed Multi-Scale Patch Message Passing Swin Transformer for multi-class\nretinal disease classification. Specifically, we design a Patch Message Passing\n(PMP) module based on the Message Passing mechanism to establish global\ninteraction for pathological semantic features and to exploit the subtle\ndifferences further between different diseases. Moreover, considering the\nvarious scale of pathological features we integrate multiple PMP modules for\ndifferent patch sizes. For evaluation, we have constructed a new dataset, named\nOPTOS dataset, consisting of 1,033 high-resolution fundus images photographed\nby Optos camera and conducted comprehensive experiments to validate the\nefficacy of our proposed method. And the results on both the public dataset and\nour dataset demonstrate that our method achieves remarkable performance\ncompared to state-of-the-art methods.\n","authors":["Zhihan Yang","Zhiming Cheng","Tengjin Weng","Shucheng He","Yaqi Wang","Xin Ye","Shuai Wang"],"pdf_url":"https://arxiv.org/pdf/2311.11669v1.pdf","comment":"9 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.11666v1","updated":"2023-11-20T11:04:59Z","published":"2023-11-20T11:04:59Z","title":"OmniSeg3D: Omniversal 3D Segmentation via Hierarchical Contrastive\n  Learning","summary":"  Towards holistic understanding of 3D scenes, a general 3D segmentation method\nis needed that can segment diverse objects without restrictions on object\nquantity or categories, while also reflecting the inherent hierarchical\nstructure. To achieve this, we propose OmniSeg3D, an omniversal segmentation\nmethod aims for segmenting anything in 3D all at once. The key insight is to\nlift multi-view inconsistent 2D segmentations into a consistent 3D feature\nfield through a hierarchical contrastive learning framework, which is\naccomplished by two steps. Firstly, we design a novel hierarchical\nrepresentation based on category-agnostic 2D segmentations to model the\nmulti-level relationship among pixels. Secondly, image features rendered from\nthe 3D feature field are clustered at different levels, which can be further\ndrawn closer or pushed apart according to the hierarchical relationship between\ndifferent levels. In tackling the challenges posed by inconsistent 2D\nsegmentations, this framework yields a global consistent 3D feature field,\nwhich further enables hierarchical segmentation, multi-object selection, and\nglobal discretization. Extensive experiments demonstrate the effectiveness of\nour method on high-quality 3D segmentation and accurate hierarchical structure\nunderstanding. A graphical user interface further facilitates flexible\ninteraction for omniversal 3D segmentation.\n","authors":["Haiyang Ying","Yixuan Yin","Jinzhi Zhang","Fan Wang","Tao Yu","Ruqi Huang","Lu Fang"],"pdf_url":"https://arxiv.org/pdf/2311.11666v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.10373v3","updated":"2023-11-20T10:54:09Z","published":"2023-07-19T18:00:03Z","title":"TokenFlow: Consistent Diffusion Features for Consistent Video Editing","summary":"  The generative AI revolution has recently expanded to videos. Nevertheless,\ncurrent state-of-the-art video models are still lagging behind image models in\nterms of visual quality and user control over the generated content. In this\nwork, we present a framework that harnesses the power of a text-to-image\ndiffusion model for the task of text-driven video editing. Specifically, given\na source video and a target text-prompt, our method generates a high-quality\nvideo that adheres to the target text, while preserving the spatial layout and\nmotion of the input video. Our method is based on a key observation that\nconsistency in the edited video can be obtained by enforcing consistency in the\ndiffusion feature space. We achieve this by explicitly propagating diffusion\nfeatures based on inter-frame correspondences, readily available in the model.\nThus, our framework does not require any training or fine-tuning, and can work\nin conjunction with any off-the-shelf text-to-image editing method. We\ndemonstrate state-of-the-art editing results on a variety of real-world videos.\nWebpage: https://diffusion-tokenflow.github.io/\n","authors":["Michal Geyer","Omer Bar-Tal","Shai Bagon","Tali Dekel"],"pdf_url":"https://arxiv.org/pdf/2307.10373v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11662v1","updated":"2023-11-20T10:53:59Z","published":"2023-11-20T10:53:59Z","title":"Enhanced Spatio-Temporal Context for Temporally Consistent Robust 3D\n  Human Motion Recovery from Monocular Videos","summary":"  Recovering temporally consistent 3D human body pose, shape and motion from a\nmonocular video is a challenging task due to (self-)occlusions, poor lighting\nconditions, complex articulated body poses, depth ambiguity, and limited\navailability of annotated data. Further, doing a simple perframe estimation is\ninsufficient as it leads to jittery and implausible results. In this paper, we\npropose a novel method for temporally consistent motion estimation from a\nmonocular video. Instead of using generic ResNet-like features, our method uses\na body-aware feature representation and an independent per-frame pose and\ncamera initialization over a temporal window followed by a novel\nspatio-temporal feature aggregation by using a combination of self-similarity\nand self-attention over the body-aware features and the perframe\ninitialization. Together, they yield enhanced spatiotemporal context for every\nframe by considering remaining past and future frames. These features are used\nto predict the pose and shape parameters of the human body model, which are\nfurther refined using an LSTM. Experimental results on the publicly available\nbenchmark data show that our method attains significantly lower acceleration\nerror and outperforms the existing state-of-the-art methods over all key\nquantitative evaluation metrics, including complex scenarios like partial\nocclusion, complex poses and even relatively low illumination.\n","authors":["Sushovan Chanda","Amogh Tiwari","Lokender Tiwari","Brojeshwar Bhowmick","Avinash Sharma","Hrishav Barua"],"pdf_url":"https://arxiv.org/pdf/2311.11662v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11659v1","updated":"2023-11-20T10:49:32Z","published":"2023-11-20T10:49:32Z","title":"MGCT: Mutual-Guided Cross-Modality Transformer for Survival Outcome\n  Prediction using Integrative Histopathology-Genomic Features","summary":"  The rapidly emerging field of deep learning-based computational pathology has\nshown promising results in utilizing whole slide images (WSIs) to objectively\nprognosticate cancer patients. However, most prognostic methods are currently\nlimited to either histopathology or genomics alone, which inevitably reduces\ntheir potential to accurately predict patient prognosis. Whereas integrating\nWSIs and genomic features presents three main challenges: (1) the enormous\nheterogeneity of gigapixel WSIs which can reach sizes as large as\n150,000x150,000 pixels; (2) the absence of a spatially corresponding\nrelationship between histopathology images and genomic molecular data; and (3)\nthe existing early, late, and intermediate multimodal feature fusion strategies\nstruggle to capture the explicit interactions between WSIs and genomics. To\nameliorate these issues, we propose the Mutual-Guided Cross-Modality\nTransformer (MGCT), a weakly-supervised, attention-based multimodal learning\nframework that can combine histology features and genomic features to model the\ngenotype-phenotype interactions within the tumor microenvironment. To validate\nthe effectiveness of MGCT, we conduct experiments using nearly 3,600 gigapixel\nWSIs across five different cancer types sourced from The Cancer Genome Atlas\n(TCGA). Extensive experimental results consistently emphasize that MGCT\noutperforms the state-of-the-art (SOTA) methods.\n","authors":["Mingxin Liu","Yunzan Liu","Hui Cui","Chunquan Li","Jiquan Ma"],"pdf_url":"https://arxiv.org/pdf/2311.11659v1.pdf","comment":"7 pages, 4 figures, accepted by 2023 IEEE International Conference on\n  Bioinformatics and Biomedicine (BIBM 2023)"},{"id":"http://arxiv.org/abs/2311.11656v1","updated":"2023-11-20T10:45:39Z","published":"2023-11-20T10:45:39Z","title":"Double-Condensing Attention Condenser: Leveraging Attention in Deep\n  Learning to Detect Skin Cancer from Skin Lesion Images","summary":"  Skin cancer is the most common type of cancer in the United States and is\nestimated to affect one in five Americans. Recent advances have demonstrated\nstrong performance on skin cancer detection, as exemplified by state of the art\nperformance in the SIIM-ISIC Melanoma Classification Challenge; however these\nsolutions leverage ensembles of complex deep neural architectures requiring\nimmense storage and compute costs, and therefore may not be tractable. A recent\nmovement for TinyML applications is integrating Double-Condensing Attention\nCondensers (DC-AC) into a self-attention neural network backbone architecture\nto allow for faster and more efficient computation. This paper explores\nleveraging an efficient self-attention structure to detect skin cancer in skin\nlesion images and introduces a deep neural network design with DC-AC customized\nfor skin cancer detection from skin lesion images. The final model is publicly\navailable as a part of a global open-source initiative dedicated to\naccelerating advancement in machine learning to aid clinicians in the fight\nagainst cancer.\n","authors":["Chi-en Amy Tai","Elizabeth Janes","Chris Czarnecki","Alexander Wong"],"pdf_url":"https://arxiv.org/pdf/2311.11656v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11647v1","updated":"2023-11-20T10:28:52Z","published":"2023-11-20T10:28:52Z","title":"Cancer-Net PCa-Data: An Open-Source Benchmark Dataset for Prostate\n  Cancer Clinical Decision Support using Synthetic Correlated Diffusion Imaging\n  Data","summary":"  The recent introduction of synthetic correlated diffusion (CDI$^s$) imaging\nhas demonstrated significant potential in the realm of clinical decision\nsupport for prostate cancer (PCa). CDI$^s$ is a new form of magnetic resonance\nimaging (MRI) designed to characterize tissue characteristics through the joint\ncorrelation of diffusion signal attenuation across different Brownian motion\nsensitivities. Despite the performance improvement, the CDI$^s$ data for PCa\nhas not been previously made publicly available. In our commitment to advance\nresearch efforts for PCa, we introduce Cancer-Net PCa-Data, an open-source\nbenchmark dataset of volumetric CDI$^s$ imaging data of PCa patients.\nCancer-Net PCa-Data consists of CDI$^s$ volumetric images from a patient cohort\nof 200 patient cases, along with full annotations (gland masks, tumor masks,\nand PCa diagnosis for each tumor). We also analyze the demographic and label\nregion diversity of Cancer-Net PCa-Data for potential biases. Cancer-Net\nPCa-Data is the first-ever public dataset of CDI$^s$ imaging data for PCa, and\nis a part of the global open-source initiative dedicated to advancement in\nmachine learning and imaging research to aid clinicians in the global fight\nagainst cancer.\n","authors":["Hayden Gunraj","Chi-en Amy Tai","Alexander Wong"],"pdf_url":"https://arxiv.org/pdf/2311.11647v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11646v1","updated":"2023-11-20T10:26:04Z","published":"2023-11-20T10:26:04Z","title":"CastDet: Toward Open Vocabulary Aerial Object Detection with\n  CLIP-Activated Student-Teacher Learning","summary":"  Object detection in aerial images is a pivotal task for various earth\nobservation applications, whereas current algorithms learn to detect only a\npre-defined set of object categories demanding sufficient bounding-box\nannotated training samples and fail to detect novel object categories. In this\npaper, we consider open-vocabulary object detection (OVD) in aerial images that\nenables the characterization of new objects beyond training categories on the\nearth surface without annotating training images for these new categories. The\nperformance of OVD depends on the quality of class-agnostic region proposals\nand pseudo-labels that can generalize well to novel object categories. To\nsimultaneously generate high-quality proposals and pseudo-labels, we propose\nCastDet, a CLIP-activated student-teacher open-vocabulary object Detection\nframework. Our end-to-end framework within the student-teacher mechanism\nemploys the CLIP model as an extra omniscient teacher of rich knowledge into\nthe student-teacher self-learning process. By doing so, our approach boosts\nnovel object proposals and classification. Furthermore, we design a dynamic\nlabel queue technique to maintain high-quality pseudo labels during batch\ntraining and mitigate label imbalance. We conduct extensive experiments on\nmultiple existing aerial object detection datasets, which are set up for the\nOVD task. Experimental results demonstrate our CastDet achieving superior\nopen-vocabulary detection performance, e.g., reaching 40.0 HM (Harmonic Mean),\nwhich outperforms previous methods Detic/ViLD by 26.9/21.1 on the VisDroneZSD\ndataset.\n","authors":["Yan Li","Weiwei Guo","Dunyun He","Jiaqi Zhou","Yuze Gao","Wenxian Yu"],"pdf_url":"https://arxiv.org/pdf/2311.11646v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.12634v2","updated":"2023-11-20T10:06:03Z","published":"2023-08-24T08:19:15Z","title":"Towards Hierarchical Regional Transformer-based Multiple Instance\n  Learning","summary":"  The classification of gigapixel histopathology images with deep multiple\ninstance learning models has become a critical task in digital pathology and\nprecision medicine. In this work, we propose a Transformer-based multiple\ninstance learning approach that replaces the traditional learned attention\nmechanism with a regional, Vision Transformer inspired self-attention\nmechanism. We present a method that fuses regional patch information to derive\nslide-level predictions and show how this regional aggregation can be stacked\nto hierarchically process features on different distance levels. To increase\npredictive accuracy, especially for datasets with small, local morphological\nfeatures, we introduce a method to focus the image processing on high attention\nregions during inference. Our approach is able to significantly improve\nperformance over the baseline on two histopathology datasets and points towards\npromising directions for further research.\n","authors":["Josef Cersovsky","Sadegh Mohammadi","Dagmar Kainmueller","Johannes Hoehne"],"pdf_url":"https://arxiv.org/pdf/2308.12634v2.pdf","comment":"8 pages, LaTeX; header update after published, fixed typos"},{"id":"http://arxiv.org/abs/2311.11642v1","updated":"2023-11-20T10:01:13Z","published":"2023-11-20T10:01:13Z","title":"Video Face Re-Aging: Toward Temporally Consistent Face Re-Aging","summary":"  Video face re-aging deals with altering the apparent age of a person to the\ntarget age in videos. This problem is challenging due to the lack of paired\nvideo datasets maintaining temporal consistency in identity and age. Most\nre-aging methods process each image individually without considering the\ntemporal consistency of videos. While some existing works address the issue of\ntemporal coherence through video facial attribute manipulation in latent space,\nthey often fail to deliver satisfactory performance in age transformation. To\ntackle the issues, we propose (1) a novel synthetic video dataset that features\nsubjects across a diverse range of age groups; (2) a baseline architecture\ndesigned to validate the effectiveness of our proposed dataset, and (3) the\ndevelopment of three novel metrics tailored explicitly for evaluating the\ntemporal consistency of video re-aging techniques. Our comprehensive\nexperiments on public datasets, such as VFHQ and CelebV-HQ, show that our\nmethod outperforms the existing approaches in terms of both age transformation\nand temporal consistency.\n","authors":["Abdul Muqeet","Kyuchul Lee","Bumsoo Kim","Yohan Hong","Hyungrae Lee","Woonggon Kim","Kwang Hee Lee"],"pdf_url":"https://arxiv.org/pdf/2311.11642v1.pdf","comment":"8 pages, 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2311.11638v1","updated":"2023-11-20T09:55:06Z","published":"2023-11-20T09:55:06Z","title":"Reti-Diff: Illumination Degradation Image Restoration with Retinex-based\n  Latent Diffusion Model","summary":"  Illumination degradation image restoration (IDIR) techniques aim to improve\nthe visibility of degraded images and mitigate the adverse effects of\ndeteriorated illumination. Among these algorithms, diffusion model (DM)-based\nmethods have shown promising performance but are often burdened by heavy\ncomputational demands and pixel misalignment issues when predicting the\nimage-level distribution. To tackle these problems, we propose to leverage DM\nwithin a compact latent space to generate concise guidance priors and introduce\na novel solution called Reti-Diff for the IDIR task. Reti-Diff comprises two\nkey components: the Retinex-based latent DM (RLDM) and the Retinex-guided\ntransformer (RGformer). To ensure detailed reconstruction and illumination\ncorrection, RLDM is empowered to acquire Retinex knowledge and extract\nreflectance and illumination priors. These priors are subsequently utilized by\nRGformer to guide the decomposition of image features into their respective\nreflectance and illumination components. Following this, RGformer further\nenhances and consolidates the decomposed features, resulting in the production\nof refined images with consistent content and robustness to handle complex\ndegradation scenarios. Extensive experiments show that Reti-Diff outperforms\nexisting methods on three IDIR tasks, as well as downstream applications. Code\nwill be available at \\url{https://github.com/ChunmingHe/Reti-Diff}.\n","authors":["Chunming He","Chengyu Fang","Yulun Zhang","Kai Li","Longxiang Tang","Chenyu You","Fengyang Xiao","Zhenhua Guo","Xiu Li"],"pdf_url":"https://arxiv.org/pdf/2311.11638v1.pdf","comment":"12 pages, 6 figures, 9 tables"},{"id":"http://arxiv.org/abs/2311.10543v2","updated":"2023-11-20T09:50:24Z","published":"2023-11-17T14:10:55Z","title":"Joint covariance property under geometric image transformations for\n  spatio-temporal receptive fields according to the generalized Gaussian\n  derivative model for visual receptive fields","summary":"  The influence of natural image transformations on receptive field responses\nis crucial for modelling visual operations in computer vision and biological\nvision. In this regard, covariance properties with respect to geometric image\ntransformations in the earliest layers of the visual hierarchy are essential\nfor expressing robust image operations and for formulating invariant visual\noperations at higher levels. This paper defines and proves a joint covariance\nproperty under compositions of spatial scaling transformations, spatial affine\ntransformations, Galilean transformations and temporal scaling transformations,\nwhich makes it possible to characterize how different types of image\ntransformations interact with each other. Specifically, the derived relations\nshow how the receptive field parameters need to be transformed, in order to\nmatch the output from spatio-temporal receptive fields with the underlying\nspatio-temporal image transformations.\n","authors":["Tony Lindeberg"],"pdf_url":"https://arxiv.org/pdf/2311.10543v2.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2309.07510v4","updated":"2023-11-20T09:47:00Z","published":"2023-09-14T08:24:32Z","title":"Learning Environment-Aware Affordance for 3D Articulated Object\n  Manipulation under Occlusions","summary":"  Perceiving and manipulating 3D articulated objects in diverse environments is\nessential for home-assistant robots. Recent studies have shown that point-level\naffordance provides actionable priors for downstream manipulation tasks.\nHowever, existing works primarily focus on single-object scenarios with\nhomogeneous agents, overlooking the realistic constraints imposed by the\nenvironment and the agent's morphology, e.g., occlusions and physical\nlimitations. In this paper, we propose an environment-aware affordance\nframework that incorporates both object-level actionable priors and environment\nconstraints. Unlike object-centric affordance approaches, learning\nenvironment-aware affordance faces the challenge of combinatorial explosion due\nto the complexity of various occlusions, characterized by their quantities,\ngeometries, positions and poses. To address this and enhance data efficiency,\nwe introduce a novel contrastive affordance learning framework capable of\ntraining on scenes containing a single occluder and generalizing to scenes with\ncomplex occluder combinations. Experiments demonstrate the effectiveness of our\nproposed approach in learning affordance considering environment constraints.\nProject page at https://chengkaiacademycity.github.io/EnvAwareAfford/\n","authors":["Kai Cheng","Ruihai Wu","Yan Shen","Chuanruo Ning","Guanqi Zhan","Hao Dong"],"pdf_url":"https://arxiv.org/pdf/2309.07510v4.pdf","comment":"In 37th Conference on Neural Information Processing Systems (NeurIPS\n  2023). Website at https://chengkaiacademycity.github.io/EnvAwareAfford/"},{"id":"http://arxiv.org/abs/2311.11629v1","updated":"2023-11-20T09:28:04Z","published":"2023-11-20T09:28:04Z","title":"Generating Realistic Counterfactuals for Retinal Fundus and OCT Images\n  using Diffusion Models","summary":"  Counterfactual reasoning is often used in a clinical setting to explain\ndecisions or weigh alternatives. Therefore, for imaging based modalities such\nas ophthalmology, it would be beneficial to be able to create counterfactual\nimages, illustrating the answer to the question: \"If the subject had had\ndiabetic retinopathy, how would the fundus image have looked?\" Here, we\ndemonstrate that using a diffusion model in combination with an adversarially\nrobust classifier trained on retinal disease classification tasks enables\ngeneration of highly realistic counterfactuals of retinal fundus images and\noptical coherence tomorgraphy (OCT) B-scans. Ideally, these classifiers encode\nthe salient features indicative for each disease class and can steer the\ndiffusion model to show realistic disease signs or remove disease-related\nlesions in a realistic way. Importantly, in a user study, domain experts found\nthe counterfactuals generated using our method significantly more realistic\nthan counterfactuals generated from a previous method, and even\nindistiguishable from realistic images.\n","authors":["Indu Ilanchezian","Valentyn Boreiko","Laura Kühlewein","Ziwei Huang","Murat Seçkin Ayhan","Matthias Hein","Lisa Koch","Philipp Berens"],"pdf_url":"https://arxiv.org/pdf/2311.11629v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02421v2","updated":"2023-11-20T09:08:42Z","published":"2023-07-05T16:43:56Z","title":"DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models","summary":"  Despite the ability of existing large-scale text-to-image (T2I) models to\ngenerate high-quality images from detailed textual descriptions, they often\nlack the ability to precisely edit the generated or real images. In this paper,\nwe propose a novel image editing method, DragonDiffusion, enabling Drag-style\nmanipulation on Diffusion models. Specifically, we construct classifier\nguidance based on the strong correspondence of intermediate features in the\ndiffusion model. It can transform the editing signals into gradients via\nfeature correspondence loss to modify the intermediate representation of the\ndiffusion model. Based on this guidance strategy, we also build a multi-scale\nguidance to consider both semantic and geometric alignment. Moreover, a\ncross-branch self-attention is added to maintain the consistency between the\noriginal image and the editing result. Our method, through an efficient design,\nachieves various editing modes for the generated or real images, such as object\nmoving, object resizing, object appearance replacement, and content dragging.\nIt is worth noting that all editing and content preservation signals come from\nthe image itself, and the model does not require fine-tuning or additional\nmodules. Our source code will be available at\nhttps://github.com/MC-E/DragonDiffusion.\n","authors":["Chong Mou","Xintao Wang","Jiechong Song","Ying Shan","Jian Zhang"],"pdf_url":"https://arxiv.org/pdf/2307.02421v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.11887v2","updated":"2023-11-20T08:57:58Z","published":"2023-08-23T03:20:31Z","title":"A Unified Framework for 3D Point Cloud Visual Grounding","summary":"  Thanks to its precise spatial referencing, 3D point cloud visual grounding is\nessential for deep understanding and dynamic interaction in 3D environments,\nencompassing 3D Referring Expression Comprehension (3DREC) and Segmentation\n(3DRES). We argue that 3DREC and 3DRES should be unified in one framework,\nwhich is also a natural progression in the community. To explain, 3DREC help\n3DRES locate the referent, while 3DRES also facilitate 3DREC via more\nfine-grained language-visual alignment. To achieve this, this paper takes the\ninitiative step to integrate 3DREC and 3DRES into a unified framework, termed\n3D Referring Transformer (3DRefTR). Its key idea is to build upon a mature\n3DREC model and leverage ready query embeddings and visual tokens from the\n3DREC model to construct a dedicated mask branch. Specially, we propose\nSuperpoint Mask Branch, which serves a dual purpose: i) By harnessing on the\ninherent association between the superpoints and point cloud, it eliminates the\nheavy computational overhead on the high-resolution visual features for\nupsampling; ii) By leveraging the heterogeneous CPU-GPU parallelism, while the\nGPU is occupied generating visual and language tokens, the CPU concurrently\nproduces superpoints, equivalently accomplishing the upsampling computation.\nThis elaborate design enables 3DRefTR to achieve both well-performing 3DRES and\n3DREC capacities with only a 6% additional latency compared to the original\n3DREC model. Empirical evaluations affirm the superiority of 3DRefTR.\nSpecifically, on the ScanRefer dataset, 3DRefTR surpasses the state-of-the-art\n3DRES method by 12.43% in mIoU and improves upon the SOTA 3DREC method by 0.6%\nAcc@0.25IoU. The codes and models will be released soon.\n","authors":["Haojia Lin","Yongdong Luo","Xiawu Zheng","Lijiang Li","Fei Chao","Taisong Jin","Donghao Luo","Yan Wang","Liujuan Cao","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2308.11887v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11614v1","updated":"2023-11-20T08:56:51Z","published":"2023-11-20T08:56:51Z","title":"Semantic-Preserved Point-based Human Avatar","summary":"  To enable realistic experience in AR/VR and digital entertainment, we present\nthe first point-based human avatar model that embodies the entirety expressive\nrange of digital humans. We employ two MLPs to model pose-dependent deformation\nand linear skinning (LBS) weights. The representation of appearance relies on a\ndecoder and the features that attached to each point. In contrast to\nalternative implicit approaches, the oriented points representation not only\nprovides a more intuitive way to model human avatar animation but also\nsignificantly reduces both training and inference time. Moreover, we propose a\nnovel method to transfer semantic information from the SMPL-X model to the\npoints, which enables to better understand human body movements. By leveraging\nthe semantic information of points, we can facilitate virtual try-on and human\navatar composition through exchanging the points of same category across\ndifferent subjects. Experimental results demonstrate the efficacy of our\npresented method.\n","authors":["Lixiang Lin","Jianke Zhu"],"pdf_url":"https://arxiv.org/pdf/2311.11614v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2104.00851v3","updated":"2023-11-20T08:50:33Z","published":"2021-04-02T02:10:32Z","title":"Estimating the Generalization in Deep Neural Networks via Sparsity","summary":"  Generalization is the key capability for deep neural networks (DNNs).\nHowever, it is challenging to give a reliable measure of the generalization\nability of a DNN via only its nature. In this paper, we propose a novel method\nfor estimating the generalization gap based on network sparsity. In our method,\ntwo key quantities are proposed first. They have close relationship with the\ngeneralization ability and can be calculated directly from the training results\nalone. Then a simple linear model involving two key quantities are constructed\nto give accurate estimation of the generalization gap. By training DNNs with a\nwide range of generalization gap on popular datasets, we show that our key\nquantities and linear model could be efficient tools for estimating the\ngeneralization gap of DNNs.\n","authors":["Yang Zhao","Hao Zhang"],"pdf_url":"https://arxiv.org/pdf/2104.00851v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2011.00789v2","updated":"2023-11-20T08:48:07Z","published":"2020-11-02T07:37:31Z","title":"Role Taxonomy of Units in Deep Neural Networks","summary":"  Identifying the role of network units in deep neural networks (DNNs) is\ncritical in many aspects including giving understandings on the mechanisms of\nDNNs and building basic connections between deep learning and neuroscience.\nHowever, there remains unclear on which roles the units in DNNs with different\ngeneralization ability could present. To this end, we give role taxonomy of\nunits in DNNs via introducing the retrieval-of-function test, where units are\ncategorized into four types in terms of their functional preference on\nseparately the training set and testing set. We show that ratios of the four\ncategories are highly associated with the generalization ability of DNNs from\ntwo distinct perspectives, based on which we give signs of DNNs with well\ngeneralization.\n","authors":["Yang Zhao","Hao Zhang","Xiuyuan Hu"],"pdf_url":"https://arxiv.org/pdf/2011.00789v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12685v2","updated":"2023-11-20T08:46:28Z","published":"2023-06-22T06:12:23Z","title":"Rethinking the Backward Propagation for Adversarial Transferability","summary":"  Transfer-based attacks generate adversarial examples on the surrogate model,\nwhich can mislead other black-box models without access, making it promising to\nattack real-world applications. Recently, several works have been proposed to\nboost adversarial transferability, in which the surrogate model is usually\noverlooked. In this work, we identify that non-linear layers (e.g., ReLU,\nmax-pooling, etc.) truncate the gradient during backward propagation, making\nthe gradient w.r.t. input image imprecise to the loss function. We hypothesize\nand empirically validate that such truncation undermines the transferability of\nadversarial examples. Based on these findings, we propose a novel method called\nBackward Propagation Attack (BPA) to increase the relevance between the\ngradient w.r.t. input image and loss function so as to generate adversarial\nexamples with higher transferability. Specifically, BPA adopts a non-monotonic\nfunction as the derivative of ReLU and incorporates softmax with temperature to\nsmooth the derivative of max-pooling, thereby mitigating the information loss\nduring the backward propagation of gradients. Empirical results on the ImageNet\ndataset demonstrate that not only does our method substantially boost the\nadversarial transferability, but it is also general to existing transfer-based\nattacks. Code is available at https://github.com/Trustworthy-AI-Group/RPA.\n","authors":["Xiaosen Wang","Kangheng Tong","Kun He"],"pdf_url":"https://arxiv.org/pdf/2306.12685v2.pdf","comment":"Accepted by NeurIPS 2023"},{"id":"http://arxiv.org/abs/2302.06494v3","updated":"2023-11-20T08:44:23Z","published":"2023-02-13T16:19:54Z","title":"Explicit3D: Graph Network with Spatial Inference for Single Image 3D\n  Object Detection","summary":"  Indoor 3D object detection is an essential task in single image scene\nunderstanding, impacting spatial cognition fundamentally in visual reasoning.\nExisting works on 3D object detection from a single image either pursue this\ngoal through independent predictions of each object or implicitly reason over\nall possible objects, failing to harness relational geometric information\nbetween objects. To address this problem, we propose a dynamic sparse graph\npipeline named Explicit3D based on object geometry and semantics features.\nTaking the efficiency into consideration, we further define a relatedness score\nand design a novel dynamic pruning algorithm followed by a cluster sampling\nmethod for sparse scene graph generation and updating. Furthermore, our\nExplicit3D introduces homogeneous matrices and defines new relative loss and\ncorner loss to model the spatial difference between target pairs explicitly.\nInstead of using ground-truth labels as direct supervision, our relative and\ncorner loss are derived from the homogeneous transformation, which renders the\nmodel to learn the geometric consistency between objects. The experimental\nresults on the SUN RGB-D dataset demonstrate that our Explicit3D achieves\nbetter performance balance than the-state-of-the-art.\n","authors":["Yanjun Liu","Wenming Yang"],"pdf_url":"https://arxiv.org/pdf/2302.06494v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11604v1","updated":"2023-11-20T08:40:01Z","published":"2023-11-20T08:40:01Z","title":"CurriculumLoc: Enhancing Cross-Domain Geolocalization through\n  Multi-Stage Refinement","summary":"  Visual geolocalization is a cost-effective and scalable task that involves\nmatching one or more query images, taken at some unknown location, to a set of\ngeo-tagged reference images. Existing methods, devoted to semantic features\nrepresentation, evolving towards robustness to a wide variety between query and\nreference, including illumination and viewpoint changes, as well as scale and\nseasonal variations. However, practical visual geolocalization approaches need\nto be robust in appearance changing and extreme viewpoint variation conditions,\nwhile providing accurate global location estimates. Therefore, inspired by\ncurriculum design, human learn general knowledge first and then delve into\nprofessional expertise. We first recognize semantic scene and then measure\ngeometric structure. Our approach, termed CurriculumLoc, involves a delicate\ndesign of multi-stage refinement pipeline and a novel keypoint detection and\ndescription with global semantic awareness and local geometric verification. We\nrerank candidates and solve a particular cross-domain perspective-n-point (PnP)\nproblem based on these keypoints and corresponding descriptors, position\nrefinement occurs incrementally. The extensive experimental results on our\ncollected dataset, TerraTrack and a benchmark dataset, ALTO, demonstrate that\nour approach results in the aforementioned desirable characteristics of a\npractical visual geolocalization solution. Additionally, we achieve new high\nrecall@1 scores of 62.6% and 94.5% on ALTO, with two different distances\nmetrics, respectively. Dataset, code and trained models are publicly available\non https://github.com/npupilab/CurriculumLoc.\n","authors":["Boni Hu","Lin Chen","Runjian Chen","Shuhui Bu","Pengcheng Han","Haowei Li"],"pdf_url":"https://arxiv.org/pdf/2311.11604v1.pdf","comment":"14 pages, 15 figures"},{"id":"http://arxiv.org/abs/2311.11602v1","updated":"2023-11-20T08:29:55Z","published":"2023-11-20T08:29:55Z","title":"A Multi-In-Single-Out Network for Video Frame Interpolation without\n  Optical Flow","summary":"  In general, deep learning-based video frame interpolation (VFI) methods have\npredominantly focused on estimating motion vectors between two input frames and\nwarping them to the target time. While this approach has shown impressive\nperformance for linear motion between two input frames, it exhibits limitations\nwhen dealing with occlusions and nonlinear movements. Recently, generative\nmodels have been applied to VFI to address these issues. However, as VFI is not\na task focused on generating plausible images, but rather on predicting\naccurate intermediate frames between two given frames, performance limitations\nstill persist. In this paper, we propose a multi-in-single-out (MISO) based VFI\nmethod that does not rely on motion vector estimation, allowing it to\neffectively model occlusions and nonlinear motion. Additionally, we introduce a\nnovel motion perceptual loss that enables MISO-VFI to better capture the\nspatio-temporal correlations within the video frames. Our MISO-VFI method\nachieves state-of-the-art results on VFI benchmarks Vimeo90K, Middlebury, and\nUCF101, with a significant performance gap compared to existing approaches.\n","authors":["Jaemin Lee","Minseok Seo","Sangwoo Lee","Hyobin Park","Dong-Geol Choi"],"pdf_url":"https://arxiv.org/pdf/2311.11602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11600v1","updated":"2023-11-20T08:27:56Z","published":"2023-11-20T08:27:56Z","title":"Deep Equilibrium Diffusion Restoration with Parallel Sampling","summary":"  Diffusion-based image restoration (IR) methods aim to use diffusion models to\nrecover high-quality (HQ) images from degraded images and achieve promising\nperformance. Due to the inherent property of diffusion models, most of these\nmethods need long serial sampling chains to restore HQ images step-by-step. As\na result, it leads to expensive sampling time and high computation costs.\nMoreover, such long sampling chains hinder understanding the relationship\nbetween the restoration results and the inputs since it is hard to compute the\ngradients in the whole chains. In this work, we aim to rethink the\ndiffusion-based IR models through a different perspective, i.e., a deep\nequilibrium (DEQ) fixed point system. Specifically, we derive an analytical\nsolution by modeling the entire sampling chain in diffusion-based IR models as\na joint multivariate fixed point system. With the help of the analytical\nsolution, we are able to conduct single-image sampling in a parallel way and\nrestore HQ images without training. Furthermore, we compute fast gradients in\nDEQ and found that initialization optimization can boost performance and\ncontrol the generation direction. Extensive experiments on benchmarks\ndemonstrate the effectiveness of our proposed method on typical IR tasks and\nreal-world settings. The code and models will be made publicly available.\n","authors":["Jiezhang Cao","Yue Shi","Kai Zhang","Yulun Zhang","Radu Timofte","Luc Van Gool"],"pdf_url":"https://arxiv.org/pdf/2311.11600v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02358v3","updated":"2023-11-20T08:15:57Z","published":"2023-11-04T09:57:50Z","title":"Domain Transfer in Latent Space (DTLS) Wins on Image Super-Resolution --\n  a Non-Denoising Model","summary":"  Large scale image super-resolution is a challenging computer vision task,\nsince vast information is missing in a highly degraded image, say for example\nforscale x16 super-resolution. Diffusion models are used successfully in recent\nyears in extreme super-resolution applications, in which Gaussian noise is used\nas a means to form a latent photo-realistic space, and acts as a link between\nthe space of latent vectors and the latent photo-realistic space. There are\nquite a few sophisticated mathematical derivations on mapping the statistics of\nGaussian noises making Diffusion Models successful. In this paper we propose a\nsimple approach which gets away from using Gaussian noise but adopts some basic\nstructures of diffusion models for efficient image super-resolution.\nEssentially, we propose a DNN to perform domain transfer between neighbor\ndomains, which can learn the differences in statistical properties to\nfacilitate gradual interpolation with results of reasonable quality. Further\nquality improvement is achieved by conditioning the domain transfer with\nreference to the input LR image. Experimental results show that our method\noutperforms not only state-of-the-art large scale super resolution models, but\nalso the current diffusion models for image super-resolution. The approach can\nreadily be extended to other image-to-image tasks, such as image enlightening,\ninpainting, denoising, etc.\n","authors":["Chun-Chuen Hui","Wan-Chi Siu","Ngai-Fong Law"],"pdf_url":"https://arxiv.org/pdf/2311.02358v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11592v1","updated":"2023-11-20T08:09:54Z","published":"2023-11-20T08:09:54Z","title":"Predicting urban tree cover from incomplete point labels and limited\n  background information","summary":"  Trees inside cities are important for the urban microclimate, contributing\npositively to the physical and mental health of the urban dwellers. Despite\ntheir importance, often only limited information about city trees is available.\nTherefore in this paper, we propose a method for mapping urban trees in\nhigh-resolution aerial imagery using limited datasets and deep learning. Deep\nlearning has become best-practice for this task, however, existing approaches\nrely on large and accurately labelled training datasets, which can be difficult\nand expensive to obtain. However, often noisy and incomplete data may be\navailable that can be combined and utilized to solve more difficult tasks than\nthose datasets were intended for. This paper studies how to combine accurate\npoint labels of urban trees along streets with crowd-sourced annotations from\nan open geographic database to delineate city trees in remote sensing images, a\ntask which is challenging even for humans. To that end, we perform semantic\nsegmentation of very high resolution aerial imagery using a fully convolutional\nneural network. The main challenge is that our segmentation maps are sparsely\nannotated and incomplete. Small areas around the point labels of the street\ntrees coming from official and crowd-sourced data are marked as foreground\nclass. Crowd-sourced annotations of streets, buildings, etc. define the\nbackground class. Since the tree data is incomplete, we introduce a masking to\navoid class confusion. Our experiments in Hamburg, Germany, showed that the\nsystem is able to produce tree cover maps, not limited to trees along streets,\nwithout providing tree delineations. We evaluated the method on manually\nlabelled trees and show that performance drastically deteriorates if the open\ngeographic database is not used.\n","authors":["Hui Zhang","Ankit Kariryaa","Venkanna Babu Guthula","Christian Igel","Stefan Oehmcke"],"pdf_url":"https://arxiv.org/pdf/2311.11592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.06335v2","updated":"2023-11-20T08:03:40Z","published":"2023-02-13T13:12:55Z","title":"Online Arbitrary Shaped Clustering through Correlated Gaussian Functions","summary":"  There is no convincing evidence that backpropagation is a biologically\nplausible mechanism, and further studies of alternative learning methods are\nneeded. A novel online clustering algorithm is presented that can produce\narbitrary shaped clusters from inputs in an unsupervised manner, and requires\nno prior knowledge of the number of clusters in the input data. This is\nachieved by finding correlated outputs from functions that capture commonly\noccurring input patterns. The algorithm can be deemed more biologically\nplausible than model optimization through backpropagation, although practical\napplicability may require additional research. However, the method yields\nsatisfactory results on several toy datasets on a noteworthy range of\nhyperparameters.\n","authors":["Ole Christian Eidheim"],"pdf_url":"https://arxiv.org/pdf/2302.06335v2.pdf","comment":"Corrected uniform distribution range; removed \"average\" from last\n  sentence in section 4"},{"id":"http://arxiv.org/abs/2311.11590v1","updated":"2023-11-20T08:03:12Z","published":"2023-11-20T08:03:12Z","title":"Advancing Urban Renewal: An Automated Approach to Generating Historical\n  Arcade Facades with Stable Diffusion Models","summary":"  Urban renewal and transformation processes necessitate the preservation of\nthe historical urban fabric, particularly in districts known for their\narchitectural and historical significance. These regions, with their diverse\narchitectural styles, have traditionally required extensive preliminary\nresearch, often leading to subjective results. However, the advent of machine\nlearning models has opened up new avenues for generating building facade\nimages. Despite this, creating high-quality images for historical district\nrenovations remains challenging, due to the complexity and diversity inherent\nin such districts. In response to these challenges, our study introduces a new\nmethodology for automatically generating images of historical arcade facades,\nutilizing Stable Diffusion models conditioned on textual descriptions. By\nclassifying and tagging a variety of arcade styles, we have constructed several\nrealistic arcade facade image datasets. We trained multiple low-rank adaptation\n(LoRA) models to control the stylistic aspects of the generated images,\nsupplemented by ControlNet models for improved precision and authenticity. Our\napproach has demonstrated high levels of precision, authenticity, and diversity\nin the generated images, showing promising potential for real-world urban\nrenewal projects. This new methodology offers a more efficient and accurate\nalternative to conventional design processes in urban renewal, bypassing issues\nof unconvincing image details, lack of precision, and limited stylistic\nvariety. Future research could focus on integrating this two-dimensional image\ngeneration with three-dimensional modeling techniques, providing a more\ncomprehensive solution for renovating architectural facades in historical\ndistricts.\n","authors":["Zheyuan Kuang","Jiaxin Zhang","Yiying Huang","Yunqin Li"],"pdf_url":"https://arxiv.org/pdf/2311.11590v1.pdf","comment":"HABITS OF THE ANTHROPOCENE - Proceedings of the 43rd ACADIA\n  Conference - Volume II: Proceedings book one, University of Colorado Denver,\n  Denver, Colorado, USA, 26-28 October 2023, pp. 616-625, CUMINCAD, 2023"},{"id":"http://arxiv.org/abs/2308.12313v2","updated":"2023-11-20T08:01:17Z","published":"2023-08-23T07:11:58Z","title":"Gaze Estimation on Spresense","summary":"  Gaze estimation is a valuable technology with numerous applications in fields\nsuch as human-computer interaction, virtual reality, and medicine. This report\npresents the implementation of a gaze estimation system using the Sony\nSpresense microcontroller board and explores its performance in latency,\nMAC/cycle, and power consumption. The report also provides insights into the\nsystem's architecture, including the gaze estimation model used. Additionally,\na demonstration of the system is presented, showcasing its functionality and\nperformance. Our lightweight model TinyTrackerS is a mere 169Kb in size, using\n85.8k parameters and runs on the Spresense platform at 3 FPS.\n","authors":["Thomas Ruegg","Pietro Bonazzi","Andrea Ronco"],"pdf_url":"https://arxiv.org/pdf/2308.12313v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.07813v5","updated":"2023-11-20T08:00:38Z","published":"2023-07-15T14:34:25Z","title":"TinyTracker: Ultra-Fast and Ultra-Low-Power Edge Vision In-Sensor for\n  Gaze Estimation","summary":"  Intelligent edge vision tasks encounter the critical challenge of ensuring\npower and latency efficiency due to the typically heavy computational load they\nimpose on edge platforms.This work leverages one of the first \"AI in sensor\"\nvision platforms, IMX500 by Sony, to achieve ultra-fast and ultra-low-power\nend-to-end edge vision applications. We evaluate the IMX500 and compare it to\nother edge platforms, such as the Google Coral Dev Micro and Sony Spresense, by\nexploring gaze estimation as a case study. We propose TinyTracker, a highly\nefficient, fully quantized model for 2D gaze estimation designed to maximize\nthe performance of the edge vision systems considered in this study.\nTinyTracker achieves a 41x size reduction (600Kb) compared to iTracker [1]\nwithout significant loss in gaze estimation accuracy (maximum of 0.16 cm when\nfully quantized). TinyTracker's deployment on the Sony IMX500 vision sensor\nresults in end-to-end latency of around 19ms. The camera takes around 17.9ms to\nread, process and transmit the pixels to the accelerator. The inference time of\nthe network is 0.86ms with an additional 0.24 ms for retrieving the results\nfrom the sensor. The overall energy consumption of the end-to-end system is 4.9\nmJ, including 0.06 mJ for inference. The end-to-end study shows that IMX500 is\n1.7x faster than CoralMicro (19ms vs 34.4ms) and 7x more power efficient (4.9mJ\nVS 34.2mJ)\n","authors":["Pietro Bonazzi","Thomas Ruegg","Sizhen Bian","Yawei Li","Michele Magno"],"pdf_url":"https://arxiv.org/pdf/2307.07813v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11587v1","updated":"2023-11-20T07:54:54Z","published":"2023-11-20T07:54:54Z","title":"AKConv: Convolutional Kernel with Arbitrary Sampled Shapes and Arbitrary\n  Number of Parameters","summary":"  Neural networks based on convolutional operations have achieved remarkable\nresults in the field of deep learning, but there are two inherent flaws in\nstandard convolutional operations. On the one hand, the convolution operation\nbe confined to a local window and cannot capture information from other\nlocations, and its sampled shapes is fixed. On the other hand, the size of the\nconvolutional kernel is fixed to k $\\times$ k, which is a fixed square shape,\nand the number of parameters tends to grow squarely with size. It is obvious\nthat the shape and size of targets are various in different datasets and at\ndifferent locations. Convolutional kernels with fixed sample shapes and squares\ndo not adapt well to changing targets. In response to the above questions, the\nAlterable Kernel Convolution (AKConv) is explored in this work, which gives the\nconvolution kernel an arbitrary number of parameters and arbitrary sampled\nshapes to provide richer options for the trade-off between network overhead and\nperformance. In AKConv, we define initial positions for convolutional kernels\nof arbitrary size by means of a new coordinate generation algorithm. To adapt\nto changes for targets, we introduce offsets to adjust the shape of the samples\nat each position. Moreover, we explore the effect of the neural network by\nusing the AKConv with the same size and different initial sampled shapes.\nAKConv completes the process of efficient feature extraction by irregular\nconvolutional operations and brings more exploration options for convolutional\nsampling shapes. Object detection experiments on representative datasets\nCOCO2017, VOC 7+12 and VisDrone-DET2021 fully demonstrate the advantages of\nAKConv. AKConv can be used as a plug-and-play convolutional operation to\nreplace convolutional operations to improve network performance. The code for\nthe relevant tasks can be found at https://github.com/CV-ZhangXin/AKConv.\n","authors":["Xin Zhang","Yingze Song","Tingting Song","Degang Yang","Yichen Ye","Jie Zhou","Liming Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.11587v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.11580v1","updated":"2023-11-20T07:34:01Z","published":"2023-11-20T07:34:01Z","title":"SeaDSC: A video-based unsupervised method for dynamic scene change\n  detection in unmanned surface vehicles","summary":"  Recently, there has been an upsurge in the research on maritime vision, where\na lot of works are influenced by the application of computer vision for\nUnmanned Surface Vehicles (USVs). Various sensor modalities such as camera,\nradar, and lidar have been used to perform tasks such as object detection,\nsegmentation, object tracking, and motion planning. A large subset of this\nresearch is focused on the video analysis, since most of the current vessel\nfleets contain the camera's onboard for various surveillance tasks. Due to the\nvast abundance of the video data, video scene change detection is an initial\nand crucial stage for scene understanding of USVs. This paper outlines our\napproach to detect dynamic scene changes in USVs. To the best of our\nunderstanding, this work represents the first investigation of scene change\ndetection in the maritime vision application. Our objective is to identify\nsignificant changes in the dynamic scenes of maritime video data, particularly\nthose scenes that exhibit a high degree of resemblance. In our system for\ndynamic scene change detection, we propose completely unsupervised learning\nmethod. In contrast to earlier studies, we utilize a modified cutting-edge\ngenerative picture model called VQ-VAE-2 to train on multiple marine datasets,\naiming to enhance the feature extraction. Next, we introduce our innovative\nsimilarity scoring technique for directly calculating the level of similarity\nin a sequence of consecutive frames by utilizing grid calculation on retrieved\nfeatures. The experiments were conducted using a nautical video dataset called\nRoboWhaler to showcase the efficient performance of our technique.\n","authors":["Linh Trinh","Ali Anwar","Siegfried Mercelis"],"pdf_url":"https://arxiv.org/pdf/2311.11580v1.pdf","comment":"WACV 2024 conference"},{"id":"http://arxiv.org/abs/2311.11578v1","updated":"2023-11-20T07:29:33Z","published":"2023-11-20T07:29:33Z","title":"A 3D Multi-Style Cross-Modality Segmentation Framework for Segmenting\n  Vestibular Schwannoma and Cochlea","summary":"  The crossMoDA2023 challenge aims to segment the vestibular schwannoma\n(sub-divided into intra- and extra-meatal components) and cochlea regions of\nunlabeled hrT2 scans by leveraging labeled ceT1 scans. In this work, we\nproposed a 3D multi-style cross-modality segmentation framework for the\ncrossMoDA2023 challenge, including the multi-style translation and\nself-training segmentation phases. Considering heterogeneous distributions and\nvarious image sizes in multi-institutional scans, we first utilize the min-max\nnormalization, voxel size resampling, and center cropping to obtain fixed-size\nsub-volumes from ceT1 and hrT2 scans for training. Then, we perform the\nmulti-style image translation phase to overcome the intensity distribution\ndiscrepancy between unpaired multi-modal scans. Specifically, we design three\ndifferent translation networks with 2D or 2.5D inputs to generate multi-style\nand realistic target-like volumes from labeled ceT1 volumes. Finally, we\nperform the self-training volumetric segmentation phase in the target domain,\nwhich employs the nnU-Net framework and iterative self-training method using\npseudo-labels for training accurate segmentation models in the unlabeled target\ndomain. On the crossMoDA2023 validation dataset, our method produces promising\nresults and achieves the mean DSC values of 72.78% and 80.64% and ASSD values\nof 5.85 mm and 0.25 mm for VS tumor and cochlea regions, respectively.\nMoreover, for intra- and extra-meatal regions, our method achieves the DSC\nvalues of 59.77% and 77.14%, respectively.\n","authors":["Yuzhou Zhuang"],"pdf_url":"https://arxiv.org/pdf/2311.11578v1.pdf","comment":"Technical report of cmda2023 challenge"},{"id":"http://arxiv.org/abs/2311.11570v1","updated":"2023-11-20T07:10:39Z","published":"2023-11-20T07:10:39Z","title":"Decoupled DETR For Few-shot Object Detection","summary":"  Few-shot object detection (FSOD), an efficient method for addressing the\nsevere data-hungry problem, has been extensively discussed. Current works have\nsignificantly advanced the problem in terms of model and data. However, the\noverall performance of most FSOD methods still does not fulfill the desired\naccuracy. In this paper we improve the FSOD model to address the severe issue\nof sample imbalance and weak feature propagation. To alleviate modeling bias\nfrom data-sufficient base classes, we examine the effect of decoupling the\nparameters for classes with sufficient data and classes with few samples in\nvarious ways. We design a base-novel categories decoupled DETR (DeDETR) for\nFSOD. We also explore various types of skip connection between the encoder and\ndecoder for DETR. Besides, we notice that the best outputs could come from the\nintermediate layer of the decoder instead of the last layer; therefore, we\nbuild a unified decoder module that could dynamically fuse the decoder layers\nas the output feature. We evaluate our model on commonly used datasets such as\nPASCAL VOC and MSCOCO. Our results indicate that our proposed module could\nachieve stable improvements of 5% to 10% in both fine-tuning and meta-learning\nparadigms and has outperformed the highest score in recent works.\n","authors":["Zeyu Shangguan","Lian Huai","Tong Liu","Xingqun Jiang"],"pdf_url":"https://arxiv.org/pdf/2311.11570v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11567v1","updated":"2023-11-20T07:06:31Z","published":"2023-11-20T07:06:31Z","title":"CORE-MM: Complex Open-Ended Reasoning Evaluation For Multi-Modal Large\n  Language Models","summary":"  Multi-modal Large Language Models (MLLMs) are increasingly prominent in the\nfield of artificial intelligence. These models not only excel in traditional\nvision-language tasks but also demonstrate impressive performance in\ncontemporary multi-modal benchmarks. Although many of these benchmarks attempt\nto holistically evaluate MLLMs, they typically concentrate on basic reasoning\ntasks, often yielding only simple yes/no or multi-choice responses. These\nmethods naturally lead to confusion and difficulties in conclusively\ndetermining the reasoning capabilities of MLLMs. To mitigate this issue, we\nmanually curate a benchmark dataset specifically designed for MLLMs, with a\nfocus on complex reasoning tasks. Our benchmark comprises three key reasoning\ncategories: deductive, abductive, and analogical reasoning. The queries in our\ndataset are intentionally constructed to engage the reasoning capabilities of\nMLLMs in the process of generating answers. For a fair comparison across\nvarious MLLMs, we incorporate intermediate reasoning steps into our evaluation\ncriteria. In instances where an MLLM is unable to produce a definitive answer,\nits reasoning ability is evaluated by requesting intermediate reasoning steps.\nIf these steps align with our manual annotations, appropriate scores are\nassigned. This evaluation scheme resembles methods commonly used in human\nassessments, such as exams or assignments, and represents what we consider a\nmore effective assessment technique compared with existing benchmarks. We\nevaluate a selection of representative MLLMs using this rigorously developed\nopen-ended multi-step elaborate reasoning benchmark, designed to challenge and\naccurately measure their reasoning capabilities. The code and data will be\nreleased at https://core-mm.github.io/\n","authors":["Xiaotian Han","Quanzeng You","Yongfei Liu","Wentao Chen","Huangjie Zheng","Khalil Mrini","Xudong Lin","Yiqi Wang","Bohan Zhai","Jianbo Yuan","Heng Wang","Hongxia Yang"],"pdf_url":"https://arxiv.org/pdf/2311.11567v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11566v1","updated":"2023-11-20T07:04:46Z","published":"2023-11-20T07:04:46Z","title":"Does complimentary information from multispectral imaging improve face\n  presentation attack detection?","summary":"  Presentation Attack Detection (PAD) has been extensively studied,\nparticularly in the visible spectrum. With the advancement of sensing\ntechnology beyond the visible range, multispectral imaging has gained\nsignificant attention in this direction. We present PAD based on multispectral\nimages constructed for eight different presentation artifacts resulted from\nthree different artifact species. In this work, we introduce Face Presentation\nAttack Multispectral (FPAMS) database to demonstrate the significance of\nemploying multispectral imaging. The goal of this work is to study\ncomplementary information that can be combined in two different ways (image\nfusion and score fusion) from multispectral imaging to improve the face PAD.\nThe experimental evaluation results present an extensive qualitative analysis\nof 61650 sample multispectral images collected for bonafide and artifacts. The\nPAD based on the score fusion and image fusion method presents superior\nperformance, demonstrating the significance of employing multispectral imaging\nto detect presentation artifacts.\n","authors":["Narayan Vetrekar","Raghavendra Ramachandra","Sushma Venkatesh","Jyoti D. Pawar","R. S. Gad"],"pdf_url":"https://arxiv.org/pdf/2311.11566v1.pdf","comment":"Accepted in International IEEE Applied Sensing Conference (IEEE\n  APSCON) 2024"},{"id":"http://arxiv.org/abs/2306.05238v2","updated":"2023-11-20T06:57:05Z","published":"2023-06-08T14:36:10Z","title":"SparseTrack: Multi-Object Tracking by Performing Scene Decomposition\n  based on Pseudo-Depth","summary":"  Exploring robust and efficient association methods has always been an\nimportant issue in multiple-object tracking (MOT). Although existing tracking\nmethods have achieved impressive performance, congestion and frequent\nocclusions still pose challenging problems in multi-object tracking. We reveal\nthat performing sparse decomposition on dense scenes is a crucial step to\nenhance the performance of associating occluded targets. To this end, we\npropose a pseudo-depth estimation method for obtaining the relative depth of\ntargets from 2D images. Secondly, we design a depth cascading matching (DCM)\nalgorithm, which can use the obtained depth information to convert a dense\ntarget set into multiple sparse target subsets and perform data association on\nthese sparse target subsets in order from near to far. By integrating the\npseudo-depth method and the DCM strategy into the data association process, we\npropose a new tracker, called SparseTrack. SparseTrack provides a new\nperspective for solving the challenging crowded scene MOT problem. Only using\nIoU matching, SparseTrack achieves comparable performance with the\nstate-of-the-art (SOTA) methods on the MOT17 and MOT20 benchmarks. Code and\nmodels are publicly available at \\url{https://github.com/hustvl/SparseTrack}.\n","authors":["Zelin Liu","Xinggang Wang","Cheng Wang","Wenyu Liu","Xiang Bai"],"pdf_url":"https://arxiv.org/pdf/2306.05238v2.pdf","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2305.02722v4","updated":"2023-11-20T06:34:16Z","published":"2023-05-04T10:43:11Z","title":"Avatar Knowledge Distillation: Self-ensemble Teacher Paradigm with\n  Uncertainty","summary":"  Knowledge distillation is an effective paradigm for boosting the performance\nof pocket-size model, especially when multiple teacher models are available,\nthe student would break the upper limit again. However, it is not economical to\ntrain diverse teacher models for the disposable distillation. In this paper, we\nintroduce a new concept dubbed Avatars for distillation, which are the\ninference ensemble models derived from the teacher. Concretely, (1) For each\niteration of distillation training, various Avatars are generated by a\nperturbation transformation. We validate that Avatars own higher upper limit of\nworking capacity and teaching ability, aiding the student model in learning\ndiverse and receptive knowledge perspectives from the teacher model. (2) During\nthe distillation, we propose an uncertainty-aware factor from the variance of\nstatistical differences between the vanilla teacher and Avatars, to adjust\nAvatars' contribution on knowledge transfer adaptively. Avatar Knowledge\nDistillation AKD is fundamentally different from existing methods and refines\nwith the innovative view of unequal training. Comprehensive experiments\ndemonstrate the effectiveness of our Avatars mechanism, which polishes up the\nstate-of-the-art distillation methods for dense prediction without more extra\ncomputational cost. The AKD brings at most 0.7 AP gains on COCO 2017 for Object\nDetection and 1.83 mIoU gains on Cityscapes for Semantic Segmentation,\nrespectively. Code is available at https://github.com/Gumpest/AvatarKD.\n","authors":["Yuan Zhang","Weihua Chen","Yichen Lu","Tao Huang","Xiuyu Sun","Jian Cao"],"pdf_url":"https://arxiv.org/pdf/2305.02722v4.pdf","comment":"Accepted by ACM MM 2023"},{"id":"http://arxiv.org/abs/2209.12699v3","updated":"2023-11-20T06:26:47Z","published":"2022-09-23T08:14:30Z","title":"Accurate and Efficient Stereo Matching via Attention Concatenation\n  Volume","summary":"  Stereo matching is a fundamental building block for many vision and robotics\napplications. An informative and concise cost volume representation is vital\nfor stereo matching of high accuracy and efficiency. In this paper, we present\na novel cost volume construction method, named attention concatenation volume\n(ACV), which generates attention weights from correlation clues to suppress\nredundant information and enhance matching-related information in the\nconcatenation volume. The ACV can be seamlessly embedded into most stereo\nmatching networks, the resulting networks can use a more lightweight\naggregation network and meanwhile achieve higher accuracy. We further design a\nfast version of ACV to enable real-time performance, named Fast-ACV, which\ngenerates high likelihood disparity hypotheses and the corresponding attention\nweights from low-resolution correlation clues to significantly reduce\ncomputational and memory cost and meanwhile maintain a satisfactory accuracy.\nThe core idea of our Fast-ACV is volume attention propagation (VAP) which can\nautomatically select accurate correlation values from an upsampled correlation\nvolume and propagate these accurate values to the surroundings pixels with\nambiguous correlation clues. Furthermore, we design a highly accurate network\nACVNet and a real-time network Fast-ACVNet based on our ACV and Fast-ACV\nrespectively, which achieve the state-of-the-art performance on several\nbenchmarks (i.e., our ACVNet ranks the 2nd on KITTI 2015 and Scene Flow, and\nthe 3rd on KITTI 2012 and ETH3D among all the published methods; our\nFast-ACVNet outperforms almost all state-of-the-art real-time methods on Scene\nFlow, KITTI 2012 and 2015 and meanwhile has better generalization ability)\n","authors":["Gangwei Xu","Yun Wang","Junda Cheng","Jinhui Tang","Xin Yang"],"pdf_url":"https://arxiv.org/pdf/2209.12699v3.pdf","comment":"Accepted to TPAMI 2023. arXiv admin note: substantial text overlap\n  with arXiv:2203.02146"},{"id":"http://arxiv.org/abs/2311.11555v1","updated":"2023-11-20T06:15:46Z","published":"2023-11-20T06:15:46Z","title":"NePF: Neural Photon Field for Single-Stage Inverse Rendering","summary":"  We present a novel single-stage framework, Neural Photon Field (NePF), to\naddress the ill-posed inverse rendering from multi-view images. Contrary to\nprevious methods that recover the geometry, material, and illumination in\nmultiple stages and extract the properties from various multi-layer perceptrons\nacross different neural fields, we question such complexities and introduce our\nmethod - a single-stage framework that uniformly recovers all properties. NePF\nachieves this unification by fully utilizing the physical implication behind\nthe weight function of neural implicit surfaces and the view-dependent\nradiance. Moreover, we introduce an innovative coordinate-based illumination\nmodel for rapid volume physically-based rendering. To regularize this\nillumination, we implement the subsurface scattering model for diffuse\nestimation. We evaluate our method on both real and synthetic datasets. The\nresults demonstrate the superiority of our approach in recovering high-fidelity\ngeometry and visual-plausible material attributes.\n","authors":["Tuen-Yue Tsui","Qin Zou"],"pdf_url":"https://arxiv.org/pdf/2311.11555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.03358v2","updated":"2023-11-20T06:08:28Z","published":"2023-10-05T07:29:29Z","title":"Enhancing Robust Representation in Adversarial Training: Alignment and\n  Exclusion Criteria","summary":"  Deep neural networks are vulnerable to adversarial noise. Adversarial\nTraining (AT) has been demonstrated to be the most effective defense strategy\nto protect neural networks from being fooled. However, we find AT omits to\nlearning robust features, resulting in poor performance of adversarial\nrobustness. To address this issue, we highlight two criteria of robust\nrepresentation: (1) Exclusion: \\emph{the feature of examples keeps away from\nthat of other classes}; (2) Alignment: \\emph{the feature of natural and\ncorresponding adversarial examples is close to each other}. These motivate us\nto propose a generic framework of AT to gain robust representation, by the\nasymmetric negative contrast and reverse attention. Specifically, we design an\nasymmetric negative contrast based on predicted probabilities, to push away\nexamples of different classes in the feature space. Moreover, we propose to\nweight feature by parameters of the linear classifier as the reverse attention,\nto obtain class-aware feature and pull close the feature of the same class.\nEmpirical evaluations on three benchmark datasets show our methods greatly\nadvance the robustness of AT and achieve state-of-the-art performance.\n","authors":["Nuoyan Zhou","Nannan Wang","Decheng Liu","Dawei Zhou","Xinbo Gao"],"pdf_url":"https://arxiv.org/pdf/2310.03358v2.pdf","comment":"10 pages, 9 figures, Submitted to TIFS"},{"id":"http://arxiv.org/abs/2311.11549v1","updated":"2023-11-20T06:04:09Z","published":"2023-11-20T06:04:09Z","title":"Unearthing Common Inconsistency for Generalisable Deepfake Detection","summary":"  Deepfake has emerged for several years, yet efficient detection techniques\ncould generalize over different manipulation methods require further research.\nWhile current image-level detection method fails to generalize to unseen\ndomains, owing to the domain-shift phenomenon brought by CNN's strong inductive\nbias towards Deepfake texture, video-level one shows its potential to have both\ngeneralization across multiple domains and robustness to compression. We argue\nthat although distinct face manipulation tools have different inherent bias,\nthey all disrupt the consistency between frames, which is a natural\ncharacteristic shared by authentic videos. Inspired by this, we proposed a\ndetection approach by capturing frame inconsistency that broadly exists in\ndifferent forgery techniques, termed unearthing-common-inconsistency (UCI).\nConcretely, the UCI network based on self-supervised contrastive learning can\nbetter distinguish temporal consistency between real and fake videos from\nmultiple domains. We introduced a temporally-preserved module method to\nintroduce spatial noise perturbations, directing the model's attention towards\ntemporal information. Subsequently, leveraging a multi-view cross-correlation\nlearning module, we extensively learn the disparities in temporal\nrepresentations between genuine and fake samples. Extensive experiments\ndemonstrate the generalization ability of our method on unseen Deepfake\ndomains.\n","authors":["Beilin Chu","Xuan Xu","Weike You","Linna Zhou"],"pdf_url":"https://arxiv.org/pdf/2311.11549v1.pdf","comment":"9 pages, 2 figures and 5 tables"},{"id":"http://arxiv.org/abs/2311.11533v1","updated":"2023-11-20T04:36:19Z","published":"2023-11-20T04:36:19Z","title":"Event Camera Data Dense Pre-training","summary":"  This paper introduces a self-supervised learning framework designed for\npre-training neural networks tailored to dense prediction tasks using event\ncamera data. Our approach utilizes solely event data for training.\n  Transferring achievements from dense RGB pre-training directly to event\ncamera data yields subpar performance. This is attributed to the spatial\nsparsity inherent in an event image (converted from event data), where many\npixels do not contain information. To mitigate this sparsity issue, we encode\nan event image into event patch features, automatically mine contextual\nsimilarity relationships among patches, group the patch features into\ndistinctive contexts, and enforce context-to-context similarities to learn\ndiscriminative event features.\n  For training our framework, we curate a synthetic event camera dataset\nfeaturing diverse scene and motion patterns. Transfer learning performance on\ndownstream dense prediction tasks illustrates the superiority of our method\nover state-of-the-art approaches. Notably, our single model secured the top\nposition in the challenging DSEC-Flow benchmark.\n","authors":["Yan Yang","Liyuan Pan","Liu Liu"],"pdf_url":"https://arxiv.org/pdf/2311.11533v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11525v1","updated":"2023-11-20T04:11:16Z","published":"2023-11-20T04:11:16Z","title":"Generalized Category Discovery in Semantic Segmentation","summary":"  This paper explores a novel setting called Generalized Category Discovery in\nSemantic Segmentation (GCDSS), aiming to segment unlabeled images given prior\nknowledge from a labeled set of base classes. The unlabeled images contain\npixels of the base class or novel class. In contrast to Novel Category\nDiscovery in Semantic Segmentation (NCDSS), there is no prerequisite for prior\nknowledge mandating the existence of at least one novel class in each unlabeled\nimage. Besides, we broaden the segmentation scope beyond foreground objects to\ninclude the entire image. Existing NCDSS methods rely on the aforementioned\npriors, making them challenging to truly apply in real-world situations. We\npropose a straightforward yet effective framework that reinterprets the GCDSS\nchallenge as a task of mask classification. Additionally, we construct a\nbaseline method and introduce the Neighborhood Relations-Guided Mask Clustering\nAlgorithm (NeRG-MaskCA) for mask categorization to address the fragmentation in\nsemantic representation. A benchmark dataset, Cityscapes-GCD, derived from the\nCityscapes dataset, is established to evaluate the GCDSS framework. Our method\ndemonstrates the feasibility of the GCDSS problem and the potential for\ndiscovering and segmenting novel object classes in unlabeled images. We employ\nthe generated pseudo-labels from our approach as ground truth to supervise the\ntraining of other models, thereby enabling them with the ability to segment\nnovel classes. It paves the way for further research in generalized category\ndiscovery, broadening the horizons of semantic segmentation and its\napplications. For details, please visit https://github.com/JethroPeng/GCDSS\n","authors":["Zhengyuan Peng","Qijian Tian","Jianqing Xu","Yizhang Jin","Xuequan Lu","Xin Tan","Yuan Xie","Lizhuang Ma"],"pdf_url":"https://arxiv.org/pdf/2311.11525v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11520v1","updated":"2023-11-20T03:51:39Z","published":"2023-11-20T03:51:39Z","title":"Liver Tumor Prediction with Advanced Attention Mechanisms Integrated\n  into a Depth-Based Variant Search Algorithm","summary":"  In recent days, Deep Learning (DL) techniques have become an emerging\ntransformation in the field of machine learning, artificial intelligence,\ncomputer vision, and so on. Subsequently, researchers and industries have been\nhighly endorsed in the medical field, predicting and controlling diverse\ndiseases at specific intervals. Liver tumor prediction is a vital chore in\nanalyzing and treating liver diseases. This paper proposes a novel approach for\npredicting liver tumors using Convolutional Neural Networks (CNN) and a\ndepth-based variant search algorithm with advanced attention mechanisms\n(CNN-DS-AM). The proposed work aims to improve accuracy and robustness in\ndiagnosing and treating liver diseases. The anticipated model is assessed on a\nComputed Tomography (CT) scan dataset containing both benign and malignant\nliver tumors. The proposed approach achieved high accuracy in predicting liver\ntumors, outperforming other state-of-the-art methods. Additionally, advanced\nattention mechanisms were incorporated into the CNN model to enable the\nidentification and highlighting of regions of the CT scans most relevant to\npredicting liver tumors. The results suggest that incorporating attention\nmechanisms and a depth-based variant search algorithm into the CNN model is a\npromising approach for improving the accuracy and robustness of liver tumor\nprediction. It can assist radiologists in their diagnosis and treatment\nplanning. The proposed system achieved a high accuracy of 95.5% in predicting\nliver tumors, outperforming other state-of-the-art methods.\n","authors":["P. Kalaiselvi","S. Anusuya"],"pdf_url":"https://arxiv.org/pdf/2311.11520v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11512v1","updated":"2023-11-20T03:23:03Z","published":"2023-11-20T03:23:03Z","title":"Seeing through the Mask: Multi-task Generative Mask Decoupling Face\n  Recognition","summary":"  The outbreak of COVID-19 pandemic make people wear masks more frequently than\never. Current general face recognition system suffers from serious performance\ndegradation,when encountering occluded scenes. The potential reason is that\nface features are corrupted by occlusions on key facial regions. To tackle this\nproblem, previous works either extract identity-related embeddings on feature\nlevel by additional mask prediction, or restore the occluded facial part by\ngenerative models. However, the former lacks visual results for model\ninterpretation, while the latter suffers from artifacts which may affect\ndownstream recognition. Therefore, this paper proposes a Multi-task gEnerative\nmask dEcoupling face Recognition (MEER) network to jointly handle these two\ntasks, which can learn occlusionirrelevant and identity-related representation\nwhile achieving unmasked face synthesis. We first present a novel mask\ndecoupling module to disentangle mask and identity information, which makes the\nnetwork obtain purer identity features from visible facial components. Then, an\nunmasked face is restored by a joint-training strategy, which will be further\nused to refine the recognition network with an id-preserving loss. Experiments\non masked face recognition under realistic and synthetic occlusions benchmarks\ndemonstrate that the MEER can outperform the state-ofthe-art methods.\n","authors":["Zhaohui Wang","Sufang Zhang","Jianteng Peng","Xinyi Wang","Yandong Guo"],"pdf_url":"https://arxiv.org/pdf/2311.11512v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.02783v2","updated":"2023-11-20T03:15:27Z","published":"2023-07-06T05:22:20Z","title":"UIT-Saviors at MEDVQA-GI 2023: Improving Multimodal Learning with Image\n  Enhancement for Gastrointestinal Visual Question Answering","summary":"  In recent years, artificial intelligence has played an important role in\nmedicine and disease diagnosis, with many applications to be mentioned, one of\nwhich is Medical Visual Question Answering (MedVQA). By combining computer\nvision and natural language processing, MedVQA systems can assist experts in\nextracting relevant information from medical image based on a given question\nand providing precise diagnostic answers. The ImageCLEFmed-MEDVQA-GI-2023\nchallenge carried out visual question answering task in the gastrointestinal\ndomain, which includes gastroscopy and colonoscopy images. Our team approached\nTask 1 of the challenge by proposing a multimodal learning method with image\nenhancement to improve the VQA performance on gastrointestinal images. The\nmultimodal architecture is set up with BERT encoder and different pre-trained\nvision models based on convolutional neural network (CNN) and Transformer\narchitecture for features extraction from question and endoscopy image. The\nresult of this study highlights the dominance of Transformer-based vision\nmodels over the CNNs and demonstrates the effectiveness of the image\nenhancement process, with six out of the eight vision models achieving better\nF1-Score. Our best method, which takes advantages of BERT+BEiT fusion and image\nenhancement, achieves up to 87.25% accuracy and 91.85% F1-Score on the\ndevelopment test set, while also producing good result on the private test set\nwith accuracy of 82.01%.\n","authors":["Triet M. Thai","Anh T. Vo","Hao K. Tieu","Linh N. P. Bui","Thien T. B. Nguyen"],"pdf_url":"https://arxiv.org/pdf/2307.02783v2.pdf","comment":"ImageCLEF2023 published version:\n  https://ceur-ws.org/Vol-3497/paper-129.pdf"},{"id":"http://arxiv.org/abs/2310.19909v2","updated":"2023-11-20T03:05:50Z","published":"2023-10-30T18:23:58Z","title":"Battle of the Backbones: A Large-Scale Comparison of Pretrained Models\n  across Computer Vision Tasks","summary":"  Neural network based computer vision systems are typically built on a\nbackbone, a pretrained or randomly initialized feature extractor. Several years\nago, the default option was an ImageNet-trained convolutional neural network.\nHowever, the recent past has seen the emergence of countless backbones\npretrained using various algorithms and datasets. While this abundance of\nchoice has led to performance increases for a range of systems, it is difficult\nfor practitioners to make informed decisions about which backbone to choose.\nBattle of the Backbones (BoB) makes this choice easier by benchmarking a\ndiverse suite of pretrained models, including vision-language models, those\ntrained via self-supervised learning, and the Stable Diffusion backbone, across\na diverse set of computer vision tasks ranging from classification to object\ndetection to OOD generalization and more. Furthermore, BoB sheds light on\npromising directions for the research community to advance computer vision by\nilluminating strengths and weakness of existing approaches through a\ncomprehensive analysis conducted on more than 1500 training runs. While vision\ntransformers (ViTs) and self-supervised learning (SSL) are increasingly\npopular, we find that convolutional neural networks pretrained in a supervised\nfashion on large training sets still perform best on most tasks among the\nmodels we consider. Moreover, in apples-to-apples comparisons on the same\narchitectures and similarly sized pretraining datasets, we find that SSL\nbackbones are highly competitive, indicating that future works should perform\nSSL pretraining with advanced architectures and larger pretraining datasets. We\nrelease the raw results of our experiments along with code that allows\nresearchers to put their own backbones through the gauntlet here:\nhttps://github.com/hsouri/Battle-of-the-Backbones\n","authors":["Micah Goldblum","Hossein Souri","Renkun Ni","Manli Shu","Viraj Prabhu","Gowthami Somepalli","Prithvijit Chattopadhyay","Mark Ibrahim","Adrien Bardes","Judy Hoffman","Rama Chellappa","Andrew Gordon Wilson","Tom Goldstein"],"pdf_url":"https://arxiv.org/pdf/2310.19909v2.pdf","comment":"Accepted to NeurIPS 2023"},{"id":"http://arxiv.org/abs/2107.11851v2","updated":"2023-11-20T02:14:36Z","published":"2021-07-25T17:24:50Z","title":"Transcript to Video: Efficient Clip Sequencing from Texts","summary":"  Among numerous videos shared on the web, well-edited ones always attract more\nattention. However, it is difficult for inexperienced users to make well-edited\nvideos because it requires professional expertise and immense manual labor. To\nmeet the demands for non-experts, we present Transcript-to-Video -- a\nweakly-supervised framework that uses texts as input to automatically create\nvideo sequences from an extensive collection of shots. Specifically, we propose\na Content Retrieval Module and a Temporal Coherent Module to learn\nvisual-language representations and model shot sequencing styles, respectively.\nFor fast inference, we introduce an efficient search strategy for real-time\nvideo clip sequencing. Quantitative results and user studies demonstrate\nempirically that the proposed learning framework can retrieve content-relevant\nshots while creating plausible video sequences in terms of style. Besides, the\nrun-time performance analysis shows that our framework can support real-world\napplications.\n","authors":["Yu Xiong","Fabian Caba Heilbron","Dahua Lin"],"pdf_url":"https://arxiv.org/pdf/2107.11851v2.pdf","comment":"Tech Report; Demo and project page at\n  http://www.xiongyu.me/projects/transcript2video/"},{"id":"http://arxiv.org/abs/2311.09574v3","updated":"2023-11-20T02:01:33Z","published":"2023-11-16T05:17:14Z","title":"LymphoML: An interpretable artificial intelligence-based method\n  identifies morphologic features that correlate with lymphoma subtype","summary":"  The accurate classification of lymphoma subtypes using hematoxylin and eosin\n(H&E)-stained tissue is complicated by the wide range of morphological features\nthese cancers can exhibit. We present LymphoML - an interpretable machine\nlearning method that identifies morphologic features that correlate with\nlymphoma subtypes. Our method applies steps to process H&E-stained tissue\nmicroarray cores, segment nuclei and cells, compute features encompassing\nmorphology, texture, and architecture, and train gradient-boosted models to\nmake diagnostic predictions. LymphoML's interpretable models, developed on a\nlimited volume of H&E-stained tissue, achieve non-inferior diagnostic accuracy\nto pathologists using whole-slide images and outperform black box deep-learning\non a dataset of 670 cases from Guatemala spanning 8 lymphoma subtypes. Using\nSHapley Additive exPlanation (SHAP) analysis, we assess the impact of each\nfeature on model prediction and find that nuclear shape features are most\ndiscriminative for DLBCL (F1-score: 78.7%) and classical Hodgkin lymphoma\n(F1-score: 74.5%). Finally, we provide the first demonstration that a model\ncombining features from H&E-stained tissue with features from a standardized\npanel of 6 immunostains results in a similar diagnostic accuracy (85.3%) to a\n46-stain panel (86.1%).\n","authors":["Vivek Shankar","Xiaoli Yang","Vrishab Krishna","Brent Tan","Oscar Silva","Rebecca Rojansky","Andrew Ng","Fabiola Valvert","Edward Briercheck","David Weinstock","Yasodha Natkunam","Sebastian Fernandez-Pol","Pranav Rajpurkar"],"pdf_url":"https://arxiv.org/pdf/2311.09574v3.pdf","comment":"To be published in Proceedings of the 3rd Machine Learning for Health\n  symposium, Proceedings of Machine Learning Research (PMLR)"},{"id":"http://arxiv.org/abs/2305.10808v2","updated":"2023-11-20T02:00:02Z","published":"2023-05-18T08:42:41Z","title":"Manifold-Aware Self-Training for Unsupervised Domain Adaptation on\n  Regressing 6D Object Pose","summary":"  Domain gap between synthetic and real data in visual regression (e.g. 6D pose\nestimation) is bridged in this paper via global feature alignment and local\nrefinement on the coarse classification of discretized anchor classes in target\nspace, which imposes a piece-wise target manifold regularization into\ndomain-invariant representation learning. Specifically, our method incorporates\nan explicit self-supervised manifold regularization, revealing consistent\ncumulative target dependency across domains, to a self-training scheme (e.g.\nthe popular Self-Paced Self-Training) to encourage more discriminative\ntransferable representations of regression tasks. Moreover, learning unified\nimplicit neural functions to estimate relative direction and distance of\ntargets to their nearest class bins aims to refine target classification\npredictions, which can gain robust performance against inconsistent feature\nscaling sensitive to UDA regressors. Experiment results on three public\nbenchmarks of the challenging 6D pose estimation task can verify the\neffectiveness of our method, consistently achieving superior performance to the\nstate-of-the-art for UDA on 6D pose estimation.\n","authors":["Yichen Zhang","Jiehong Lin","Ke Chen","Zelin Xu","Yaowei Wang","Kui Jia"],"pdf_url":"https://arxiv.org/pdf/2305.10808v2.pdf","comment":"Accepted by IJCAI 2023"},{"id":"http://arxiv.org/abs/2311.10251v2","updated":"2023-11-20T01:59:11Z","published":"2023-11-17T00:44:56Z","title":"UniMOS: A Universal Framework For Multi-Organ Segmentation Over\n  Label-Constrained Datasets","summary":"  Machine learning models for medical images can help physicians diagnose and\nmanage diseases. However, due to the fact that medical image annotation\nrequires a great deal of manpower and expertise, as well as the fact that\nclinical departments perform image annotation based on task orientation, there\nis the problem of having fewer medical image annotation data with more\nunlabeled data and having many datasets that annotate only a single organ. In\nthis paper, we present UniMOS, the first universal framework for achieving the\nutilization of fully and partially labeled images as well as unlabeled images.\nSpecifically, we construct a Multi-Organ Segmentation (MOS) module over\nfully/partially labeled data as the basenet and designed a new target adaptive\nloss. Furthermore, we incorporate a semi-supervised training module that\ncombines consistent regularization and pseudolabeling techniques on unlabeled\ndata, which significantly improves the segmentation of unlabeled data.\nExperiments show that the framework exhibits excellent performance in several\nmedical image segmentation tasks compared to other advanced methods, and also\nsignificantly improves data utilization and reduces annotation cost. Code and\nmodels are available at: https://github.com/lw8807001/UniMOS.\n","authors":["Can Li","Sheng Shao","Junyi Qu","Shuchao Pang","Mehmet A. Orgun"],"pdf_url":"https://arxiv.org/pdf/2311.10251v2.pdf","comment":"Accepted by BIBM2023"},{"id":"http://arxiv.org/abs/2311.11477v1","updated":"2023-11-20T01:07:30Z","published":"2023-11-20T01:07:30Z","title":"What's left can't be right -- The remaining positional incompetence of\n  contrastive vision-language models","summary":"  Contrastive vision-language models like CLIP have been found to lack spatial\nunderstanding capabilities. In this paper we discuss the possible causes of\nthis phenomenon by analysing both datasets and embedding space. By focusing on\nsimple left-right positional relations, we show that this behaviour is entirely\npredictable, even with large-scale datasets, demonstrate that these relations\ncan be taught using synthetic data and show that this approach can generalise\nwell to natural images - improving the performance on left-right relations on\nVisual Genome Relations.\n","authors":["Nils Hoehing","Ellen Rushe","Anthony Ventresque"],"pdf_url":"https://arxiv.org/pdf/2311.11477v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.15308v2","updated":"2023-11-20T00:56:15Z","published":"2023-10-23T19:21:57Z","title":"SAM-CLIP: Merging Vision Foundation Models towards Semantic and Spatial\n  Understanding","summary":"  The landscape of publicly available vision foundation models (VFMs), such as\nCLIP and Segment Anything Model (SAM), is expanding rapidly. VFMs are endowed\nwith distinct capabilities stemming from their pre-training objectives. For\ninstance, CLIP excels in semantic understanding, while SAM specializes in\nspatial understanding for segmentation. In this work, we introduce a simple\nrecipe to efficiently merge VFMs into a unified model that absorbs their\nexpertise. Our method integrates techniques of multi-task learning, continual\nlearning, and distillation. Further, it demands significantly less\ncomputational cost compared to traditional multi-task training from scratch,\nand it only needs a small fraction of the pre-training datasets that were\ninitially used to train individual models. By applying our method to SAM and\nCLIP, we obtain SAM-CLIP: a unified model that combines the capabilities of SAM\nand CLIP into a single vision transformer. Compared with deploying SAM and CLIP\nindependently, our merged model, SAM-CLIP, reduces storage and compute costs\nfor inference, making it well-suited for edge device applications. We show that\nSAM-CLIP not only retains the foundational strengths of SAM and CLIP, but also\nintroduces synergistic functionalities, notably in zero-shot semantic\nsegmentation, where SAM-CLIP establishes new state-of-the-art results on 5\nbenchmarks. It outperforms previous models that are specifically designed for\nthis task by a large margin, including +6.8% and +5.9% mean IoU improvement on\nPascal-VOC and COCO-Stuff datasets, respectively.\n","authors":["Haoxiang Wang","Pavan Kumar Anasosalu Vasu","Fartash Faghri","Raviteja Vemulapalli","Mehrdad Farajtabar","Sachin Mehta","Mohammad Rastegari","Oncel Tuzel","Hadi Pouransari"],"pdf_url":"https://arxiv.org/pdf/2310.15308v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12225v1","updated":"2023-11-20T22:43:07Z","published":"2023-11-20T22:43:07Z","title":"HandSight: DeCAF & Improved Fisher Vectors to Classify Clothing Color\n  and Texture with a Finger-Mounted Camera","summary":"  We demonstrate the use of DeCAF and Improved Fisher Vector image features to\nclassify clothing texture. The issue of choosing clothes is a problem for the\nblind every day. This work attempts to solve the issue with a finger-mounted\ncamera and state-of-the-art classification algorithms. To evaluate our\nsolution, we collected 520 close-up images across 29 pieces of clothing. We\ncontribute (1) the HCTD, an image dataset taken with a NanEyeGS camera, a\ncamera small enough to be mounted on the finger, and (2) evaluations of\nstate-of-the-art recognition algorithms applied to our dataset - achieving an\naccuracy >95%. Throughout the paper, we will discuss previous work, evaluate\nthe current work, and finally, suggest the project's future direction.\n","authors":["Alexander J. Medeiros","Lee Stearns","Jon E. Froehlich"],"pdf_url":"https://arxiv.org/pdf/2311.12225v1.pdf","comment":"10 pages, 15 figures"},{"id":"http://arxiv.org/abs/2311.06031v2","updated":"2023-11-20T22:25:15Z","published":"2023-11-10T12:38:16Z","title":"Diagonal Hierarchical Consistency Learning for Semi-supervised Medical\n  Image Segmentation","summary":"  Medical image segmentation, which is essential for many clinical\napplications, has achieved almost human-level performance via data-driven deep\nlearning techniques. Nevertheless, its performance is predicated upon the\ncostly process of manually annotating a vast amount of medical images. To this\nend, we propose a novel framework for robust semi-supervised medical image\nsegmentation using diagonal hierarchical consistency learning (DiHC-Net).\nFirst, it is composed of multiple sub-models with identical multi-scale\narchitecture but with distinct sub-layers, such as up-sampling and\nnormalisation layers. Second, along with mutual consistency, a novel diagonal\nhierarchical consistency is enforced between one model's intermediate and final\nprediction and other models' soft pseudo labels in a diagonal hierarchical\nfashion. Experimental results verify the efficacy of our simple framework,\noutperforming all previous approaches on public Left Atrium (LA) dataset.\n","authors":["Heejoon Koo"],"pdf_url":"https://arxiv.org/pdf/2311.06031v2.pdf","comment":"5 pages, 2 figures, and 2 tables. Corrected typos and errors"},{"id":"http://arxiv.org/abs/2311.12202v1","updated":"2023-11-20T21:43:32Z","published":"2023-11-20T21:43:32Z","title":"Nepotistically Trained Generative-AI Models Collapse","summary":"  Trained on massive amounts of human-generated content, AI (artificial\nintelligence) image synthesis is capable of reproducing semantically coherent\nimages that match the visual appearance of its training data. We show that when\nretrained on even small amounts of their own creation, these generative-AI\nmodels produce highly distorted images. We also show that this distortion\nextends beyond the text prompts used in retraining, and that once poisoned, the\nmodels struggle to fully heal even after retraining on only real images.\n","authors":["Matyas Bohacek","Hany Farid"],"pdf_url":"https://arxiv.org/pdf/2311.12202v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12198v1","updated":"2023-11-20T21:34:52Z","published":"2023-11-20T21:34:52Z","title":"PhysGaussian: Physics-Integrated 3D Gaussians for Generative Dynamics","summary":"  We introduce PhysGaussian, a new method that seamlessly integrates physically\ngrounded Newtonian dynamics within 3D Gaussians to achieve high-quality novel\nmotion synthesis. Employing a custom Material Point Method (MPM), our approach\nenriches 3D Gaussian kernels with physically meaningful kinematic deformation\nand mechanical stress attributes, all evolved in line with continuum mechanics\nprinciples. A defining characteristic of our method is the seamless integration\nbetween physical simulation and visual rendering: both components utilize the\nsame 3D Gaussian kernels as their discrete representations. This negates the\nnecessity for triangle/tetrahedron meshing, marching cubes, \"cage meshes,\" or\nany other geometry embedding, highlighting the principle of \"what you see is\nwhat you simulate (WS$^2$).\" Our method demonstrates exceptional versatility\nacross a wide variety of materials--including elastic entities, metals,\nnon-Newtonian fluids, and granular materials--showcasing its strong\ncapabilities in creating diverse visual content with novel viewpoints and\nmovements. Our project page is at: https://xpandora.github.io/PhysGaussian/\n","authors":["Tianyi Xie","Zeshun Zong","Yuxin Qiu","Xuan Li","Yutao Feng","Yin Yang","Chenfanfu Jiang"],"pdf_url":"https://arxiv.org/pdf/2311.12198v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.08577v2","updated":"2023-11-20T21:32:27Z","published":"2023-11-14T22:46:01Z","title":"Finding AI-Generated Faces in the Wild","summary":"  AI-based image generation has continued to rapidly improve, producing\nincreasingly more realistic images with fewer obvious visual flaws.\nAI-generated images are being used to create fake online profiles which in turn\nare being used for spam, fraud, and disinformation campaigns. As the general\nproblem of detecting any type of manipulated or synthesized content is\nreceiving increasing attention, here we focus on a more narrow task of\ndistinguishing a real face from an AI-generated face. This is particularly\napplicable when tackling inauthentic online accounts with a fake user profile\nphoto. We show that by focusing on only faces, a more resilient and\ngeneral-purpose artifact can be detected that allows for the detection of\nAI-generated faces from a variety of GAN- and diffusion-based synthesis\nengines, and across image resolutions (as low as 128 x 128 pixels) and\nqualities.\n","authors":["Gonzalo J. Aniano Porcile","Jack Gindi","Shivansh Mundra","James R. Verbus","Hany Farid"],"pdf_url":"https://arxiv.org/pdf/2311.08577v2.pdf","comment":"Removed anonymization of the LinkedIn platform"},{"id":"http://arxiv.org/abs/2311.12194v1","updated":"2023-11-20T21:20:37Z","published":"2023-11-20T21:20:37Z","title":"DiffAvatar: Simulation-Ready Garment Optimization with Differentiable\n  Simulation","summary":"  The realism of digital avatars is crucial in enabling telepresence\napplications with self-expression and customization. A key aspect of this\nrealism originates from the physical accuracy of both a true-to-life body shape\nand clothing. While physical simulations can produce high-quality, realistic\nmotions for clothed humans, they require precise estimation of body shape and\nhigh-quality garment assets with associated physical parameters for cloth\nsimulations. However, manually creating these assets and calibrating their\nparameters is labor-intensive and requires specialized expertise. To address\nthis gap, we propose DiffAvatar, a novel approach that performs body and\ngarment co-optimization using differentiable simulation. By integrating\nphysical simulation into the optimization loop and accounting for the complex\nnonlinear behavior of cloth and its intricate interaction with the body, our\nframework recovers body and garment geometry and extracts important material\nparameters in a physically plausible way. Our experiments demonstrate that our\napproach generates realistic clothing and body shape that can be easily used in\ndownstream applications.\n","authors":["Yifei Li","Hsiao-yu Chen","Egor Larionov","Nikolaos Sarafianos","Wojciech Matusik","Tuur Stuyck"],"pdf_url":"https://arxiv.org/pdf/2311.12194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12193v1","updated":"2023-11-20T21:20:15Z","published":"2023-11-20T21:20:15Z","title":"Disentangling Structure and Appearance in ViT Feature Space","summary":"  We present a method for semantically transferring the visual appearance of\none natural image to another. Specifically, our goal is to generate an image in\nwhich objects in a source structure image are \"painted\" with the visual\nappearance of their semantically related objects in a target appearance image.\nTo integrate semantic information into our framework, our key idea is to\nleverage a pre-trained and fixed Vision Transformer (ViT) model. Specifically,\nwe derive novel disentangled representations of structure and appearance\nextracted from deep ViT features. We then establish an objective function that\nsplices the desired structure and appearance representations, interweaving them\ntogether in the space of ViT features. Based on our objective function, we\npropose two frameworks of semantic appearance transfer -- \"Splice\", which works\nby training a generator on a single and arbitrary pair of structure-appearance\nimages, and \"SpliceNet\", a feed-forward real-time appearance transfer model\ntrained on a dataset of images from a specific domain. Our frameworks do not\ninvolve adversarial training, nor do they require any additional input\ninformation such as semantic segmentation or correspondences. We demonstrate\nhigh-resolution results on a variety of in-the-wild image pairs, under\nsignificant variations in the number of objects, pose, and appearance. Code and\nsupplementary material are available in our project page: splice-vit.github.io.\n","authors":["Narek Tumanyan","Omer Bar-Tal","Shir Amir","Shai Bagon","Tali Dekel"],"pdf_url":"https://arxiv.org/pdf/2311.12193v1.pdf","comment":"Accepted to ACM Transactions on Graphics. arXiv admin note:\n  substantial text overlap with arXiv:2201.00424"},{"id":"http://arxiv.org/abs/2209.08660v2","updated":"2023-11-20T21:07:44Z","published":"2022-09-18T21:29:58Z","title":"Learn the Time to Learn: Replay Scheduling in Continual Learning","summary":"  Replay methods are known to be successful at mitigating catastrophic\nforgetting in continual learning scenarios despite having limited access to\nhistorical data. However, storing historical data is cheap in many real-world\nsettings, yet replaying all historical data is often prohibited due to\nprocessing time constraints. In such settings, we propose that continual\nlearning systems should learn the time to learn and schedule which tasks to\nreplay at different time steps. We first demonstrate the benefits of our\nproposal by using Monte Carlo tree search to find a proper replay schedule, and\nshow that the found replay schedules can outperform fixed scheduling policies\nwhen combined with various replay methods in different continual learning\nsettings. Additionally, we propose a framework for learning replay scheduling\npolicies with reinforcement learning. We show that the learned policies can\ngeneralize better in new continual learning scenarios compared to equally\nreplaying all seen tasks, without added computational cost. Our study reveals\nthe importance of learning the time to learn in continual learning, which\nbrings current research closer to real-world needs.\n","authors":["Marcus Klasson","Hedvig Kjellström","Cheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2209.08660v2.pdf","comment":"Published in TMLR (2023)"},{"id":"http://arxiv.org/abs/2311.02332v3","updated":"2023-11-20T20:55:29Z","published":"2023-11-04T05:42:51Z","title":"Multimodal Machine Learning in Image-Based and Clinical Biomedicine:\n  Survey and Prospects","summary":"  Machine learning (ML) applications in medical artificial intelligence (AI)\nsystems have shifted from traditional and statistical methods to increasing\napplication of deep learning models. This survey navigates the current\nlandscape of multimodal ML, focusing on its profound impact on medical image\nanalysis and clinical decision support systems. Emphasizing challenges and\ninnovations in addressing multimodal representation, fusion, translation,\nalignment, and co-learning, the paper explores the transformative potential of\nmultimodal models for clinical predictions. It also questions practical\nimplementation of such models, bringing attention to the dynamics between\ndecision support systems and healthcare providers. Despite advancements,\nchallenges such as data biases and the scarcity of \"big data\" in many\nbiomedical domains persist. We conclude with a discussion on effective\ninnovation and collaborative efforts to further the miss\n","authors":["Elisa Warner","Joonsang Lee","William Hsu","Tanveer Syeda-Mahmood","Charles Kahn","Olivier Gevaert","Arvind Rao"],"pdf_url":"https://arxiv.org/pdf/2311.02332v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12174v1","updated":"2023-11-20T20:40:24Z","published":"2023-11-20T20:40:24Z","title":"LABELMAKER: Automatic Semantic Label Generation from RGB-D Trajectories","summary":"  Semantic annotations are indispensable to train or evaluate perception\nmodels, yet very costly to acquire. This work introduces a fully automated\n2D/3D labeling framework that, without any human intervention, can generate\nlabels for RGB-D scans at equal (or better) level of accuracy than comparable\nmanually annotated datasets such as ScanNet. Our approach is based on an\nensemble of state-of-the-art segmentation models and 3D lifting through neural\nrendering. We demonstrate the effectiveness of our LabelMaker pipeline by\ngenerating significantly better labels for the ScanNet datasets and\nautomatically labelling the previously unlabeled ARKitScenes dataset. Code and\nmodels are available at https://labelmaker.org\n","authors":["Silvan Weder","Hermann Blum","Francis Engelmann","Marc Pollefeys"],"pdf_url":"https://arxiv.org/pdf/2311.12174v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12161v1","updated":"2023-11-20T20:27:42Z","published":"2023-11-20T20:27:42Z","title":"ChemScraper: Graphics Extraction, Molecular Diagram Parsing, and\n  Annotated Data Generation for PDF Images","summary":"  Existing visual parsers for molecule diagrams translate pixel-based raster\nimages such as PNGs to chemical structure representations (e.g., SMILES).\nHowever, PDFs created by word processors including \\LaTeX{} and Word provide\nexplicit locations and shapes for characters, lines, and polygons. We\n%introduce a method to extract symbols from born-digital PDF molecule images\nand then apply simple graph transformations to capture both visual and chemical\nstructure in editable ChemDraw files (CDXML). Our fast ( PDF $\\rightarrow$\nvisual graph $\\rightarrow$ chemical graph ) pipeline does not require GPUs,\nOptical Character Recognition (OCR) or vectorization. We evaluate on standard\nbenchmarks using SMILES strings, along with a novel evaluation that provides\ngraph-based metrics and error compilation using LgEval. The geometric\ninformation in born-digital PDFs produces a highly accurate parser, motivating\ngenerating training data for visual parsers that recognize from raster images,\nwith extracted graphics, visual structure, and chemical structure as\nannotations. To do this we render SMILES strings in Indigo, parse molecule\nstructure, and then validate recognized structure to select correct files.\n","authors":["Ayush Kumar Shah","Bryan Manrique Amador","Abhisek Dey","Ming Creekmore","Blake Ocampo","Scott Denmark","Richard Zanibbi"],"pdf_url":"https://arxiv.org/pdf/2311.12161v1.pdf","comment":"20 pages without references, 10 figures, 3 Tables, submitted to\n  International Journal on Document Analysis and Recognition (IJDAR)"},{"id":"http://arxiv.org/abs/2311.12159v1","updated":"2023-11-20T20:24:45Z","published":"2023-11-20T20:24:45Z","title":"Conditional Modeling Based Automatic Video Summarization","summary":"  The aim of video summarization is to shorten videos automatically while\nretaining the key information necessary to convey the overall story. Video\nsummarization methods mainly rely on visual factors, such as visual\nconsecutiveness and diversity, which may not be sufficient to fully understand\nthe content of the video. There are other non-visual factors, such as\ninterestingness, representativeness, and storyline consistency that should also\nbe considered for generating high-quality video summaries. Current methods do\nnot adequately take into account these non-visual factors, resulting in\nsuboptimal performance. In this work, a new approach to video summarization is\nproposed based on insights gained from how humans create ground truth video\nsummaries. The method utilizes a conditional modeling perspective and\nintroduces multiple meaningful random variables and joint distributions to\ncharacterize the key components of video summarization. Helper distributions\nare employed to improve the training of the model. A conditional attention\nmodule is designed to mitigate potential performance degradation in the\npresence of multi-modal input. The proposed video summarization method\nincorporates the above innovative design choices that aim to narrow the gap\nbetween human-generated and machine-generated video summaries. Extensive\nexperiments show that the proposed approach outperforms existing methods and\nachieves state-of-the-art performance on commonly used video summarization\ndatasets.\n","authors":["Jia-Hong Huang","Chao-Han Huck Yang","Pin-Yu Chen","Min-Hung Chen","Marcel Worring"],"pdf_url":"https://arxiv.org/pdf/2311.12159v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  arXiv admin note: substantial text overlap with arXiv:2305.00455"},{"id":"http://arxiv.org/abs/2311.12157v1","updated":"2023-11-20T20:22:55Z","published":"2023-11-20T20:22:55Z","title":"Model-aware 3D Eye Gaze from Weak and Few-shot Supervisions","summary":"  The task of predicting 3D eye gaze from eye images can be performed either by\n(a) end-to-end learning for image-to-gaze mapping or by (b) fitting a 3D eye\nmodel onto images. The former case requires 3D gaze labels, while the latter\nrequires eye semantics or landmarks to facilitate the model fitting. Although\nobtaining eye semantics and landmarks is relatively easy, fitting an accurate\n3D eye model on them remains to be very challenging due to its ill-posed nature\nin general. On the other hand, obtaining large-scale 3D gaze data is cumbersome\ndue to the required hardware setups and computational demands. In this work, we\npropose to predict 3D eye gaze from weak supervision of eye semantic\nsegmentation masks and direct supervision of a few 3D gaze vectors. The\nproposed method combines the best of both worlds by leveraging large amounts of\nweak annotations--which are easy to obtain, and only a few 3D gaze\nvectors--which alleviate the difficulty of fitting 3D eye models on the\nsemantic segmentation of eye images. Thus, the eye gaze vectors, used in the\nmodel fitting, are directly supervised using the few-shot gaze labels.\nAdditionally, we propose a transformer-based network architecture, that serves\nas a solid baseline for our improvements. Our experiments in diverse settings\nillustrate the significant benefits of the proposed method, achieving about 5\ndegrees lower angular gaze error over the baseline, when only 0.05% 3D\nannotations of the training images are used. The source code is available at\nhttps://github.com/dimitris-christodoulou57/Model-aware_3D_Eye_Gaze.\n","authors":["Nikola Popovic","Dimitrios Christodoulou","Danda Pani Paudel","Xi Wang","Luc Van Gool"],"pdf_url":"https://arxiv.org/pdf/2311.12157v1.pdf","comment":"Accepted to ISMAR2023 as a poster paper"},{"id":"http://arxiv.org/abs/2311.12153v1","updated":"2023-11-20T20:09:48Z","published":"2023-11-20T20:09:48Z","title":"Uncertainty Estimation in Contrast-Enhanced MR Image Translation with\n  Multi-Axis Fusion","summary":"  In recent years, deep learning has been applied to a wide range of medical\nimaging and image processing tasks. In this work, we focus on the estimation of\nepistemic uncertainty for 3D medical image-to-image translation. We propose a\nnovel model uncertainty quantification method, Multi-Axis Fusion (MAF), which\nrelies on the integration of complementary information derived from multiple\nviews on volumetric image data. The proposed approach is applied to the task of\nsynthesizing contrast enhanced T1-weighted images based on native T1, T2 and\nT2-FLAIR scans. The quantitative findings indicate a strong correlation\n($\\rho_{\\text healthy} = 0.89$) between the mean absolute image synthetization\nerror and the mean uncertainty score for our MAF method. Hence, we consider MAF\nas a promising approach to solve the highly relevant task of detecting\nsynthetization failures at inference time.\n","authors":["Ivo M. Baltruschat","Parvaneh Janbakhshi","Melanie Dohmen","Matthias Lenga"],"pdf_url":"https://arxiv.org/pdf/2311.12153v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12151v1","updated":"2023-11-20T20:03:34Z","published":"2023-11-20T20:03:34Z","title":"Teaching Robots to Build Simulations of Themselves","summary":"  Simulation enables robots to plan and estimate the outcomes of prospective\nactions without the need to physically execute them. We introduce a\nself-supervised learning framework to enable robots model and predict their\nmorphology, kinematics and motor control using only brief raw video data,\neliminating the need for extensive real-world data collection and kinematic\npriors. By observing their own movements, akin to humans watching their\nreflection in a mirror, robots learn an ability to simulate themselves and\npredict their spatial motion for various tasks. Our results demonstrate that\nthis self-learned simulation not only enables accurate motion planning but also\nallows the robot to detect abnormalities and recover from damage.\n","authors":["Yuhang Hu","Jiong Lin","Hod Lipson"],"pdf_url":"https://arxiv.org/pdf/2311.12151v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.09248v2","updated":"2023-11-20T19:48:39Z","published":"2023-04-13T22:04:30Z","title":"Real-Time Helmet Violation Detection in AI City Challenge 2023 with\n  Genetic Algorithm-Enhanced YOLOv5","summary":"  This research focuses on real-time surveillance systems as a means for\ntackling the issue of non-compliance with helmet regulations, a practice that\nconsiderably amplifies the risk for motorcycle drivers or riders. Despite the\nwell-established advantages of helmet usage, achieving widespread compliance\nremains challenging due to diverse contributing factors. To effectively address\nthis concern, real-time monitoring and enforcement of helmet laws have been\nproposed as a plausible solution. However, previous attempts at real-time\nhelmet violation detection have been hindered by their limited ability to\noperate in real-time. To overcome this limitation, the current paper introduces\na novel real-time helmet violation detection system that utilizes the YOLOv5\nsingle-stage object detection model. This model is trained on the 2023 NVIDIA\nAI City Challenge 2023 Track 5 dataset. The optimal hyperparameters for\ntraining the model are determined using genetic algorithms. Additionally, data\naugmentation and various sampling techniques are implemented to enhance the\nmodel's performance. The efficacy of the models is evaluated using precision,\nrecall, and mean Average Precision (mAP) metrics. The results demonstrate\nimpressive precision, recall, and mAP scores of 0.848, 0.599, and 0.641,\nrespectively for the training data. Furthermore, the model achieves notable mAP\nscore of 0.6667 for the test datasets, leading to a commendable 4th place rank\nin the public leaderboard. This innovative approach represents a notable\nbreakthrough in the field and holds immense potential to substantially enhance\nmotorcycle safety. By enabling real-time monitoring and enforcement\ncapabilities, this system has the capacity to contribute towards increased\ncompliance with helmet laws, thereby effectively reducing the risks faced by\nmotorcycle riders and passengers.\n","authors":["Elham Soltanikazemi","Ashwin Dhakal","Bijaya Kumar Hatuwal","Imad Eddine Toubal","Armstrong Aboah","Kannappan Palaniappan"],"pdf_url":"https://arxiv.org/pdf/2304.09248v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12144v1","updated":"2023-11-20T19:45:27Z","published":"2023-11-20T19:45:27Z","title":"Applications of Large Scale Foundation Models for Autonomous Driving","summary":"  Since DARPA Grand Challenges (rural) in 2004/05 and Urban Challenges in 2007,\nautonomous driving has been the most active field of AI applications. Recently\npowered by large language models (LLMs), chat systems, such as chatGPT and\nPaLM, emerge and rapidly become a promising direction to achieve artificial\ngeneral intelligence (AGI) in natural language processing (NLP). There comes a\nnatural thinking that we could employ these abilities to reformulate autonomous\ndriving. By combining LLM with foundation models, it is possible to utilize the\nhuman knowledge, commonsense and reasoning to rebuild autonomous driving\nsystems from the current long-tailed AI dilemma. In this paper, we investigate\nthe techniques of foundation models and LLMs applied for autonomous driving,\ncategorized as simulation, world model, data annotation and planning or E2E\nsolutions etc.\n","authors":["Yu Huang","Yue Chen","Zhu Li"],"pdf_url":"https://arxiv.org/pdf/2311.12144v1.pdf","comment":"42 pages"},{"id":"http://arxiv.org/abs/2311.12128v1","updated":"2023-11-20T19:11:16Z","published":"2023-11-20T19:11:16Z","title":"Fingerspelling PoseNet: Enhancing Fingerspelling Translation with\n  Pose-Based Transformer Models","summary":"  We address the task of American Sign Language fingerspelling translation\nusing videos in the wild. We exploit advances in more accurate hand pose\nestimation and propose a novel architecture that leverages the transformer\nbased encoder-decoder model enabling seamless contextual word translation. The\ntranslation model is augmented by a novel loss term that accurately predicts\nthe length of the finger-spelled word, benefiting both training and inference.\nWe also propose a novel two-stage inference approach that re-ranks the\nhypotheses using the language model capabilities of the decoder. Through\nextensive experiments, we demonstrate that our proposed method outperforms the\nstate-of-the-art models on ChicagoFSWild and ChicagoFSWild+ achieving more than\n10% relative improvement in performance. Our findings highlight the\neffectiveness of our approach and its potential to advance fingerspelling\nrecognition in sign language translation. Code is also available at\nhttps://github.com/pooyafayyaz/Fingerspelling-PoseNet.\n","authors":["Pooya Fayyazsanavi","Negar Nejatishahidin","Jana Kosecka"],"pdf_url":"https://arxiv.org/pdf/2311.12128v1.pdf","comment":"WACV 2024"},{"id":"http://arxiv.org/abs/2311.12125v1","updated":"2023-11-20T19:05:57Z","published":"2023-11-20T19:05:57Z","title":"Mixing-Denoising Generalizable Occupancy Networks","summary":"  While current state-of-the-art generalizable implicit neural shape models\nrely on the inductive bias of convolutions, it is still not entirely clear how\nproperties emerging from such biases are compatible with the task of 3D\nreconstruction from point cloud. We explore an alternative approach to\ngeneralizability in this context. We relax the intrinsic model bias (i.e. using\nMLPs to encode local features as opposed to convolutions) and constrain the\nhypothesis space instead with an auxiliary regularization related to the\nreconstruction task, i.e. denoising. The resulting model is the first only-MLP\nlocally conditioned implicit shape reconstruction from point cloud network with\nfast feed forward inference. Point cloud borne features and denoising offsets\nare predicted from an exclusively MLP-made network in a single forward pass. A\ndecoder predicts occupancy probabilities for queries anywhere in space by\npooling nearby features from the point cloud order-invariantly, guided by\ndenoised relative positional encoding. We outperform the state-of-the-art\nconvolutional method while using half the number of model parameters.\n","authors":["Amine Ouasfi","Adnane Boukhayma"],"pdf_url":"https://arxiv.org/pdf/2311.12125v1.pdf","comment":"3DV 2024"},{"id":"http://arxiv.org/abs/2308.01981v3","updated":"2023-11-20T19:04:02Z","published":"2023-08-03T18:28:50Z","title":"CartiMorph: a framework for automated knee articular cartilage\n  morphometrics","summary":"  We introduce CartiMorph, a framework for automated knee articular cartilage\nmorphometrics. It takes an image as input and generates quantitative metrics\nfor cartilage subregions, including the percentage of full-thickness cartilage\nloss (FCL), mean thickness, surface area, and volume. CartiMorph leverages the\npower of deep learning models for hierarchical image feature representation.\nDeep learning models were trained and validated for tissue segmentation,\ntemplate construction, and template-to-image registration. We established\nmethods for surface-normal-based cartilage thickness mapping, FCL estimation,\nand rule-based cartilage parcellation. Our cartilage thickness map showed less\nerror in thin and peripheral regions. We evaluated the effectiveness of the\nadopted segmentation model by comparing the quantitative metrics obtained from\nmodel segmentation and those from manual segmentation. The root-mean-squared\ndeviation of the FCL measurements was less than 8%, and strong correlations\nwere observed for the mean thickness (Pearson's correlation coefficient $\\rho\n\\in [0.82,0.97]$), surface area ($\\rho \\in [0.82,0.98]$) and volume ($\\rho \\in\n[0.89,0.98]$) measurements. We compared our FCL measurements with those from a\nprevious study and found that our measurements deviated less from the ground\ntruths. We observed superior performance of the proposed rule-based cartilage\nparcellation method compared with the atlas-based approach. CartiMorph has the\npotential to promote imaging biomarkers discovery for knee osteoarthritis.\n","authors":["Yongcheng Yao","Junru Zhong","Liping Zhang","Sheheryar Khan","Weitian Chen"],"pdf_url":"https://arxiv.org/pdf/2308.01981v3.pdf","comment":"This preprint is an proofread version of a paper published in Medical\n  Image Analysis (2023), which can be found at\n  https://doi.org/10.1016/j.media.2023.103035"},{"id":"http://arxiv.org/abs/2311.12092v1","updated":"2023-11-20T18:59:01Z","published":"2023-11-20T18:59:01Z","title":"Concept Sliders: LoRA Adaptors for Precise Control in Diffusion Models","summary":"  We present a method to create interpretable concept sliders that enable\nprecise control over attributes in image generations from diffusion models. Our\napproach identifies a low-rank parameter direction corresponding to one concept\nwhile minimizing interference with other attributes. A slider is created using\na small set of prompts or sample images; thus slider directions can be created\nfor either textual or visual concepts. Concept Sliders are plug-and-play: they\ncan be composed efficiently and continuously modulated, enabling precise\ncontrol over image generation. In quantitative experiments comparing to\nprevious editing techniques, our sliders exhibit stronger targeted edits with\nlower interference. We showcase sliders for weather, age, styles, and\nexpressions, as well as slider compositions. We show how sliders can transfer\nlatents from StyleGAN for intuitive editing of visual concepts for which\ntextual description is difficult. We also find that our method can help address\npersistent quality issues in Stable Diffusion XL including repair of object\ndeformations and fixing distorted hands. Our code, data, and trained sliders\nare available at https://sliders.baulab.info/\n","authors":["Rohit Gandikota","Joanna Materzynska","Tingrui Zhou","Antonio Torralba","David Bau"],"pdf_url":"https://arxiv.org/pdf/2311.12092v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12091v1","updated":"2023-11-20T18:49:58Z","published":"2023-11-20T18:49:58Z","title":"DAS: A Deformable Attention to Capture Salient Information in CNNs","summary":"  Convolutional Neural Networks (CNNs) excel in local spatial pattern\nrecognition. For many vision tasks, such as object recognition and\nsegmentation, salient information is also present outside CNN's kernel\nboundaries. However, CNNs struggle in capturing such relevant information due\nto their confined receptive fields. Self-attention can improve a model's access\nto global information but increases computational overhead. We present a fast\nand simple fully convolutional method called DAS that helps focus attention on\nrelevant information. It uses deformable convolutions for the location of\npertinent image regions and separable convolutions for efficiency. DAS plugs\ninto existing CNNs and propagates relevant information using a gating\nmechanism. Compared to the O(n^2) computational complexity of transformer-style\nattention, DAS is O(n). Our claim is that DAS's ability to pay increased\nattention to relevant features results in performance improvements when added\nto popular CNNs for Image Classification and Object Detection. For example, DAS\nyields an improvement on Stanford Dogs (4.47%), ImageNet (1.91%), and COCO AP\n(3.3%) with base ResNet50 backbone. This outperforms other CNN attention\nmechanisms while using similar or less FLOPs. Our code will be publicly\navailable.\n","authors":["Farzad Salajegheh","Nader Asadi","Soroush Saryazdi","Sudhir Mudur"],"pdf_url":"https://arxiv.org/pdf/2311.12091v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2311.11824v1","updated":"2023-11-20T15:01:33Z","published":"2023-11-20T15:01:33Z","title":"Graph Variational Embedding Collaborative Filtering","summary":"  The customization of recommended content to users holds significant\nimportance in enhancing user experiences across a wide spectrum of applications\nsuch as e-commerce, music, and shopping. Graph-based methods have achieved\nconsiderable performance by capturing user-item interactions. However, these\nmethods tend to utilize randomly constructed embeddings in the dataset used for\ntraining the recommender, which lacks any user preferences. Here, we propose\nthe concept of variational embeddings as a means of pre-training the\nrecommender system to improve the feature propagation through the layers of\ngraph convolutional networks (GCNs). The graph variational embedding\ncollaborative filtering (GVECF) is introduced as a novel framework to\nincorporate representations learned through a variational graph auto-encoder\nwhich are embedded into a GCN-based collaborative filtering. This approach\neffectively transforms latent high-order user-item interactions into more\ntrainable vectors, ultimately resulting in better performance in terms of\nrecall and normalized discounted cumulative gain(NDCG) metrics. The experiments\nconducted on benchmark datasets demonstrate that our proposed method achieves\nup to 13.78% improvement in the recall over the test data.\n","authors":["Narges Sadat Fazeli Dehkordi","Hadi Zare","Parham Moradi","Mahdi Jalili"],"pdf_url":"https://arxiv.org/pdf/2311.11824v1.pdf","comment":"Submitted for PAKDD2024 conference,12 pages"},{"id":"http://arxiv.org/abs/2311.11701v1","updated":"2023-11-20T12:08:32Z","published":"2023-11-20T12:08:32Z","title":"Control in Hybrid Chatbots","summary":"  Customer data typically is held in database systems, which can be seen as\nrule-based knowledge base, whereas businesses increasingly want to benefit from\nthe capabilities of large, pre-trained language models.\n  In this technical report, we describe a case study of how a commercial rule\nengine and an integrated neural chatbot may be integrated, and what level of\ncontrol that particular integration mode leads to. We also discuss alternative\nways (including past ways realized in other systems) how researchers strive to\nmaintain control and avoid what has recently been called model \"hallucination\".\n","authors":["Thomas Rüdel","Jochen L. Leidner"],"pdf_url":"https://arxiv.org/pdf/2311.11701v1.pdf","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.11691v1","updated":"2023-11-20T11:44:01Z","published":"2023-11-20T11:44:01Z","title":"Towards Robust Text Retrieval with Progressive Learning","summary":"  Retrieval augmentation has become an effective solution to empower large\nlanguage models (LLMs) with external and verified knowledge sources from the\ndatabase, which overcomes the limitations and hallucinations of LLMs in\nhandling up-to-date and domain-specific information. However, existing\nembedding models for text retrieval usually have three non-negligible\nlimitations. First, the number and diversity of samples in a batch are too\nrestricted to supervise the modeling of textual nuances at scale. Second, the\nhigh proportional noise are detrimental to the semantic correctness and\nconsistency of embeddings. Third, the equal treatment to easy and difficult\nsamples would cause sub-optimum convergence of embeddings with poorer\ngeneralization. In this paper, we propose the PEG, a progressively learned\nembeddings for robust text retrieval. Specifically, we increase the training\nin-batch negative samples to 80,000, and for each query, we extracted five hard\nnegatives. Concurrently, we incorporated a progressive learning mechanism,\nenabling the model to dynamically modulate its attention to the samples\nthroughout the entire training process. Additionally, PEG is trained on more\nthan 100 million data, encompassing a wide range of domains (e.g., finance,\nmedicine, and tourism) and covering various tasks (e.g., question-answering,\nmachine reading comprehension, and similarity matching). Extensive experiments\nconducted on C-MTEB and DuReader demonstrate that PEG surpasses\nstate-of-the-art embeddings in retrieving true positives, highlighting its\nsignificant potential for applications in LLMs. Our model is publicly available\nat https://huggingface.co/TownsWu/PEG.\n","authors":["Tong Wu","Yulei Qin","Enwei Zhang","Zihan Xu","Yuting Gao","Ke Li","Xing Sun"],"pdf_url":"https://arxiv.org/pdf/2311.11691v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.08302v2","updated":"2023-11-20T23:52:58Z","published":"2023-11-14T16:46:10Z","title":"Inverse Learning with Extremely Sparse Feedback for Recommendation","summary":"  Modern personalized recommendation services often rely on user feedback,\neither explicit or implicit, to improve the quality of services. Explicit\nfeedback refers to behaviors like ratings, while implicit feedback refers to\nbehaviors like user clicks. However, in the scenario of full-screen video\nviewing experiences like Tiktok and Reels, the click action is absent,\nresulting in unclear feedback from users, hence introducing noises in modeling\ntraining. Existing approaches on de-noising recommendation mainly focus on\npositive instances while ignoring the noise in a large amount of sampled\nnegative feedback. In this paper, we propose a meta-learning method to annotate\nthe unlabeled data from loss and gradient perspectives, which considers the\nnoises in both positive and negative instances. Specifically, we first propose\nan Inverse Dual Loss (IDL) to boost the true label learning and prevent the\nfalse label learning. Then we further propose an Inverse Gradient (IG) method\nto explore the correct updating gradient and adjust the updating based on\nmeta-learning. Finally, we conduct extensive experiments on both benchmark and\nindustrial datasets where our proposed method can significantly improve AUC by\n9.25% against state-of-the-art methods. Further analysis verifies the proposed\ninverse learning framework is model-agnostic and can improve a variety of\nrecommendation backbones. The source code, along with the best hyper-parameter\nsettings, is available at this link:\nhttps://github.com/Guanyu-Lin/InverseLearning.\n","authors":["Guanyu Lin","Chen Gao","Yu Zheng","Yinfeng Li","Jianxin Chang","Yanan Niu","Yang Song","Kun Gai","Zhiheng Li","Depeng Jin","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2311.08302v2.pdf","comment":"WSDM 2024"},{"id":"http://arxiv.org/abs/2311.12159v1","updated":"2023-11-20T20:24:45Z","published":"2023-11-20T20:24:45Z","title":"Conditional Modeling Based Automatic Video Summarization","summary":"  The aim of video summarization is to shorten videos automatically while\nretaining the key information necessary to convey the overall story. Video\nsummarization methods mainly rely on visual factors, such as visual\nconsecutiveness and diversity, which may not be sufficient to fully understand\nthe content of the video. There are other non-visual factors, such as\ninterestingness, representativeness, and storyline consistency that should also\nbe considered for generating high-quality video summaries. Current methods do\nnot adequately take into account these non-visual factors, resulting in\nsuboptimal performance. In this work, a new approach to video summarization is\nproposed based on insights gained from how humans create ground truth video\nsummaries. The method utilizes a conditional modeling perspective and\nintroduces multiple meaningful random variables and joint distributions to\ncharacterize the key components of video summarization. Helper distributions\nare employed to improve the training of the model. A conditional attention\nmodule is designed to mitigate potential performance degradation in the\npresence of multi-modal input. The proposed video summarization method\nincorporates the above innovative design choices that aim to narrow the gap\nbetween human-generated and machine-generated video summaries. Extensive\nexperiments show that the proposed approach outperforms existing methods and\nachieves state-of-the-art performance on commonly used video summarization\ndatasets.\n","authors":["Jia-Hong Huang","Chao-Han Huck Yang","Pin-Yu Chen","Min-Hung Chen","Marcel Worring"],"pdf_url":"https://arxiv.org/pdf/2311.12159v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  arXiv admin note: substantial text overlap with arXiv:2305.00455"},{"id":"http://arxiv.org/abs/2311.12136v1","updated":"2023-11-20T19:37:57Z","published":"2023-11-20T19:37:57Z","title":"Multi-view Graph Convolution for Participant Recommendation","summary":"  Social networks have become essential for people's lives. The proliferation\nof web services further expands social networks at an unprecedented scale,\nleading to immeasurable commercial value for online platforms. Recently, the\ngroup buying (GB) business mode is prevalent and also becoming more popular in\nE-commerce. GB explicitly forms groups of users with similar interests to\nsecure better discounts from the merchants, often operating within social\nnetworks. It is a novel way to further unlock the commercial value by\nexplicitly utilizing the online social network in E-commerce. Participant\nrecommendation, a fundamental problem emerging together with GB, aims to find\nthe participants for a launched group buying process with an initiator and a\ntarget item to increase the GB success rate. This paper proposes Multi-View\nGraph Convolution for Participant Recommendation (MVPRec) to tackle this\nproblem. To differentiate the roles of users (Initiator/Participant) within the\nGB process, we explicitly reconstruct historical GB data into initiator-view\nand participant-view graphs. Together with the social graph, we obtain a\nmulti-view user representation with graph encoders. Then MVPRec fuses the GB\nand social representation with an attention module to obtain the user\nrepresentation and learns a matching score with the initiator's social friends\nvia a multi-head attention mechanism. Social friends with the Top-k matching\nscore are recommended for the corresponding GB process. Experiments on three\ndatasets justify the effectiveness of MVPRec in the emerging participant\nrecommendation problem.\n","authors":["Xiaolong Liu","Liangwei Yang","Chen Wang","Mingdai Yang","Zhiwei Liu","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2311.12136v1.pdf","comment":"10 pages, 5 figures, 2023 IEEE International Conference on Big Data"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2311.12028v1","updated":"2023-11-20T18:59:51Z","published":"2023-11-20T18:59:51Z","title":"Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose\n  Estimation","summary":"  Transformers have been successfully applied in the field of video-based 3D\nhuman pose estimation. However, the high computational costs of these video\npose transformers (VPTs) make them impractical on resource-constrained devices.\nIn this paper, we present a plug-and-play pruning-and-recovering framework,\ncalled Hourglass Tokenizer (HoT), for efficient transformer-based 3D human pose\nestimation from videos. Our HoT begins with pruning pose tokens of redundant\nframes and ends with recovering full-length tokens, resulting in a few pose\ntokens in the intermediate transformer blocks and thus improving the model\nefficiency. To effectively achieve this, we propose a token pruning cluster\n(TPC) that dynamically selects a few representative tokens with high semantic\ndiversity while eliminating the redundancy of video frames. In addition, we\ndevelop a token recovering attention (TRA) to restore the detailed\nspatio-temporal information based on the selected tokens, thereby expanding the\nnetwork output to the original full-length temporal resolution for fast\ninference. Extensive experiments on two benchmark datasets (i.e., Human3.6M and\nMPI-INF-3DHP) demonstrate that our method can achieve both high efficiency and\nestimation accuracy compared to the original VPT models. For instance, applying\nto MotionBERT and MixSTE on Human3.6M, our HoT can save nearly 50% FLOPs\nwithout sacrificing accuracy and nearly 40% FLOPs with only 0.2% accuracy drop,\nrespectively. Our source code will be open-sourced.\n","authors":["Wenhao Li","Mengyuan Liu","Hong Liu","Pichao Wang","Jialun Cai","Nicu Sebe"],"pdf_url":"https://arxiv.org/pdf/2311.12028v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12023v1","updated":"2023-11-20T18:57:41Z","published":"2023-11-20T18:57:41Z","title":"LQ-LoRA: Low-rank Plus Quantized Matrix Decomposition for Efficient\n  Language Model Finetuning","summary":"  We propose a simple approach for memory-efficient adaptation of pretrained\nlanguage models. Our approach uses an iterative algorithm to decompose each\npretrained matrix into a high-precision low-rank component and a\nmemory-efficient quantized component. During finetuning, the quantized\ncomponent remains fixed and only the low-rank component is updated. We present\nan integer linear programming formulation of the quantization component which\nenables dynamic configuration of quantization parameters (e.g., bit-width,\nblock size) for each matrix given an overall target memory budget. We further\nexplore a data-aware version of the algorithm which uses an approximation of\nthe Fisher information matrix to weight the reconstruction objective during\nmatrix decomposition. Experiments on adapting RoBERTa and LLaMA-2 (7B and 70B)\ndemonstrate that our low-rank plus quantized matrix decomposition approach\n(LQ-LoRA) outperforms strong QLoRA and GPTQ-LoRA baselines and moreover enables\nmore aggressive quantization. For example, on the OpenAssistant benchmark\nLQ-LoRA is able to learn a 2.5-bit LLaMA-2 model that is competitive with a\nmodel finetuned with 4-bit QLoRA. When finetuned on a language modeling\ncalibration dataset, LQ-LoRA can also be used for model compression; in this\nsetting our 2.75-bit LLaMA-2-70B model (which has 2.85 bits on average when\nincluding the low-rank components and requires 27GB of GPU memory) is\ncompetitive with the original model in full precision.\n","authors":["Han Guo","Philip Greengard","Eric P. Xing","Yoon Kim"],"pdf_url":"https://arxiv.org/pdf/2311.12023v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.15127v2","updated":"2023-11-20T18:51:29Z","published":"2023-10-23T17:31:55Z","title":"Open-Ended Instructable Embodied Agents with Memory-Augmented Large\n  Language Models","summary":"  Pre-trained and frozen large language models (LLMs) can effectively map\nsimple scene rearrangement instructions to programs over a robot's visuomotor\nfunctions through appropriate few-shot example prompting. To parse open-domain\nnatural language and adapt to a user's idiosyncratic procedures, not known\nduring prompt engineering time, fixed prompts fall short. In this paper, we\nintroduce HELPER, an embodied agent equipped with an external memory of\nlanguage-program pairs that parses free-form human-robot dialogue into action\nprograms through retrieval-augmented LLM prompting: relevant memories are\nretrieved based on the current dialogue, instruction, correction, or VLM\ndescription, and used as in-context prompt examples for LLM querying. The\nmemory is expanded during deployment to include pairs of user's language and\naction plans, to assist future inferences and personalize them to the user's\nlanguage and routines. HELPER sets a new state-of-the-art in the TEACh\nbenchmark in both Execution from Dialog History (EDH) and Trajectory from\nDialogue (TfD), with a 1.7x improvement over the previous state-of-the-art for\nTfD. Our models, code, and video results can be found in our project's website:\nhttps://helper-agent-llm.github.io.\n","authors":["Gabriel Sarch","Yue Wu","Michael J. Tarr","Katerina Fragkiadaki"],"pdf_url":"https://arxiv.org/pdf/2310.15127v2.pdf","comment":"Project page with code & videos: https://helper-agent-llm.github.io"},{"id":"http://arxiv.org/abs/2311.12004v1","updated":"2023-11-20T18:36:10Z","published":"2023-11-20T18:36:10Z","title":"Risk-averse Batch Active Inverse Reward Design","summary":"  Designing a perfect reward function that depicts all the aspects of the\nintended behavior is almost impossible, especially generalizing it outside of\nthe training environments. Active Inverse Reward Design (AIRD) proposed the use\nof a series of queries, comparing possible reward functions in a single\ntraining environment. This allows the human to give information to the agent\nabout suboptimal behaviors, in order to compute a probability distribution over\nthe intended reward function. However, it ignores the possibility of unknown\nfeatures appearing in real-world environments, and the safety measures needed\nuntil the agent completely learns the reward function. I improved this method\nand created Risk-averse Batch Active Inverse Reward Design (RBAIRD), which\nconstructs batches, sets of environments the agent encounters when being used\nin the real world, processes them sequentially, and, for a predetermined number\nof iterations, asks queries that the human needs to answer for each environment\nof the batch. After this process is completed in one batch, the probabilities\nhave been improved and are transferred to the next batch. This makes it capable\nof adapting to real-world scenarios and learning how to treat unknown features\nit encounters for the first time. I also integrated a risk-averse planner,\nsimilar to that of Inverse Reward Design (IRD), which samples a set of reward\nfunctions from the probability distribution and computes a trajectory that\ntakes the most certain rewards possible. This ensures safety while the agent is\nstill learning the reward function, and enables the use of this approach in\nsituations where cautiousness is vital. RBAIRD outperformed the previous\napproaches in terms of efficiency, accuracy, and action certainty, demonstrated\nquick adaptability to new, unknown features, and can be more widely used for\nthe alignment of crucial, powerful AI models.\n","authors":["Panagiotis Liampas"],"pdf_url":"https://arxiv.org/pdf/2311.12004v1.pdf","comment":"14 pages, 12 figures"},{"id":"http://arxiv.org/abs/2311.11995v1","updated":"2023-11-20T18:26:01Z","published":"2023-11-20T18:26:01Z","title":"BrainWash: A Poisoning Attack to Forget in Continual Learning","summary":"  Continual learning has gained substantial attention within the deep learning\ncommunity, offering promising solutions to the challenging problem of\nsequential learning. Yet, a largely unexplored facet of this paradigm is its\nsusceptibility to adversarial attacks, especially with the aim of inducing\nforgetting. In this paper, we introduce \"BrainWash,\" a novel data poisoning\nmethod tailored to impose forgetting on a continual learner. By adding the\nBrainWash noise to a variety of baselines, we demonstrate how a trained\ncontinual learner can be induced to forget its previously learned tasks\ncatastrophically, even when using these continual learning baselines. An\nimportant feature of our approach is that the attacker requires no access to\nprevious tasks' data and is armed merely with the model's current parameters\nand the data belonging to the most recent task. Our extensive experiments\nhighlight the efficacy of BrainWash, showcasing degradation in performance\nacross various regularization-based continual learning methods.\n","authors":["Ali Abbasi","Parsa Nooralinejad","Hamed Pirsiavash","Soheil Kolouri"],"pdf_url":"https://arxiv.org/pdf/2311.11995v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11992v1","updated":"2023-11-20T18:23:41Z","published":"2023-11-20T18:23:41Z","title":"Exploring Lip Segmentation Techniques in Computer Vision: A Comparative\n  Analysis","summary":"  Lip segmentation is crucial in computer vision, especially for lip reading.\nDespite extensive face segmentation research, lip segmentation has received\nlimited attention. The aim of this study is to compare state-of-the-art lip\nsegmentation models using a standardized setting and a publicly available\ndataset. Five techniques, namely EHANet, Mask2Former, BiSeNet V2, PIDNet, and\nSTDC1, are qualitatively selected based on their reported performance,\ninference time, code availability, recency, and popularity. The CelebAMask-HQ\ndataset, comprising manually annotated face images, is used to fairly assess\nthe lip segmentation performance of the selected models. Inference experiments\nare conducted on a Raspberry Pi4 to emulate limited computational resources.\nThe results show that Mask2Former and EHANet have the best performances in\nterms of mIoU score. BiSeNet V2 demonstrate competitive performance, while\nPIDNet excels in recall but has lower precision. Most models present inference\ntime ranging from 1000 to around 3000 milliseconds on a Raspberry Pi4, with\nPIDNet having the lowest mean inference time. This study provides a\ncomprehensive evaluation of lip segmentation models, highlighting their\nperformance and inference times. The findings contribute to the development of\nlightweight techniques and establish benchmarks for future advances in lip\nsegmentation, especially in IoT and edge computing scenarios.\n","authors":["Pietro B. S. Masur","Francisco Braulio Oliveira","Lucas Moreira Medino","Emanuel Huber","Milene Haraguchi Padilha","Cassio de Alcantara","Renata Sellaro"],"pdf_url":"https://arxiv.org/pdf/2311.11992v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11990v1","updated":"2023-11-20T18:21:53Z","published":"2023-11-20T18:21:53Z","title":"Machine-Learned Atomic Cluster Expansion Potentials for Fast and\n  Quantum-Accurate Thermal Simulations of Wurtzite AlN","summary":"  Using the atomic cluster expansion (ACE) framework, we develop a machine\nlearning interatomic potential for fast and accurately modelling the phonon\ntransport properties of wurtzite aluminum nitride. The predictive power of the\nACE potential against density functional theory (DFT) is demonstrated across a\nbroad range of properties of w-AlN, including ground-state lattice parameters,\nspecific heat capacity, coefficients of thermal expansion, bulk modulus, and\nharmonic phonon dispersions. Validation of lattice thermal conductivity is\nfurther carried out by comparing the ACE-predicted values to the DFT\ncalculations and experiments, exhibiting the overall capability of our ACE\npotential in sufficiently describing anharmonic phonon interactions. As a\npractical application, we perform a lattice dynamics analysis using the\npotential to unravel the effects of biaxial strains on thermal conductivity and\nphonon properties of w-AlN, which is identified as a significant tuning factor\nfor near-junction thermal design of w-AlN-based electronics.\n","authors":["Guang Yang","Yuan-Bin Liu","Lei Yang","Bing-Yang Cao"],"pdf_url":"https://arxiv.org/pdf/2311.11990v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11980v1","updated":"2023-11-20T18:14:53Z","published":"2023-11-20T18:14:53Z","title":"Leveraging Previous Facial Action Units Knowledge for Emotion\n  Recognition on Faces","summary":"  People naturally understand emotions, thus permitting a machine to do the\nsame could open new paths for human-computer interaction. Facial expressions\ncan be very useful for emotion recognition techniques, as these are the biggest\ntransmitters of non-verbal cues capable of being correlated with emotions.\nSeveral techniques are based on Convolutional Neural Networks (CNNs) to extract\ninformation in a machine learning process. However, simple CNNs are not always\nsufficient to locate points of interest on the face that can be correlated with\nemotions. In this work, we intend to expand the capacity of emotion recognition\ntechniques by proposing the usage of Facial Action Units (AUs) recognition\ntechniques to recognize emotions. This recognition will be based on the Facial\nAction Coding System (FACS) and computed by a machine learning system. In\nparticular, our method expands over EmotiRAM, an approach for multi-cue emotion\nrecognition, in which we improve over their facial encoding module.\n","authors":["Pietro B. S. Masur","Willams Costa","Lucas S. Figueredo","Veronica Teichrieb"],"pdf_url":"https://arxiv.org/pdf/2311.11980v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11974v1","updated":"2023-11-20T18:02:20Z","published":"2023-11-20T18:02:20Z","title":"Evaluating Supervision Levels Trade-Offs for Infrared-Based People\n  Counting","summary":"  Object detection models are commonly used for people counting (and\nlocalization) in many applications but require a dataset with costly bounding\nbox annotations for training. Given the importance of privacy in people\ncounting, these models rely more and more on infrared images, making the task\neven harder. In this paper, we explore how weaker levels of supervision can\naffect the performance of deep person counting architectures for image\nclassification and point-level localization. Our experiments indicate that\ncounting people using a CNN Image-Level model achieves competitive results with\nYOLO detectors and point-level models, yet provides a higher frame rate and a\nsimilar amount of model parameters.\n","authors":["David Latortue","Moetez Kdayem","Fidel A Guerrero Peña","Eric Granger","Marco Pedersoli"],"pdf_url":"https://arxiv.org/pdf/2311.11974v1.pdf","comment":"Accepted in IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV) 2024"},{"id":"http://arxiv.org/abs/2311.11973v1","updated":"2023-11-20T18:01:29Z","published":"2023-11-20T18:01:29Z","title":"Adaptive Training Distributions with Scalable Online Bilevel\n  Optimization","summary":"  Large neural networks pretrained on web-scale corpora are central to modern\nmachine learning. In this paradigm, the distribution of the large,\nheterogeneous pretraining data rarely matches that of the application domain.\nThis work considers modifying the pretraining distribution in the case where\none has a small sample of data reflecting the targeted test conditions. We\npropose an algorithm motivated by a recent formulation of this setting as an\nonline, bilevel optimization problem. With scalability in mind, our algorithm\nprioritizes computing gradients at training points which are likely to most\nimprove the loss on the targeted distribution. Empirically, we show that in\nsome cases this approach is beneficial over existing strategies from the domain\nadaptation literature but may not succeed in other cases. We propose a simple\ntest to evaluate when our approach can be expected to work well and point\ntowards further research to address current limitations.\n","authors":["David Grangier","Pierre Ablin","Awni Hannun"],"pdf_url":"https://arxiv.org/pdf/2311.11973v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04292v2","updated":"2023-11-20T17:45:37Z","published":"2023-03-07T23:54:35Z","title":"ERUDITE: Human-in-the-Loop IoT for an Adaptive Personalized Learning\n  System","summary":"  Thanks to the rapid growth in wearable technologies and recent advancement in\nmachine learning and signal processing, monitoring complex human contexts\nbecomes feasible, paving the way to develop human-in-the-loop IoT systems that\nnaturally evolve to adapt to the human and environment state autonomously.\nNevertheless, a central challenge in designing many of these IoT systems arises\nfrom the requirement to infer the human mental state, such as intention,\nstress, cognition load, or learning ability. While different human contexts can\nbe inferred from the fusion of different sensor modalities that can correlate\nto a particular mental state, the human brain provides a richer sensor modality\nthat gives us more insights into the required human context. This paper\nproposes ERUDITE, a human-in-the-loop IoT system for the learning environment\nthat exploits recent wearable neurotechnology to decode brain signals. Through\ninsights from concept learning theory, ERUDITE can infer the human state of\nlearning and understand when human learning increases or declines. By\nquantifying human learning as an input sensory signal, ERUDITE can provide\nadequate personalized feedback to humans in a learning environment to enhance\ntheir learning experience. ERUDITE is evaluated across $15$ participants and\nshowed that by using the brain signals as a sensor modality to infer the human\nlearning state and providing personalized adaptation to the learning\nenvironment, the participants' learning performance increased on average by\n$26\\%$. Furthermore, we showed that ERUDITE can be deployed on an edge-based\nprototype to evaluate its practicality and scalability.\n","authors":["Mojtaba Taherisadr","Mohammad Abdullah Al Faruque","Salma Elmalaki"],"pdf_url":"https://arxiv.org/pdf/2303.04292v2.pdf","comment":"It is under review in the IEEE IoT journal"},{"id":"http://arxiv.org/abs/2311.11965v1","updated":"2023-11-20T17:44:40Z","published":"2023-11-20T17:44:40Z","title":"Provably Efficient CVaR RL in Low-rank MDPs","summary":"  We study risk-sensitive Reinforcement Learning (RL), where we aim to maximize\nthe Conditional Value at Risk (CVaR) with a fixed risk tolerance $\\tau$. Prior\ntheoretical work studying risk-sensitive RL focuses on the tabular Markov\nDecision Processes (MDPs) setting. To extend CVaR RL to settings where state\nspace is large, function approximation must be deployed. We study CVaR RL in\nlow-rank MDPs with nonlinear function approximation. Low-rank MDPs assume the\nunderlying transition kernel admits a low-rank decomposition, but unlike prior\nlinear models, low-rank MDPs do not assume the feature or state-action\nrepresentation is known. We propose a novel Upper Confidence Bound (UCB)\nbonus-driven algorithm to carefully balance the interplay between exploration,\nexploitation, and representation learning in CVaR RL. We prove that our\nalgorithm achieves a sample complexity of $\\tilde{O}\\left(\\frac{H^7 A^2\nd^4}{\\tau^2 \\epsilon^2}\\right)$ to yield an $\\epsilon$-optimal CVaR, where $H$\nis the length of each episode, $A$ is the capacity of action space, and $d$ is\nthe dimension of representations. Computational-wise, we design a novel\ndiscretized Least-Squares Value Iteration (LSVI) algorithm for the CVaR\nobjective as the planning oracle and show that we can find the near-optimal\npolicy in a polynomial running time with a Maximum Likelihood Estimation\noracle. To our knowledge, this is the first provably efficient CVaR RL\nalgorithm in low-rank MDPs.\n","authors":["Yulai Zhao","Wenhao Zhan","Xiaoyan Hu","Ho-fung Leung","Farzan Farnia","Wen Sun","Jason D. Lee"],"pdf_url":"https://arxiv.org/pdf/2311.11965v1.pdf","comment":"The first three authors contribute equally and are ordered randomly"},{"id":"http://arxiv.org/abs/2311.11963v1","updated":"2023-11-20T17:43:09Z","published":"2023-11-20T17:43:09Z","title":"What Can AutoML Do For Continual Learning?","summary":"  This position paper outlines the potential of AutoML for incremental\n(continual) learning to encourage more research in this direction. Incremental\nlearning involves incorporating new data from a stream of tasks and\ndistributions to learn enhanced deep representations and adapt better to new\ntasks. However, a significant limitation of incremental learners is that most\ncurrent techniques freeze the backbone architecture, hyperparameters, and the\norder & structure of the learning tasks throughout the learning and adaptation\nprocess. We strongly believe that AutoML offers promising solutions to address\nthese limitations, enabling incremental learning to adapt to more diverse\nreal-world tasks. Therefore, instead of directly proposing a new method, this\npaper takes a step back by posing the question: \"What can AutoML do for\nincremental learning?\" We outline three key areas of research that can\ncontribute to making incremental learners more dynamic, highlighting concrete\nopportunities to apply AutoML methods in novel ways as well as entirely new\nchallenges for AutoML research.\n","authors":["Mert Kilickaya","Joaquin Vanschoren"],"pdf_url":"https://arxiv.org/pdf/2311.11963v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.02249v2","updated":"2023-11-20T17:40:06Z","published":"2022-07-05T18:23:20Z","title":"Learning Task Embeddings for Teamwork Adaptation in Multi-Agent\n  Reinforcement Learning","summary":"  Successful deployment of multi-agent reinforcement learning often requires\nagents to adapt their behaviour. In this work, we discuss the problem of\nteamwork adaptation in which a team of agents needs to adapt their policies to\nsolve novel tasks with limited fine-tuning. Motivated by the intuition that\nagents need to be able to identify and distinguish tasks in order to adapt\ntheir behaviour to the current task, we propose to learn multi-agent task\nembeddings (MATE). These task embeddings are trained using an encoder-decoder\narchitecture optimised for reconstruction of the transition and reward\nfunctions which uniquely identify tasks. We show that a team of agents is able\nto adapt to novel tasks when provided with task embeddings. We propose three\nMATE training paradigms: independent MATE, centralised MATE, and mixed MATE\nwhich vary in the information used for the task encoding. We show that the\nembeddings learned by MATE identify tasks and provide useful information which\nagents leverage during adaptation to novel tasks.\n","authors":["Lukas Schäfer","Filippos Christianos","Amos Storkey","Stefano V. Albrecht"],"pdf_url":"https://arxiv.org/pdf/2207.02249v2.pdf","comment":"To be presented at the Seventh Workshop on Generalization in Planning\n  at the NeurIPS 2023 conference"},{"id":"http://arxiv.org/abs/2311.11961v1","updated":"2023-11-20T17:38:35Z","published":"2023-11-20T17:38:35Z","title":"NNG-Mix: Improving Semi-supervised Anomaly Detection with Pseudo-anomaly\n  Generation","summary":"  Anomaly detection (AD) is essential in identifying rare and often critical\nevents in complex systems, finding applications in fields such as network\nintrusion detection, financial fraud detection, and fault detection in\ninfrastructure and industrial systems. While AD is typically treated as an\nunsupervised learning task due to the high cost of label annotation, it is more\npractical to assume access to a small set of labeled anomaly samples from\ndomain experts, as is the case for semi-supervised anomaly detection.\nSemi-supervised and supervised approaches can leverage such labeled data,\nresulting in improved performance. In this paper, rather than proposing a new\nsemi-supervised or supervised approach for AD, we introduce a novel algorithm\nfor generating additional pseudo-anomalies on the basis of the limited labeled\nanomalies and a large volume of unlabeled data. This serves as an augmentation\nto facilitate the detection of new anomalies. Our proposed algorithm, named\nNearest Neighbor Gaussian Mixup (NNG-Mix), efficiently integrates information\nfrom both labeled and unlabeled data to generate pseudo-anomalies. We compare\nthe performance of this novel algorithm with commonly applied augmentation\ntechniques, such as Mixup and Cutout. We evaluate NNG-Mix by training various\nexisting semi-supervised and supervised anomaly detection algorithms on the\noriginal training data along with the generated pseudo-anomalies. Through\nextensive experiments on 57 benchmark datasets in ADBench, reflecting different\ndata types, we demonstrate that NNG-Mix outperforms other data augmentation\nmethods. It yields significant performance improvements compared to the\nbaselines trained exclusively on the original training data. Notably, NNG-Mix\nyields up to 16.4%, 8.8%, and 8.0% improvements on Classical, CV, and NLP\ndatasets in ADBench. Our source code will be available at\nhttps://github.com/donghao51/NNG-Mix.\n","authors":["Hao Dong","Gaëtan Frusque","Yue Zhao","Eleni Chatzi","Olga Fink"],"pdf_url":"https://arxiv.org/pdf/2311.11961v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11959v1","updated":"2023-11-20T17:35:44Z","published":"2023-11-20T17:35:44Z","title":"Correlated Attention in Transformers for Multivariate Time Series","summary":"  Multivariate time series (MTS) analysis prevails in real-world applications\nsuch as finance, climate science and healthcare. The various self-attention\nmechanisms, the backbone of the state-of-the-art Transformer-based models,\nefficiently discover the temporal dependencies, yet cannot well capture the\nintricate cross-correlation between different features of MTS data, which\ninherently stems from complex dynamical systems in practice. To this end, we\npropose a novel correlated attention mechanism, which not only efficiently\ncaptures feature-wise dependencies, but can also be seamlessly integrated\nwithin the encoder blocks of existing well-known Transformers to gain\nefficiency improvement. In particular, correlated attention operates across\nfeature channels to compute cross-covariance matrices between queries and keys\nwith different lag values, and selectively aggregate representations at the\nsub-series level. This architecture facilitates automated discovery and\nrepresentation learning of not only instantaneous but also lagged\ncross-correlations, while inherently capturing time series auto-correlation.\nWhen combined with prevalent Transformer baselines, correlated attention\nmechanism constitutes a better alternative for encoder-only architectures,\nwhich are suitable for a wide range of tasks including imputation, anomaly\ndetection and classification. Extensive experiments on the aforementioned tasks\nconsistently underscore the advantages of correlated attention mechanism in\nenhancing base Transformer models, and demonstrate our state-of-the-art results\nin imputation, anomaly detection and classification.\n","authors":["Quang Minh Nguyen","Lam M. Nguyen","Subhro Das"],"pdf_url":"https://arxiv.org/pdf/2311.11959v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.17113v2","updated":"2023-11-20T17:31:20Z","published":"2023-09-29T10:12:30Z","title":"Meta-Path Learning for Multi-relational Graph Neural Networks","summary":"  Existing multi-relational graph neural networks use one of two strategies for\nidentifying informative relations: either they reduce this problem to low-level\nweight learning, or they rely on handcrafted chains of relational dependencies,\ncalled meta-paths. However, the former approach faces challenges in the\npresence of many relations (e.g., knowledge graphs), while the latter requires\nsubstantial domain expertise to identify relevant meta-paths. In this work we\npropose a novel approach to learn meta-paths and meta-path GNNs that are highly\naccurate based on a small number of informative meta-paths. Key element of our\napproach is a scoring function for measuring the potential informativeness of a\nrelation in the incremental construction of the meta-path. Our experimental\nevaluation shows that the approach manages to correctly identify relevant\nmeta-paths even with a large number of relations, and substantially outperforms\nexisting multi-relational GNNs on synthetic and real-world experiments.\n","authors":["Francesco Ferrini","Antonio Longa","Andrea Passerini","Manfred Jaeger"],"pdf_url":"https://arxiv.org/pdf/2309.17113v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11934v1","updated":"2023-11-20T17:18:21Z","published":"2023-11-20T17:18:21Z","title":"Estimation of entropy-regularized optimal transport maps between\n  non-compactly supported measures","summary":"  This paper addresses the problem of estimating entropy-regularized optimal\ntransport (EOT) maps with squared-Euclidean cost between source and target\nmeasures that are subGaussian. In the case that the target measure is compactly\nsupported or strongly log-concave, we show that for a recently proposed\nin-sample estimator, the expected squared $L^2$-error decays at least as fast\nas $O(n^{-1/3})$ where $n$ is the sample size. For the general subGaussian case\nwe show that the expected $L^1$-error decays at least as fast as $O(n^{-1/6})$,\nand in both cases we have polynomial dependence on the regularization\nparameter. While these results are suboptimal compared to known results in the\ncase of compactness of both the source and target measures (squared $L^2$-error\nconverging at a rate $O(n^{-1})$) and for when the source is subGaussian while\nthe target is compactly supported (squared $L^2$-error converging at a rate\n$O(n^{-1/2})$), their importance lie in eliminating the compact support\nrequirements. The proof technique makes use of a bias-variance decomposition\nwhere the variance is controlled using standard concentration of measure\nresults and the bias is handled by T1-transport inequalities along with sample\ncomplexity results in estimation of EOT cost under subGaussian assumptions. Our\nexperimental results point to a looseness in controlling the variance terms and\nwe conclude by posing several open problems.\n","authors":["Matthew Werenski","James M. Murphy","Shuchin Aeron"],"pdf_url":"https://arxiv.org/pdf/2311.11934v1.pdf","comment":"30 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.11932v1","updated":"2023-11-20T17:17:29Z","published":"2023-11-20T17:17:29Z","title":"Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review\n  from the Perspectives of Key Features of Data Analysis and AI Assurance","summary":"  Background and objectives: By extracting this information, Machine or Deep\nLearning (ML/DL)-based autonomous data analysis tools can assist clinicians and\ncancer researchers in discovering patterns and relationships from complex data\nsets. Many DL-based analyses on ovarian cancer (OC) data have recently been\npublished. These analyses are highly diverse in various aspects of cancer\n(e.g., subdomain(s) and cancer type they address) and data analysis features.\nHowever, a comprehensive understanding of these analyses in terms of these\nfeatures and AI assurance (AIA) is currently lacking. This systematic review\naims to fill this gap by examining the existing literature and identifying\nimportant aspects of OC data analysis using DL, explicitly focusing on the key\nfeatures and AI assurance perspectives. Methods: The PRISMA framework was used\nto conduct comprehensive searches in three journal databases. Only studies\npublished between 2015 and 2023 in peer-reviewed journals were included in the\nanalysis. Results: In the review, a total of 96 DL-driven analyses were\nexamined. The findings reveal several important insights regarding DL-driven\novarian cancer data analysis: - Most studies 71% (68 out of 96) focused on\ndetection and diagnosis, while no study addressed the prediction and prevention\nof OC. - The analyses were predominantly based on samples from a non-diverse\npopulation (75% (72/96 studies)), limited to a geographic location or country.\n- Only a small proportion of studies (only 33% (32/96)) performed integrated\nanalyses, most of which used homogeneous data (clinical or omics). - Notably, a\nmere 8.3% (8/96) of the studies validated their models using external and\ndiverse data sets, highlighting the need for enhanced model validation, and -\nThe inclusion of AIA in cancer data analysis is in a very early stage; only\n2.1% (2/96) explicitly addressed AIA through explainability.\n","authors":["Muta Tah Hira","Mohammad A. Razzaque","Mosharraf Sarker"],"pdf_url":"https://arxiv.org/pdf/2311.11932v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.08176v4","updated":"2023-11-20T17:10:22Z","published":"2023-10-12T10:01:39Z","title":"Infinite Width Graph Neural Networks for Node Regression/ Classification","summary":"  This work analyzes Graph Neural Networks, a generalization of Fully-Connected\nDeep Neural Nets on Graph structured data, when their width, that is the number\nof nodes in each fullyconnected layer is increasing to infinity. Infinite Width\nNeural Networks are connecting Deep Learning to Gaussian Processes and Kernels,\nboth Machine Learning Frameworks with long traditions and extensive theoretical\nfoundations. Gaussian Processes and Kernels have much less hyperparameters then\nNeural Networks and can be used for uncertainty estimation, making them more\nuser friendly for applications. This works extends the increasing amount of\nresearch connecting Gaussian Processes and Kernels to Neural Networks. The\nKernel and Gaussian Process closed forms are derived for a variety of\narchitectures, namely the standard Graph Neural Network, the Graph Neural\nNetwork with Skip-Concatenate Connections and the Graph Attention Neural\nNetwork. All architectures are evaluated on a variety of datasets on the task\nof transductive Node Regression and Classification. Additionally, a Spectral\nSparsification method known as Effective Resistance is used to improve runtime\nand memory requirements. Extending the setting to inductive graph learning\ntasks (Graph Regression/ Classification) is straightforward and is briefly\ndiscussed in 3.5.\n","authors":["Yunus Cobanoglu"],"pdf_url":"https://arxiv.org/pdf/2310.08176v4.pdf","comment":"49 Pages, 2 Figures (with subfigures), multiple tables, v2: made\n  table of contents fit to one page and added derivatives on GAT*NTK and GAT*GP\n  in A.4, v3: shorten parts of introduction and fixed typos, added numberings\n  to equations and discussion section, v4: fix two missing citations on page 10"},{"id":"http://arxiv.org/abs/2305.17010v3","updated":"2023-11-20T16:57:12Z","published":"2023-05-26T15:13:09Z","title":"Let the Flows Tell: Solving Graph Combinatorial Optimization Problems\n  with GFlowNets","summary":"  Combinatorial optimization (CO) problems are often NP-hard and thus out of\nreach for exact algorithms, making them a tempting domain to apply machine\nlearning methods. The highly structured constraints in these problems can\nhinder either optimization or sampling directly in the solution space. On the\nother hand, GFlowNets have recently emerged as a powerful machinery to\nefficiently sample from composite unnormalized densities sequentially and have\nthe potential to amortize such solution-searching processes in CO, as well as\ngenerate diverse solution candidates. In this paper, we design Markov decision\nprocesses (MDPs) for different combinatorial problems and propose to train\nconditional GFlowNets to sample from the solution space. Efficient training\ntechniques are also developed to benefit long-range credit assignment. Through\nextensive experiments on a variety of different CO tasks with synthetic and\nrealistic data, we demonstrate that GFlowNet policies can efficiently find\nhigh-quality solutions. Our implementation is open-sourced at\nhttps://github.com/zdhNarsil/GFlowNet-CombOpt.\n","authors":["Dinghuai Zhang","Hanjun Dai","Nikolay Malkin","Aaron Courville","Yoshua Bengio","Ling Pan"],"pdf_url":"https://arxiv.org/pdf/2305.17010v3.pdf","comment":"Accepted by NeurIPS 2023 as spotlight"},{"id":"http://arxiv.org/abs/2311.11913v1","updated":"2023-11-20T16:44:18Z","published":"2023-11-20T16:44:18Z","title":"Deep Calibration of Market Simulations using Neural Density Estimators\n  and Embedding Networks","summary":"  The ability to construct a realistic simulator of financial exchanges,\nincluding reproducing the dynamics of the limit order book, can give insight\ninto many counterfactual scenarios, such as a flash crash, a margin call, or\nchanges in macroeconomic outlook. In recent years, agent-based models have been\ndeveloped that reproduce many features of an exchange, as summarised by a set\nof stylised facts and statistics. However, the ability to calibrate simulators\nto a specific period of trading remains an open challenge. In this work, we\ndevelop a novel approach to the calibration of market simulators by leveraging\nrecent advances in deep learning, specifically using neural density estimators\nand embedding networks. We demonstrate that our approach is able to correctly\nidentify high probability parameter sets, both when applied to synthetic and\nhistorical data, and without reliance on manually selected or weighted\nensembles of stylised facts.\n","authors":["Namid R. Stillman","Rory Baggott","Justin Lyon","Jianfei Zhang","Dingqiu Zhu","Tao Chen","Perukrishnen Vytelingum"],"pdf_url":"https://arxiv.org/pdf/2311.11913v1.pdf","comment":"4th ACM International Conference on AI in Finance (ICAIF 2023)"},{"id":"http://arxiv.org/abs/2311.11911v1","updated":"2023-11-20T16:41:54Z","published":"2023-11-20T16:41:54Z","title":"Certification of Distributional Individual Fairness","summary":"  Providing formal guarantees of algorithmic fairness is of paramount\nimportance to socially responsible deployment of machine learning algorithms.\nIn this work, we study formal guarantees, i.e., certificates, for individual\nfairness (IF) of neural networks. We start by introducing a novel convex\napproximation of IF constraints that exponentially decreases the computational\ncost of providing formal guarantees of local individual fairness. We highlight\nthat prior methods are constrained by their focus on global IF certification\nand can therefore only scale to models with a few dozen hidden neurons, thus\nlimiting their practical impact. We propose to certify distributional\nindividual fairness which ensures that for a given empirical distribution and\nall distributions within a $\\gamma$-Wasserstein ball, the neural network has\nguaranteed individually fair predictions. Leveraging developments in\nquasi-convex optimization, we provide novel and efficient certified bounds on\ndistributional individual fairness and show that our method allows us to\ncertify and regularize neural networks that are several orders of magnitude\nlarger than those considered by prior works. Moreover, we study real-world\ndistribution shifts and find our bounds to be a scalable, practical, and sound\nsource of IF guarantees.\n","authors":["Matthew Wicker","Vihari Piratia","Adrian Weller"],"pdf_url":"https://arxiv.org/pdf/2311.11911v1.pdf","comment":"21 Pages, Neural Information Processing Systems 2023"},{"id":"http://arxiv.org/abs/2311.11908v1","updated":"2023-11-20T16:40:29Z","published":"2023-11-20T16:40:29Z","title":"Continual Learning: Applications and the Road Forward","summary":"  Continual learning is a sub-field of machine learning, which aims to allow\nmachine learning models to continuously learn on new data, by accumulating\nknowledge without forgetting what was learned in the past. In this work, we\ntake a step back, and ask: \"Why should one care about continual learning in the\nfirst place?\". We set the stage by surveying recent continual learning papers\npublished at three major machine learning conferences, and show that\nmemory-constrained settings dominate the field. Then, we discuss five open\nproblems in machine learning, and even though they seem unrelated to continual\nlearning at first sight, we show that continual learning will inevitably be\npart of their solution. These problems are model-editing, personalization,\non-device learning, faster (re-)training and reinforcement learning. Finally,\nby comparing the desiderata from these unsolved problems and the current\nassumptions in continual learning, we highlight and discuss four future\ndirections for continual learning research. We hope that this work offers an\ninteresting perspective on the future of continual learning, while displaying\nits potential value and the paths we have to pursue in order to make it\nsuccessful. This work is the result of the many discussions the authors had at\nthe Dagstuhl seminar on Deep Continual Learning, in March 2023.\n","authors":["Eli Verwimp","Shai Ben-David","Matthias Bethge","Andrea Cossu","Alexander Gepperth","Tyler L. Hayes","Eyke Hüllermeier","Christopher Kanan","Dhireesha Kudithipudi","Christoph H. Lampert","Martin Mundt","Razvan Pascanu","Adrian Popescu","Andreas S. Tolias","Joost van de Weijer","Bing Liu","Vincenzo Lomonaco","Tinne Tuytelaars","Gido M. van de Ven"],"pdf_url":"https://arxiv.org/pdf/2311.11908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11905v1","updated":"2023-11-20T16:38:45Z","published":"2023-11-20T16:38:45Z","title":"Real-Time Surface-to-Air Missile Engagement Zone Prediction Using\n  Simulation and Machine Learning","summary":"  Surface-to-Air Missiles (SAMs) are crucial in modern air defense systems. A\ncritical aspect of their effectiveness is the Engagement Zone (EZ), the spatial\nregion within which a SAM can effectively engage and neutralize a target.\nNotably, the EZ is intrinsically related to the missile's maximum range; it\ndefines the furthest distance at which a missile can intercept a target. The\naccurate computation of this EZ is essential but challenging due to the dynamic\nand complex factors involved, which often lead to high computational costs and\nextended processing times when using conventional simulation methods. In light\nof these challenges, our study investigates the potential of machine learning\ntechniques, proposing an approach that integrates machine learning with a\ncustom-designed simulation tool to train supervised algorithms. We leverage a\ncomprehensive dataset of pre-computed SAM EZ simulations, enabling our model to\naccurately predict the SAM EZ for new input parameters. It accelerates SAM EZ\nsimulations, enhances air defense strategic planning, and provides real-time\ninsights, improving SAM system performance. The study also includes a\ncomparative analysis of machine learning algorithms, illuminating their\ncapabilities and performance metrics and suggesting areas for future research,\nhighlighting the transformative potential of machine learning in SAM EZ\nsimulations.\n","authors":["Joao P. A. Dantas","Diego Geraldo","Felipe L. L. Medeiros","Marcos R. O. A. Maximo","Takashi Yoneyama"],"pdf_url":"https://arxiv.org/pdf/2311.11905v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11904v1","updated":"2023-11-20T16:37:45Z","published":"2023-11-20T16:37:45Z","title":"LLMs as Visual Explainers: Advancing Image Classification with Evolving\n  Visual Descriptions","summary":"  Vision-language models (VLMs) offer a promising paradigm for image\nclassification by comparing the similarity between images and class embeddings.\nA critical challenge lies in crafting precise textual representations for class\nnames. While previous studies have leveraged recent advancements in large\nlanguage models (LLMs) to enhance these descriptors, their outputs often suffer\nfrom ambiguity and inaccuracy. We identify two primary causes: 1) The prevalent\nreliance on textual interactions with LLMs, leading to a mismatch between the\ngenerated text and the visual content in VLMs' latent space - a phenomenon we\nterm the \"explain without seeing\" dilemma. 2) The oversight of the inter-class\nrelationships, resulting in descriptors that fail to differentiate similar\nclasses effectively. To address these issues, we propose a novel image\nclassification framework combining VLMs with LLMs, named Iterative Optimization\nwith Visual Feedback. In particular, our method develops an LLM-based agent,\nemploying an evolutionary optimization strategy to refine class descriptors.\nCrucially, we incorporate visual feedback from VLM classification metrics,\nthereby guiding the optimization process with concrete visual data. Our method\nleads to improving accuracy on a wide range of image classification benchmarks,\nwith 3.47\\% average gains over state-of-the-art methods. We also highlight the\nresulting descriptions serve as explainable and robust features that can\nconsistently improve the performance across various backbone models.\n","authors":["Songhao Han","Le Zhuo","Yue Liao","Si Liu"],"pdf_url":"https://arxiv.org/pdf/2311.11904v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11900v1","updated":"2023-11-20T16:34:48Z","published":"2023-11-20T16:34:48Z","title":"Measuring and Mitigating Biases in Motor Insurance Pricing","summary":"  The non-life insurance sector operates within a highly competitive and\ntightly regulated framework, confronting a pivotal juncture in the formulation\nof pricing strategies. Insurers are compelled to harness a range of statistical\nmethodologies and available data to construct optimal pricing structures that\nalign with the overarching corporate strategy while accommodating the dynamics\nof market competition. Given the fundamental societal role played by insurance,\npremium rates are subject to rigorous scrutiny by regulatory authorities. These\nrates must conform to principles of transparency, explainability, and ethical\nconsiderations. Consequently, the act of pricing transcends mere statistical\ncalculations and carries the weight of strategic and societal factors. These\nmultifaceted concerns may drive insurers to establish equitable premiums,\ntaking into account various variables. For instance, regulations mandate the\nprovision of equitable premiums, considering factors such as policyholder\ngender or mutualist group dynamics in accordance with respective corporate\nstrategies. Age-based premium fairness is also mandated. In certain insurance\ndomains, variables such as the presence of serious illnesses or disabilities\nare emerging as new dimensions for evaluating fairness. Regardless of the\nmotivating factor prompting an insurer to adopt fairer pricing strategies for a\nspecific variable, the insurer must possess the capability to define, measure,\nand ultimately mitigate any ethical biases inherent in its pricing practices\nwhile upholding standards of consistency and performance. This study seeks to\nprovide a comprehensive set of tools for these endeavors and assess their\neffectiveness through practical application in the context of automobile\ninsurance.\n","authors":["Mulah Moriah","Franck Vermet","Arthur Charpentier"],"pdf_url":"https://arxiv.org/pdf/2311.11900v1.pdf","comment":"37 pages"},{"id":"http://arxiv.org/abs/2311.11891v1","updated":"2023-11-20T16:24:23Z","published":"2023-11-20T16:24:23Z","title":"AMES: A Differentiable Embedding Space Selection Framework for Latent\n  Graph Inference","summary":"  In real-world scenarios, although data entities may possess inherent\nrelationships, the specific graph illustrating their connections might not be\ndirectly accessible. Latent graph inference addresses this issue by enabling\nGraph Neural Networks (GNNs) to operate on point cloud data, dynamically\nlearning the necessary graph structure. These graphs are often derived from a\nlatent embedding space, which can be modeled using Euclidean, hyperbolic,\nspherical, or product spaces. However, currently, there is no principled\ndifferentiable method for determining the optimal embedding space. In this\nwork, we introduce the Attentional Multi-Embedding Selection (AMES) framework,\na differentiable method for selecting the best embedding space for latent graph\ninference through backpropagation, considering a downstream task. Our framework\nconsistently achieves comparable or superior results compared to previous\nmethods for latent graph inference across five benchmark datasets. Importantly,\nour approach eliminates the need for conducting multiple experiments to\nidentify the optimal embedding space. Furthermore, we explore interpretability\ntechniques that track the gradient contributions of different latent graphs,\nshedding light on how our attention-based, fully differentiable approach learns\nto choose the appropriate latent space. In line with previous works, our\nexperiments emphasize the advantages of hyperbolic spaces in enhancing\nperformance. More importantly, our interpretability framework provides a\ngeneral approach for quantitatively comparing embedding spaces across different\ntasks based on their contributions, a dimension that has been overlooked in\nprevious literature on latent graph inference.\n","authors":["Yuan Lu","Haitz Sáez de Ocáriz Borde","Pietro Liò"],"pdf_url":"https://arxiv.org/pdf/2311.11891v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11883v1","updated":"2023-11-20T16:20:13Z","published":"2023-11-20T16:20:13Z","title":"Efficient Neural Networks for Tiny Machine Learning: A Comprehensive\n  Review","summary":"  The field of Tiny Machine Learning (TinyML) has gained significant attention\ndue to its potential to enable intelligent applications on resource-constrained\ndevices. This review provides an in-depth analysis of the advancements in\nefficient neural networks and the deployment of deep learning models on\nultra-low power microcontrollers (MCUs) for TinyML applications. It begins by\nintroducing neural networks and discussing their architectures and resource\nrequirements. It then explores MEMS-based applications on ultra-low power MCUs,\nhighlighting their potential for enabling TinyML on resource-constrained\ndevices. The core of the review centres on efficient neural networks for\nTinyML. It covers techniques such as model compression, quantization, and\nlow-rank factorization, which optimize neural network architectures for minimal\nresource utilization on MCUs. The paper then delves into the deployment of deep\nlearning models on ultra-low power MCUs, addressing challenges such as limited\ncomputational capabilities and memory resources. Techniques like model pruning,\nhardware acceleration, and algorithm-architecture co-design are discussed as\nstrategies to enable efficient deployment. Lastly, the review provides an\noverview of current limitations in the field, including the trade-off between\nmodel complexity and resource constraints. Overall, this review paper presents\na comprehensive analysis of efficient neural networks and deployment strategies\nfor TinyML on ultra-low-power MCUs. It identifies future research directions\nfor unlocking the full potential of TinyML applications on resource-constrained\ndevices.\n","authors":["Minh Tri Lê","Pierre Wolinski","Julyan Arbel"],"pdf_url":"https://arxiv.org/pdf/2311.11883v1.pdf","comment":"39 pages, 9 figures, 5 tables"},{"id":"http://arxiv.org/abs/2311.11882v1","updated":"2023-11-20T16:19:46Z","published":"2023-11-20T16:19:46Z","title":"Multi-Task Faces (MTF) Data Set: A Legally and Ethically Compliant\n  Collection of Face Images for Various Classification Tasks","summary":"  Human facial data hold tremendous potential to address a variety of\nclassification problems, including face recognition, age estimation, gender\nidentification, emotion analysis, and race classification. However, recent\nprivacy regulations, such as the EU General Data Protection Regulation and\nothers, have restricted the ways in which human images may be collected and\nused for research. As a result, several previously published data sets\ncontaining human faces have been removed from the internet due to inadequate\ndata collection methods that failed to meet privacy regulations. Data sets\nconsisting of synthetic data have been proposed as an alternative, but they\nfall short of accurately representing the real data distribution. On the other\nhand, most available data sets are labeled for just a single task, which limits\ntheir applicability. To address these issues, we present the Multi-Task Faces\n(MTF) image data set, a meticulously curated collection of face images designed\nfor various classification tasks, including face recognition, as well as race,\ngender, and age classification. The MTF data set has been ethically gathered by\nleveraging publicly available images of celebrities and strictly adhering to\ncopyright regulations. In this paper, we present this data set and provide\ndetailed descriptions of the followed data collection and processing\nprocedures. Furthermore, we evaluate the performance of five deep learning (DL)\nmodels on the MTF data set across the aforementioned classification tasks.\nAdditionally, we compare the performance of DL models over the processed MTF\ndata and over raw data crawled from the internet. The reported results\nconstitute a baseline for further research employing these data. The MTF data\nset can be accessed through the following link (please cite the present paper\nif you use the data set): https://github.com/RamiHaf/MTF_data_set\n","authors":["Rami Haffar","David Sánchez","Josep Domingo-Ferrer"],"pdf_url":"https://arxiv.org/pdf/2311.11882v1.pdf","comment":"21 pages, 2 figures, 9 Tables,"},{"id":"http://arxiv.org/abs/2310.18288v3","updated":"2023-11-20T16:17:38Z","published":"2023-10-27T17:25:12Z","title":"Sustainable Concrete via Bayesian Optimization","summary":"  Eight percent of global carbon dioxide emissions can be attributed to the\nproduction of cement, the main component of concrete, which is also the\ndominant source of CO2 emissions in the construction of data centers. The\ndiscovery of lower-carbon concrete formulae is therefore of high significance\nfor sustainability. However, experimenting with new concrete formulae is time\nconsuming and labor intensive, as one usually has to wait to record the\nconcrete's 28-day compressive strength, a quantity whose measurement can by its\ndefinition not be accelerated. This provides an opportunity for experimental\ndesign methodology like Bayesian Optimization (BO) to accelerate the search for\nstrong and sustainable concrete formulae. Herein, we 1) propose modeling steps\nthat make concrete strength amenable to be predicted accurately by a Gaussian\nprocess model with relatively few measurements, 2) formulate the search for\nsustainable concrete as a multi-objective optimization problem, and 3) leverage\nthe proposed model to carry out multi-objective BO with real-world strength\nmeasurements of the algorithmically proposed mixes. Our experimental results\nshow improved trade-offs between the mixtures' global warming potential (GWP)\nand their associated compressive strengths, compared to mixes based on current\nindustry practices. Our methods are open-sourced at\ngithub.com/facebookresearch/SustainableConcrete.\n","authors":["Sebastian Ament","Andrew Witte","Nishant Garg","Julius Kusuma"],"pdf_url":"https://arxiv.org/pdf/2310.18288v3.pdf","comment":"NeurIPS 2023 Workshop on Adaptive Experimental Design and Active\n  Learning in the Real World"},{"id":"http://arxiv.org/abs/2311.11876v1","updated":"2023-11-20T16:12:34Z","published":"2023-11-20T16:12:34Z","title":"Forward Gradients for Data-Driven CFD Wall Modeling","summary":"  Computational Fluid Dynamics (CFD) is used in the design and optimization of\ngas turbines and many other industrial/ scientific applications. However, the\npractical use is often limited by the high computational cost, and the accurate\nresolution of near-wall flow is a significant contributor to this cost. Machine\nlearning (ML) and other data-driven methods can complement existing wall\nmodels. Nevertheless, training these models is bottlenecked by the large\ncomputational effort and memory footprint demanded by back-propagation. Recent\nwork has presented alternatives for computing gradients of neural networks\nwhere a separate forward and backward sweep is not needed and storage of\nintermediate results between sweeps is not required because an unbiased\nestimator for the gradient is computed in a single forward sweep. In this\npaper, we discuss the application of this approach for training a subgrid wall\nmodel that could potentially be used as a surrogate in wall-bounded flow CFD\nsimulations to reduce the computational overhead while preserving predictive\naccuracy.\n","authors":["Jan Hückelheim","Tadbhagya Kumar","Krishnan Raghavan","Pinaki Pal"],"pdf_url":"https://arxiv.org/pdf/2311.11876v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.04741v3","updated":"2023-11-20T16:09:07Z","published":"2023-10-07T08:54:43Z","title":"Balancing stability and plasticity in continual learning: the\n  readout-decomposition of activation change (RDAC) framework","summary":"  Continual learning (CL) algorithms strive to acquire new knowledge while\npreserving prior information. However, this stability-plasticity trade-off\nremains a central challenge. This paper introduces a framework that dissects\nthis trade-off, offering valuable insights into CL algorithms. The\nReadout-Decomposition of Activation Change (RDAC) framework first addresses the\nstability-plasticity dilemma and its relation to catastrophic forgetting. It\nrelates learning-induced activation changes in the range of prior readouts to\nthe degree of stability and changes in the null space to the degree of\nplasticity. In deep non-linear networks tackling split-CIFAR-110 tasks, the\nframework clarifies the stability-plasticity trade-offs of the popular\nregularization algorithms Synaptic intelligence (SI), Elastic-weight\nconsolidation (EWC), and learning without Forgetting (LwF), and replay-based\nalgorithms Gradient episodic memory (GEM), and data replay. GEM and data replay\npreserved stability and plasticity, while SI, EWC, and LwF traded off\nplasticity for stability. The inability of the regularization algorithms to\nmaintain plasticity was linked to them restricting the change of activations in\nthe null space of the prior readout. Additionally, for one-hidden-layer linear\nneural networks, we derived a gradient decomposition algorithm to restrict\nactivation change only in the range of the prior readouts, to maintain high\nstability while not further sacrificing plasticity. Results demonstrate that\nthe algorithm maintained stability without significant plasticity loss. The\nRDAC framework informs the behavior of existing CL algorithms and paves the way\nfor novel CL approaches. Finally, it sheds light on the connection between\nlearning-induced activation/representation changes and the stability-plasticity\ndilemma, also offering insights into representational drift in biological\nsystems.\n","authors":["Daniel Anthes","Sushrut Thorat","Peter König","Tim C. Kietzmann"],"pdf_url":"https://arxiv.org/pdf/2310.04741v3.pdf","comment":"15 pages, 5 figures, Revision"},{"id":"http://arxiv.org/abs/2311.11871v1","updated":"2023-11-20T16:06:35Z","published":"2023-11-20T16:06:35Z","title":"Training robust and generalizable quantum models","summary":"  Adversarial robustness and generalization are both crucial properties of\nreliable machine learning models. In this paper, we study these properties in\nthe context of quantum machine learning based on Lipschitz bounds. We derive\ntailored, parameter-dependent Lipschitz bounds for quantum models with\ntrainable encoding, showing that the norm of the data encoding has a crucial\nimpact on the robustness against perturbations in the input data. Further, we\nderive a bound on the generalization error which explicitly depends on the\nparameters of the data encoding. Our theoretical findings give rise to a\npractical strategy for training robust and generalizable quantum models by\nregularizing the Lipschitz bound in the cost. Further, we show that, for fixed\nand non-trainable encodings as frequently employed in quantum machine learning,\nthe Lipschitz bound cannot be influenced by tuning the parameters. Thus,\ntrainable encodings are crucial for systematically adapting robustness and\ngeneralization during training. With numerical results, we demonstrate that,\nindeed, Lipschitz bound regularization leads to substantially more robust and\ngeneralizable quantum models.\n","authors":["Julian Berberich","Daniel Fink","Daniel Pranjić","Christian Tutschku","Christian Holm"],"pdf_url":"https://arxiv.org/pdf/2311.11871v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11862v1","updated":"2023-11-20T15:57:49Z","published":"2023-11-20T15:57:49Z","title":"Establishing Central Sensitization Inventory Cut-off Values in patients\n  with Chronic Low Back Pain by Unsupervised Machine Learning","summary":"  Human Assumed Central Sensitization is involved in the development and\nmaintenance of chronic low back pain (CLBP). The Central Sensitization\nInventory (CSI) was developed to evaluate the presence of HACS, with a cut-off\nvalue of 40/100 based on patients with chronic pain. However, various factors\nincluding pain conditions (e.g., CLBP), and gender may influence this cut-off\nvalue. For chronic pain condition such as CLBP, unsupervised clustering\napproaches can take these factors into consideration and automatically learn\nthe HACS-related patterns. Therefore, this study aimed to determine the cut-off\nvalues for a Dutch-speaking population with CLBP, considering the total group\nand stratified by gender based on unsupervised machine learning. In this study,\nquestionnaire data covering pain, physical, and psychological aspects were\ncollected from patients with CLBP and aged-matched pain-free adults (referred\nto as healthy controls, HC). Four clustering approaches were applied to\nidentify HACS-related clusters based on the questionnaire data and gender. The\nclustering performance was assessed using internal and external indicators.\nSubsequently, receiver operating characteristic analysis was conducted on the\nbest clustering results to determine the optimal cut-off values. The study\nincluded 151 subjects, consisting of 63 HCs and 88 patients with CLBP.\nHierarchical clustering yielded the best results, identifying three clusters:\nhealthy group, CLBP with low HACS level, and CLBP with high HACS level groups.\nBased on the low HACS levels group (including HC and CLBP with low HACS level)\nand high HACS level group, the cut-off value for the overall groups were 35, 34\nfor females, and 35 for. The findings suggest that the optimal cut-off values\nfor CLBP is 35. The gender-related cut-off values should be interpreted with\ncaution due to the unbalanced gender distribution in the sample.\n","authors":["Xiaoping Zheng","Claudine JC Lamoth","Hans Timmerman","Ebert Otten","Michiel F Reneman"],"pdf_url":"https://arxiv.org/pdf/2311.11862v1.pdf","comment":"31 pages, 5 tables, 3 figures"},{"id":"http://arxiv.org/abs/2311.10090v3","updated":"2023-11-20T15:51:07Z","published":"2023-11-16T18:58:43Z","title":"JaxMARL: Multi-Agent RL Environments in JAX","summary":"  Benchmarks play an important role in the development of machine learning\nalgorithms. For example, research in reinforcement learning (RL) has been\nheavily influenced by available environments and benchmarks. However, RL\nenvironments are traditionally run on the CPU, limiting their scalability with\ntypical academic compute. Recent advancements in JAX have enabled the wider use\nof hardware acceleration to overcome these computational hurdles, enabling\nmassively parallel RL training pipelines and environments. This is particularly\nuseful for multi-agent reinforcement learning (MARL) research. First of all,\nmultiple agents must be considered at each environment step, adding\ncomputational burden, and secondly, the sample complexity is increased due to\nnon-stationarity, decentralised partial observability, or other MARL\nchallenges. In this paper, we present JaxMARL, the first open-source code base\nthat combines ease-of-use with GPU enabled efficiency, and supports a large\nnumber of commonly used MARL environments as well as popular baseline\nalgorithms. When considering wall clock time, our experiments show that per-run\nour JAX-based training pipeline is up to 12500x faster than existing\napproaches. This enables efficient and thorough evaluations, with the potential\nto alleviate the evaluation crisis of the field. We also introduce and\nbenchmark SMAX, a vectorised, simplified version of the popular StarCraft\nMulti-Agent Challenge, which removes the need to run the StarCraft II game\nengine. This not only enables GPU acceleration, but also provides a more\nflexible MARL environment, unlocking the potential for self-play,\nmeta-learning, and other future applications in MARL. We provide code at\nhttps://github.com/flairox/jaxmarl.\n","authors":["Alexander Rutherford","Benjamin Ellis","Matteo Gallici","Jonathan Cook","Andrei Lupu","Gardar Ingvarsson","Timon Willi","Akbir Khan","Christian Schroeder de Witt","Alexandra Souly","Saptarashmi Bandyopadhyay","Mikayel Samvelyan","Minqi Jiang","Robert Tjarko Lange","Shimon Whiteson","Bruno Lacerda","Nick Hawes","Tim Rocktaschel","Chris Lu","Jakob Nicolaus Foerster"],"pdf_url":"https://arxiv.org/pdf/2311.10090v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11847v1","updated":"2023-11-20T15:37:39Z","published":"2023-11-20T15:37:39Z","title":"Deep learning complete intersection Calabi-Yau manifolds","summary":"  We review advancements in deep learning techniques for complete intersection\nCalabi-Yau (CICY) 3- and 4-folds, with the aim of understanding better how to\nhandle algebraic topological data with machine learning. We first discuss\nmethodological aspects and data analysis, before describing neural networks\narchitectures. Then, we describe the state-of-the art accuracy in predicting\nHodge numbers. We include new results on extrapolating predictions from low to\nhigh Hodge numbers, and conversely.\n","authors":["Harold Erbin","Riccardo Finotello"],"pdf_url":"https://arxiv.org/pdf/2311.11847v1.pdf","comment":"19 pages; match version published in \"Machine Learning in Pure\n  Mathematics and Theoretical Physics\" (edited by Y.-H. He, World Scientific\n  Press)"},{"id":"http://arxiv.org/abs/2305.02441v2","updated":"2023-11-20T15:27:37Z","published":"2023-05-03T22:01:10Z","title":"Reward Teaching for Federated Multi-armed Bandits","summary":"  Most of the existing federated multi-armed bandits (FMAB) designs are based\non the presumption that clients will implement the specified design to\ncollaborate with the server. In reality, however, it may not be possible to\nmodify the clients' existing protocols. To address this challenge, this work\nfocuses on clients who always maximize their individual cumulative rewards, and\nintroduces a novel idea of ``reward teaching'', where the server guides the\nclients towards global optimality through implicit local reward adjustments.\nUnder this framework, the server faces two tightly coupled tasks of bandit\nlearning and target teaching, whose combination is non-trivial and challenging.\nA phased approach, called Teaching-After-Learning (TAL), is first designed to\nencourage and discourage clients' explorations separately. General performance\nanalyses of TAL are established when the clients' strategies satisfy certain\nmild requirements. With novel technical approaches developed to analyze the\nwarm-start behaviors of bandit algorithms, particularized guarantees of TAL\nwith clients running UCB or epsilon-greedy strategies are then obtained. These\nresults demonstrate that TAL achieves logarithmic regrets while only incurring\nlogarithmic adjustment costs, which is order-optimal w.r.t. a natural lower\nbound. As a further extension, the Teaching-While-Learning (TWL) algorithm is\ndeveloped with the idea of successive arm elimination to break the non-adaptive\nphase separation in TAL. Rigorous analyses demonstrate that when facing clients\nwith UCB1, TWL outperforms TAL in terms of the dependencies on sub-optimality\ngaps thanks to its adaptive design. Experimental results demonstrate the\neffectiveness and generality of the proposed algorithms.\n","authors":["Chengshuai Shi","Wei Xiong","Cong Shen","Jing Yang"],"pdf_url":"https://arxiv.org/pdf/2305.02441v2.pdf","comment":"Accepted to IEEE Transactions on Signal Processing"},{"id":"http://arxiv.org/abs/2311.11841v1","updated":"2023-11-20T15:17:20Z","published":"2023-11-20T15:17:20Z","title":"High Probability Guarantees for Random Reshuffling","summary":"  We consider the stochastic gradient method with random reshuffling\n($\\mathsf{RR}$) for tackling smooth nonconvex optimization problems.\n$\\mathsf{RR}$ finds broad applications in practice, notably in training neural\nnetworks. In this work, we first investigate the concentration property of\n$\\mathsf{RR}$'s sampling procedure and establish a new high probability sample\ncomplexity guarantee for driving the gradient (without expectation) below\n$\\varepsilon$, which effectively characterizes the efficiency of a single\n$\\mathsf{RR}$ execution. Our derived complexity matches the best existing\nin-expectation one up to a logarithmic term while imposing no additional\nassumptions nor changing $\\mathsf{RR}$'s updating rule. Furthermore, by\nleveraging our derived high probability descent property and bound on the\nstochastic error, we propose a simple and computable stopping criterion for\n$\\mathsf{RR}$ (denoted as $\\mathsf{RR}$-$\\mathsf{sc}$). This criterion is\nguaranteed to be triggered after a finite number of iterations, and then\n$\\mathsf{RR}$-$\\mathsf{sc}$ returns an iterate with its gradient below\n$\\varepsilon$ with high probability. Moreover, building on the proposed\nstopping criterion, we design a perturbed random reshuffling method\n($\\mathsf{p}$-$\\mathsf{RR}$) that involves an additional randomized\nperturbation procedure near stationary points. We derive that\n$\\mathsf{p}$-$\\mathsf{RR}$ provably escapes strict saddle points and\nefficiently returns a second-order stationary point with high probability,\nwithout making any sub-Gaussian tail-type assumptions on the stochastic\ngradient errors. Finally, we conduct numerical experiments on neural network\ntraining to support our theoretical findings.\n","authors":["Hengxu Yu","Xiao Li"],"pdf_url":"https://arxiv.org/pdf/2311.11841v1.pdf","comment":"21 pages, 3 figures"},{"id":"http://arxiv.org/abs/2310.20049v3","updated":"2023-11-20T15:16:59Z","published":"2023-10-30T22:12:35Z","title":"SURF: A Generalization Benchmark for GNNs Predicting Fluid Dynamics","summary":"  Simulating fluid dynamics is crucial for the design and development process,\nranging from simple valves to complex turbomachinery. Accurately solving the\nunderlying physical equations is computationally expensive. Therefore,\nlearning-based solvers that model interactions on meshes have gained interest\ndue to their promising speed-ups. However, it is unknown to what extent these\nmodels truly understand the underlying physical principles and can generalize\nrather than interpolate. Generalization is a key requirement for a\ngeneral-purpose fluid simulator, which should adapt to different topologies,\nresolutions, or thermodynamic ranges. We propose SURF, a benchmark designed to\ntest the $\\textit{generalization}$ of learned graph-based fluid simulators.\nSURF comprises individual datasets and provides specific performance and\ngeneralization metrics for evaluating and comparing different models. We\nempirically demonstrate the applicability of SURF by thoroughly investigating\nthe two state-of-the-art graph-based models, yielding new insights into their\ngeneralization.\n","authors":["Stefan Künzli","Florian Grötschla","Joël Mathys","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2310.20049v3.pdf","comment":"Accepted at LoG 2023, Learning on Graphs Conference"},{"id":"http://arxiv.org/abs/2311.11837v1","updated":"2023-11-20T15:11:31Z","published":"2023-11-20T15:11:31Z","title":"Kandinsky Conformal Prediction: Efficient Calibration of Image\n  Segmentation Algorithms","summary":"  Image segmentation algorithms can be understood as a collection of pixel\nclassifiers, for which the outcomes of nearby pixels are correlated. Classifier\nmodels can be calibrated using Inductive Conformal Prediction, but this\nrequires holding back a sufficiently large calibration dataset for computing\nthe distribution of non-conformity scores of the model's predictions. If one\nonly requires only marginal calibration on the image level, this calibration\nset consists of all individual pixels in the images available for calibration.\nHowever, if the goal is to attain proper calibration for each individual pixel\nclassifier, the calibration set consists of individual images. In a scenario\nwhere data are scarce (such as the medical domain), it may not always be\npossible to set aside sufficiently many images for this pixel-level\ncalibration. The method we propose, dubbed ``Kandinsky calibration'', makes use\nof the spatial structure present in the distribution of natural images to\nsimultaneously calibrate the classifiers of ``similar'' pixels. This can be\nseen as an intermediate approach between marginal (imagewise) and conditional\n(pixelwise) calibration, where non-conformity scores are aggregated over\nsimilar image regions, thereby making more efficient use of the images\navailable for calibration. We run experiments on segmentation algorithms\ntrained and calibrated on subsets of the public MS-COCO and Medical Decathlon\ndatasets, demonstrating that Kandinsky calibration method can significantly\nimprove the coverage. When compared to both pixelwise and imagewise calibration\non little data, the Kandinsky method achieves much lower coverage errors,\nindicating the data efficiency of the Kandinsky calibration.\n","authors":["Joren Brunekreef","Eric Marcus","Ray Sheombarsing","Jan-Jakob Sonke","Jonas Teuwen"],"pdf_url":"https://arxiv.org/pdf/2311.11837v1.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2311.08427v2","updated":"2023-11-20T15:05:59Z","published":"2023-11-13T13:23:31Z","title":"Towards a Transportable Causal Network Model Based on Observational\n  Healthcare Data","summary":"  Over the last decades, many prognostic models based on artificial\nintelligence techniques have been used to provide detailed predictions in\nhealthcare. Unfortunately, the real-world observational data used to train and\nvalidate these models are almost always affected by biases that can strongly\nimpact the outcomes validity: two examples are values missing not-at-random and\nselection bias. Addressing them is a key element in achieving transportability\nand in studying the causal relationships that are critical in clinical decision\nmaking, going beyond simpler statistical approaches based on probabilistic\nassociation.\n  In this context, we propose a novel approach that combines selection\ndiagrams, missingness graphs, causal discovery and prior knowledge into a\nsingle graphical model to estimate the cardiovascular risk of adolescent and\nyoung females who survived breast cancer. We learn this model from data\ncomprising two different cohorts of patients. The resulting causal network\nmodel is validated by expert clinicians in terms of risk assessment, accuracy\nand explainability, and provides a prognostic model that outperforms competing\nmachine learning methods.\n","authors":["Alice Bernasconi","Alessio Zanga","Peter J. F. Lucas","Marco Scutari","Fabio Stella"],"pdf_url":"https://arxiv.org/pdf/2311.08427v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11829v1","updated":"2023-11-20T15:04:50Z","published":"2023-11-20T15:04:50Z","title":"System 2 Attention (is something you might need too)","summary":"  Soft attention in Transformer-based Large Language Models (LLMs) is\nsusceptible to incorporating irrelevant information from the context into its\nlatent representations, which adversely affects next token generations. To help\nrectify these issues, we introduce System 2 Attention (S2A), which leverages\nthe ability of LLMs to reason in natural language and follow instructions in\norder to decide what to attend to. S2A regenerates the input context to only\ninclude the relevant portions, before attending to the regenerated context to\nelicit the final response. In experiments, S2A outperforms standard\nattention-based LLMs on three tasks containing opinion or irrelevant\ninformation, QA, math word problems and longform generation, where S2A\nincreases factuality and objectivity, and decreases sycophancy.\n","authors":["Jason Weston","Sainbayar Sukhbaatar"],"pdf_url":"https://arxiv.org/pdf/2311.11829v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11827v1","updated":"2023-11-20T15:04:16Z","published":"2023-11-20T15:04:16Z","title":"Few-shot Multispectral Segmentation with Representations Generated by\n  Reinforcement Learning","summary":"  The task of multispectral image segmentation (segmentation of images with\nnumerous channels/bands, each capturing a specific range of wavelengths of\nelectromagnetic radiation) has been previously explored in contexts with large\namounts of labeled data. However, these models tend not to generalize well to\ndatasets of smaller size. In this paper, we propose a novel approach for\nimproving few-shot segmentation performance on multispectral images using\nreinforcement learning to generate representations. These representations are\ngenerated in the form of mathematical expressions between channels and are\ntailored to the specific class being segmented. Our methodology involves\ntraining an agent to identify the most informative expressions, updating the\ndataset using these expressions, and then using the updated dataset to perform\nsegmentation. Due to the limited length of the expressions, the model receives\nuseful representations without any added risk of overfitting. We evaluate the\neffectiveness of our approach on several multispectral datasets and demonstrate\nits effectiveness in boosting the performance of segmentation algorithms.\n","authors":["Dilith Jayakody","Thanuja Ambegoda"],"pdf_url":"https://arxiv.org/pdf/2311.11827v1.pdf","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2308.15283v2","updated":"2023-11-20T15:03:58Z","published":"2023-08-29T13:14:53Z","title":"Structural Node Embeddings with Homomorphism Counts","summary":"  Graph homomorphism counts, first explored by Lov\\'asz in 1967, have recently\ngarnered interest as a powerful tool in graph-based machine learning. Grohe\n(PODS 2020) proposed the theoretical foundations for using homomorphism counts\nin machine learning on graph level as well as node level tasks. By their very\nnature, these capture local structural information, which enables the creation\nof robust structural embeddings. While a first approach for graph level tasks\nhas been made by Nguyen and Maehara (ICML 2020), we experimentally show the\neffectiveness of homomorphism count based node embeddings. Enriched with node\nlabels, node weights, and edge weights, these offer an interpretable\nrepresentation of graph data, allowing for enhanced explainability of machine\nlearning models.\n  We propose a theoretical framework for isomorphism-invariant homomorphism\ncount based embeddings which lend themselves to a wide variety of downstream\ntasks. Our approach capitalises on the efficient computability of graph\nhomomorphism counts for bounded treewidth graph classes, rendering it a\npractical solution for real-world applications. We demonstrate their\nexpressivity through experiments on benchmark datasets. Although our results do\nnot match the accuracy of state-of-the-art neural architectures, they are\ncomparable to other advanced graph learning models. Remarkably, our approach\ndemarcates itself by ensuring explainability for each individual feature. By\nintegrating interpretable machine learning algorithms like SVMs or Random\nForests, we establish a seamless, end-to-end explainable pipeline. Our study\ncontributes to the advancement of graph-based techniques that offer both\nperformance and interpretability.\n","authors":["Hinrikus Wolf","Luca Oeljeklaus","Pascal Kühner","Martin Grohe"],"pdf_url":"https://arxiv.org/pdf/2308.15283v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07750v2","updated":"2023-11-20T15:01:19Z","published":"2023-11-13T21:07:07Z","title":"SynthEnsemble: A Fusion of CNN, Vision Transformer, and Hybrid Models\n  for Multi-Label Chest X-Ray Classification","summary":"  Chest X-rays are widely used to diagnose thoracic diseases, but the lack of\ndetailed information about these abnormalities makes it challenging to develop\naccurate automated diagnosis systems, which is crucial for early detection and\neffective treatment. To address this challenge, we employed deep learning\ntechniques to identify patterns in chest X-rays that correspond to different\ndiseases. We conducted experiments on the \"ChestX-ray14\" dataset using various\npre-trained CNNs, transformers, hybrid(CNN+Transformer) models and classical\nmodels. The best individual model was the CoAtNet, which achieved an area under\nthe receiver operating characteristic curve (AUROC) of 84.2%. By combining the\npredictions of all trained models using a weighted average ensemble where the\nweight of each model was determined using differential evolution, we further\nimproved the AUROC to 85.4%, outperforming other state-of-the-art methods in\nthis field. Our findings demonstrate the potential of deep learning techniques,\nparticularly ensemble deep learning, for improving the accuracy of automatic\ndiagnosis of thoracic diseases from chest X-rays.\n","authors":["S. M. Nabil Ashraf","Md. Adyelullahil Mamun","Hasnat Md. Abdullah","Md. Golam Rabiul Alam"],"pdf_url":"https://arxiv.org/pdf/2311.07750v2.pdf","comment":"Accepted in International Conference on Computer and Information\n  Technology (ICCIT) 2023"},{"id":"http://arxiv.org/abs/2311.11822v1","updated":"2023-11-20T14:58:56Z","published":"2023-11-20T14:58:56Z","title":"Zero redundancy distributed learning with differential privacy","summary":"  Deep learning using large models have achieved great success in a wide range\nof domains. However, training these models on billions of parameters is very\nchallenging in terms of the training speed, memory cost, and communication\nefficiency, especially under the privacy-preserving regime with differential\nprivacy (DP). On the one hand, DP optimization has comparable efficiency to the\nstandard non-private optimization on a single GPU, but on multiple GPUs,\nexisting DP distributed learning (such as pipeline parallel) has suffered from\nsignificantly worse efficiency. On the other hand, the Zero Redundancy\nOptimizer (ZeRO) is a state-of-the-art solution to the standard distributed\nlearning, exhibiting excellent training efficiency on large models, but to work\ncompatibly with DP is technically complicated. In this work, we develop a new\nsystematic solution, DP-ZeRO, (I) to scale up the trainable DP model size, e.g.\nto GPT-100B, (II) to obtain the same computation and communication efficiency\nas the standard ZeRO, and (III) to enable mixed-precision DP training. Our\nDP-ZeRO, like the standard ZeRO, has the potential to train models with\narbitrary size and is evaluated on the world's largest DP models in terms of\nthe number of trainable parameters.\n","authors":["Zhiqi Bu","Justin Chiu","Ruixuan Liu","Sheng Zha","George Karypis"],"pdf_url":"https://arxiv.org/pdf/2311.11822v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11821v1","updated":"2023-11-20T14:58:47Z","published":"2023-11-20T14:58:47Z","title":"Cross-View Graph Consistency Learning for Invariant Graph\n  Representations","summary":"  Graph representation learning is fundamental for analyzing graph-structured\ndata. Exploring invariant graph representations remains a challenge for most\nexisting graph representation learning methods. In this paper, we propose a\ncross-view graph consistency learning (CGCL) method that learns invariant graph\nrepresentations for link prediction. First, two complementary augmented views\nare derived from an incomplete graph structure through a bidirectional graph\nstructure augmentation scheme. This augmentation scheme mitigates the potential\ninformation loss that is commonly associated with various data augmentation\ntechniques involving raw graph data, such as edge perturbation, node removal,\nand attribute masking. Second, we propose a CGCL model that can learn invariant\ngraph representations. A cross-view training scheme is proposed to train the\nproposed CGCL model. This scheme attempts to maximize the consistency\ninformation between one augmented view and the graph structure reconstructed\nfrom the other augmented view. Furthermore, we offer a comprehensive\ntheoretical CGCL analysis. This paper empirically and experimentally\ndemonstrates the effectiveness of the proposed CGCL method, achieving\ncompetitive results on graph datasets in comparisons with several\nstate-of-the-art algorithms.\n","authors":["Jie Chen","Zhiming Li","Hua Mao","Wai Lok Woo","Xi Peng"],"pdf_url":"https://arxiv.org/pdf/2311.11821v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2311.11819v1","updated":"2023-11-20T14:55:40Z","published":"2023-11-20T14:55:40Z","title":"Generalized super-resolution 4D Flow MRI -- using ensemble learning to\n  extend across the cardiovascular system","summary":"  4D Flow Magnetic Resonance Imaging (4D Flow MRI) is a non-invasive\nmeasurement technique capable of quantifying blood flow across the\ncardiovascular system. While practical use is limited by spatial resolution and\nimage noise, incorporation of trained super-resolution (SR) networks has\npotential to enhance image quality post-scan. However, these efforts have\npredominantly been restricted to narrowly defined cardiovascular domains, with\nlimited exploration of how SR performance extends across the cardiovascular\nsystem; a task aggravated by contrasting hemodynamic conditions apparent across\nthe cardiovasculature. The aim of our study was to explore the generalizability\nof SR 4D Flow MRI using a combination of heterogeneous training sets and\ndedicated ensemble learning. With synthetic training data generated across\nthree disparate domains (cardiac, aortic, cerebrovascular), varying\nconvolutional base and ensemble learners were evaluated as a function of domain\nand architecture, quantifying performance on both in-silico and acquired\nin-vivo data from the same three domains. Results show that both bagging and\nstacking ensembling enhance SR performance across domains, accurately\npredicting high-resolution velocities from low-resolution input data in-silico.\nLikewise, optimized networks successfully recover native resolution velocities\nfrom downsampled in-vivo data, as well as show qualitative potential in\ngenerating denoised SR-images from clinical level input data. In conclusion,\nour work presents a viable approach for generalized SR 4D Flow MRI, with\nensemble learning extending utility across various clinical areas of interest.\n","authors":["Leon Ericsson","Adam Hjalmarsson","Muhammad Usman Akbar","Edward Ferdian","Mia Bonini","Brandon Hardy","Jonas Schollenberger","Maria Aristova","Patrick Winter","Nicholas Burris","Alexander Fyrdahl","Andreas Sigfridsson","Susanne Schnell","C. Alberto Figueroa","David Nordsletten","Alistair A. Young","David Marlevi"],"pdf_url":"https://arxiv.org/pdf/2311.11819v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2310.08278v2","updated":"2023-11-20T14:54:09Z","published":"2023-10-12T12:29:32Z","title":"Lag-Llama: Towards Foundation Models for Time Series Forecasting","summary":"  Aiming to build foundation models for time-series forecasting and study their\nscaling behavior, we present here our work-in-progress on Lag-Llama, a\ngeneral-purpose univariate probabilistic time-series forecasting model trained\non a large collection of time-series data. The model shows good zero-shot\nprediction capabilities on unseen \"out-of-distribution\" time-series datasets,\noutperforming supervised baselines. We use smoothly broken power-laws to fit\nand predict model scaling behavior. The open source code is made available at\nhttps://github.com/kashif/pytorch-transformer-ts.\n","authors":["Kashif Rasul","Arjun Ashok","Andrew Robert Williams","Arian Khorasani","George Adamopoulos","Rishika Bhagwatkar","Marin Biloš","Hena Ghonia","Nadhir Vincent Hassen","Anderson Schneider","Sahil Garg","Alexandre Drouin","Nicolas Chapados","Yuriy Nevmyvaka","Irina Rish"],"pdf_url":"https://arxiv.org/pdf/2310.08278v2.pdf","comment":"Preliminary Draft. Accepted at NeurIPS 2023 R0-FoMo Workshop. Full\n  paper coming soon with comprehensive results and open-source model\n  checkpoints"},{"id":"http://arxiv.org/abs/2311.11809v1","updated":"2023-11-20T14:42:13Z","published":"2023-11-20T14:42:13Z","title":"LogLead -- Fast and Integrated Log Loader, Enhancer, and Anomaly\n  Detector","summary":"  This paper introduces LogLead, a tool designed for efficient log analysis.\nLogLead combines three essential steps in log processing: loading, enhancing,\nand anomaly detection. The tool leverages Polars, a high-speed DataFrame\nlibrary. We currently have 7 Loaders out of which 4 is for public data sets\n(HDFS, Hadoop, BGL, and Thunderbird). We have multiple enhancers with three\nparsers (Drain, Spell, LenMa), Bert embedding creation and other log\nrepresentation techniques like bag-of-words. LogLead integrates to 5 supervised\nand 4 unsupervised machine learning algorithms for anomaly detection from\nSKLearn. By integrating diverse datasets, log representation methods and\nanomaly detectors, LogLead facilitates comprehensive benchmarking in log\nanalysis research. We demonstrate that log loading from raw file to dataframe\nis over 10x faster with LogLead is compared to past solutions. We demonstrate\nroughly 2x improvement in Drain parsing speed by off-loading log message\nnormalization to LogLead. We demonstrate a brief benchmarking on HDFS\nsuggesting that log representations beyond bag-of-words provide limited\nbenefits. Screencast demonstrating the tool: https://youtu.be/8stdbtTfJVo\n","authors":["Mika Mäntylä","Yuqing Wang","Jesse Nyyssölä"],"pdf_url":"https://arxiv.org/pdf/2311.11809v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11798v1","updated":"2023-11-20T14:31:18Z","published":"2023-11-20T14:31:18Z","title":"Operator Learning for Continuous Spatial-Temporal Model with A Hybrid\n  Optimization Scheme","summary":"  Partial differential equations are often used in the spatial-temporal\nmodeling of complex dynamical systems in many engineering applications. In this\nwork, we build on the recent progress of operator learning and present a\ndata-driven modeling framework that is continuous in both space and time. A key\nfeature of the proposed model is the resolution-invariance with respect to both\nspatial and temporal discretizations. To improve the long-term performance of\nthe calibrated model, we further propose a hybrid optimization scheme that\nleverages both gradient-based and derivative-free optimization methods and\nefficiently trains on both short-term time series and long-term statistics. We\ninvestigate the performance of the spatial-temporal continuous learning\nframework with three numerical examples, including the viscous Burgers'\nequation, the Navier-Stokes equations, and the Kuramoto-Sivashinsky equation.\nThe results confirm the resolution-invariance of the proposed modeling\nframework and also demonstrate stable long-term simulations with only\nshort-term time series data. In addition, we show that the proposed model can\nbetter predict long-term statistics via the hybrid optimization scheme with a\ncombined use of short-term and long-term data.\n","authors":["Chuanqi Chen","Jin-Long Wu"],"pdf_url":"https://arxiv.org/pdf/2311.11798v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.16854v2","updated":"2023-11-20T14:27:39Z","published":"2023-05-26T12:04:59Z","title":"Channel and Gradient-Importance Aware Device Scheduling for Over-the-Air\n  Federated Learning","summary":"  Federated learning (FL) is a popular privacy-preserving distributed training\nscheme, where multiple devices collaborate to train machine learning models by\nuploading local model updates. To improve communication efficiency,\nover-the-air computation (AirComp) has been applied to FL, which leverages\nanalog modulation to harness the superposition property of radio waves such\nthat numerous devices can upload their model updates concurrently for\naggregation. However, the uplink channel noise incurs considerable model\naggregation distortion, which is critically determined by the device scheduling\nand compromises the learned model performance. In this paper, we propose a\nprobabilistic device scheduling framework for over-the-air FL, named PO-FL, to\nmitigate the negative impact of channel noise, where each device is scheduled\naccording to a certain probability and its model update is reweighted using\nthis probability in aggregation. We prove the unbiasedness of this aggregation\nscheme and demonstrate the convergence of PO-FL on both convex and non-convex\nloss functions. Our convergence bounds unveil that the device scheduling\naffects the learning performance through the communication distortion and\nglobal update variance. Based on the convergence analysis, we further develop a\nchannel and gradient-importance aware algorithm to optimize the device\nscheduling probabilities in PO-FL. Extensive simulation results show that the\nproposed PO-FL framework with channel and gradient-importance awareness\nachieves faster convergence and produces better models than baseline methods.\n","authors":["Yuchang Sun","Zehong lin","Yuyi Mao","Shi Jin","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.16854v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11789v1","updated":"2023-11-20T14:14:13Z","published":"2023-11-20T14:14:13Z","title":"Approximate Linear Programming and Decentralized Policy Improvement in\n  Cooperative Multi-agent Markov Decision Processes","summary":"  In this work, we consider a `cooperative' multi-agent Markov decision process\n(MDP) involving m greater than 1 agents, where all agents are aware of the\nsystem model. At each decision epoch, all the m agents cooperatively select\nactions in order to maximize a common long-term objective. Since the number of\nactions grows exponentially in the number of agents, policy improvement is\ncomputationally expensive. Recent works have proposed using decentralized\npolicy improvement in which each agent assumes that the decisions of the other\nagents are fixed and it improves its decisions unilaterally. Yet, in these\nworks, exact values are computed. In our work, for cooperative multi-agent\nfinite and infinite horizon discounted MDPs, we propose suitable approximate\npolicy iteration algorithms, wherein we use approximate linear programming to\ncompute the approximate value function and use decentralized policy\nimprovement. Thus our algorithms can handle both large number of states as well\nas multiple agents. We provide theoretical guarantees for our algorithms and\nalso demonstrate the performance of our algorithms on some numerical examples.\n","authors":["Lakshmi Mandal","Chandrashekar Lakshminarayanan","Shalabh Bhatnagar"],"pdf_url":"https://arxiv.org/pdf/2311.11789v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11782v1","updated":"2023-11-20T14:07:38Z","published":"2023-11-20T14:07:38Z","title":"Robust Tumor Segmentation with Hyperspectral Imaging and Graph Neural\n  Networks","summary":"  Segmenting the boundary between tumor and healthy tissue during surgical\ncancer resection poses a significant challenge. In recent years, Hyperspectral\nImaging (HSI) combined with Machine Learning (ML) has emerged as a promising\nsolution. However, due to the extensive information contained within the\nspectral domain, most ML approaches primarily classify individual HSI\n(super-)pixels, or tiles, without taking into account their spatial context. In\nthis paper, we propose an improved methodology that leverages the spatial\ncontext of tiles for more robust and smoother segmentation. To address the\nirregular shapes of tiles, we utilize Graph Neural Networks (GNNs) to propagate\ncontext information across neighboring regions. The features for each tile\nwithin the graph are extracted using a Convolutional Neural Network (CNN),\nwhich is trained simultaneously with the subsequent GNN. Moreover, we\nincorporate local image quality metrics into the loss function to enhance the\ntraining procedure's robustness against low-quality regions in the training\nimages. We demonstrate the superiority of our proposed method using a clinical\nex vivo dataset consisting of 51 HSI images from 30 patients. Despite the\nlimited dataset, the GNN-based model significantly outperforms context-agnostic\napproaches, accurately distinguishing between healthy and tumor tissues, even\nin images from previously unseen patients. Furthermore, we show that our\ncarefully designed loss function, accounting for local image quality, results\nin additional improvements. Our findings demonstrate that context-aware GNN\nalgorithms can robustly find tumor demarcations on HSI images, ultimately\ncontributing to better surgery success and patient outcome.\n","authors":["Mayar Lotfy","Anna Alperovich","Tommaso Giannantonio","Bjorn Barz","Xiaohan Zhang","Felix Holm","Nassir Navab","Felix Boehm","Carolin Schwamborn","Thomas K. Hoffmann","Patrick J. Schuler"],"pdf_url":"https://arxiv.org/pdf/2311.11782v1.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.11777v1","updated":"2023-11-20T14:02:50Z","published":"2023-11-20T14:02:50Z","title":"Multimodal deep learning for mapping forest dominant height by fusing\n  GEDI with earth observation data","summary":"  The integration of multisource remote sensing data and deep learning models\noffers new possibilities for accurately mapping high spatial resolution forest\nheight. We found that GEDI relative heights (RH) metrics exhibited strong\ncorrelation with the mean of the top 10 highest trees (dominant height)\nmeasured in situ at the corresponding footprint locations. Consequently, we\nproposed a novel deep learning framework termed the multi-modal attention\nremote sensing network (MARSNet) to estimate forest dominant height by\nextrapolating dominant height derived from GEDI, using Setinel-1 data, ALOS-2\nPALSAR-2 data, Sentinel-2 optical data and ancillary data. MARSNet comprises\nseparate encoders for each remote sensing data modality to extract multi-scale\nfeatures, and a shared decoder to fuse the features and estimate height. Using\nindividual encoders for each remote sensing imagery avoids interference across\nmodalities and extracts distinct representations. To focus on the efficacious\ninformation from each dataset, we reduced the prevalent spatial and band\nredundancies in each remote sensing data by incorporating the extended spatial\nand band reconstruction convolution modules in the encoders. MARSNet achieved\ncommendable performance in estimating dominant height, with an R2 of 0.62 and\nRMSE of 2.82 m, outperforming the widely used random forest approach which\nattained an R2 of 0.55 and RMSE of 3.05 m. Finally, we applied the trained\nMARSNet model to generate wall-to-wall maps at 10 m resolution for Jilin,\nChina. Through independent validation using field measurements, MARSNet\ndemonstrated an R2 of 0.58 and RMSE of 3.76 m, compared to 0.41 and 4.37 m for\nthe random forest baseline. Our research demonstrates the effectiveness of a\nmultimodal deep learning approach fusing GEDI with SAR and passive optical\nimagery for enhancing the accuracy of high resolution dominant height\nestimation.\n","authors":["Man Chen","Wenquan Dong","Hao Yu","Iain Woodhouse","Casey M. Ryan","Haoyu Liu","Selena Georgiou","Edward T. A. Mitchard"],"pdf_url":"https://arxiv.org/pdf/2311.11777v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.15363v4","updated":"2023-11-20T13:59:16Z","published":"2023-08-29T14:59:54Z","title":"Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation","summary":"  Large language models (LLMs) have emerged as a new paradigm for Text-to-SQL\ntask. However, the absence of a systematical benchmark inhibits the development\nof designing effective, efficient and economic LLM-based Text-to-SQL solutions.\nTo address this challenge, in this paper, we first conduct a systematical and\nextensive comparison over existing prompt engineering methods, including\nquestion representation, example selection and example organization, and with\nthese experimental results, we elaborate their pros and cons. Based on these\nfindings, we propose a new integrated solution, named DAIL-SQL, which refreshes\nthe Spider leaderboard with 86.6% execution accuracy and sets a new bar. To\nexplore the potential of open-source LLM, we investigate them in various\nscenarios, and further enhance their performance with supervised fine-tuning.\nOur explorations highlight open-source LLMs' potential in Text-to-SQL, as well\nas the advantages and disadvantages of the supervised fine-tuning.\nAdditionally, towards an efficient and economic LLM-based Text-to-SQL solution,\nwe emphasize the token efficiency in prompt engineering and compare the prior\nstudies under this metric. We hope that our work provides a deeper\nunderstanding of Text-to-SQL with LLMs, and inspires further investigations and\nbroad applications.\n","authors":["Dawei Gao","Haibin Wang","Yaliang Li","Xiuyu Sun","Yichen Qian","Bolin Ding","Jingren Zhou"],"pdf_url":"https://arxiv.org/pdf/2308.15363v4.pdf","comment":"We have released code on https://github.com/BeachWang/DAIL-SQL"},{"id":"http://arxiv.org/abs/2311.11772v1","updated":"2023-11-20T13:58:26Z","published":"2023-11-20T13:58:26Z","title":"A Good Feature Extractor Is All You Need for Weakly Supervised Learning\n  in Histopathology","summary":"  Deep learning is revolutionising pathology, offering novel opportunities in\ndisease prognosis and personalised treatment. Historically, stain normalisation\nhas been a crucial preprocessing step in computational pathology pipelines, and\npersists into the deep learning era. Yet, with the emergence of feature\nextractors trained using self-supervised learning (SSL) on diverse pathology\ndatasets, we call this practice into question. In an empirical evaluation of\npublicly available feature extractors, we find that omitting stain\nnormalisation and image augmentations does not compromise downstream\nperformance, while incurring substantial savings in memory and compute.\nFurther, we show that the top-performing feature extractors are remarkably\nrobust to variations in stain and augmentations like rotation in their latent\nspace. Contrary to previous patch-level benchmarking studies, our approach\nemphasises clinical relevance by focusing on slide-level prediction tasks in a\nweakly supervised setting with external validation cohorts. This work\nrepresents the most comprehensive robustness evaluation of public pathology SSL\nfeature extractors to date, involving more than 6,000 training runs across nine\ntasks, five datasets, three downstream architectures, and various preprocessing\nsetups. Our findings stand to streamline digital pathology workflows by\nminimising preprocessing needs and informing the selection of feature\nextractors.\n","authors":["Georg Wölflein","Dyke Ferber","Asier Rabasco Meneghetti","Omar S. M. El Nahhas","Daniel Truhn","Zunamys I. Carrero","David J. Harrison","Ognjen Arandjelović","Jakob N. Kather"],"pdf_url":"https://arxiv.org/pdf/2311.11772v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.09369v2","updated":"2023-11-20T13:55:08Z","published":"2022-04-20T10:18:39Z","title":"A Variational Autoencoder for Heterogeneous Temporal and Longitudinal\n  Data","summary":"  The variational autoencoder (VAE) is a popular deep latent variable model\nused to analyse high-dimensional datasets by learning a low-dimensional latent\nrepresentation of the data. It simultaneously learns a generative model and an\ninference network to perform approximate posterior inference. Recently proposed\nextensions to VAEs that can handle temporal and longitudinal data have\napplications in healthcare, behavioural modelling, and predictive maintenance.\nHowever, these extensions do not account for heterogeneous data (i.e., data\ncomprising of continuous and discrete attributes), which is common in many\nreal-life applications. In this work, we propose the heterogeneous longitudinal\nVAE (HL-VAE) that extends the existing temporal and longitudinal VAEs to\nheterogeneous data. HL-VAE provides efficient inference for high-dimensional\ndatasets and includes likelihood models for continuous, count, categorical, and\nordinal data while accounting for missing observations. We demonstrate our\nmodel's efficacy through simulated as well as clinical datasets, and show that\nour proposed model achieves competitive performance in missing value imputation\nand predictive accuracy.\n","authors":["Mine Öğretir","Siddharth Ramchandran","Dimitrios Papatheodorou","Harri Lähdesmäki"],"pdf_url":"https://arxiv.org/pdf/2204.09369v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.09115v2","updated":"2023-11-20T13:55:04Z","published":"2023-11-15T17:06:26Z","title":"HEALNet -- Hybrid Multi-Modal Fusion for Heterogeneous Biomedical Data","summary":"  Technological advances in medical data collection such as high-resolution\nhistopathology and high-throughput genomic sequencing have contributed to the\nrising requirement for multi-modal biomedical modelling, specifically for\nimage, tabular, and graph data. Most multi-modal deep learning approaches use\nmodality-specific architectures that are trained separately and cannot capture\nthe crucial cross-modal information that motivates the integration of different\ndata sources. This paper presents the Hybrid Early-fusion Attention Learning\nNetwork (HEALNet): a flexible multi-modal fusion architecture, which a)\npreserves modality-specific structural information, b) captures the cross-modal\ninteractions and structural information in a shared latent space, c) can\neffectively handle missing modalities during training and inference, and d)\nenables intuitive model inspection by learning on the raw data input instead of\nopaque embeddings. We conduct multi-modal survival analysis on Whole Slide\nImages and Multi-omic data on four cancer cohorts of The Cancer Genome Atlas\n(TCGA). HEALNet achieves state-of-the-art performance, substantially improving\nover both uni-modal and recent multi-modal baselines, whilst being robust in\nscenarios with missing modalities.\n","authors":["Konstantin Hemker","Nikola Simidjievski","Mateja Jamnik"],"pdf_url":"https://arxiv.org/pdf/2311.09115v2.pdf","comment":"7 pages body, 5 pages appendix"},{"id":"http://arxiv.org/abs/2209.07067v4","updated":"2023-11-20T13:49:25Z","published":"2022-09-15T05:56:36Z","title":"Efficient learning of nonlinear prediction models with time-series\n  privileged information","summary":"  In domains where sample sizes are limited, efficient learning algorithms are\ncritical. Learning using privileged information (LuPI) offers increased sample\nefficiency by allowing prediction models access to auxiliary information at\ntraining time which is unavailable when the models are used. In recent work, it\nwas shown that for prediction in linear-Gaussian dynamical systems, a LuPI\nlearner with access to intermediate time series data is never worse and often\nbetter in expectation than any unbiased classical learner. We provide new\ninsights into this analysis and generalize it to nonlinear prediction tasks in\nlatent dynamical systems, extending theoretical guarantees to the case where\nthe map connecting latent variables and observations is known up to a linear\ntransform. In addition, we propose algorithms based on random features and\nrepresentation learning for the case when this map is unknown. A suite of\nempirical results confirm theoretical findings and show the potential of using\nprivileged time-series information in nonlinear prediction.\n","authors":["Bastian Jung","Fredrik D Johansson"],"pdf_url":"https://arxiv.org/pdf/2209.07067v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2007.07606v2","updated":"2023-11-20T13:48:09Z","published":"2020-07-15T10:32:43Z","title":"timeXplain -- A Framework for Explaining the Predictions of Time Series\n  Classifiers","summary":"  Modern time series classifiers display impressive predictive capabilities,\nyet their decision-making processes mostly remain black boxes to the user. At\nthe same time, model-agnostic explainers, such as the recently proposed SHAP,\npromise to make the predictions of machine learning models interpretable,\nprovided there are well-designed domain mappings. We bring both worlds together\nin our timeXplain framework, extending the reach of explainable artificial\nintelligence to time series classification and value prediction. We present\nnovel domain mappings for the time domain, frequency domain, and time series\nstatistics and analyze their explicative power as well as their limits. We\nemploy a novel evaluation metric to experimentally compare timeXplain to\nseveral model-specific explanation approaches for state-of-the-art time series\nclassifiers.\n","authors":["Felix Mujkanovic","Vanja Doskoč","Martin Schirneck","Patrick Schäfer","Tobias Friedrich"],"pdf_url":"https://arxiv.org/pdf/2007.07606v2.pdf","comment":"9 pages; published code, added combined time slice and frequency band\n  mapping, added quantitative evaluation and comparison to model-specific\n  explainers"},{"id":"http://arxiv.org/abs/2306.08744v2","updated":"2023-11-20T13:42:20Z","published":"2023-06-14T21:01:35Z","title":"High-performance deep spiking neural networks with 0.3 spikes per neuron","summary":"  Communication by rare, binary spikes is a key factor for the energy\nefficiency of biological brains. However, it is harder to train\nbiologically-inspired spiking neural networks (SNNs) than artificial neural\nnetworks (ANNs). This is puzzling given that theoretical results provide exact\nmapping algorithms from ANNs to SNNs with time-to-first-spike (TTFS) coding. In\nthis paper we analyze in theory and simulation the learning dynamics of\nTTFS-networks and identify a specific instance of the vanishing-or-exploding\ngradient problem. While two choices of SNN mappings solve this problem at\ninitialization, only the one with a constant slope of the neuron membrane\npotential at threshold guarantees the equivalence of the training trajectory\nbetween SNNs and ANNs with rectified linear units. We demonstrate that training\ndeep SNN models achieves the exact same performance as that of ANNs, surpassing\nprevious SNNs on image classification datasets such as MNIST/Fashion-MNIST,\nCIFAR10/CIFAR100 and PLACES365. Our SNN accomplishes high-performance\nclassification with less than 0.3 spikes per neuron, lending itself for an\nenergy-efficient implementation. We show that fine-tuning SNNs with our robust\ngradient descent algorithm enables their optimization for hardware\nimplementations with low latency and resilience to noise and quantization.\n","authors":["Ana Stanojevic","Stanisław Woźniak","Guillaume Bellec","Giovanni Cherubini","Angeliki Pantazi","Wulfram Gerstner"],"pdf_url":"https://arxiv.org/pdf/2306.08744v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11762v1","updated":"2023-11-20T13:40:40Z","published":"2023-11-20T13:40:40Z","title":"MUVO: A Multimodal Generative World Model for Autonomous Driving with\n  Geometric Representations","summary":"  Learning unsupervised world models for autonomous driving has the potential\nto improve the reasoning capabilities of today's systems dramatically. However,\nmost work neglects the physical attributes of the world and focuses on sensor\ndata alone. We propose MUVO, a MUltimodal World Model with Geometric VOxel\nRepresentations to address this challenge. We utilize raw camera and lidar data\nto learn a sensor-agnostic geometric representation of the world, which can\ndirectly be used by downstream tasks, such as planning. We demonstrate\nmultimodal future predictions and show that our geometric representation\nimproves the prediction quality of both camera images and lidar point clouds.\n","authors":["Daniel Bogdoll","Yitian Yang","J. Marius Zöllner"],"pdf_url":"https://arxiv.org/pdf/2311.11762v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11759v1","updated":"2023-11-20T13:39:19Z","published":"2023-11-20T13:39:19Z","title":"Unveiling the Unseen Potential of Graph Learning through MLPs: Effective\n  Graph Learners Using Propagation-Embracing MLPs","summary":"  Recent studies attempted to utilize multilayer perceptrons (MLPs) to solve\nsemi-supervised node classification on graphs, by training a student MLP by\nknowledge distillation (KD) from a teacher graph neural network (GNN). While\nprevious studies have focused mostly on training the student MLP by matching\nthe output probability distributions between the teacher and student models\nduring KD, it has not been systematically studied how to inject the structural\ninformation in an explicit and interpretable manner. Inspired by GNNs that\nseparate feature transformation $T$ and propagation $\\Pi$, we re-frame the KD\nprocess as enabling the student MLP to explicitly learn both $T$ and $\\Pi$.\nAlthough this can be achieved by applying the inverse propagation $\\Pi^{-1}$\nbefore distillation from the teacher GNN, it still comes with a high\ncomputational cost from large matrix multiplications during training. To solve\nthis problem, we propose Propagate & Distill (P&D), which propagates the output\nof the teacher GNN before KD and can be interpreted as an approximate process\nof the inverse propagation $\\Pi^{-1}$. Through comprehensive evaluations using\nreal-world benchmark datasets, we demonstrate the effectiveness of P&D by\nshowing further performance boost of the student MLP.\n","authors":["Yong-Min Shin","Won-Yong Shin"],"pdf_url":"https://arxiv.org/pdf/2311.11759v1.pdf","comment":"35 pages, 5 figures, 8 tables"},{"id":"http://arxiv.org/abs/2311.10489v2","updated":"2023-11-20T13:37:58Z","published":"2023-11-17T12:41:07Z","title":"Handling Overlapping Asymmetric Datasets -- A Twice Penalized P-Spline\n  Approach","summary":"  Overlapping asymmetric datasets are common in data science and pose questions\nof how they can be incorporated together into a predictive analysis. In\nhealthcare datasets there is often a small amount of information that is\navailable for a larger number of patients such as an electronic health record,\nhowever a small number of patients may have had extensive further testing.\nCommon solutions such as missing imputation can often be unwise if the smaller\ncohort is significantly different in scale to the larger sample, therefore the\naim of this research is to develop a new method which can model the smaller\ncohort against a particular response, whilst considering the larger cohort\nalso. Motivated by non-parametric models, and specifically flexible smoothing\ntechniques via generalized additive models, we model a twice penalized P-Spline\napproximation method to firstly prevent over/under-fitting of the smaller\ncohort and secondly to consider the larger cohort. This second penalty is\ncreated through discrepancies in the marginal value of covariates that exist in\nboth the smaller and larger cohorts. Through data simulations, parameter\ntunings and model adaptations to consider a continuous and binary response, we\nfind our twice penalized approach offers an enhanced fit over a linear B-Spline\nand once penalized P-Spline approximation. Applying to a real-life dataset\nrelating to a person's risk of developing Non-Alcoholic Steatohepatitis, we see\nan improved model fit performance of over 65%. Areas for future work within\nthis space include adapting our method to not require dimensionality reduction\nand also consider parametric modelling methods. However, to our knowledge this\nis the first work to propose additional marginal penalties in a flexible\nregression of which we can report a vastly improved model fit that is able to\nconsider asymmetric datasets, without the need for missing data imputation.\n","authors":["Matthew McTeer","Robin Henderson","Quentin M Anstee","Paolo Missier"],"pdf_url":"https://arxiv.org/pdf/2311.10489v2.pdf","comment":"52 pages, 17 figures, 8 tables, 34 references"},{"id":"http://arxiv.org/abs/2309.10003v3","updated":"2023-11-20T13:31:47Z","published":"2023-09-17T16:50:07Z","title":"A novel approach to measuring patent claim scope based on probabilities\n  obtained from (large) language models","summary":"  This work proposes to measure the scope of a patent claim as the reciprocal\nof the self-information contained in this claim. A probability of occurrence of\nthe claim is obtained from a language model and this probability is used to\ncompute the self-information. Grounded in information theory, this approach is\nbased on the assumption that an unlikely concept is more informative than a\nusual concept, insofar as it is more surprising. In turn, the more surprising\nthe information required to defined the claim, the narrower its scope. Five\nlanguage models are considered, ranging from simplest models (each word or\ncharacter is assigned an identical probability) to intermediate models (using\naverage word or character frequencies), to a large language model (GPT2).\nInterestingly, the scope resulting from the simplest language models is\nproportional to the reciprocal of the number of words or characters involved in\nthe claim, a metric already used in previous works. Application is made to\nmultiple series of patent claims directed to distinct inventions, where each\nseries consists of claims devised to have a gradually decreasing scope. The\nperformance of the language models is assessed with respect to several ad hoc\ntests. The more sophisticated the model, the better the results. I.e., the GPT2\nprobability model outperforms models based on word and character frequencies,\nwhich themselves outdo the simplest models based on word or character counts.\nStill, the character count appears to be a more reliable indicator than the\nword count.\n","authors":["Sébastien Ragot"],"pdf_url":"https://arxiv.org/pdf/2309.10003v3.pdf","comment":"58 pages, 8 tables, 6 figures. Substantial changes made to version 2:\n  New section 4.1 added (including a new table); Minor normalization issue\n  corrected in values listed in Appendix B; Content of former appendix C now\n  moved to Section 3; and new Appendix C added. Minor changes made to version 3\n  (style, typos, language)"},{"id":"http://arxiv.org/abs/2311.11749v1","updated":"2023-11-20T13:21:10Z","published":"2023-11-20T13:21:10Z","title":"Revealing behavioral impact on mobility prediction networks through\n  causal interventions","summary":"  Deep neural networks are increasingly utilized in mobility prediction tasks,\nyet their intricate internal workings pose challenges for interpretability,\nespecially in comprehending how various aspects of mobility behavior affect\npredictions. In this study, we introduce a causal intervention framework to\nassess the impact of mobility-related factors on neural networks designed for\nnext location prediction -- a task focusing on predicting the immediate next\nlocation of an individual. To achieve this, we employ individual mobility\nmodels to generate synthetic location visit sequences and control behavior\ndynamics by intervening in their data generation process. We evaluate the\ninterventional location sequences using mobility metrics and input them into\nwell-trained networks to analyze performance variations. The results\ndemonstrate the effectiveness in producing location sequences with distinct\nmobility behaviors, thus facilitating the simulation of diverse spatial and\ntemporal changes. These changes result in performance fluctuations in next\nlocation prediction networks, revealing impacts of critical mobility behavior\nfactors, including sequential patterns in location transitions, proclivity for\nexploring new locations, and preferences in location choices at population and\nindividual levels. The gained insights hold significant value for the\nreal-world application of mobility prediction networks, and the framework is\nexpected to promote the use of causal inference for enhancing the\ninterpretability and robustness of neural networks in mobility applications.\n","authors":["Ye Hong","Yanan Xin","Simon Dirmeier","Fernando Perez-Cruz","Martin Raubal"],"pdf_url":"https://arxiv.org/pdf/2311.11749v1.pdf","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2310.18534v2","updated":"2023-11-20T13:11:01Z","published":"2023-10-27T23:18:44Z","title":"Multi Time Scale World Models","summary":"  Intelligent agents use internal world models to reason and make predictions\nabout different courses of their actions at many scales. Devising learning\nparadigms and architectures that allow machines to learn world models that\noperate at multiple levels of temporal abstractions while dealing with complex\nuncertainty predictions is a major technical hurdle. In this work, we propose a\nprobabilistic formalism to learn multi-time scale world models which we call\nthe Multi Time Scale State Space (MTS3) model. Our model uses a computationally\nefficient inference scheme on multiple time scales for highly accurate\nlong-horizon predictions and uncertainty estimates over several seconds into\nthe future. Our experiments, which focus on action conditional long horizon\nfuture predictions, show that MTS3 outperforms recent methods on several system\nidentification benchmarks including complex simulated and real-world dynamical\nsystems.\n","authors":["Vaisakh Shaj","Saleh Gholam Zadeh","Ozan Demir","Luiz Ricardo Douat","Gerhard Neumann"],"pdf_url":"https://arxiv.org/pdf/2310.18534v2.pdf","comment":"Accepted as spotlight at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.01310v2","updated":"2023-11-20T13:08:27Z","published":"2023-11-02T15:24:23Z","title":"Scattering Vision Transformer: Spectral Mixing Matters","summary":"  Vision transformers have gained significant attention and achieved\nstate-of-the-art performance in various computer vision tasks, including image\nclassification, instance segmentation, and object detection. However,\nchallenges remain in addressing attention complexity and effectively capturing\nfine-grained information within images. Existing solutions often resort to\ndown-sampling operations, such as pooling, to reduce computational cost.\nUnfortunately, such operations are non-invertible and can result in information\nloss. In this paper, we present a novel approach called Scattering Vision\nTransformer (SVT) to tackle these challenges. SVT incorporates a spectrally\nscattering network that enables the capture of intricate image details. SVT\novercomes the invertibility issue associated with down-sampling operations by\nseparating low-frequency and high-frequency components. Furthermore, SVT\nintroduces a unique spectral gating network utilizing Einstein multiplication\nfor token and channel mixing, effectively reducing complexity. We show that SVT\nachieves state-of-the-art performance on the ImageNet dataset with a\nsignificant reduction in a number of parameters and FLOPS. SVT shows 2\\%\nimprovement over LiTv2 and iFormer. SVT-H-S reaches 84.2\\% top-1 accuracy,\nwhile SVT-H-B reaches 85.2\\% (state-of-art for base versions) and SVT-H-L\nreaches 85.7\\% (again state-of-art for large versions). SVT also shows\ncomparable results in other vision tasks such as instance segmentation. SVT\nalso outperforms other transformers in transfer learning on standard datasets\nsuch as CIFAR10, CIFAR100, Oxford Flower, and Stanford Car datasets. The\nproject page is available on this\nwebpage.\\url{https://badripatro.github.io/svt/}.\n","authors":["Badri N. Patro","Vijay Srinivas Agneeswaran"],"pdf_url":"https://arxiv.org/pdf/2311.01310v2.pdf","comment":"Accepted @NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.11723v1","updated":"2023-11-20T12:40:25Z","published":"2023-11-20T12:40:25Z","title":"Leveraging Uncertainty Estimates To Improve Classifier Performance","summary":"  Binary classification involves predicting the label of an instance based on\nwhether the model score for the positive class exceeds a threshold chosen based\non the application requirements (e.g., maximizing recall for a precision\nbound). However, model scores are often not aligned with the true positivity\nrate. This is especially true when the training involves a differential\nsampling across classes or there is distributional drift between train and test\nsettings. In this paper, we provide theoretical analysis and empirical evidence\nof the dependence of model score estimation bias on both uncertainty and score\nitself. Further, we formulate the decision boundary selection in terms of both\nmodel score and uncertainty, prove that it is NP-hard, and present algorithms\nbased on dynamic programming and isotonic regression. Evaluation of the\nproposed algorithms on three real-world datasets yield 25%-40% gain in recall\nat high precision bounds over the traditional approach of using model score\nalone, highlighting the benefits of leveraging uncertainty.\n","authors":["Gundeep Arora","Srujana Merugu","Anoop Saladi","Rajeev Rastogi"],"pdf_url":"https://arxiv.org/pdf/2311.11723v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.12253v2","updated":"2023-11-20T12:38:42Z","published":"2023-09-21T16:57:09Z","title":"SALSA-CLRS: A Sparse and Scalable Benchmark for Algorithmic Reasoning","summary":"  We introduce an extension to the CLRS algorithmic learning benchmark,\nprioritizing scalability and the utilization of sparse representations. Many\nalgorithms in CLRS require global memory or information exchange, mirrored in\nits execution model, which constructs fully connected (not sparse) graphs based\non the underlying problem. Despite CLRS's aim of assessing how effectively\nlearned algorithms can generalize to larger instances, the existing execution\nmodel becomes a significant constraint due to its demanding memory requirements\nand runtime (hard to scale). However, many important algorithms do not demand a\nfully connected graph; these algorithms, primarily distributed in nature, align\nclosely with the message-passing paradigm employed by Graph Neural Networks.\nHence, we propose SALSA-CLRS, an extension of the current CLRS benchmark\nspecifically with scalability and sparseness in mind. Our approach includes\nadapted algorithms from the original CLRS benchmark and introduces new problems\nfrom distributed and randomized algorithms. Moreover, we perform a thorough\nempirical evaluation of our benchmark. Code is publicly available at\nhttps://github.com/jkminder/SALSA-CLRS.\n","authors":["Julian Minder","Florian Grötschla","Joël Mathys","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2309.12253v2.pdf","comment":"(Extended Abstract) Presented at the Second Learning on Graphs\n  Conference (LoG 2023)"},{"id":"http://arxiv.org/abs/2310.18936v2","updated":"2023-11-20T12:35:55Z","published":"2023-10-29T08:50:27Z","title":"Adversarial Examples Are Not Real Features","summary":"  The existence of adversarial examples has been a mystery for years and\nattracted much interest. A well-known theory by \\citet{ilyas2019adversarial}\nexplains adversarial vulnerability from a data perspective by showing that one\ncan extract non-robust features from adversarial examples and these features\nalone are useful for classification. However, the explanation remains quite\ncounter-intuitive since non-robust features are mostly noise features to\nhumans. In this paper, we re-examine the theory from a larger context by\nincorporating multiple learning paradigms. Notably, we find that contrary to\ntheir good usefulness under supervised learning, non-robust features attain\npoor usefulness when transferred to other self-supervised learning paradigms,\nsuch as contrastive learning, masked image modeling, and diffusion models. It\nreveals that non-robust features are not really as useful as robust or natural\nfeatures that enjoy good transferability between these paradigms. Meanwhile,\nfor robustness, we also show that naturally trained encoders from robust\nfeatures are largely non-robust under AutoAttack. Our cross-paradigm\nexamination suggests that the non-robust features are not really useful but\nmore like paradigm-wise shortcuts, and robust features alone might be\ninsufficient to attain reliable model robustness. Code is available at\n\\url{https://github.com/PKU-ML/AdvNotRealFeatures}.\n","authors":["Ang Li","Yifei Wang","Yiwen Guo","Yisen Wang"],"pdf_url":"https://arxiv.org/pdf/2310.18936v2.pdf","comment":"NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.11717v1","updated":"2023-11-20T12:35:11Z","published":"2023-11-20T12:35:11Z","title":"Can we infer the presence of Differential Privacy in Deep Learning\n  models' weights? Towards more secure Deep Learning","summary":"  Differential Privacy (DP) is a key property to protect data and models from\nintegrity attacks. In the Deep Learning (DL) field, it is commonly implemented\nthrough the Differentially Private Stochastic Gradient Descent (DP-SGD).\nHowever, when a model is shared or released, there is no way to check whether\nit is differentially private, that is, it required to trust the model provider.\nThis situation poses a problem when data privacy is mandatory, specially with\ncurrent data regulations, as the presence of DP can not be certificated\nconsistently by any third party. Thus, we face the challenge of determining\nwhether a DL model has been trained with DP, according to the title question:\nCan we infer the presence of Differential Privacy in Deep Learning models'\nweights? Since the DP-SGD significantly changes the training process of a DL\nmodel, we hypothesize that DP leaves an imprint in the weights of a DL model,\nwhich can be used to predict whether a model has been trained with DP\nregardless of its architecture and the training dataset. In this paper, we\npropose to employ the imprint in model weights of using DP to infer the\npresence of DP training in a DL model. To substantiate our hypothesis, we\ndeveloped an experimental methodology based on two datasets of weights of DL\nmodels, each with models with and without DP training and a meta-classifier to\ninfer whether DP was used in the training process of a DL model, by accessing\nits weights. We accomplish both, the removal of the requirement of a trusted\nmodel provider and a strong foundation for this interesting line of research.\nThus, our contribution is an additional layer of security on top of the strict\nprivate requirements of DP training in DL models, towards to DL models.\n","authors":[" Jiménez-López"," Daniel"," Rodríguez-Barroso"," Nuria"," Luzón","M. Victoria"," Herrera"," Francisco"],"pdf_url":"https://arxiv.org/pdf/2311.11717v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.09191v3","updated":"2023-11-20T12:05:15Z","published":"2023-07-17T13:17:26Z","title":"A benchmark of categorical encoders for binary classification","summary":"  Categorical encoders transform categorical features into numerical\nrepresentations that are indispensable for a wide range of machine learning\nmodels. Existing encoder benchmark studies lack generalizability because of\ntheir limited choice of (1) encoders, (2) experimental factors, and (3)\ndatasets. Additionally, inconsistencies arise from the adoption of varying\naggregation strategies. This paper is the most comprehensive benchmark of\ncategorical encoders to date, including an extensive evaluation of 32\nconfigurations of encoders from diverse families, with 36 combinations of\nexperimental factors, and on 50 datasets. The study shows the profound\ninfluence of dataset selection, experimental factors, and aggregation\nstrategies on the benchmark's conclusions -- aspects disregarded in previous\nencoder benchmarks.\n","authors":["Federico Matteucci","Vadim Arzamasov","Klemens Boehm"],"pdf_url":"https://arxiv.org/pdf/2307.09191v3.pdf","comment":"To be published in the 37th Conference on Neural Information\n  Processing Systems (NeurIPS 2023) Track on Datasets and Benchmarks"},{"id":"http://arxiv.org/abs/2311.11696v1","updated":"2023-11-20T11:56:25Z","published":"2023-11-20T11:56:25Z","title":"Sparse Low-rank Adaptation of Pre-trained Language Models","summary":"  Fine-tuning pre-trained large language models in a parameter-efficient manner\nis widely studied for its effectiveness and efficiency. The popular method of\nlow-rank adaptation (LoRA) offers a notable approach, hypothesizing that the\nadaptation process is intrinsically low-dimensional. Although LoRA has\ndemonstrated commendable performance, it is implemented with a fixed and\nunalterable intrinsic rank that might not always be the ideal choice.\nRecognizing the need for more flexible adaptation, we extend the methodology of\nLoRA to an innovative approach we call sparse low-rank adaptation (SoRA) that\nenables dynamic adjustments to the intrinsic rank during the adaptation\nprocess. We achieve this through the incorporation of a gate unit optimized\nwith proximal gradient method in the training stage, controlling the\ncardinality of rank under the sparsity of the gate. In the subsequent inference\nstage, we eliminate the parameter blocks corresponding to the zeroed-out ranks,\nto reduce each SoRA module back to a concise yet rank-optimal LoRA. Our\napproach strengthens the representation power of LoRA by initializing it with a\nhigher rank, while efficiently taming a temporarily increased number of\nparameters via updating in a sparse way. We further introduce a sparsifying\nscheduler for SoRA, aiming to examine the impact of the number of non-zero\nparameters on the model's memorization and generalization. Our experimental\nresults demonstrate that SoRA can outperform other baselines even with 70%\nretained parameters and 70% training time.\n","authors":["Ning Ding","Xingtai Lv","Qiaosen Wang","Yulin Chen","Bowen Zhou","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2311.11696v1.pdf","comment":"Accepted to EMNLP 2023 (Main Conference)"},{"id":"http://arxiv.org/abs/2205.04712v3","updated":"2023-11-20T11:54:28Z","published":"2022-05-10T07:25:32Z","title":"Knowledge Augmented Machine Learning with Applications in Autonomous\n  Driving: A Survey","summary":"  The availability of representative datasets is an essential prerequisite for\nmany successful artificial intelligence and machine learning models. However,\nin real life applications these models often encounter scenarios that are\ninadequately represented in the data used for training. There are various\nreasons for the absence of sufficient data, ranging from time and cost\nconstraints to ethical considerations. As a consequence, the reliable usage of\nthese models, especially in safety-critical applications, is still a tremendous\nchallenge. Leveraging additional, already existing sources of knowledge is key\nto overcome the limitations of purely data-driven approaches. Knowledge\naugmented machine learning approaches offer the possibility of compensating for\ndeficiencies, errors, or ambiguities in the data, thus increasing the\ngeneralization capability of the applied models. Even more, predictions that\nconform with knowledge are crucial for making trustworthy and safe decisions\neven in underrepresented scenarios. This work provides an overview of existing\ntechniques and methods in the literature that combine data-driven models with\nexisting knowledge. The identified approaches are structured according to the\ncategories knowledge integration, extraction and conformity. In particular, we\naddress the application of the presented methods in the field of autonomous\ndriving.\n","authors":["Julian Wörmann","Daniel Bogdoll","Christian Brunner","Etienne Bührle","Han Chen","Evaristus Fuh Chuo","Kostadin Cvejoski","Ludger van Elst","Philip Gottschall","Stefan Griesche","Christian Hellert","Christian Hesels","Sebastian Houben","Tim Joseph","Niklas Keil","Johann Kelsch","Mert Keser","Hendrik Königshof","Erwin Kraft","Leonie Kreuser","Kevin Krone","Tobias Latka","Denny Mattern","Stefan Matthes","Franz Motzkus","Mohsin Munir","Moritz Nekolla","Adrian Paschke","Stefan Pilar von Pilchau","Maximilian Alexander Pintz","Tianming Qiu","Faraz Qureishi","Syed Tahseen Raza Rizvi","Jörg Reichardt","Laura von Rueden","Alexander Sagel","Diogo Sasdelli","Tobias Scholl","Gerhard Schunk","Gesina Schwalbe","Hao Shen","Youssef Shoeb","Hendrik Stapelbroek","Vera Stehr","Gurucharan Srinivas","Anh Tuan Tran","Abhishek Vivekanandan","Ya Wang","Florian Wasserrab","Tino Werner","Christian Wirth","Stefan Zwicklbauer"],"pdf_url":"https://arxiv.org/pdf/2205.04712v3.pdf","comment":"111 pages, Added section on Run-time Network Verification"},{"id":"http://arxiv.org/abs/2311.11694v1","updated":"2023-11-20T11:48:50Z","published":"2023-11-20T11:48:50Z","title":"Unveiling the Power of Self-Attention for Shipping Cost Prediction: The\n  Rate Card Transformer","summary":"  Amazon ships billions of packages to its customers annually within the United\nStates. Shipping cost of these packages are used on the day of shipping (day 0)\nto estimate profitability of sales. Downstream systems utilize these days 0\nprofitability estimates to make financial decisions, such as pricing strategies\nand delisting loss-making products. However, obtaining accurate shipping cost\nestimates on day 0 is complex for reasons like delay in carrier invoicing or\nfixed cost components getting recorded at monthly cadence. Inaccurate shipping\ncost estimates can lead to bad decision, such as pricing items too low or high,\nor promoting the wrong product to the customers. Current solutions for\nestimating shipping costs on day 0 rely on tree-based models that require\nextensive manual engineering efforts. In this study, we propose a novel\narchitecture called the Rate Card Transformer (RCT) that uses self-attention to\nencode all package shipping information such as package attributes, carrier\ninformation and route plan. Unlike other transformer-based tabular models, RCT\nhas the ability to encode a variable list of one-to-many relations of a\nshipment, allowing it to capture more information about a shipment. For\nexample, RCT can encode properties of all products in a package. Our results\ndemonstrate that cost predictions made by the RCT have 28.82% less error\ncompared to tree-based GBDT model. Moreover, the RCT outperforms the\nstate-of-the-art transformer-based tabular model, FTTransformer, by 6.08%. We\nalso illustrate that the RCT learns a generalized manifold of the rate card\nthat can improve the performance of tree-based models.\n","authors":["P Aditya Sreekar","Sahil Verma","Varun Madhavan","Abhishek Persad"],"pdf_url":"https://arxiv.org/pdf/2311.11694v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.10348v2","updated":"2023-11-20T11:31:16Z","published":"2023-10-16T12:34:43Z","title":"Attribution Patching Outperforms Automated Circuit Discovery","summary":"  Automated interpretability research has recently attracted attention as a\npotential research direction that could scale explanations of neural network\nbehavior to large models. Existing automated circuit discovery work applies\nactivation patching to identify subnetworks responsible for solving specific\ntasks (circuits). In this work, we show that a simple method based on\nattribution patching outperforms all existing methods while requiring just two\nforward passes and a backward pass. We apply a linear approximation to\nactivation patching to estimate the importance of each edge in the\ncomputational subgraph. Using this approximation, we prune the least important\nedges of the network. We survey the performance and limitations of this method,\nfinding that averaged over all tasks our method has greater AUC from circuit\nrecovery than other methods.\n","authors":["Aaquib Syed","Can Rager","Arthur Conmy"],"pdf_url":"https://arxiv.org/pdf/2310.10348v2.pdf","comment":"6 main paper pages, 6 additional pages. NeurIPS 2023 ATTRIB Workshop"},{"id":"http://arxiv.org/abs/2311.03197v2","updated":"2023-11-20T11:18:17Z","published":"2023-11-06T15:39:05Z","title":"Stable Linear Subspace Identification: A Machine Learning Approach","summary":"  Machine Learning (ML) and linear System Identification (SI) have been\nhistorically developed independently. In this paper, we leverage\nwell-established ML tools - especially the automatic differentiation framework\n- to introduce SIMBa, a family of discrete linear multi-step-ahead state-space\nSI methods using backpropagation. SIMBa relies on a novel\nLinear-Matrix-Inequality-based free parametrization of Schur matrices to ensure\nthe stability of the identified model.\n  We show how SIMBa generally outperforms traditional linear state-space SI\nmethods, and sometimes significantly, although at the price of a higher\ncomputational burden. This performance gap is particularly remarkable compared\nto other SI methods with stability guarantees, where the gain is frequently\nabove 25% in our investigations, hinting at SIMBa's ability to simultaneously\nachieve state-of-the-art fitting performance and enforce stability.\nInterestingly, these observations hold for a wide variety of input-output\nsystems and on both simulated and real-world data, showcasing the flexibility\nof the proposed approach. We postulate that this new SI paradigm presents a\ngreat extension potential to identify structured nonlinear models from data,\nand we hence open-source SIMBa on https://github.com/Cemempamoi/simba.\n","authors":["Loris Di Natale","Muhammad Zakwan","Bratislav Svetozarevic","Philipp Heer","Giancarlo Ferrari Trecate","Colin N. Jones"],"pdf_url":"https://arxiv.org/pdf/2311.03197v2.pdf","comment":"Submitted to ECC 2024"},{"id":"http://arxiv.org/abs/2307.13831v3","updated":"2023-11-20T10:57:01Z","published":"2023-07-25T21:59:17Z","title":"Relationship between Batch Size and Number of Steps Needed for Nonconvex\n  Optimization of Stochastic Gradient Descent using Armijo Line Search","summary":"  Stochastic gradient descent (SGD) is the simplest deep learning optimizer\nwith which to train deep neural networks. While SGD can use various learning\nrates, such as constant or diminishing rates, the previous numerical results\nshowed that SGD performs better than other deep learning optimizers using when\nit uses learning rates given by line search methods. In this paper, we perform\na convergence analysis on SGD with a learning rate given by an Armijo line\nsearch for nonconvex optimization. The analysis indicates that the upper bound\nof the expectation of the squared norm of the full gradient becomes small when\nthe number of steps and the batch size are large. Next, we show that, for SGD\nwith the Armijo-line-search learning rate, the number of steps needed for\nnonconvex optimization is a monotone decreasing convex function of the batch\nsize; that is, the number of steps needed for nonconvex optimization decreases\nas the batch size increases. Furthermore, we show that the stochastic\nfirst-order oracle (SFO) complexity, which is the stochastic gradient\ncomputation cost, is a convex function of the batch size; that is, there exists\na critical batch size that minimizes the SFO complexity. Finally, we provide\nnumerical results that support our theoretical results. The numerical results\nindicate that the number of steps needed for training deep neural networks\ndecreases as the batch size increases and that there exist the critical batch\nsizes that can be estimated from the theoretical results.\n","authors":["Yuki Tsukada","Hideaki Iiduka"],"pdf_url":"https://arxiv.org/pdf/2307.13831v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11644v1","updated":"2023-11-20T10:22:38Z","published":"2023-11-20T10:22:38Z","title":"Unraveling the Control Engineer's Craft with Neural Networks","summary":"  Many industrial processes require suitable controllers to meet their\nperformance requirements. More often, a sophisticated digital twin is\navailable, which is a highly complex model that is a virtual representation of\na given physical process, whose parameters may not be properly tuned to capture\nthe variations in the physical process. In this paper, we present a sim2real,\ndirect data-driven controller tuning approach, where the digital twin is used\nto generate input-output data and suitable controllers for several\nperturbations in its parameters. State-of-the art neural-network architectures\nare then used to learn the controller tuning rule that maps input-output data\nonto the controller parameters, based on artificially generated data from\nperturbed versions of the digital twin. In this way, as far as we are aware, we\ntackle for the first time the problem of re-calibrating the controller by\nmeta-learning the tuning rule directly from data, thus practically replacing\nthe control engineer with a machine learning model. The benefits of this\nmethodology are illustrated via numerical simulations for several choices of\nneural-network architectures.\n","authors":["Braghadeesh Lakshminarayanan","Federico Dettù","Cristian R. Rojas","Simone Formentin"],"pdf_url":"https://arxiv.org/pdf/2311.11644v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2308.12634v2","updated":"2023-11-20T10:06:03Z","published":"2023-08-24T08:19:15Z","title":"Towards Hierarchical Regional Transformer-based Multiple Instance\n  Learning","summary":"  The classification of gigapixel histopathology images with deep multiple\ninstance learning models has become a critical task in digital pathology and\nprecision medicine. In this work, we propose a Transformer-based multiple\ninstance learning approach that replaces the traditional learned attention\nmechanism with a regional, Vision Transformer inspired self-attention\nmechanism. We present a method that fuses regional patch information to derive\nslide-level predictions and show how this regional aggregation can be stacked\nto hierarchically process features on different distance levels. To increase\npredictive accuracy, especially for datasets with small, local morphological\nfeatures, we introduce a method to focus the image processing on high attention\nregions during inference. Our approach is able to significantly improve\nperformance over the baseline on two histopathology datasets and points towards\npromising directions for further research.\n","authors":["Josef Cersovsky","Sadegh Mohammadi","Dagmar Kainmueller","Johannes Hoehne"],"pdf_url":"https://arxiv.org/pdf/2308.12634v2.pdf","comment":"8 pages, LaTeX; header update after published, fixed typos"},{"id":"http://arxiv.org/abs/2311.11629v1","updated":"2023-11-20T09:28:04Z","published":"2023-11-20T09:28:04Z","title":"Generating Realistic Counterfactuals for Retinal Fundus and OCT Images\n  using Diffusion Models","summary":"  Counterfactual reasoning is often used in a clinical setting to explain\ndecisions or weigh alternatives. Therefore, for imaging based modalities such\nas ophthalmology, it would be beneficial to be able to create counterfactual\nimages, illustrating the answer to the question: \"If the subject had had\ndiabetic retinopathy, how would the fundus image have looked?\" Here, we\ndemonstrate that using a diffusion model in combination with an adversarially\nrobust classifier trained on retinal disease classification tasks enables\ngeneration of highly realistic counterfactuals of retinal fundus images and\noptical coherence tomorgraphy (OCT) B-scans. Ideally, these classifiers encode\nthe salient features indicative for each disease class and can steer the\ndiffusion model to show realistic disease signs or remove disease-related\nlesions in a realistic way. Importantly, in a user study, domain experts found\nthe counterfactuals generated using our method significantly more realistic\nthan counterfactuals generated from a previous method, and even\nindistiguishable from realistic images.\n","authors":["Indu Ilanchezian","Valentyn Boreiko","Laura Kühlewein","Ziwei Huang","Murat Seçkin Ayhan","Matthias Hein","Lisa Koch","Philipp Berens"],"pdf_url":"https://arxiv.org/pdf/2311.11629v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11628v1","updated":"2023-11-20T09:27:09Z","published":"2023-11-20T09:27:09Z","title":"Incorporating LLM Priors into Tabular Learners","summary":"  We present a method to integrate Large Language Models (LLMs) and traditional\ntabular data classification techniques, addressing LLMs challenges like data\nserialization sensitivity and biases. We introduce two strategies utilizing\nLLMs for ranking categorical variables and generating priors on correlations\nbetween continuous variables and targets, enhancing performance in few-shot\nscenarios. We focus on Logistic Regression, introducing MonotonicLR that\nemploys a non-linear monotonic function for mapping ordinals to cardinals while\npreserving LLM-determined orders. Validation against baseline models reveals\nthe superior performance of our approach, especially in low-data scenarios,\nwhile remaining interpretable.\n","authors":["Max Zhu","Siniša Stanivuk","Andrija Petrovic","Mladen Nikolic","Pietro Lio"],"pdf_url":"https://arxiv.org/pdf/2311.11628v1.pdf","comment":"Table Representation Learning Workshop at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.11626v1","updated":"2023-11-20T09:20:26Z","published":"2023-11-20T09:20:26Z","title":"A novel transformer-based approach for soil temperature prediction","summary":"  Soil temperature is one of the most significant parameters that plays a\ncrucial role in glacier energy, dynamics of mass balance, processes of surface\nhydrological, coaction of glacier-atmosphere, nutrient cycling, ecological\nstability, the management of soil, water, and field crop. In this work, we\nintroduce a novel approach using transformer models for the purpose of\nforecasting soil temperature prediction. To the best of our knowledge, the\nusage of transformer models in this work is the very first attempt to predict\nsoil temperature. Experiments are carried out using six different FLUXNET\nstations by modeling them with five different transformer models, namely,\nVanilla Transformer, Informer, Autoformer, Reformer, and ETSformer. To\ndemonstrate the effectiveness of the proposed model, experiment results are\ncompared with both deep learning approaches and literature studies. Experiment\nresults show that the utilization of transformer models ensures a significant\ncontribution to the literature, thence determining the new state-of-the-art.\n","authors":["Muhammet Mucahit Enes Yurtsever","Ayhan Kucukmanisa","Zeynep Hilal Kilimci"],"pdf_url":"https://arxiv.org/pdf/2311.11626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2011.00789v2","updated":"2023-11-20T08:48:07Z","published":"2020-11-02T07:37:31Z","title":"Role Taxonomy of Units in Deep Neural Networks","summary":"  Identifying the role of network units in deep neural networks (DNNs) is\ncritical in many aspects including giving understandings on the mechanisms of\nDNNs and building basic connections between deep learning and neuroscience.\nHowever, there remains unclear on which roles the units in DNNs with different\ngeneralization ability could present. To this end, we give role taxonomy of\nunits in DNNs via introducing the retrieval-of-function test, where units are\ncategorized into four types in terms of their functional preference on\nseparately the training set and testing set. We show that ratios of the four\ncategories are highly associated with the generalization ability of DNNs from\ntwo distinct perspectives, based on which we give signs of DNNs with well\ngeneralization.\n","authors":["Yang Zhao","Hao Zhang","Xiuyuan Hu"],"pdf_url":"https://arxiv.org/pdf/2011.00789v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.18415v3","updated":"2023-11-20T08:31:51Z","published":"2023-05-28T18:48:50Z","title":"Geometric Algebra Transformer","summary":"  Problems involving geometric data arise in physics, chemistry, robotics,\ncomputer vision, and many other fields. Such data can take numerous forms, for\ninstance points, direction vectors, translations, or rotations, but to date\nthere is no single architecture that can be applied to such a wide variety of\ngeometric types while respecting their symmetries. In this paper we introduce\nthe Geometric Algebra Transformer (GATr), a general-purpose architecture for\ngeometric data. GATr represents inputs, outputs, and hidden states in the\nprojective geometric (or Clifford) algebra, which offers an efficient\n16-dimensional vector-space representation of common geometric objects as well\nas operators acting on them. GATr is equivariant with respect to E(3), the\nsymmetry group of 3D Euclidean space. As a Transformer, GATr is versatile,\nefficient, and scalable. We demonstrate GATr in problems from n-body modeling\nto wall-shear-stress estimation on large arterial meshes to robotic motion\nplanning. GATr consistently outperforms both non-geometric and equivariant\nbaselines in terms of error, data efficiency, and scalability.\n","authors":["Johann Brehmer","Pim de Haan","Sönke Behrends","Taco Cohen"],"pdf_url":"https://arxiv.org/pdf/2305.18415v3.pdf","comment":"Published at NeurIPS 2023, implementation available at\n  https://github.com/qualcomm-ai-research/geometric-algebra-transformer . v3:\n  matches camera-ready version"},{"id":"http://arxiv.org/abs/2302.06335v2","updated":"2023-11-20T08:03:40Z","published":"2023-02-13T13:12:55Z","title":"Online Arbitrary Shaped Clustering through Correlated Gaussian Functions","summary":"  There is no convincing evidence that backpropagation is a biologically\nplausible mechanism, and further studies of alternative learning methods are\nneeded. A novel online clustering algorithm is presented that can produce\narbitrary shaped clusters from inputs in an unsupervised manner, and requires\nno prior knowledge of the number of clusters in the input data. This is\nachieved by finding correlated outputs from functions that capture commonly\noccurring input patterns. The algorithm can be deemed more biologically\nplausible than model optimization through backpropagation, although practical\napplicability may require additional research. However, the method yields\nsatisfactory results on several toy datasets on a noteworthy range of\nhyperparameters.\n","authors":["Ole Christian Eidheim"],"pdf_url":"https://arxiv.org/pdf/2302.06335v2.pdf","comment":"Corrected uniform distribution range; removed \"average\" from last\n  sentence in section 4"},{"id":"http://arxiv.org/abs/2301.01333v2","updated":"2023-11-20T07:49:11Z","published":"2023-01-03T19:52:17Z","title":"oneDNN Graph Compiler: A Hybrid Approach for High-Performance Deep\n  Learning Compilation","summary":"  With the rapid development of deep learning models and hardware support for\ndense computing, the deep learning workload characteristics changed\nsignificantly from a few hot spots on compute-intensive operations to a broad\nrange of operations scattered across the models. Accelerating a few\ncompute-intensive operations using the expert-tuned implementation of\nprimitives does not fully exploit the performance potential of AI hardware.\nVarious efforts have been made to compile a full deep neural network (DNN)\ngraph. One of the biggest challenges is to achieve high-performance tensor\ncompilation by generating expert level performance code for the dense\ncompute-intensive operations and applying compilation optimization at the scope\nof DNN computation graph across multiple compute-intensive operations.\n  We present oneDNN Graph Compiler, a tensor compiler that employs a hybrid\napproach of using techniques from both compiler optimization and expert-tuned\nkernels for high performance code generation of the deep neural network graph.\noneDNN Graph Compiler addresses unique optimization challenges in the deep\nlearning domain, such as low-precision computation, aggressive fusion of graph\noperations, optimization for static tensor shapes and memory layout, constant\nweight optimization, and memory buffer reuse. Experimental results demonstrate\nsignificant performance gains over existing tensor compiler and primitives\nlibrary for performance-critical DNN computation graphs and end-to-end models\non Intel Xeon Scalable Processors.\n","authors":["Jianhui Li","Zhennan Qin","Yijie Mei","Jingze Cui","Yunfei Song","Ciyong Chen","Yifei Zhang","Longsheng Du","Xianhang Cheng","Baihui Jin","Yan Zhang","Igor Safonov","Jason Ye","Eric Lin","Dan Lavery"],"pdf_url":"https://arxiv.org/pdf/2301.01333v2.pdf","comment":"10 pages excluding reference, 9 figures, 1 table"},{"id":"http://arxiv.org/abs/2311.11575v1","updated":"2023-11-20T07:19:52Z","published":"2023-11-20T07:19:52Z","title":"Testing multivariate normality by testing independence","summary":"  We propose a simple multivariate normality test based on Kac-Bernstein's\ncharacterization, which can be conducted by utilising existing statistical\nindependence tests for sums and differences of data samples. We also perform\nits empirical investigation, which reveals that for high-dimensional data, the\nproposed approach may be more efficient than the alternative ones. The\naccompanying code repository is provided at \\url{https://shorturl.at/rtuy5}.\n","authors":["Povilas Daniušis"],"pdf_url":"https://arxiv.org/pdf/2311.11575v1.pdf","comment":"6 pages, 1 figure"},{"id":"http://arxiv.org/abs/2311.11558v1","updated":"2023-11-20T06:35:23Z","published":"2023-11-20T06:35:23Z","title":"A Deep-Genetic Algorithm (Deep-GA) Approach for High-Dimensional\n  Nonlinear Parabolic Partial Differential Equations","summary":"  We propose a new method, called a deep-genetic algorithm (deep-GA), to\naccelerate the performance of the so-called deep-BSDE method, which is a deep\nlearning algorithm to solve high dimensional partial differential equations\nthrough their corresponding backward stochastic differential equations (BSDEs).\nRecognizing the sensitivity of the solver to the initial guess selection, we\nembed a genetic algorithm (GA) into the solver to optimize the selection. We\naim to achieve faster convergence for the nonlinear PDEs on a broader interval\nthan deep-BSDE. Our proposed method is applied to two nonlinear parabolic PDEs,\ni.e., the Black-Scholes (BS) equation with default risk and the\nHamilton-Jacobi-Bellman (HJB) equation. We compare the results of our method\nwith those of the deep-BSDE and show that our method provides comparable\naccuracy with significantly improved computational efficiency.\n","authors":["Endah Rokhmati Merdika Putri","Muhammad Luthfi Shahab","Mohammad Iqbal","Imam Mukhlash","Amirul Hakam","Lutfi Mardianto","Hadi Susanto"],"pdf_url":"https://arxiv.org/pdf/2311.11558v1.pdf","comment":"Accepted for publication in Computers and Mathematics with\n  Applications, 19 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.11557v1","updated":"2023-11-20T06:21:52Z","published":"2023-11-20T06:21:52Z","title":"Replay-enhanced Continual Reinforcement Learning","summary":"  Replaying past experiences has proven to be a highly effective approach for\naverting catastrophic forgetting in supervised continual learning. However,\nsome crucial factors are still largely ignored, making it vulnerable to serious\nfailure, when used as a solution to forgetting in continual reinforcement\nlearning, even in the context of perfect memory where all data of previous\ntasks are accessible in the current task. On the one hand, since most\nreinforcement learning algorithms are not invariant to the reward scale, the\npreviously well-learned tasks (with high rewards) may appear to be more salient\nto the current learning process than the current task (with small initial\nrewards). This causes the agent to concentrate on those salient tasks at the\nexpense of generality on the current task. On the other hand, offline learning\non replayed tasks while learning a new task may induce a distributional shift\nbetween the dataset and the learned policy on old tasks, resulting in\nforgetting. In this paper, we introduce RECALL, a replay-enhanced method that\ngreatly improves the plasticity of existing replay-based methods on new tasks\nwhile effectively avoiding the recurrence of catastrophic forgetting in\ncontinual reinforcement learning. RECALL leverages adaptive normalization on\napproximate targets and policy distillation on old tasks to enhance generality\nand stability, respectively. Extensive experiments on the Continual World\nbenchmark show that RECALL performs significantly better than purely perfect\nmemory replay, and achieves comparable or better overall performance against\nstate-of-the-art continual learning methods.\n","authors":["Tiantian Zhang","Kevin Zehua Shen","Zichuan Lin","Bo Yuan","Xueqian Wang","Xiu Li","Deheng Ye"],"pdf_url":"https://arxiv.org/pdf/2311.11557v1.pdf","comment":"Accepted by Transactions on Machine Learning Research 2023"},{"id":"http://arxiv.org/abs/2310.03358v2","updated":"2023-11-20T06:08:28Z","published":"2023-10-05T07:29:29Z","title":"Enhancing Robust Representation in Adversarial Training: Alignment and\n  Exclusion Criteria","summary":"  Deep neural networks are vulnerable to adversarial noise. Adversarial\nTraining (AT) has been demonstrated to be the most effective defense strategy\nto protect neural networks from being fooled. However, we find AT omits to\nlearning robust features, resulting in poor performance of adversarial\nrobustness. To address this issue, we highlight two criteria of robust\nrepresentation: (1) Exclusion: \\emph{the feature of examples keeps away from\nthat of other classes}; (2) Alignment: \\emph{the feature of natural and\ncorresponding adversarial examples is close to each other}. These motivate us\nto propose a generic framework of AT to gain robust representation, by the\nasymmetric negative contrast and reverse attention. Specifically, we design an\nasymmetric negative contrast based on predicted probabilities, to push away\nexamples of different classes in the feature space. Moreover, we propose to\nweight feature by parameters of the linear classifier as the reverse attention,\nto obtain class-aware feature and pull close the feature of the same class.\nEmpirical evaluations on three benchmark datasets show our methods greatly\nadvance the robustness of AT and achieve state-of-the-art performance.\n","authors":["Nuoyan Zhou","Nannan Wang","Decheng Liu","Dawei Zhou","Xinbo Gao"],"pdf_url":"https://arxiv.org/pdf/2310.03358v2.pdf","comment":"10 pages, 9 figures, Submitted to TIFS"},{"id":"http://arxiv.org/abs/2311.11552v1","updated":"2023-11-20T06:06:22Z","published":"2023-11-20T06:06:22Z","title":"Exploring Prompting Large Language Models as Explainable Metrics","summary":"  This paper describes the IUST NLP Lab submission to the Prompting Large\nLanguage Models as Explainable Metrics Shared Task at the Eval4NLP 2023\nWorkshop on Evaluation & Comparison of NLP Systems. We have proposed a\nzero-shot prompt-based strategy for explainable evaluation of the summarization\ntask using Large Language Models (LLMs). The conducted experiments demonstrate\nthe promising potential of LLMs as evaluation metrics in Natural Language\nProcessing (NLP), particularly in the field of summarization. Both few-shot and\nzero-shot approaches are employed in these experiments. The performance of our\nbest provided prompts achieved a Kendall correlation of 0.477 with human\nevaluations in the text summarization task on the test data. Code and results\nare publicly available on GitHub.\n","authors":["Ghazaleh Mahmoudi"],"pdf_url":"https://arxiv.org/pdf/2311.11552v1.pdf","comment":"9 pages, Eval4NLP 2023"},{"id":"http://arxiv.org/abs/2311.11544v1","updated":"2023-11-20T05:35:40Z","published":"2023-11-20T05:35:40Z","title":"Understanding Variation in Subpopulation Susceptibility to Poisoning\n  Attacks","summary":"  Machine learning is susceptible to poisoning attacks, in which an attacker\ncontrols a small fraction of the training data and chooses that data with the\ngoal of inducing some behavior unintended by the model developer in the trained\nmodel. We consider a realistic setting in which the adversary with the ability\nto insert a limited number of data points attempts to control the model's\nbehavior on a specific subpopulation. Inspired by previous observations on\ndisparate effectiveness of random label-flipping attacks on different\nsubpopulations, we investigate the properties that can impact the effectiveness\nof state-of-the-art poisoning attacks against different subpopulations. For a\nfamily of 2-dimensional synthetic datasets, we empirically find that dataset\nseparability plays a dominant role in subpopulation vulnerability for less\nseparable datasets. However, well-separated datasets exhibit more dependence on\nindividual subpopulation properties. We further discover that a crucial\nsubpopulation property is captured by the difference in loss on the clean\ndataset between the clean model and a target model that misclassifies the\nsubpopulation, and a subpopulation is much easier to attack if the loss\ndifference is small. This property also generalizes to high-dimensional\nbenchmark datasets. For the Adult benchmark dataset, we show that we can find\nsemantically-meaningful subpopulation properties that are related to the\nsusceptibilities of a selected group of subpopulations. The results in this\npaper are accompanied by a fully interactive web-based visualization of\nsubpopulation poisoning attacks found at\nhttps://uvasrg.github.io/visualizing-poisoning\n","authors":["Evan Rose","Fnu Suya","David Evans"],"pdf_url":"https://arxiv.org/pdf/2311.11544v1.pdf","comment":"18 pages, 11 figures"},{"id":"http://arxiv.org/abs/2211.10890v4","updated":"2023-11-20T05:25:23Z","published":"2022-11-20T07:18:56Z","title":"Single-Pass Contrastive Learning Can Work for Both Homophilic and\n  Heterophilic Graph","summary":"  Existing graph contrastive learning (GCL) techniques typically require two\nforward passes for a single instance to construct the contrastive loss, which\nis effective for capturing the low-frequency signals of node features. Such a\ndual-pass design has shown empirical success on homophilic graphs, but its\neffectiveness on heterophilic graphs, where directly connected nodes typically\nhave different labels, is unknown. In addition, existing GCL approaches fail to\nprovide strong performance guarantees. Coupled with the unpredictability of GCL\napproaches on heterophilic graphs, their applicability in real-world contexts\nis limited. Then, a natural question arises: Can we design a GCL method that\nworks for both homophilic and heterophilic graphs with a performance guarantee?\nTo answer this question, we theoretically study the concentration property of\nfeatures obtained by neighborhood aggregation on homophilic and heterophilic\ngraphs, introduce the single-pass augmentation-free graph contrastive learning\nloss based on the property, and provide performance guarantees for the\nminimizer of the loss on downstream tasks. As a direct consequence of our\nanalysis, we implement the Single-Pass Graph Contrastive Learning method\n(SP-GCL). Empirically, on 14 benchmark datasets with varying degrees of\nhomophily, the features learned by the SP-GCL can match or outperform existing\nstrong baselines with significantly less computational overhead, which\ndemonstrates the usefulness of our findings in real-world cases.\n","authors":["Haonan Wang","Jieyu Zhang","Qi Zhu","Wei Huang","Kenji Kawaguchi","Xiaokui Xiao"],"pdf_url":"https://arxiv.org/pdf/2211.10890v4.pdf","comment":"This article has been accepted for publication by the Transactions on\n  Machine Learning Research. OpenReview at:\n  https://openreview.net/forum?id=244KePn09i"},{"id":"http://arxiv.org/abs/2310.15516v2","updated":"2023-11-20T05:06:11Z","published":"2023-10-24T04:50:32Z","title":"Graph Attention-based Deep Reinforcement Learning for solving the\n  Chinese Postman Problem with Load-dependent costs","summary":"  Recently, Deep reinforcement learning (DRL) models have shown promising\nresults in solving routing problems. However, most DRL solvers are commonly\nproposed to solve node routing problems, such as the Traveling Salesman Problem\n(TSP). Meanwhile, there has been limited research on applying neural methods to\narc routing problems, such as the Chinese Postman Problem (CPP), since they\noften feature irregular and complex solution spaces compared to TSP. To fill\nthese gaps, this paper proposes a novel DRL framework to address the CPP with\nload-dependent costs (CPP-LC) (Corberan et al., 2018), which is a complex arc\nrouting problem with load constraints. The novelty of our method is two-fold.\nFirst, we formulate the CPP-LC as a Markov Decision Process (MDP) sequential\nmodel. Subsequently, we introduce an autoregressive model based on DRL, namely\nArc-DRL, consisting of an encoder and decoder to address the CPP-LC challenge\neffectively. Such a framework allows the DRL model to work efficiently and\nscalably to arc routing problems. Furthermore, we propose a new bio-inspired\nmeta-heuristic solution based on Evolutionary Algorithm (EA) for CPP-LC.\nExtensive experiments show that Arc-DRL outperforms existing meta-heuristic\nmethods such as Iterative Local Search (ILS) and Variable Neighborhood Search\n(VNS) proposed by (Corberan et al., 2018) on large benchmark datasets for\nCPP-LC regarding both solution quality and running time; while the EA gives the\nbest solution quality with much more running time. We release our C++\nimplementations for metaheuristics such as EA, ILS and VNS along with the code\nfor data generation and our generated data at\nhttps://github.com/HySonLab/Chinese_Postman_Problem\n","authors":["Truong Son Hy","Cong Dao Tran"],"pdf_url":"https://arxiv.org/pdf/2310.15516v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11537v1","updated":"2023-11-20T04:54:51Z","published":"2023-11-20T04:54:51Z","title":"ADAPTER-RL: Adaptation of Any Agent using Reinforcement Learning","summary":"  Deep Reinforcement Learning (DRL) agents frequently face challenges in\nadapting to tasks outside their training distribution, including issues with\nover-fitting, catastrophic forgetting and sample inefficiency. Although the\napplication of adapters has proven effective in supervised learning contexts\nsuch as natural language processing and computer vision, their potential within\nthe DRL domain remains largely unexplored. This paper delves into the\nintegration of adapters in reinforcement learning, presenting an innovative\nadaptation strategy that demonstrates enhanced training efficiency and\nimprovement of the base-agent, experimentally in the nanoRTS environment, a\nreal-time strategy (RTS) game simulation. Our proposed universal approach is\nnot only compatible with pre-trained neural networks but also with rule-based\nagents, offering a means to integrate human expertise.\n","authors":["Yizhao Jin","Greg Slabaugh","Simon Lucas"],"pdf_url":"https://arxiv.org/pdf/2311.11537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13335v3","updated":"2023-11-20T04:52:36Z","published":"2023-02-26T15:40:09Z","title":"Diffusion Model-Augmented Behavioral Cloning","summary":"  Imitation learning addresses the challenge of learning by observing an\nexpert's demonstrations without access to reward signals from environments.\nMost existing imitation learning methods that do not require interacting with\nenvironments either model the expert distribution as the conditional\nprobability p(a|s) (e.g., behavioral cloning, BC) or the joint probability p(s,\na). Despite its simplicity, modeling the conditional probability with BC\nusually struggles with generalization. While modeling the joint probability can\nlead to improved generalization performance, the inference procedure is often\ntime-consuming and the model can suffer from manifold overfitting. This work\nproposes an imitation learning framework that benefits from modeling both the\nconditional and joint probability of the expert distribution. Our proposed\ndiffusion model-augmented behavioral cloning (DBC) employs a diffusion model\ntrained to model expert behaviors and learns a policy to optimize both the BC\nloss (conditional) and our proposed diffusion model loss (joint). DBC\noutperforms baselines in various continuous control tasks in navigation, robot\narm manipulation, dexterous manipulation, and locomotion. We design additional\nexperiments to verify the limitations of modeling either the conditional\nprobability or the joint probability of the expert distribution as well as\ncompare different generative models. Ablation studies justify the effectiveness\nof our design choices.\n","authors":["Hsiang-Chun Wang","Shang-Fu Chen","Ming-Hao Hsu","Chun-Mao Lai","Shao-Hua Sun"],"pdf_url":"https://arxiv.org/pdf/2302.13335v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.17713v2","updated":"2023-11-20T04:36:29Z","published":"2023-03-30T21:16:44Z","title":"Mitigating Source Bias for Fairer Weak Supervision","summary":"  Weak supervision enables efficient development of training sets by reducing\nthe need for ground truth labels. However, the techniques that make weak\nsupervision attractive -- such as integrating any source of signal to estimate\nunknown labels -- also entail the danger that the produced pseudolabels are\nhighly biased. Surprisingly, given everyday use and the potential for increased\nbias, weak supervision has not been studied from the point of view of fairness.\nWe begin such a study, starting with the observation that even when a fair\nmodel can be built from a dataset with access to ground-truth labels, the\ncorresponding dataset labeled via weak supervision can be arbitrarily unfair.\nTo address this, we propose and empirically validate a model for source\nunfairness in weak supervision, then introduce a simple counterfactual\nfairness-based technique that can mitigate these biases. Theoretically, we show\nthat it is possible for our approach to simultaneously improve both accuracy\nand fairness -- in contrast to standard fairness approaches that suffer from\ntradeoffs. Empirically, we show that our technique improves accuracy on weak\nsupervision baselines by as much as 32\\% while reducing demographic parity gap\nby 82.5\\%. A simple extension of our method aimed at maximizing performance\nproduces state-of-the-art performance in five out of ten datasets in the WRENCH\nbenchmark.\n","authors":["Changho Shin","Sonia Cromp","Dyah Adila","Frederic Sala"],"pdf_url":"https://arxiv.org/pdf/2303.17713v2.pdf","comment":"42 pages"},{"id":"http://arxiv.org/abs/2311.11532v1","updated":"2023-11-20T04:34:19Z","published":"2023-11-20T04:34:19Z","title":"Optimal Hyperparameter $ε$ for Adaptive Stochastic Optimizers\n  through Gradient Histograms","summary":"  Optimizers are essential components for successfully training deep neural\nnetwork models. In order to achieve the best performance from such models,\ndesigners need to carefully choose the optimizer hyperparameters. However, this\ncan be a computationally expensive and time-consuming process. Although it is\nknown that all optimizer hyperparameters must be tuned for maximum performance,\nthere is still a lack of clarity regarding the individual influence of minor\npriority hyperparameters, including the safeguard factor $\\epsilon$ and\nmomentum factor $\\beta$, in leading adaptive optimizers (specifically, those\nbased on the Adam optimizers). In this manuscript, we introduce a new framework\nbased on gradient histograms to analyze and justify important attributes of\nadaptive optimizers, such as their optimal performance and the relationships\nand dependencies among hyperparameters. Furthermore, we propose a novel\ngradient histogram-based algorithm that automatically estimates a reduced and\naccurate search space for the safeguard hyperparameter $\\epsilon$, where the\noptimal value can be easily found.\n","authors":["Gustavo Silva","Paul Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2311.11532v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.15439v2","updated":"2023-11-20T04:31:13Z","published":"2022-05-30T21:34:40Z","title":"StyleTTS: A Style-Based Generative Model for Natural and Diverse\n  Text-to-Speech Synthesis","summary":"  Text-to-Speech (TTS) has recently seen great progress in synthesizing\nhigh-quality speech owing to the rapid development of parallel TTS systems, but\nproducing speech with naturalistic prosodic variations, speaking styles and\nemotional tones remains challenging. Moreover, since duration and speech are\ngenerated separately, parallel TTS models still have problems finding the best\nmonotonic alignments that are crucial for naturalistic speech synthesis. Here,\nwe propose StyleTTS, a style-based generative model for parallel TTS that can\nsynthesize diverse speech with natural prosody from a reference speech\nutterance. With novel Transferable Monotonic Aligner (TMA) and\nduration-invariant data augmentation schemes, our method significantly\noutperforms state-of-the-art models on both single and multi-speaker datasets\nin subjective tests of speech naturalness and speaker similarity. Through\nself-supervised learning of the speaking styles, our model can synthesize\nspeech with the same prosodic and emotional tone as any given reference speech\nwithout the need for explicitly labeling these categories.\n","authors":["Yinghao Aaron Li","Cong Han","Nima Mesgarani"],"pdf_url":"https://arxiv.org/pdf/2205.15439v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.07691v2","updated":"2023-11-20T04:23:08Z","published":"2023-06-13T11:04:43Z","title":"StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion\n  and Adversarial Training with Large Speech Language Models","summary":"  In this paper, we present StyleTTS 2, a text-to-speech (TTS) model that\nleverages style diffusion and adversarial training with large speech language\nmodels (SLMs) to achieve human-level TTS synthesis. StyleTTS 2 differs from its\npredecessor by modeling styles as a latent random variable through diffusion\nmodels to generate the most suitable style for the text without requiring\nreference speech, achieving efficient latent diffusion while benefiting from\nthe diverse speech synthesis offered by diffusion models. Furthermore, we\nemploy large pre-trained SLMs, such as WavLM, as discriminators with our novel\ndifferentiable duration modeling for end-to-end training, resulting in improved\nspeech naturalness. StyleTTS 2 surpasses human recordings on the single-speaker\nLJSpeech dataset and matches it on the multispeaker VCTK dataset as judged by\nnative English speakers. Moreover, when trained on the LibriTTS dataset, our\nmodel outperforms previous publicly available models for zero-shot speaker\nadaptation. This work achieves the first human-level TTS on both single and\nmultispeaker datasets, showcasing the potential of style diffusion and\nadversarial training with large SLMs. The audio demos and source code are\navailable at https://styletts2.github.io/.\n","authors":["Yinghao Aaron Li","Cong Han","Vinay S. Raghavan","Gavin Mischler","Nima Mesgarani"],"pdf_url":"https://arxiv.org/pdf/2306.07691v2.pdf","comment":"NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.11520v1","updated":"2023-11-20T03:51:39Z","published":"2023-11-20T03:51:39Z","title":"Liver Tumor Prediction with Advanced Attention Mechanisms Integrated\n  into a Depth-Based Variant Search Algorithm","summary":"  In recent days, Deep Learning (DL) techniques have become an emerging\ntransformation in the field of machine learning, artificial intelligence,\ncomputer vision, and so on. Subsequently, researchers and industries have been\nhighly endorsed in the medical field, predicting and controlling diverse\ndiseases at specific intervals. Liver tumor prediction is a vital chore in\nanalyzing and treating liver diseases. This paper proposes a novel approach for\npredicting liver tumors using Convolutional Neural Networks (CNN) and a\ndepth-based variant search algorithm with advanced attention mechanisms\n(CNN-DS-AM). The proposed work aims to improve accuracy and robustness in\ndiagnosing and treating liver diseases. The anticipated model is assessed on a\nComputed Tomography (CT) scan dataset containing both benign and malignant\nliver tumors. The proposed approach achieved high accuracy in predicting liver\ntumors, outperforming other state-of-the-art methods. Additionally, advanced\nattention mechanisms were incorporated into the CNN model to enable the\nidentification and highlighting of regions of the CT scans most relevant to\npredicting liver tumors. The results suggest that incorporating attention\nmechanisms and a depth-based variant search algorithm into the CNN model is a\npromising approach for improving the accuracy and robustness of liver tumor\nprediction. It can assist radiologists in their diagnosis and treatment\nplanning. The proposed system achieved a high accuracy of 95.5% in predicting\nliver tumors, outperforming other state-of-the-art methods.\n","authors":["P. Kalaiselvi","S. Anusuya"],"pdf_url":"https://arxiv.org/pdf/2311.11520v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11518v1","updated":"2023-11-20T03:44:32Z","published":"2023-11-20T03:44:32Z","title":"Multi-teacher Distillation for Multilingual Spelling Correction","summary":"  Accurate spelling correction is a critical step in modern search interfaces,\nespecially in an era of mobile devices and speech-to-text interfaces. For\nservices that are deployed around the world, this poses a significant challenge\nfor multilingual NLP: spelling errors need to be caught and corrected in all\nlanguages, and even in queries that use multiple languages. In this paper, we\ntackle this challenge using multi-teacher distillation. On our approach, a\nmonolingual teacher model is trained for each language/locale, and these\nindividual models are distilled into a single multilingual student model\nintended to serve all languages/locales. In experiments using open-source data\nas well as user data from a worldwide search service, we show that this leads\nto highly effective spelling correction models that can meet the tight latency\nrequirements of deployed services.\n","authors":["Jingfen Zhang","Xuan Guo","Sravan Bodapati","Christopher Potts"],"pdf_url":"https://arxiv.org/pdf/2311.11518v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.20258v3","updated":"2023-11-20T03:43:31Z","published":"2023-10-31T08:24:41Z","title":"Advancing Bayesian Optimization via Learning Correlated Latent Space","summary":"  Bayesian optimization is a powerful method for optimizing black-box functions\nwith limited function evaluations. Recent works have shown that optimization in\na latent space through deep generative models such as variational autoencoders\nleads to effective and efficient Bayesian optimization for structured or\ndiscrete data. However, as the optimization does not take place in the input\nspace, it leads to an inherent gap that results in potentially suboptimal\nsolutions. To alleviate the discrepancy, we propose Correlated latent space\nBayesian Optimization (CoBO), which focuses on learning correlated latent\nspaces characterized by a strong correlation between the distances in the\nlatent space and the distances within the objective function. Specifically, our\nmethod introduces Lipschitz regularization, loss weighting, and trust region\nrecoordination to minimize the inherent gap around the promising areas. We\ndemonstrate the effectiveness of our approach on several optimization tasks in\ndiscrete data, such as molecule design and arithmetic expression fitting, and\nachieve high performance within a small budget.\n","authors":["Seunghun Lee","Jaewon Chu","Sihyeon Kim","Juyeon Ko","Hyunwoo J. Kim"],"pdf_url":"https://arxiv.org/pdf/2310.20258v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.06657v3","updated":"2023-11-20T03:39:38Z","published":"2023-05-11T08:52:09Z","title":"On Practical Robust Reinforcement Learning: Practical Uncertainty Set\n  and Double-Agent Algorithm","summary":"  Robust reinforcement learning (RRL) aims at seeking a robust policy to\noptimize the worst case performance over an uncertainty set of Markov decision\nprocesses (MDPs). This set contains some perturbed MDPs from a nominal MDP\n(N-MDP) that generate samples for training, which reflects some potential\nmismatches between training (i.e., N-MDP) and true environments. In this paper\nwe present an elaborated uncertainty set by excluding some implausible MDPs\nfrom the existing sets. Under this uncertainty set, we develop a sample-based\nRRL algorithm (named ARQ-Learning) for tabular setting and characterize its\nfinite-time error bound. Also, it is proved that ARQ-Learning converges as fast\nas the standard Q-Learning and robust Q-Learning while ensuring better\nrobustness. We introduce an additional pessimistic agent which can tackle the\nmajor bottleneck for the extension of ARQ-Learning into the cases with larger\nor continuous state spaces. Incorporating this idea into RL algorithms, we\npropose double-agent algorithms for model-free RRL. Via experiments, we\ndemonstrate the effectiveness of the proposed algorithms.\n","authors":["Ukjo Hwang","Songnam Hong"],"pdf_url":"https://arxiv.org/pdf/2305.06657v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11509v1","updated":"2023-11-20T03:17:21Z","published":"2023-11-20T03:17:21Z","title":"Token-Level Adversarial Prompt Detection Based on Perplexity Measures\n  and Contextual Information","summary":"  In recent years, Large Language Models (LLM) have emerged as pivotal tools in\nvarious applications. However, these models are susceptible to adversarial\nprompt attacks, where attackers can carefully curate input strings that lead to\nundesirable outputs. The inherent vulnerability of LLMs stems from their\ninput-output mechanisms, especially when presented with intensely\nout-of-distribution (OOD) inputs. This paper proposes a token-level detection\nmethod to identify adversarial prompts, leveraging the LLM's capability to\npredict the next token's probability. We measure the degree of the model's\nperplexity and incorporate neighboring token information to encourage the\ndetection of contiguous adversarial prompt sequences. As a result, we propose\ntwo methods: one that identifies each token as either being part of an\nadversarial prompt or not, and another that estimates the probability of each\ntoken being part of an adversarial prompt.\n","authors":["Zhengmian Hu","Gang Wu","Saayan Mitra","Ruiyi Zhang","Tong Sun","Heng Huang","Vishy Swaminathan"],"pdf_url":"https://arxiv.org/pdf/2311.11509v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.19909v2","updated":"2023-11-20T03:05:50Z","published":"2023-10-30T18:23:58Z","title":"Battle of the Backbones: A Large-Scale Comparison of Pretrained Models\n  across Computer Vision Tasks","summary":"  Neural network based computer vision systems are typically built on a\nbackbone, a pretrained or randomly initialized feature extractor. Several years\nago, the default option was an ImageNet-trained convolutional neural network.\nHowever, the recent past has seen the emergence of countless backbones\npretrained using various algorithms and datasets. While this abundance of\nchoice has led to performance increases for a range of systems, it is difficult\nfor practitioners to make informed decisions about which backbone to choose.\nBattle of the Backbones (BoB) makes this choice easier by benchmarking a\ndiverse suite of pretrained models, including vision-language models, those\ntrained via self-supervised learning, and the Stable Diffusion backbone, across\na diverse set of computer vision tasks ranging from classification to object\ndetection to OOD generalization and more. Furthermore, BoB sheds light on\npromising directions for the research community to advance computer vision by\nilluminating strengths and weakness of existing approaches through a\ncomprehensive analysis conducted on more than 1500 training runs. While vision\ntransformers (ViTs) and self-supervised learning (SSL) are increasingly\npopular, we find that convolutional neural networks pretrained in a supervised\nfashion on large training sets still perform best on most tasks among the\nmodels we consider. Moreover, in apples-to-apples comparisons on the same\narchitectures and similarly sized pretraining datasets, we find that SSL\nbackbones are highly competitive, indicating that future works should perform\nSSL pretraining with advanced architectures and larger pretraining datasets. We\nrelease the raw results of our experiments along with code that allows\nresearchers to put their own backbones through the gauntlet here:\nhttps://github.com/hsouri/Battle-of-the-Backbones\n","authors":["Micah Goldblum","Hossein Souri","Renkun Ni","Manli Shu","Viraj Prabhu","Gowthami Somepalli","Prithvijit Chattopadhyay","Mark Ibrahim","Adrien Bardes","Judy Hoffman","Rama Chellappa","Andrew Gordon Wilson","Tom Goldstein"],"pdf_url":"https://arxiv.org/pdf/2310.19909v2.pdf","comment":"Accepted to NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.11501v1","updated":"2023-11-20T02:59:18Z","published":"2023-11-20T02:59:18Z","title":"MultiLoRA: Democratizing LoRA for Better Multi-Task Learning","summary":"  LoRA achieves remarkable resource efficiency and comparable performance when\nadapting LLMs for specific tasks. Since ChatGPT demonstrated superior\nperformance on various tasks, there has been a growing desire to adapt one\nmodel for all tasks. However, the explicit low-rank of LoRA limits the\nadaptation performance in complex multi-task scenarios. LoRA is dominated by a\nsmall number of top singular vectors while fine-tuning decomposes into a set of\nless important unitary transforms. In this paper, we propose MultiLoRA for\nbetter multi-task adaptation by reducing the dominance of top singular vectors\nobserved in LoRA. MultiLoRA scales LoRA modules horizontally and change\nparameter initialization of adaptation matrices to reduce parameter dependency,\nthus yields more balanced unitary subspaces. We unprecedentedly construct\nspecialized training data by mixing datasets of instruction follow, natural\nlanguage understanding, world knowledge, to cover semantically and\nsyntactically different samples. With only 2.5% of additional parameters,\nMultiLoRA outperforms single LoRA counterparts and fine-tuning on multiple\nbenchmarks and model scales. Further investigation into weight update matrices\nof MultiLoRA exhibits reduced dependency on top singular vectors and more\ndemocratic unitary transform contributions.\n","authors":["Yiming Wang","Yu Lin","Xiaodong Zeng","Guannan Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.11501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11491v1","updated":"2023-11-20T02:31:08Z","published":"2023-11-20T02:31:08Z","title":"Interpretability in Machine Learning: on the Interplay with\n  Explainability, Predictive Performances and Models","summary":"  Interpretability has recently gained attention in the field of machine\nlearning, for it is crucial when it comes to high-stakes decisions or\ntroubleshooting. This abstract concept is hard to grasp and has been\nassociated, over time, with many labels and preconceived ideas. In this\nposition paper, in order to clarify some misunderstandings regarding\ninterpretability, we discuss its relationship with significant concepts in\nmachine learning: explainability, predictive performances, and machine learning\nmodels. For instance, we challenge the idea that interpretability and\nexplainability are substitutes to one another, or that a fixed degree of\ninterpretability can be associated with a given machine learning model.\n","authors":["Benjamin Leblanc","Pascal Germain"],"pdf_url":"https://arxiv.org/pdf/2311.11491v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.09952v2","updated":"2023-11-20T02:14:51Z","published":"2023-08-19T09:12:47Z","title":"Finding emergence in data: causal emergence inspired dynamics learning","summary":"  Modelling complex dynamical systems in a data-driven manner is challenging\ndue to the presence of emergent behaviors and properties that cannot be\ndirectly captured by micro-level observational data. Therefore, it is crucial\nto develop a model that can effectively capture emergent dynamics at the\nmacro-level and quantify emergence based on the available data. Drawing\ninspiration from the theory of causal emergence, this paper introduces a\nmachine learning framework aimed at learning macro-dynamics within an emergent\nlatent space. The framework achieves this by maximizing the effective\ninformation (EI) to obtain a macro-dynamics model with stronger causal effects.\nExperimental results on both simulated and real data demonstrate the\neffectiveness of the proposed framework. Not only does it successfully capture\nemergent patterns, but it also learns the coarse-graining strategy and\nquantifies the degree of causal emergence in the data. Furthermore, experiments\nconducted on environments different from the training dataset highlight the\nsuperior generalization ability of our model.\n","authors":["Mingzhe Yang","Zhipeng Wang","Kaiwei Liu","Yingqi Rong","Bing Yuan","Jiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2308.09952v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.09574v3","updated":"2023-11-20T02:01:33Z","published":"2023-11-16T05:17:14Z","title":"LymphoML: An interpretable artificial intelligence-based method\n  identifies morphologic features that correlate with lymphoma subtype","summary":"  The accurate classification of lymphoma subtypes using hematoxylin and eosin\n(H&E)-stained tissue is complicated by the wide range of morphological features\nthese cancers can exhibit. We present LymphoML - an interpretable machine\nlearning method that identifies morphologic features that correlate with\nlymphoma subtypes. Our method applies steps to process H&E-stained tissue\nmicroarray cores, segment nuclei and cells, compute features encompassing\nmorphology, texture, and architecture, and train gradient-boosted models to\nmake diagnostic predictions. LymphoML's interpretable models, developed on a\nlimited volume of H&E-stained tissue, achieve non-inferior diagnostic accuracy\nto pathologists using whole-slide images and outperform black box deep-learning\non a dataset of 670 cases from Guatemala spanning 8 lymphoma subtypes. Using\nSHapley Additive exPlanation (SHAP) analysis, we assess the impact of each\nfeature on model prediction and find that nuclear shape features are most\ndiscriminative for DLBCL (F1-score: 78.7%) and classical Hodgkin lymphoma\n(F1-score: 74.5%). Finally, we provide the first demonstration that a model\ncombining features from H&E-stained tissue with features from a standardized\npanel of 6 immunostains results in a similar diagnostic accuracy (85.3%) to a\n46-stain panel (86.1%).\n","authors":["Vivek Shankar","Xiaoli Yang","Vrishab Krishna","Brent Tan","Oscar Silva","Rebecca Rojansky","Andrew Ng","Fabiola Valvert","Edward Briercheck","David Weinstock","Yasodha Natkunam","Sebastian Fernandez-Pol","Pranav Rajpurkar"],"pdf_url":"https://arxiv.org/pdf/2311.09574v3.pdf","comment":"To be published in Proceedings of the 3rd Machine Learning for Health\n  symposium, Proceedings of Machine Learning Research (PMLR)"},{"id":"http://arxiv.org/abs/2311.11485v1","updated":"2023-11-20T02:00:33Z","published":"2023-11-20T02:00:33Z","title":"An NMF-Based Building Block for Interpretable Neural Networks With\n  Continual Learning","summary":"  Existing learning methods often struggle to balance interpretability and\npredictive performance. While models like nearest neighbors and non-negative\nmatrix factorization (NMF) offer high interpretability, their predictive\nperformance on supervised learning tasks is often limited. In contrast, neural\nnetworks based on the multi-layer perceptron (MLP) support the modular\nconstruction of expressive architectures and tend to have better recognition\naccuracy but are often regarded as black boxes in terms of interpretability.\nOur approach aims to strike a better balance between these two aspects through\nthe use of a building block based on NMF that incorporates supervised neural\nnetwork training methods to achieve high predictive performance while retaining\nthe desirable interpretability properties of NMF. We evaluate our Predictive\nFactorized Coupling (PFC) block on small datasets and show that it achieves\ncompetitive predictive performance with MLPs while also offering improved\ninterpretability. We demonstrate the benefits of this approach in various\nscenarios, such as continual learning, training on non-i.i.d. data, and\nknowledge removal after training. Additionally, we show examples of using the\nPFC block to build more expressive architectures, including a fully-connected\nresidual network as well as a factorized recurrent neural network (RNN) that\nperforms competitively with vanilla RNNs while providing improved\ninterpretability. The PFC block uses an iterative inference algorithm that\nconverges to a fixed point, making it possible to trade off accuracy vs\ncomputation after training but also currently preventing its use as a general\nMLP replacement in some scenarios such as training on very large datasets. We\nprovide source code at https://github.com/bkvogel/pfc\n","authors":["Brian K. Vogel"],"pdf_url":"https://arxiv.org/pdf/2311.11485v1.pdf","comment":"42 pages, 13 figures"},{"id":"http://arxiv.org/abs/2311.10251v2","updated":"2023-11-20T01:59:11Z","published":"2023-11-17T00:44:56Z","title":"UniMOS: A Universal Framework For Multi-Organ Segmentation Over\n  Label-Constrained Datasets","summary":"  Machine learning models for medical images can help physicians diagnose and\nmanage diseases. However, due to the fact that medical image annotation\nrequires a great deal of manpower and expertise, as well as the fact that\nclinical departments perform image annotation based on task orientation, there\nis the problem of having fewer medical image annotation data with more\nunlabeled data and having many datasets that annotate only a single organ. In\nthis paper, we present UniMOS, the first universal framework for achieving the\nutilization of fully and partially labeled images as well as unlabeled images.\nSpecifically, we construct a Multi-Organ Segmentation (MOS) module over\nfully/partially labeled data as the basenet and designed a new target adaptive\nloss. Furthermore, we incorporate a semi-supervised training module that\ncombines consistent regularization and pseudolabeling techniques on unlabeled\ndata, which significantly improves the segmentation of unlabeled data.\nExperiments show that the framework exhibits excellent performance in several\nmedical image segmentation tasks compared to other advanced methods, and also\nsignificantly improves data utilization and reduces annotation cost. Code and\nmodels are available at: https://github.com/lw8807001/UniMOS.\n","authors":["Can Li","Sheng Shao","Junyi Qu","Shuchao Pang","Mehmet A. Orgun"],"pdf_url":"https://arxiv.org/pdf/2311.10251v2.pdf","comment":"Accepted by BIBM2023"},{"id":"http://arxiv.org/abs/2311.11483v1","updated":"2023-11-20T01:58:27Z","published":"2023-11-20T01:58:27Z","title":"A Multi-Center Study on the Adaptability of a Shared Foundation Model\n  for Electronic Health Records","summary":"  Foundation models hold promise for transforming AI in healthcare by providing\nmodular components that are easily adaptable to downstream healthcare tasks,\nmaking AI development more scalable and cost-effective. Structured EHR\nfoundation models, trained on coded medical records from millions of patients,\ndemonstrated benefits including increased performance with fewer training\nlabels, and improved robustness to distribution shifts. However, questions\nremain on the feasibility of sharing these models across different hospitals\nand their performance for local task adaptation. This multi-center study\nexamined the adaptability of a recently released structured EHR foundation\nmodel ($FM_{SM}$), trained on longitudinal medical record data from 2.57M\nStanford Medicine patients. Experiments were conducted using EHR data at The\nHospital for Sick Children and MIMIC-IV. We assessed both adaptability via\ncontinued pretraining on local data, and task adaptability compared to\nbaselines of training models from scratch at each site, including a local\nfoundation model. We evaluated the performance of these models on 8 clinical\nprediction tasks. In both datasets, adapting the off-the-shelf $FM_{SM}$\nmatched the performance of GBM models locally trained on all data while\nproviding a 13% improvement in settings with few task-specific training labels.\nWith continued pretraining on local data, label efficiency substantially\nimproved, such that $FM_{SM}$ required fewer than 1% of training examples to\nmatch the fully trained GBM's performance. Continued pretraining was also 60 to\n90% more sample-efficient than training local foundation models from scratch.\nOur findings show that adapting shared EHR foundation models across hospitals\nprovides improved prediction performance at less cost, underscoring the utility\nof base foundation models as modular components to streamline the development\nof healthcare AI.\n","authors":["Lin Lawrence Guo","Jason Fries","Ethan Steinberg","Scott Lanyon Fleming","Keith Morse","Catherine Aftandilian","Jose Posada","Nigam Shah","Lillian Sung"],"pdf_url":"https://arxiv.org/pdf/2311.11483v1.pdf","comment":"41 pages, 3 figures, 2 tables, 16 appendices"},{"id":"http://arxiv.org/abs/2305.16300v2","updated":"2023-11-20T01:16:17Z","published":"2023-05-25T17:53:42Z","title":"Landmark Attention: Random-Access Infinite Context Length for\n  Transformers","summary":"  While Transformers have shown remarkable success in natural language\nprocessing, their attention mechanism's large memory requirements have limited\ntheir ability to handle longer contexts. Prior approaches, such as recurrent\nmemory or retrieval-based augmentation, have either compromised the\nrandom-access flexibility of attention (i.e., the capability to select any\ntoken in the entire context) or relied on separate mechanisms for relevant\ncontext retrieval, which may not be compatible with the model's attention. In\nthis paper, we present a novel approach that allows access to the complete\ncontext while retaining random-access flexibility, closely resembling running\nattention on the entire context. Our method uses a landmark token to represent\neach block of the input and trains the attention to use it for selecting\nrelevant blocks, enabling retrieval of blocks directly through the attention\nmechanism instead of by relying on a separate mechanism. Our approach\nseamlessly integrates with specialized data structures and the system's memory\nhierarchy, enabling processing of arbitrarily long context lengths. We\ndemonstrate that our method can obtain comparable performance with\nTransformer-XL while significantly reducing the number of retrieved tokens in\neach step. Finally, we show that fine-tuning LLaMA 7B with our method\nsuccessfully extends its context length capacity to over 32k tokens, allowing\nfor inference at the context lengths of GPT-4. We release the implementation of\nlandmark attention and the code to reproduce our experiments at\nhttps://github.com/epfml/landmark-attention/.\n","authors":["Amirkeivan Mohtashami","Martin Jaggi"],"pdf_url":"https://arxiv.org/pdf/2305.16300v2.pdf","comment":"Published as a conference paper at NeurIPS 2023 - 37th Conference on\n  Neural Information Processing Systems"},{"id":"http://arxiv.org/abs/2311.11475v1","updated":"2023-11-20T00:59:20Z","published":"2023-11-20T00:59:20Z","title":"Gaussian Interpolation Flows","summary":"  Gaussian denoising has emerged as a powerful principle for constructing\nsimulation-free continuous normalizing flows for generative modeling. Despite\ntheir empirical successes, theoretical properties of these flows and the\nregularizing effect of Gaussian denoising have remained largely unexplored. In\nthis work, we aim to address this gap by investigating the well-posedness of\nsimulation-free continuous normalizing flows built on Gaussian denoising.\nThrough a unified framework termed Gaussian interpolation flow, we establish\nthe Lipschitz regularity of the flow velocity field, the existence and\nuniqueness of the flow, and the Lipschitz continuity of the flow map and the\ntime-reversed flow map for several rich classes of target distributions. This\nanalysis also sheds light on the auto-encoding and cycle-consistency properties\nof Gaussian interpolation flows. Additionally, we delve into the stability of\nthese flows in source distributions and perturbations of the velocity field,\nusing the quadratic Wasserstein distance as a metric. Our findings offer\nvaluable insights into the learning techniques employed in Gaussian\ninterpolation flows for generative modeling, providing a solid theoretical\nfoundation for end-to-end error analyses of learning GIFs with empirical\nobservations.\n","authors":["Yuan Gao","Jian Huang","Yuling Jiao"],"pdf_url":"https://arxiv.org/pdf/2311.11475v1.pdf","comment":"49 pages, 4 figures"},{"id":"http://arxiv.org/abs/2311.11473v1","updated":"2023-11-20T00:57:30Z","published":"2023-11-20T00:57:30Z","title":"CSGNN: Conquering Noisy Node labels via Dynamic Class-wise Selection","summary":"  Graph Neural Networks (GNNs) have emerged as a powerful tool for\nrepresentation learning on graphs, but they often suffer from overfitting and\nlabel noise issues, especially when the data is scarce or imbalanced. Different\nfrom the paradigm of previous methods that rely on single-node confidence, in\nthis paper, we introduce a novel Class-wise Selection for Graph Neural\nNetworks, dubbed CSGNN, which employs a neighbor-aggregated latent space to\nadaptively select reliable nodes across different classes. Specifically, 1) to\ntackle the class imbalance issue, we introduce a dynamic class-wise selection\nmechanism, leveraging the clustering technique to identify clean nodes based on\nthe neighbor-aggregated confidences. In this way, our approach can avoid the\npitfalls of biased sampling which is common with global threshold techniques.\n2) To alleviate the problem of noisy labels, built on the concept of the\nmemorization effect, CSGNN prioritizes learning from clean nodes before noisy\nones, thereby iteratively enhancing model performance while mitigating label\nnoise. Through extensive experiments, we demonstrate that CSGNN outperforms\nstate-of-the-art methods in terms of both effectiveness and robustness.\n","authors":["Yifan Li","Zhen Tan","Kai Shu","Zongsheng Cao","Yu Kong","Huan Liu"],"pdf_url":"https://arxiv.org/pdf/2311.11473v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.15308v2","updated":"2023-11-20T00:56:15Z","published":"2023-10-23T19:21:57Z","title":"SAM-CLIP: Merging Vision Foundation Models towards Semantic and Spatial\n  Understanding","summary":"  The landscape of publicly available vision foundation models (VFMs), such as\nCLIP and Segment Anything Model (SAM), is expanding rapidly. VFMs are endowed\nwith distinct capabilities stemming from their pre-training objectives. For\ninstance, CLIP excels in semantic understanding, while SAM specializes in\nspatial understanding for segmentation. In this work, we introduce a simple\nrecipe to efficiently merge VFMs into a unified model that absorbs their\nexpertise. Our method integrates techniques of multi-task learning, continual\nlearning, and distillation. Further, it demands significantly less\ncomputational cost compared to traditional multi-task training from scratch,\nand it only needs a small fraction of the pre-training datasets that were\ninitially used to train individual models. By applying our method to SAM and\nCLIP, we obtain SAM-CLIP: a unified model that combines the capabilities of SAM\nand CLIP into a single vision transformer. Compared with deploying SAM and CLIP\nindependently, our merged model, SAM-CLIP, reduces storage and compute costs\nfor inference, making it well-suited for edge device applications. We show that\nSAM-CLIP not only retains the foundational strengths of SAM and CLIP, but also\nintroduces synergistic functionalities, notably in zero-shot semantic\nsegmentation, where SAM-CLIP establishes new state-of-the-art results on 5\nbenchmarks. It outperforms previous models that are specifically designed for\nthis task by a large margin, including +6.8% and +5.9% mean IoU improvement on\nPascal-VOC and COCO-Stuff datasets, respectively.\n","authors":["Haoxiang Wang","Pavan Kumar Anasosalu Vasu","Fartash Faghri","Raviteja Vemulapalli","Mehrdad Farajtabar","Sachin Mehta","Mohammad Rastegari","Oncel Tuzel","Hadi Pouransari"],"pdf_url":"https://arxiv.org/pdf/2310.15308v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11463v1","updated":"2023-11-20T00:15:16Z","published":"2023-11-20T00:15:16Z","title":"Towards a Post-Market Monitoring Framework for Machine Learning-based\n  Medical Devices: A case study","summary":"  After a machine learning (ML)-based system is deployed in clinical practice,\nperformance monitoring is important to ensure the safety and effectiveness of\nthe algorithm over time. The goal of this work is to highlight the complexity\nof designing a monitoring strategy and the need for a systematic framework that\ncompares the multitude of monitoring options. One of the main decisions is\nchoosing between using real-world (observational) versus interventional data.\nAlthough the former is the most convenient source of monitoring data, it\nexhibits well-known biases, such as confounding, selection, and missingness. In\nfact, when the ML algorithm interacts with its environment, the algorithm\nitself may be a primary source of bias. On the other hand, a carefully designed\ninterventional study that randomizes individuals can explicitly eliminate such\nbiases, but the ethics, feasibility, and cost of such an approach must be\ncarefully considered. Beyond the decision of the data source, monitoring\nstrategies vary in the performance criteria they track, the interpretability of\nthe test statistics, the strength of their assumptions, and their speed at\ndetecting performance decay. As a first step towards developing a framework\nthat compares the various monitoring options, we consider a case study of an\nML-based risk prediction algorithm for postoperative nausea and vomiting\n(PONV). Bringing together tools from causal inference and statistical process\ncontrol, we walk through the basic steps of defining candidate monitoring\ncriteria, describing potential sources of bias and the causal model, and\nspecifying and comparing candidate monitoring procedures. We hypothesize that\nthese steps can be applied more generally, as causal inference can address\nother sources of biases as well.\n","authors":["Jean Feng","Adarsh Subbaswamy","Alexej Gossmann","Harvineet Singh","Berkman Sahiner","Mi-Ok Kim","Gene Pennello","Nicholas Petrick","Romain Pirracchio","Fan Xia"],"pdf_url":"https://arxiv.org/pdf/2311.11463v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2311.11892v1","updated":"2023-11-20T16:25:23Z","published":"2023-11-20T16:25:23Z","title":"Multimodal Characterization of Emotion within Multimedia Space","summary":"  Technological advancement and its omnipresent connection have pushed humans\npast the boundaries and limitations of a computer screen, physical state, or\ngeographical location. It has provided a depth of avenues that facilitate\nhuman-computer interaction that was once inconceivable such as audio and body\nlanguage detection. Given the complex modularities of emotions, it becomes\nvital to study human-computer interaction, as it is the commencement of a\nthorough understanding of the emotional state of users and, in the context of\nsocial networks, the producers of multimodal information. This study first\nacknowledges the accuracy of classification found within multimodal emotion\ndetection systems compared to unimodal solutions. Second, it explores the\ncharacterization of multimedia content produced based on their emotions and the\ncoherence of emotion in different modalities by utilizing deep learning models\nto classify emotion across different modalities.\n","authors":["Dayo Samuel Banjo","Connice Trimmingham","Niloofar Yousefi","Nitin Agarwal"],"pdf_url":"https://arxiv.org/pdf/2311.11892v1.pdf","comment":"8 pages, Published in International Conference on Computers and\n  Computation (COMPUTE 2022), November 03-04, 2022, San Francisco, United\n  States"},{"id":"http://arxiv.org/abs/2311.11783v1","updated":"2023-11-20T14:09:13Z","published":"2023-11-20T14:09:13Z","title":"CityScope: Enhanced Localozation and Synchronizing AR for Dynamic Urban\n  Weather Visualization","summary":"  CityScope uses augmented reality (AR) to change our interaction with weather\ndata. The main goal is to develop real-time 3D weather visualizations, with\nTaiwan as the model. It displays live weather data from the Central Weather\nBureau (CWB), projected onto a physical representation of Taiwan's landscape. A\npivotal advancement in our project is the integration of AprilTag with plane\ndetection technology. This innovative combination significantly enhances the\nprecision of the virtual visualizations within the physical world. By\naccurately aligning AR elements with real-world environments, CityScope\nachieves a seamless and realistic amalgamation of weather data and the physical\nterrain of Taiwan. This breakthrough in AR technology not only enhances the\naccuracy of weather visualizations but also enriches user experience, offering\nan immersive and interactive way to understand and engage with meteorological\ninformation. CityScope stands as a testament to the potential of AR in\ntransforming data visualization and public engagement in meteorology.\n","authors":["Tzu Hsin Hsieh"],"pdf_url":"https://arxiv.org/pdf/2311.11783v1.pdf","comment":"9 pages, 15 figures"},{"id":"http://arxiv.org/abs/2311.12159v1","updated":"2023-11-20T20:24:45Z","published":"2023-11-20T20:24:45Z","title":"Conditional Modeling Based Automatic Video Summarization","summary":"  The aim of video summarization is to shorten videos automatically while\nretaining the key information necessary to convey the overall story. Video\nsummarization methods mainly rely on visual factors, such as visual\nconsecutiveness and diversity, which may not be sufficient to fully understand\nthe content of the video. There are other non-visual factors, such as\ninterestingness, representativeness, and storyline consistency that should also\nbe considered for generating high-quality video summaries. Current methods do\nnot adequately take into account these non-visual factors, resulting in\nsuboptimal performance. In this work, a new approach to video summarization is\nproposed based on insights gained from how humans create ground truth video\nsummaries. The method utilizes a conditional modeling perspective and\nintroduces multiple meaningful random variables and joint distributions to\ncharacterize the key components of video summarization. Helper distributions\nare employed to improve the training of the model. A conditional attention\nmodule is designed to mitigate potential performance degradation in the\npresence of multi-modal input. The proposed video summarization method\nincorporates the above innovative design choices that aim to narrow the gap\nbetween human-generated and machine-generated video summaries. Extensive\nexperiments show that the proposed approach outperforms existing methods and\nachieves state-of-the-art performance on commonly used video summarization\ndatasets.\n","authors":["Jia-Hong Huang","Chao-Han Huck Yang","Pin-Yu Chen","Min-Hung Chen","Marcel Worring"],"pdf_url":"https://arxiv.org/pdf/2311.12159v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  arXiv admin note: substantial text overlap with arXiv:2305.00455"},{"id":"http://arxiv.org/abs/2311.11642v1","updated":"2023-11-20T10:01:13Z","published":"2023-11-20T10:01:13Z","title":"Video Face Re-Aging: Toward Temporally Consistent Face Re-Aging","summary":"  Video face re-aging deals with altering the apparent age of a person to the\ntarget age in videos. This problem is challenging due to the lack of paired\nvideo datasets maintaining temporal consistency in identity and age. Most\nre-aging methods process each image individually without considering the\ntemporal consistency of videos. While some existing works address the issue of\ntemporal coherence through video facial attribute manipulation in latent space,\nthey often fail to deliver satisfactory performance in age transformation. To\ntackle the issues, we propose (1) a novel synthetic video dataset that features\nsubjects across a diverse range of age groups; (2) a baseline architecture\ndesigned to validate the effectiveness of our proposed dataset, and (3) the\ndevelopment of three novel metrics tailored explicitly for evaluating the\ntemporal consistency of video re-aging techniques. Our comprehensive\nexperiments on public datasets, such as VFHQ and CelebV-HQ, show that our\nmethod outperforms the existing approaches in terms of both age transformation\nand temporal consistency.\n","authors":["Abdul Muqeet","Kyuchul Lee","Bumsoo Kim","Yohan Hong","Hyungrae Lee","Woonggon Kim","Kwang Hee Lee"],"pdf_url":"https://arxiv.org/pdf/2311.11642v1.pdf","comment":"8 pages, 6 figures, 4 tables"}]},"2023-11-19T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2311.11462v1","updated":"2023-11-19T23:59:22Z","published":"2023-11-19T23:59:22Z","title":"LLM aided semi-supervision for Extractive Dialog Summarization","summary":"  Generating high-quality summaries for chat dialogs often requires large\nlabeled datasets. We propose a method to efficiently use unlabeled data for\nextractive summarization of customer-agent dialogs. In our method, we frame\nsummarization as a question-answering problem and use state-of-the-art large\nlanguage models (LLMs) to generate pseudo-labels for a dialog. We then use\nthese pseudo-labels to fine-tune a chat summarization model, effectively\ntransferring knowledge from the large LLM into a smaller specialized model. We\ndemonstrate our method on the \\tweetsumm dataset, and show that using 10\\% of\nthe original labelled data set we can achieve 65.9/57.0/61.0 ROUGE-1/-2/-L,\nwhereas the current state-of-the-art trained on the entire training data set\nobtains 65.16/55.81/64.37 ROUGE-1/-2/-L. In other words, in the worst case\n(i.e., ROUGE-L) we still effectively retain 94.7% of the performance while\nusing only 10% of the data.\n","authors":["Nishant Mishra","Gaurav Sahu","Iacer Calixto","Ameen Abu-Hanna","Issam H. Laradji"],"pdf_url":"https://arxiv.org/pdf/2311.11462v1.pdf","comment":"to be published in EMNLP Findings"},{"id":"http://arxiv.org/abs/2311.11441v1","updated":"2023-11-19T22:29:15Z","published":"2023-11-19T22:29:15Z","title":"Spot the Bot: Distinguishing Human-Written and Bot-Generated Texts Using\n  Clustering and Information Theory Techniques","summary":"  With the development of generative models like GPT-3, it is increasingly more\nchallenging to differentiate generated texts from human-written ones. There is\na large number of studies that have demonstrated good results in bot\nidentification. However, the majority of such works depend on supervised\nlearning methods that require labelled data and/or prior knowledge about the\nbot-model architecture. In this work, we propose a bot identification algorithm\nthat is based on unsupervised learning techniques and does not depend on a\nlarge amount of labelled data. By combining findings in semantic analysis by\nclustering (crisp and fuzzy) and information techniques, we construct a robust\nmodel that detects a generated text for different types of bot. We find that\nthe generated texts tend to be more chaotic while literary works are more\ncomplex. We also demonstrate that the clustering of human texts results in\nfuzzier clusters in comparison to the more compact and well-separated clusters\nof bot-generated texts.\n","authors":["Vasilii Gromov","Quynh Nhu Dang"],"pdf_url":"https://arxiv.org/pdf/2311.11441v1.pdf","comment":"Accepted in Pattern Recognition and Machine Intelligence 2023. 8\n  pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.11435v1","updated":"2023-11-19T22:14:48Z","published":"2023-11-19T22:14:48Z","title":"Unveiling Public Perceptions: Machine Learning-Based Sentiment Analysis\n  of COVID-19 Vaccines in India","summary":"  In March 2020, the World Health Organisation declared COVID-19 a global\npandemic as it spread to nearly every country. By mid-2021, India had\nintroduced three vaccines: Covishield, Covaxin, and Sputnik. To ensure\nsuccessful vaccination in a densely populated country like India, understanding\npublic sentiment was crucial. Social media, particularly Reddit with over 430\nmillion users, played a vital role in disseminating information. This study\nemploys data mining techniques to analyze Reddit data and gauge Indian\nsentiments towards COVID-19 vaccines. Using Python's Text Blob library,\ncomments are annotated to assess general sentiments. Results show that most\nReddit users in India expressed neutrality about vaccination, posing a\nchallenge for the Indian government's efforts to vaccinate a significant\nportion of the population.\n","authors":["Milind Gupta","Abhishek Kaushik"],"pdf_url":"https://arxiv.org/pdf/2311.11435v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11415v1","updated":"2023-11-19T20:22:05Z","published":"2023-11-19T20:22:05Z","title":"A Security Risk Taxonomy for Large Language Models","summary":"  As large language models (LLMs) permeate more and more applications, an\nassessment of their associated security risks becomes increasingly necessary.\nThe potential for exploitation by malicious actors, ranging from disinformation\nto data breaches and reputation damage, is substantial. This paper addresses a\ngap in current research by focusing on the security risks posed by LLMs, which\nextends beyond the widely covered ethical and societal implications. Our work\nproposes a taxonomy of security risks along the user-model communication\npipeline, explicitly focusing on prompt-based attacks on LLMs. We categorize\nthe attacks by target and attack type within a prompt-based interaction scheme.\nThe taxonomy is reinforced with specific attack examples to showcase the\nreal-world impact of these risks. Through this taxonomy, we aim to inform the\ndevelopment of robust and secure LLM applications, enhancing their safety and\ntrustworthiness.\n","authors":["Erik Derner","Kristina Batistič","Jan Zahálka","Robert Babuška"],"pdf_url":"https://arxiv.org/pdf/2311.11415v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.08365v2","updated":"2023-11-19T17:27:48Z","published":"2023-10-12T14:36:13Z","title":"From Large Language Models to Knowledge Graphs for Biomarker Discovery\n  in Cancer","summary":"  Domain experts often rely on most recent knowledge for apprehending and\ndisseminating specific biological processes that help them design strategies\nfor developing prevention and therapeutic decision-making in various disease\nscenarios. A challenging scenarios for artificial intelligence (AI) is using\nbiomedical data (e.g., texts, imaging, omics, and clinical) to provide\ndiagnosis and treatment recommendations for cancerous conditions.~Data and\nknowledge about biomedical entities like cancer, drugs, genes, proteins, and\ntheir mechanism is spread across structured (knowledge bases (KBs)) and\nunstructured (e.g., scientific articles) sources. A large-scale knowledge graph\n(KG) can be constructed by integrating and extracting facts about semantically\ninterrelated entities and relations. Such a KG not only allows exploration and\nquestion answering (QA) but also enables domain experts to deduce new\nknowledge. However, exploring and querying large-scale KGs is tedious for\nnon-domain users due to their lack of understanding of the data assets and\nsemantic technologies. In this paper, we develop a domain KG to leverage\ncancer-specific biomarker discovery and interactive QA. For this, we\nconstructed a domain ontology called OncoNet Ontology (ONO), which enables\nsemantic reasoning for validating gene-disease (different types of cancer)\nrelations. The KG is further enriched by harmonizing the ONO, metadata,\ncontrolled vocabularies, and biomedical concepts from scientific articles by\nemploying BioBERT- and SciBERT-based information extractors. Further, since the\nbiomedical domain is evolving, where new findings often replace old ones,\nwithout having access to up-to-date scientific findings, there is a high chance\nan AI system exhibits concept drift while providing diagnosis and treatment.\nTherefore, we fine-tune the KG using large language models (LLMs) based on more\nrecent articles and KBs.\n","authors":["Md. Rezaul Karim","Lina Molinas Comet","Md Shajalal","Oya Deniz Beyan","Dietrich Rebholz-Schuhmann","Stefan Decker"],"pdf_url":"https://arxiv.org/pdf/2310.08365v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2302.04737"},{"id":"http://arxiv.org/abs/2311.11375v1","updated":"2023-11-19T16:53:35Z","published":"2023-11-19T16:53:35Z","title":"ML-LMCL: Mutual Learning and Large-Margin Contrastive Learning for\n  Improving ASR Robustness in Spoken Language Understanding","summary":"  Spoken language understanding (SLU) is a fundamental task in the\ntask-oriented dialogue systems. However, the inevitable errors from automatic\nspeech recognition (ASR) usually impair the understanding performance and lead\nto error propagation. Although there are some attempts to address this problem\nthrough contrastive learning, they (1) treat clean manual transcripts and ASR\ntranscripts equally without discrimination in fine-tuning; (2) neglect the fact\nthat the semantically similar pairs are still pushed away when applying\ncontrastive learning; (3) suffer from the problem of Kullback-Leibler (KL)\nvanishing. In this paper, we propose Mutual Learning and Large-Margin\nContrastive Learning (ML-LMCL), a novel framework for improving ASR robustness\nin SLU. Specifically, in fine-tuning, we apply mutual learning and train two\nSLU models on the manual transcripts and the ASR transcripts, respectively,\naiming to iteratively share knowledge between these two models. We also\nintroduce a distance polarization regularizer to avoid pushing away the\nintra-cluster pairs as much as possible. Moreover, we use a cyclical annealing\nschedule to mitigate KL vanishing issue. Experiments on three datasets show\nthat ML-LMCL outperforms existing models and achieves new state-of-the-art\nperformance.\n","authors":["Xuxin Cheng","Bowen Cao","Qichen Ye","Zhihong Zhu","Hongxiang Li","Yuexian Zou"],"pdf_url":"https://arxiv.org/pdf/2311.11375v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.06476v3","updated":"2023-11-19T15:43:58Z","published":"2023-02-08T09:44:51Z","title":"Is ChatGPT a General-Purpose Natural Language Processing Task Solver?","summary":"  Spurred by advancements in scale, large language models (LLMs) have\ndemonstrated the ability to perform a variety of natural language processing\n(NLP) tasks zero-shot -- i.e., without adaptation on downstream data. Recently,\nthe debut of ChatGPT has drawn a great deal of attention from the natural\nlanguage processing (NLP) community due to the fact that it can generate\nhigh-quality responses to human input and self-correct previous mistakes based\non subsequent conversations. However, it is not yet known whether ChatGPT can\nserve as a generalist model that can perform many NLP tasks zero-shot. In this\nwork, we empirically analyze the zero-shot learning ability of ChatGPT by\nevaluating it on 20 popular NLP datasets covering 7 representative task\ncategories. With extensive empirical studies, we demonstrate both the\neffectiveness and limitations of the current version of ChatGPT. We find that\nChatGPT performs well on many tasks favoring reasoning capabilities (e.g.,\narithmetic reasoning) while it still faces challenges when solving specific\ntasks such as sequence tagging. We additionally provide in-depth analysis\nthrough qualitative case studies.\n","authors":["Chengwei Qin","Aston Zhang","Zhuosheng Zhang","Jiaao Chen","Michihiro Yasunaga","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2302.06476v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.09889v2","updated":"2023-11-19T15:23:17Z","published":"2023-11-16T13:37:21Z","title":"Language Generation from Human Brain Activities","summary":"  Generating human language through non-invasive brain-computer interfaces\n(BCIs) has the potential to unlock many applications, such as serving disabled\npatients and improving communication. Currently, however, generating language\nvia BCIs has been previously successful only within a classification setup for\nselecting pre-generated sentence continuation candidates with the most likely\ncortical semantic representation. Inspired by recent research that revealed\nassociations between the brain and the large computational language models, we\npropose a generative language BCI that utilizes the capacity of a large\nlanguage model (LLM) jointly with a semantic brain decoder to directly generate\nlanguage from functional magnetic resonance imaging (fMRI) input. The proposed\nmodel can generate coherent language sequences aligned with the semantic\ncontent of visual or auditory language stimuli perceived, without prior\nknowledge of any pre-generated candidates. We compare the language generated\nfrom the presented model with a random control, pre-generated language\nselection approach, and a standard LLM, which generates common coherent text\nsolely based on the next word likelihood according to statistical language\ntraining data. The proposed model is found to generate language that is more\naligned with semantic stimulus in response to which brain input is sampled. Our\nfindings demonstrate the potential and feasibility of employing BCIs in direct\nlanguage generation.\n","authors":["Ziyi Ye","Qingyao Ai","Yiqun Liu","Min Zhang","Christina Lioma","Tuukka Ruotsalo"],"pdf_url":"https://arxiv.org/pdf/2311.09889v2.pdf","comment":"Preprint. Under Submission"},{"id":"http://arxiv.org/abs/2302.08143v3","updated":"2023-11-19T14:31:53Z","published":"2023-02-16T08:37:22Z","title":"Learning to Initialize: Can Meta Learning Improve Cross-task\n  Generalization in Prompt Tuning?","summary":"  Prompt tuning (PT) which only tunes the embeddings of an additional sequence\nof tokens per task, keeping the pre-trained language model (PLM) frozen, has\nshown remarkable performance in few-shot learning. Despite this, PT has been\nshown to rely heavily on good initialization of the prompt embeddings. In this\nwork, we study meta prompt tuning (MPT) to systematically explore how\nmeta-learning can help improve (if it can) cross-task generalization in PT\nthrough learning to initialize the prompt embeddings from other relevant tasks.\nWe empirically analyze a representative set of meta learning algorithms in a\nwide range of adaptation settings with different source/target task\nconfigurations on a large set of few-shot tasks. With extensive experiments and\nanalysis, we demonstrate the effectiveness of MPT. We find the improvement to\nbe significant particularly on classification tasks. For other kinds of tasks\nsuch as question answering, we observe that while MPT can outperform PT in most\ncases, it does not always outperform multi-task learning. We further provide an\nin-depth analysis from the perspective of task similarity.\n","authors":["Chengwei Qin","Qian Li","Ruochen Zhao","Shafiq Joty"],"pdf_url":"https://arxiv.org/pdf/2302.08143v3.pdf","comment":"ACL2023"},{"id":"http://arxiv.org/abs/2311.11331v1","updated":"2023-11-19T14:07:57Z","published":"2023-11-19T14:07:57Z","title":"Portuguese FAQ for Financial Services","summary":"  Scarcity of domain-specific data in the Portuguese financial domain has\ndisfavored the development of Natural Language Processing (NLP) applications.\nTo address this limitation, the present study advocates for the utilization of\nsynthetic data generated through data augmentation techniques. The\ninvestigation focuses on the augmentation of a dataset sourced from the Central\nBank of Brazil FAQ, employing techniques that vary in semantic similarity.\nSupervised and unsupervised tasks are conducted to evaluate the impact of\naugmented data on both low and high semantic similarity scenarios.\nAdditionally, the resultant dataset will be publicly disseminated on the\nHugging Face Datasets platform, thereby enhancing accessibility and fostering\nbroader engagement within the NLP research community.\n","authors":["Paulo Finardi","Wanderley M. Melo","Edgard D. Medeiros Neto","Alex F. Mansano","Pablo B. Costa","Vinicius F. Caridá"],"pdf_url":"https://arxiv.org/pdf/2311.11331v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.09886v3","updated":"2023-11-19T13:52:19Z","published":"2023-10-15T16:51:11Z","title":"Lifelong Sequence Generation with Dynamic Module Expansion and\n  Adaptation","summary":"  Lifelong sequence generation (LSG), a problem in continual learning, aims to\ncontinually train a model on a sequence of generation tasks to learn constantly\nemerging new generation patterns while avoiding the forgetting of previous\nknowledge. Existing LSG methods mainly focus on maintaining old knowledge while\npaying little attention to knowledge transfer across tasks. In contrast, humans\ncan better learn new tasks by leveraging previously acquired knowledge from\nsimilar tasks. Inspired by the learning paradigm of humans, we propose Dynamic\nModule Expansion and Adaptation (DMEA), which enables the model to dynamically\ndetermine the architecture for acquiring new knowledge based on task\ncorrelation and select the most similar previous tasks to facilitate adaptation\nto new tasks. In addition, as the learning process can easily be biased towards\nthe current task which might cause more severe forgetting of previously learned\nknowledge, we propose dynamic gradient scaling to balance the learning of the\ncurrent task and replayed tasks. With extensive experiments, we demonstrate\nthat DMEA can consistently outperform existing methods in different LSG\nsettings.\n","authors":["Chengwei Qin","Chen Chen","Shafiq Joty"],"pdf_url":"https://arxiv.org/pdf/2310.09886v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.11732v2","updated":"2023-11-19T12:40:41Z","published":"2023-10-18T06:07:28Z","title":"Investigating Uncertainty Calibration of Aligned Language Models under\n  the Multiple-Choice Setting","summary":"  Despite the significant progress made in practical applications of aligned\nlanguage models (LMs), they tend to be overconfident in output answers compared\nto the corresponding pre-trained LMs. In this work, we systematically evaluate\nthe impact of the alignment process on logit-based uncertainty calibration of\nLMs under the multiple-choice setting. We first conduct a thoughtful empirical\nstudy on how aligned LMs differ in calibration from their pre-trained\ncounterparts. Experimental results reveal that there are two distinct\nuncertainties in LMs under the multiple-choice setting, which are responsible\nfor the answer decision and the format preference of the LMs, respectively.\nThen, we investigate the role of these two uncertainties on aligned LM's\ncalibration through fine-tuning in simple synthetic alignment schemes and\nconclude that one reason for aligned LMs' overconfidence is the conflation of\nthese two types of uncertainty. Furthermore, we examine the utility of common\npost-hoc calibration methods for aligned LMs and propose an easy-to-implement\nand sample-efficient method to calibrate aligned LMs. We hope our findings\ncould provide insights into the design of more reliable alignment processes for\nLMs.\n","authors":["Guande He","Peng Cui","Jianfei Chen","Wenbo Hu","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2310.11732v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11301v1","updated":"2023-11-19T11:22:00Z","published":"2023-11-19T11:22:00Z","title":"CHAMP: Efficient Annotation and Consolidation of Cluster Hierarchies","summary":"  Various NLP tasks require a complex hierarchical structure over nodes, where\neach node is a cluster of items. Examples include generating entailment graphs,\nhierarchical cross-document coreference resolution, annotating event and\nsubevent relations, etc. To enable efficient annotation of such hierarchical\nstructures, we release CHAMP, an open source tool allowing to incrementally\nconstruct both clusters and hierarchy simultaneously over any type of texts.\nThis incremental approach significantly reduces annotation time compared to the\ncommon pairwise annotation approach and also guarantees maintaining\ntransitivity at the cluster and hierarchy levels. Furthermore, CHAMP includes a\nconsolidation mode, where an adjudicator can easily compare multiple cluster\nhierarchy annotations and resolve disagreements.\n","authors":["Arie Cattan","Tom Hope","Doug Downey","Roy Bar-Haim","Lilach Eden","Yoav Kantor","Ido Dagan"],"pdf_url":"https://arxiv.org/pdf/2311.11301v1.pdf","comment":"EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.11271v1","updated":"2023-11-19T08:54:47Z","published":"2023-11-19T08:54:47Z","title":"A Cross-Attention Augmented Model for Event-Triggered Context-Aware\n  Story Generation","summary":"  Despite recent advancements, existing story generation systems continue to\nencounter difficulties in effectively incorporating contextual and event\nfeatures, which greatly influence the quality of generated narratives. To\ntackle these challenges, we introduce a novel neural generation model, EtriCA,\nthat enhances the relevance and coherence of generated stories by employing a\ncross-attention mechanism to map context features onto event sequences through\nresidual mapping. This feature capturing mechanism enables our model to exploit\nlogical relationships between events more effectively during the story\ngeneration process. To further enhance our proposed model, we employ a\npost-training framework for knowledge enhancement (KeEtriCA) on a large-scale\nbook corpus. This allows EtriCA to adapt to a wider range of data samples. This\nresults in approximately 5\\% improvement in automatic metrics and over 10\\%\nimprovement in human evaluation. We conduct extensive experiments, including\ncomparisons with state-of-the-art (SOTA) baseline models, to evaluate the\nperformance of our framework on story generation. The experimental results,\nencompassing both automated metrics and human assessments, demonstrate the\nsuperiority of our model over existing state-of-the-art baselines. These\nresults underscore the effectiveness of our model in leveraging context and\nevent features to improve the quality of generated narratives.\n","authors":["Chen Tang","Tyler Loakman","Chenghua Lin"],"pdf_url":"https://arxiv.org/pdf/2311.11271v1.pdf","comment":"Submitted to CSL"},{"id":"http://arxiv.org/abs/2311.11268v1","updated":"2023-11-19T08:41:43Z","published":"2023-11-19T08:41:43Z","title":"Towards Real-World Writing Assistance: A Chinese Character Checking\n  Benchmark with Faked and Misspelled Characters","summary":"  Writing assistance is an application closely related to human life and is\nalso a fundamental Natural Language Processing (NLP) research field. Its aim is\nto improve the correctness and quality of input texts, with character checking\nbeing crucial in detecting and correcting wrong characters. From the\nperspective of the real world where handwriting occupies the vast majority,\ncharacters that humans get wrong include faked characters (i.e., untrue\ncharacters created due to writing errors) and misspelled characters (i.e., true\ncharacters used incorrectly due to spelling errors). However, existing datasets\nand related studies only focus on misspelled characters mainly caused by\nphonological or visual confusion, thereby ignoring faked characters which are\nmore common and difficult. To break through this dilemma, we present\nVisual-C$^3$, a human-annotated Visual Chinese Character Checking dataset with\nfaked and misspelled Chinese characters. To the best of our knowledge,\nVisual-C$^3$ is the first real-world visual and the largest human-crafted\ndataset for the Chinese character checking scenario. Additionally, we also\npropose and evaluate novel baseline methods on Visual-C$^3$. Extensive\nempirical results and analyses show that Visual-C$^3$ is high-quality yet\nchallenging. The Visual-C$^3$ dataset and the baseline methods will be publicly\navailable to facilitate further research in the community.\n","authors":["Yinghui Li","Zishan Xu","Shaoshen Chen","Haojing Huang","Yangning Li","Yong Jiang","Zhongli Li","Qingyu Zhou","Hai-Tao Zheng","Ying Shen"],"pdf_url":"https://arxiv.org/pdf/2311.11268v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2311.11267v1","updated":"2023-11-19T08:40:01Z","published":"2023-11-19T08:40:01Z","title":"Rethinking Large Language Models in Mental Health Applications","summary":"  Large Language Models (LLMs) have become valuable assets in mental health,\nshowing promise in both classification tasks and counseling applications. This\npaper offers a perspective on using LLMs in mental health applications. It\ndiscusses the instability of generative models for prediction and the potential\nfor generating hallucinatory outputs, underscoring the need for ongoing audits\nand evaluations to maintain their reliability and dependability. The paper also\ndistinguishes between the often interchangeable terms ``explainability'' and\n``interpretability'', advocating for developing inherently interpretable\nmethods instead of relying on potentially hallucinated self-explanations\ngenerated by LLMs. Despite the advancements in LLMs, human counselors'\nempathetic understanding, nuanced interpretation, and contextual awareness\nremain irreplaceable in the sensitive and complex realm of mental health\ncounseling. The use of LLMs should be approached with a judicious and\nconsiderate mindset, viewing them as tools that complement human expertise\nrather than seeking to replace it.\n","authors":["Shaoxiong Ji","Tianlin Zhang","Kailai Yang","Sophia Ananiadou","Erik Cambria"],"pdf_url":"https://arxiv.org/pdf/2311.11267v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07989v2","updated":"2023-11-19T08:37:31Z","published":"2023-11-14T08:34:26Z","title":"A Survey on Language Models for Code","summary":"  In this work we systematically review the recent advancements in code\nprocessing with language models, covering 50+ models, 30+ evaluation tasks,\n150+ datasets, and 550 related works. We break down code processing models into\ngeneral language models represented by the GPT family and specialized models\nthat are specifically pretrained on code, often with tailored objectives. We\ndiscuss the relations and differences between these models, and highlight the\nhistorical transition of code modeling from statistical models and RNNs to\npretrained Transformers and LLMs, which is exactly the same course that had\nbeen taken by NLP. We also discuss code-specific features such as AST, CFG, and\nunit tests, along with their application in training code language models, and\nidentify key challenges and potential future directions in this domain. We keep\nthe survey open and updated on GitHub repository at\nhttps://github.com/codefuse-ai/Awesome-Code-LLM.\n","authors":["Ziyin Zhang","Chaoyu Chen","Bingchang Liu","Cong Liao","Zi Gong","Hang Yu","Jianguo Li","Rui Wang"],"pdf_url":"https://arxiv.org/pdf/2311.07989v2.pdf","comment":"Repo is available at https://github.com/codefuse-ai/Awesome-Code-LLM.\n  V2 adds several new tasks, and collates dozens more benchmarks"},{"id":"http://arxiv.org/abs/2303.15445v2","updated":"2023-11-19T07:43:22Z","published":"2023-03-27T17:59:55Z","title":"IRFL: Image Recognition of Figurative Language","summary":"  Figures of speech such as metaphors, similes, and idioms are integral parts\nof human communication. They are ubiquitous in many forms of discourse,\nallowing people to convey complex, abstract ideas and evoke emotion. As\nfigurative forms are often conveyed through multiple modalities (e.g., both\ntext and images), understanding multimodal figurative language is an important\nAI challenge, weaving together profound vision, language, commonsense and\ncultural knowledge.\n  In this work, we develop the Image Recognition of Figurative Language (IRFL)\ndataset. We leverage human annotation and an automatic pipeline we created to\ngenerate a multimodal dataset, and introduce two novel tasks as a benchmark for\nmultimodal figurative language understanding. We experimented with\nstate-of-the-art vision and language models and found that the best (22%)\nperformed substantially worse than humans (97%). We release our dataset,\nbenchmark, and code, in hopes of driving the development of models that can\nbetter understand figurative language.\n","authors":["Ron Yosef","Yonatan Bitton","Dafna Shahaf"],"pdf_url":"https://arxiv.org/pdf/2303.15445v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11229v1","updated":"2023-11-19T05:00:39Z","published":"2023-11-19T05:00:39Z","title":"Causal ATE Mitigates Unintended Bias in Controlled Text Generation","summary":"  We study attribute control in language models through the method of Causal\nAverage Treatment Effect (Causal ATE). Existing methods for the attribute\ncontrol task in Language Models (LMs) check for the co-occurrence of words in a\nsentence with the attribute of interest, and control for them. However,\nspurious correlation of the words with the attribute in the training dataset,\ncan cause models to hallucinate the presence of the attribute when presented\nwith the spurious correlate during inference. We show that the simple\nperturbation-based method of Causal ATE removes this unintended effect.\nAdditionally, we offer a theoretical foundation for investigating Causal ATE in\nthe classification task, and prove that it reduces the number of false\npositives -- thereby mitigating the issue of unintended bias. Specifically, we\nground it in the problem of toxicity mitigation, where a significant challenge\nlies in the inadvertent bias that often emerges towards protected groups post\ndetoxification. We show that this unintended bias can be solved by the use of\nthe Causal ATE metric.\n","authors":["Rahul Madhavan","Kahini Wadhawan"],"pdf_url":"https://arxiv.org/pdf/2311.11229v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11215v1","updated":"2023-11-19T03:43:42Z","published":"2023-11-19T03:43:42Z","title":"SPLAIN: Augmenting CybersecurityWarnings with Reasons and Data","summary":"  Effective cyber threat recognition and prevention demand comprehensible\nforecasting systems, as prior approaches commonly offer limited and,\nultimately, unconvincing information. We introduce Simplified Plaintext\nLanguage (SPLAIN), a natural language generator that converts warning data into\nuser-friendly cyber threat explanations. SPLAIN is designed to generate clear,\nactionable outputs, incorporating hierarchically organized explanatory details\nabout input data and system functionality. Given the inputs of individual\nsensor-induced forecasting signals and an overall warning from a fusion module,\nSPLAIN queries each signal for information on contributing sensors and data\nsignals. This collected data is processed into a coherent English explanation,\nencompassing forecasting, sensing, and data elements for user review. SPLAIN's\ntemplate-based approach ensures consistent warning structure and vocabulary.\nSPLAIN's hierarchical output structure allows each threat and its components to\nbe expanded to reveal underlying explanations on demand. Our conclusions\nemphasize the need for designers to specify the \"how\" and \"why\" behind cyber\nwarnings, advocate for simple structured templates in generating consistent\nexplanations, and recognize that direct causal links in Machine Learning\napproaches may not always be identifiable, requiring some explanations to focus\non general methodologies, such as model and training data.\n","authors":["Vera A. Kazakova","Jena D. Hwang","Bonnie J. Dorr","Yorick Wilks","J. Blake Gage","Alex Memory","Mark A. Clark"],"pdf_url":"https://arxiv.org/pdf/2311.11215v1.pdf","comment":"Presented at FLAIRS-2019 as poster (see ancillary files)"},{"id":"http://arxiv.org/abs/2311.11202v1","updated":"2023-11-19T02:34:12Z","published":"2023-11-19T02:34:12Z","title":"Unmasking and Improving Data Credibility: A Study with Datasets for\n  Training Harmless Language Models","summary":"  Language models have shown promise in various tasks but can be affected by\nundesired data during training, fine-tuning, or alignment. For example, if some\nunsafe conversations are wrongly annotated as safe ones, the model fine-tuned\non these samples may be harmful. Therefore, the correctness of annotations,\ni.e., the credibility of the dataset, is important. This study focuses on the\ncredibility of real-world datasets, including the popular benchmarks Jigsaw\nCivil Comments, Anthropic Harmless & Red Team, PKU BeaverTails & SafeRLHF, that\ncan be used for training a harmless language model. Given the cost and\ndifficulty of cleaning these datasets by humans, we introduce a systematic\nframework for evaluating the credibility of datasets, identifying label errors,\nand evaluating the influence of noisy labels in the curated language data,\nspecifically focusing on unsafe comments and conversation classification. With\nthe framework, we find and fix an average of 6.16% label errors in 11 datasets\nconstructed from the above benchmarks. The data credibility and downstream\nlearning performance can be remarkably improved by directly fixing label\nerrors, indicating the significance of cleaning existing real-world datasets.\nOpen-source: https://github.com/Docta-ai/docta.\n","authors":["Zhaowei Zhu","Jialu Wang","Hao Cheng","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2311.11202v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07723v2","updated":"2023-11-19T01:33:53Z","published":"2023-11-13T20:07:36Z","title":"Generalization Analogies: A Testbed for Generalizing AI Oversight to\n  Hard-To-Measure Domains","summary":"  As AI systems become more intelligent and their behavior becomes more\nchallenging to assess, they may learn to game the flaws of human feedback\ninstead of genuinely striving to follow instructions; however, this risk can be\nmitigated by controlling how LLMs generalize human feedback to situations where\nit is unreliable. To better understand how reward models generalize, we craft\n69 distribution shifts spanning 8 categories. We find that reward models do not\nlearn to evaluate `instruction-following' by default and instead favor personas\nthat resemble internet text. Techniques for interpreting reward models'\ninternal representations achieve better generalization than standard\nfine-tuning, but still frequently fail to distinguish instruction-following\nfrom conflated behaviors. We consolidate the 15 most challenging distribution\nshifts into the GENeralization analogIES (GENIES) benchmark, which we hope will\nenable progress toward controlling reward model generalization.\n","authors":["Joshua Clymer","Garrett Baker","Rohan Subramani","Sam Wang"],"pdf_url":"https://arxiv.org/pdf/2311.07723v2.pdf","comment":"Code: https://github.com/Joshuaclymer/GENIES Website:\n  https://joshuaclymer.github.io/generalization-analogies-website/"},{"id":"http://arxiv.org/abs/2305.14864v2","updated":"2023-11-19T01:14:34Z","published":"2023-05-24T08:18:35Z","title":"How To Train Your (Compressed) Large Language Model","summary":"  With the increase in the size of large language models (LLMs), we need\ncompression methods that can reduce the model size while preserving the\ngenerality and zero-shot promptability of the model. This goal is more\nambitious than the typical compression setup, which reduces the model's size at\nthe expense of specializing it to a specific end-task. To study this, we\ndevelop a task-agnostic compression pipeline with a large-scale evaluation\ncomprising language modeling perplexity and 12 zero-shot end-tasks. Our results\nshow that a simple layer-wise pruning followed by continued language model\npretraining matches or outperforms three existing state-of-the-art baselines\nwhile being 1.5x more computationally efficient. However, unlike typical\ntask-specialized compression, our best-compressed model significantly\nunderperforms a similar-sized model trained from scratch. We posit the\nhalf-sized pretrained model as an upper bound for task-agnostic compression and\ncall for future work to bridge this gap under a reasonable token budget. Our\nfindings highlight the inadequacy of existing compression methods for LLMs and\nestablish a requirement for new methods that preserve a model's generality and\nzero-shot promptability under compression. We release our code and evaluation\nsetup to facilitate reproducibility and help iterate on method design.\n","authors":["Ananya Harsh Jha","Tom Sherborne","Evan Pete Walsh","Dirk Groeneveld","Emma Strubell","Iz Beltagy"],"pdf_url":"https://arxiv.org/pdf/2305.14864v2.pdf","comment":"13 pages, 6 figures, 5 tables"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2211.11077v2","updated":"2023-11-19T23:45:09Z","published":"2022-11-20T20:30:28Z","title":"Unifying Tracking and Image-Video Object Detection","summary":"  Objection detection (OD) has been one of the most fundamental tasks in\ncomputer vision. Recent developments in deep learning have pushed the\nperformance of image OD to new heights by learning-based, data-driven\napproaches. On the other hand, video OD remains less explored, mostly due to\nmuch more expensive data annotation needs. At the same time, multi-object\ntracking (MOT) which requires reasoning about track identities and\nspatio-temporal trajectories, shares similar spirits with video OD. However,\nmost MOT datasets are class-specific (e.g., person-annotated only), which\nconstrains a model's flexibility to perform tracking on other objects. We\npropose TrIVD (Tracking and Image-Video Detection), the first framework that\nunifies image OD, video OD, and MOT within one end-to-end model. To handle the\ndiscrepancies and semantic overlaps of category labels across datasets, TrIVD\nformulates detection/tracking as grounding and reasons about object categories\nvia visual-text alignments. The unified formulation enables cross-dataset,\nmulti-task training, and thus equips TrIVD with the ability to leverage\nframe-level features, video-level spatio-temporal relations, as well as track\nidentity associations. With such joint training, we can now extend the\nknowledge from OD data, that comes with much richer object category\nannotations, to MOT and achieve zero-shot tracking capability. Experiments\ndemonstrate that multi-task co-trained TrIVD outperforms single-task baselines\nacross all image/video OD and MOT tasks. We further set the first baseline on\nthe new task of zero-shot tracking.\n","authors":["Peirong Liu","Rui Wang","Pengchuan Zhang","Omid Poursaeed","Yipin Zhou","Xuefei Cao","Sreya Dutta Roy","Ashish Shah","Ser-Nam Lim"],"pdf_url":"https://arxiv.org/pdf/2211.11077v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11439v1","updated":"2023-11-19T22:24:19Z","published":"2023-11-19T22:24:19Z","title":"Improved Defect Detection and Classification Method for Advanced IC\n  Nodes by Using Slicing Aided Hyper Inference with Refinement Strategy","summary":"  In semiconductor manufacturing, lithography has often been the manufacturing\nstep defining the smallest possible pattern dimensions. In recent years,\nprogress has been made towards high-NA (Numerical Aperture) EUVL\n(Extreme-Ultraviolet-Lithography) paradigm, which promises to advance pattern\nshrinking (2 nm node and beyond). However, a significant increase in stochastic\ndefects and the complexity of defect detection becomes more pronounced with\nhigh-NA. Present defect inspection techniques (both non-machine learning and\nmachine learning based), fail to achieve satisfactory performance at high-NA\ndimensions. In this work, we investigate the use of the Slicing Aided Hyper\nInference (SAHI) framework for improving upon current techniques. Using SAHI,\ninference is performed on size-increased slices of the SEM images. This leads\nto the object detector's receptive field being more effective in capturing\nsmall defect instances. First, the performance on previously investigated\nsemiconductor datasets is benchmarked across various configurations, and the\nSAHI approach is demonstrated to substantially enhance the detection of small\ndefects, by approx. 2x. Afterwards, we also demonstrated application of SAHI\nleads to flawless detection rates on a new test dataset, with scenarios not\nencountered during training, whereas previous trained models failed. Finally,\nwe formulate an extension of SAHI that does not significantly reduce\ntrue-positive predictions while eliminating false-positive predictions.\n","authors":["Vic De Ridder","Bappaditya Dey","Victor Blanco","Sandip Halder","Bartel Van Waeyenberge"],"pdf_url":"https://arxiv.org/pdf/2311.11439v1.pdf","comment":"12 pages, 9 figures, to be presented at International Conference on\n  Machine Intelligence with Applications (ICMIA), with proceedings by AIP"},{"id":"http://arxiv.org/abs/2110.04658v2","updated":"2023-11-19T21:56:31Z","published":"2021-10-09T22:44:30Z","title":"Differential Motion Evolution for Fine-Grained Motion Deformation in\n  Unsupervised Image Animation","summary":"  Image animation is the task of transferring the motion of a driving video to\na given object in a source image. While great progress has recently been made\nin unsupervised motion transfer, requiring no labeled data or domain priors,\nmany current unsupervised approaches still struggle to capture the motion\ndeformations when large motion/view discrepancies occur between the source and\ndriving domains. Under such conditions, there is simply not enough information\nto capture the motion field properly. We introduce DiME (Differential Motion\nEvolution), an end-to-end unsupervised motion transfer framework integrating\ndifferential refinement for motion estimation. Key findings are twofold: (1) by\ncapturing the motion transfer with an ordinary differential equation (ODE), it\nhelps to regularize the motion field, and (2) by utilizing the source image\nitself, we are able to inpaint occluded/missing regions arising from large\nmotion changes. Additionally, we also propose a natural extension to the ODE\nidea, which is that DiME can easily leverage multiple different views of the\nsource object whenever they are available by modeling an ODE per view.\nExtensive experiments across 9 benchmarks show DiME outperforms the\nstate-of-the-arts by a significant margin and generalizes much better to unseen\nobjects.\n","authors":["Peirong Liu","Rui Wang","Xuefei Cao","Yipin Zhou","Ashish Shah","Ser-Nam Lim"],"pdf_url":"https://arxiv.org/pdf/2110.04658v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11427v1","updated":"2023-11-19T21:24:34Z","published":"2023-11-19T21:24:34Z","title":"Appearance Codes using Joint Embedding Learning of Multiple Modalities","summary":"  The use of appearance codes in recent work on generative modeling has enabled\nnovel view renders with variable appearance and illumination, such as day-time\nand night-time renders of a scene. A major limitation of this technique is the\nneed to re-train new appearance codes for every scene on inference, so in this\nwork we address this problem proposing a framework that learns a joint\nembedding space for the appearance and structure of the scene by enforcing a\ncontrastive loss constraint between different modalities. We apply our\nframework to a simple Variational Auto-Encoder model on the RADIATE dataset\n\\cite{sheeny2021radiate} and qualitatively demonstrate that we can generate new\nrenders of night-time photos using day-time appearance codes without additional\noptimization iterations. Additionally, we compare our model to a baseline VAE\nthat uses the standard per-image appearance code technique and show that our\napproach achieves generations of similar quality without learning appearance\ncodes for any unseen images on inference.\n","authors":["Alex Zhang","Evan Dogariu"],"pdf_url":"https://arxiv.org/pdf/2311.11427v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2104.08717v4","updated":"2023-11-19T21:19:51Z","published":"2021-04-18T04:59:39Z","title":"Do We Really Need Dice? The Hidden Region-Size Biases of Segmentation\n  Losses","summary":"  Most segmentation losses are arguably variants of the Cross-Entropy (CE) or\nDice losses. On the surface, these two categories of losses seem unrelated, and\nthere is no clear consensus as to which category is a better choice, with\nvarying performances for each across different benchmarks and applications.\nFurthermore, it is widely argued within the medical-imaging community that Dice\nand CE are complementary, which has motivated the use of compound CE-Dice\nlosses. In this work, we provide a theoretical analysis, which shows that CE\nand Dice share a much deeper connection than previously thought. First, we show\nthat, from a constrained-optimization perspective, they both decompose into two\ncomponents, i.e., a similar ground-truth matching term, which pushes the\npredicted foreground regions towards the ground-truth, and a region-size\npenalty term imposing different biases on the size of the predicted regions.\nThen, we provide bound relationships and an information-theoretic analysis,\nwhich uncover hidden region-size biases: Dice has an intrinsic bias towards\nspecific extremely imbalanced solutions, whereas CE implicitly encourages the\nground-truth region proportions. Our theoretical results explain the wide\nexperimental evidence in the medical-imaging literature, whereby Dice losses\nbring improvements for imbalanced segmentation. Based on our theoretical\nanalysis, we propose a principled and simple solution, which enables to control\nexplicitly the region-size bias. The proposed method integrates CE with\nexplicit terms based on L1 or the KL divergence, which encourage segmenting\nregion proportions to match target class proportions, thereby mitigating class\nimbalance but without losing generality. Comprehensive experiments and ablation\nstudies over different losses and applications validate our theoretical\nanalysis, as well as the effectiveness of explicit and simple region-size\nterms.\n","authors":["Bingyuan Liu","Jose Dolz","Adrian Galdran","Riadh Kobbi","Ismail Ben Ayed"],"pdf_url":"https://arxiv.org/pdf/2104.08717v4.pdf","comment":"To be published at Medical Image Analysis(Volume 91, January 2024,\n  103015). Code available at https://github.com/by-liu/SegLossBias"},{"id":"http://arxiv.org/abs/2311.11420v1","updated":"2023-11-19T20:39:35Z","published":"2023-11-19T20:39:35Z","title":"LifeLearner: Hardware-Aware Meta Continual Learning System for Embedded\n  Computing Platforms","summary":"  Continual Learning (CL) allows applications such as user personalization and\nhousehold robots to learn on the fly and adapt to context. This is an important\nfeature when context, actions, and users change. However, enabling CL on\nresource-constrained embedded systems is challenging due to the limited labeled\ndata, memory, and computing capacity. In this paper, we propose LifeLearner, a\nhardware-aware meta continual learning system that drastically optimizes system\nresources (lower memory, latency, energy consumption) while ensuring high\naccuracy. Specifically, we (1) exploit meta-learning and rehearsal strategies\nto explicitly cope with data scarcity issues and ensure high accuracy, (2)\neffectively combine lossless and lossy compression to significantly reduce the\nresource requirements of CL and rehearsal samples, and (3) developed\nhardware-aware system on embedded and IoT platforms considering the hardware\ncharacteristics. As a result, LifeLearner achieves near-optimal CL performance,\nfalling short by only 2.8% on accuracy compared to an Oracle baseline. With\nrespect to the state-of-the-art (SOTA) Meta CL method, LifeLearner drastically\nreduces the memory footprint (by 178.7x), end-to-end latency by 80.8-94.2%, and\nenergy consumption by 80.9-94.2%. In addition, we successfully deployed\nLifeLearner on two edge devices and a microcontroller unit, thereby enabling\nefficient CL on resource-constrained platforms where it would be impractical to\nrun SOTA methods and the far-reaching deployment of adaptable CL in a\nubiquitous manner. Code is available at\nhttps://github.com/theyoungkwon/LifeLearner.\n","authors":["Young D. Kwon","Jagmohan Chauhan","Hong Jia","Stylianos I. Venieris","Cecilia Mascolo"],"pdf_url":"https://arxiv.org/pdf/2311.11420v1.pdf","comment":"Accepted for publication at SenSys 2023"},{"id":"http://arxiv.org/abs/2311.11417v1","updated":"2023-11-19T20:27:14Z","published":"2023-11-19T20:27:14Z","title":"DiffSCI: Zero-Shot Snapshot Compressive Imaging via Iterative Spectral\n  Diffusion Model","summary":"  This paper endeavors to advance the precision of snapshot compressive imaging\n(SCI) reconstruction for multispectral image (MSI). To achieve this, we\nintegrate the advantageous attributes of established SCI techniques and an\nimage generative model, propose a novel structured zero-shot diffusion model,\ndubbed DiffSCI. DiffSCI leverages the structural insights from the deep prior\nand optimization-based methodologies, complemented by the generative\ncapabilities offered by the contemporary denoising diffusion model.\nSpecifically, firstly, we employ a pre-trained diffusion model, which has been\ntrained on a substantial corpus of RGB images, as the generative denoiser\nwithin the Plug-and-Play framework for the first time. This integration allows\nfor the successful completion of SCI reconstruction, especially in the case\nthat current methods struggle to address effectively. Secondly, we\nsystematically account for spectral band correlations and introduce a robust\nmethodology to mitigate wavelength mismatch, thus enabling seamless adaptation\nof the RGB diffusion model to MSIs. Thirdly, an accelerated algorithm is\nimplemented to expedite the resolution of the data subproblem. This\naugmentation not only accelerates the convergence rate but also elevates the\nquality of the reconstruction process. We present extensive testing to show\nthat DiffSCI exhibits discernible performance enhancements over prevailing\nself-supervised and zero-shot approaches, surpassing even supervised\ntransformer counterparts across both simulated and real datasets. Our code will\nbe available.\n","authors":["Zhenghao Pan","Haijin Zeng","Jiezhang Cao","Kai Zhang","Yongyong Chen"],"pdf_url":"https://arxiv.org/pdf/2311.11417v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.00641v2","updated":"2023-11-19T18:02:21Z","published":"2023-10-01T11:05:45Z","title":"RegBN: Batch Normalization of Multimodal Data with Regularization","summary":"  Recent years have witnessed a surge of interest in integrating\nhigh-dimensional data captured by multisource sensors, driven by the impressive\nsuccess of neural networks in the integration of multimodal data. However, the\nintegration of heterogeneous multimodal data poses a significant challenge, as\nconfounding effects and dependencies among such heterogeneous data sources\nintroduce unwanted variability and bias, leading to suboptimal performance of\nmultimodal models. Therefore, it becomes crucial to normalize the low- or\nhigh-level features extracted from data modalities before their fusion takes\nplace. This paper introduces a novel approach for the normalization of\nmultimodal data, called RegBN, that incorporates regularization. RegBN uses the\nFrobenius norm as a regularizer term to address the side effects of confounders\nand underlying dependencies among different data sources. The proposed method\ngeneralizes well across multiple modalities and eliminates the need for\nlearnable parameters, simplifying training and inference. We validate the\neffectiveness of RegBN on eight databases from five research areas,\nencompassing diverse modalities such as language, audio, image, video, depth,\ntabular, and 3D MRI. The proposed method demonstrates broad applicability\nacross different architectures such as multilayer perceptrons, convolutional\nneural networks, and vision transformers, enabling effective normalization of\nboth low- and high-level features in multimodal neural networks. RegBN is\navailable at \\url{https://github.com/mogvision/regbn}.\n","authors":["Morteza Ghahremani","Christian Wachinger"],"pdf_url":"https://arxiv.org/pdf/2310.00641v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11383v1","updated":"2023-11-19T17:55:56Z","published":"2023-11-19T17:55:56Z","title":"A Survey of Emerging Applications of Diffusion Probabilistic Models in\n  MRI","summary":"  Diffusion probabilistic models (DPMs) which employ explicit likelihood\ncharacterization and a gradual sampling process to synthesize data, have gained\nincreasing research interest. Despite their huge computational burdens due to\nthe large number of steps involved during sampling, DPMs are widely appreciated\nin various medical imaging tasks for their high-quality and diversity of\ngeneration. Magnetic resonance imaging (MRI) is an important medical imaging\nmodality with excellent soft tissue contrast and superb spatial resolution,\nwhich possesses unique opportunities for diffusion models. Although there is a\nrecent surge of studies exploring DPMs in MRI, a survey paper of DPMs\nspecifically designed for MRI applications is still lacking. This review\narticle aims to help researchers in the MRI community to grasp the advances of\nDPMs in different applications. We first introduce the theory of two dominant\nkinds of DPMs, categorized according to whether the diffusion time step is\ndiscrete or continuous, and then provide a comprehensive review of emerging\nDPMs in MRI, including reconstruction, image generation, image translation,\nsegmentation, anomaly detection, and further research topics. Finally, we\ndiscuss the general limitations as well as limitations specific to the MRI\ntasks of DPMs and point out potential areas that are worth further exploration.\n","authors":["Yuheng Fan","Hanxi Liao","Shiqi Huang","Yimin Luo","Huazhu Fu","Haikun Qi"],"pdf_url":"https://arxiv.org/pdf/2311.11383v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11378v1","updated":"2023-11-19T17:22:50Z","published":"2023-11-19T17:22:50Z","title":"Inspecting Explainability of Transformer Models with Additional\n  Statistical Information","summary":"  Transformer becomes more popular in the vision domain in recent years so\nthere is a need for finding an effective way to interpret the Transformer model\nby visualizing it. In recent work, Chefer et al. can visualize the Transformer\non vision and multi-modal tasks effectively by combining attention layers to\nshow the importance of each image patch. However, when applying to other\nvariants of Transformer such as the Swin Transformer, this method can not focus\non the predicted object. Our method, by considering the statistics of tokens in\nlayer normalization layers, shows a great ability to interpret the\nexplainability of Swin Transformer and ViT.\n","authors":["Hoang C. Nguyen","Haeil Lee","Junmo Kim"],"pdf_url":"https://arxiv.org/pdf/2311.11378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.16661v3","updated":"2023-11-19T17:03:33Z","published":"2023-09-28T17:58:05Z","title":"SA2-Net: Scale-aware Attention Network for Microscopic Image\n  Segmentation","summary":"  Microscopic image segmentation is a challenging task, wherein the objective\nis to assign semantic labels to each pixel in a given microscopic image. While\nconvolutional neural networks (CNNs) form the foundation of many existing\nframeworks, they often struggle to explicitly capture long-range dependencies.\nAlthough transformers were initially devised to address this issue using\nself-attention, it has been proven that both local and global features are\ncrucial for addressing diverse challenges in microscopic images, including\nvariations in shape, size, appearance, and target region density. In this\npaper, we introduce SA2-Net, an attention-guided method that leverages\nmulti-scale feature learning to effectively handle diverse structures within\nmicroscopic images. Specifically, we propose scale-aware attention (SA2) module\ndesigned to capture inherent variations in scales and shapes of microscopic\nregions, such as cells, for accurate segmentation. This module incorporates\nlocal attention at each level of multi-stage features, as well as global\nattention across multiple resolutions. Furthermore, we address the issue of\nblurred region boundaries (e.g., cell boundaries) by introducing a novel\nupsampling strategy called the Adaptive Up-Attention (AuA) module. This module\nenhances the discriminative ability for improved localization of microscopic\nregions using an explicit attention mechanism. Extensive experiments on five\nchallenging datasets demonstrate the benefits of our SA2-Net model. Our source\ncode is publicly available at \\url{https://github.com/mustansarfiaz/SA2-Net}.\n","authors":["Mustansar Fiaz","Moein Heidari","Rao Muhammad Anwer","Hisham Cholakkal"],"pdf_url":"https://arxiv.org/pdf/2309.16661v3.pdf","comment":"BMVC 2023 accepted as oral"},{"id":"http://arxiv.org/abs/2311.11371v1","updated":"2023-11-19T16:47:51Z","published":"2023-11-19T16:47:51Z","title":"SOccDPT: Semi-Supervised 3D Semantic Occupancy from Dense Prediction\n  Transformers trained under memory constraints","summary":"  We present SOccDPT, a memory-efficient approach for 3D semantic occupancy\nprediction from monocular image input using dense prediction transformers. To\naddress the limitations of existing methods trained on structured traffic\ndatasets, we train our model on unstructured datasets including the Indian\nDriving Dataset and Bengaluru Driving Dataset. Our semi-supervised training\npipeline allows SOccDPT to learn from datasets with limited labels by reducing\nthe requirement for manual labelling by substituting it with pseudo-ground\ntruth labels to produce our Bengaluru Semantic Occupancy Dataset. This broader\ntraining enhances our model's ability to handle unstructured traffic scenarios\neffectively. To overcome memory limitations during training, we introduce\npatch-wise training where we select a subset of parameters to train each epoch,\nreducing memory usage during auto-grad graph construction. In the context of\nunstructured traffic and memory-constrained training and inference, SOccDPT\noutperforms existing disparity estimation approaches as shown by the RMSE score\nof 9.1473, achieves a semantic segmentation IoU score of 46.02% and operates at\na competitive frequency of 69.47 Hz. We make our code and semantic occupancy\ndataset public.\n","authors":["Aditya Nalgunda Ganesh"],"pdf_url":"https://arxiv.org/pdf/2311.11371v1.pdf","comment":"This work has been submitted to the ICRA 2024 IEEE for possible\n  publication. Copyright may be transferred without notice, after which this\n  version may no longer be accessible"},{"id":"http://arxiv.org/abs/2311.11367v1","updated":"2023-11-19T16:33:42Z","published":"2023-11-19T16:33:42Z","title":"Evidential Uncertainty Quantification: A Variance-Based Perspective","summary":"  Uncertainty quantification of deep neural networks has become an active field\nof research and plays a crucial role in various downstream tasks such as active\nlearning. Recent advances in evidential deep learning shed light on the direct\nquantification of aleatoric and epistemic uncertainties with a single forward\npass of the model. Most traditional approaches adopt an entropy-based method to\nderive evidential uncertainty in classification, quantifying uncertainty at the\nsample level. However, the variance-based method that has been widely applied\nin regression problems is seldom used in the classification setting. In this\nwork, we adapt the variance-based approach from regression to classification,\nquantifying classification uncertainty at the class level. The variance\ndecomposition technique in regression is extended to class covariance\ndecomposition in classification based on the law of total covariance, and the\nclass correlation is also derived from the covariance. Experiments on\ncross-domain datasets are conducted to illustrate that the variance-based\napproach not only results in similar accuracy as the entropy-based one in\nactive domain adaptation but also brings information about class-wise\nuncertainties as well as between-class correlations. The code is available at\nhttps://github.com/KerryDRX/EvidentialADA. This alternative means of evidential\nuncertainty quantification will give researchers more options when class\nuncertainties and correlations are important in their applications.\n","authors":["Ruxiao Duan","Brian Caffo","Harrison X. Bai","Haris I. Sair","Craig Jones"],"pdf_url":"https://arxiv.org/pdf/2311.11367v1.pdf","comment":"IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)\n  2024"},{"id":"http://arxiv.org/abs/2307.02500v2","updated":"2023-11-19T15:38:50Z","published":"2023-07-04T13:51:55Z","title":"Interpretable Computer Vision Models through Adversarial Training:\n  Unveiling the Robustness-Interpretability Connection","summary":"  With the perpetual increase of complexity of the state-of-the-art deep neural\nnetworks, it becomes a more and more challenging task to maintain their\ninterpretability. Our work aims to evaluate the effects of adversarial training\nutilized to produce robust models - less vulnerable to adversarial attacks. It\nhas been shown to make computer vision models more interpretable.\nInterpretability is as essential as robustness when we deploy the models to the\nreal world. To prove the correlation between these two problems, we extensively\nexamine the models using local feature-importance methods (SHAP, Integrated\nGradients) and feature visualization techniques (Representation Inversion,\nClass Specific Image Generation). Standard models, compared to robust are more\nsusceptible to adversarial attacks, and their learned representations are less\nmeaningful to humans. Conversely, these models focus on distinctive regions of\nthe images which support their predictions. Moreover, the features learned by\nthe robust model are closer to the real ones.\n","authors":["Delyan Boychev"],"pdf_url":"https://arxiv.org/pdf/2307.02500v2.pdf","comment":"13 pages, 19 figures, 6 tables"},{"id":"http://arxiv.org/abs/2311.11354v1","updated":"2023-11-19T15:35:15Z","published":"2023-11-19T15:35:15Z","title":"Scale-aware competition network for palmprint recognition","summary":"  Palmprint biometrics garner heightened attention in palm-scanning payment and\nsocial security due to their distinctive attributes. However, prevailing\nmethodologies singularly prioritize texture orientation, neglecting the\nsignificant texture scale dimension. We design an innovative network for\nconcurrently extracting intra-scale and inter-scale features to redress this\nlimitation. This paper proposes a scale-aware competitive network (SAC-Net),\nwhich includes the Inner-Scale Competition Module (ISCM) and the Across-Scale\nCompetition Module (ASCM) to capture texture characteristics related to\norientation and scale. ISCM efficiently integrates learnable Gabor filters and\na self-attention mechanism to extract rich orientation data and discern\ntextures with long-range discriminative properties. Subsequently, ASCM\nleverages a competitive strategy across various scales to effectively\nencapsulate the competitive texture scale elements. By synergizing ISCM and\nASCM, our method adeptly characterizes palmprint features. Rigorous\nexperimentation across three benchmark datasets unequivocally demonstrates our\nproposed approach's exceptional recognition performance and resilience relative\nto state-of-the-art alternatives.\n","authors":["Chengrui Gao","Ziyuan Yang","Min Zhu","Andrew Beng Jin Teo"],"pdf_url":"https://arxiv.org/pdf/2311.11354v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.10861v2","updated":"2023-11-19T14:29:57Z","published":"2023-10-16T22:21:56Z","title":"SoybeanNet: Transformer-Based Convolutional Neural Network for Soybean\n  Pod Counting from Unmanned Aerial Vehicle (UAV) Images","summary":"  Soybeans are a critical source of food, protein and oil, and thus have\nreceived extensive research aimed at enhancing their yield, refining\ncultivation practices, and advancing soybean breeding techniques. Within this\ncontext, soybean pod counting plays an essential role in understanding and\noptimizing production. Despite recent advancements, the development of a robust\npod-counting algorithm capable of performing effectively in real-field\nconditions remains a significant challenge This paper presents a pioneering\nwork of accurate soybean pod counting utilizing unmanned aerial vehicle (UAV)\nimages captured from actual soybean fields in Michigan, USA. Specifically, this\npaper presents SoybeanNet, a novel point-based counting network that harnesses\npowerful transformer backbones for simultaneous soybean pod counting and\nlocalization with high accuracy. In addition, a new dataset of UAV-acquired\nimages for soybean pod counting was created and open-sourced, consisting of 113\ndrone images with more than 260k manually annotated soybean pods captured under\nnatural lighting conditions. Through comprehensive evaluations, SoybeanNet\ndemonstrated superior performance over five state-of-the-art approaches when\ntested on the collected images. Remarkably, SoybeanNet achieved a counting\naccuracy of $84.51\\%$ when tested on the testing dataset, attesting to its\nefficacy in real-world scenarios. The publication also provides both the source\ncode (\\url{https://github.com/JiajiaLi04/Soybean-Pod-Counting-from-UAV-Images})\nand the labeled soybean dataset\n(\\url{https://www.kaggle.com/datasets/jiajiali/uav-based-soybean-pod-images}),\noffering a valuable resource for future research endeavors in soybean pod\ncounting and related fields.\n","authors":["Jiajia Li","Raju Thada Magar","Dong Chen","Feng Lin","Dechun Wang","Xiang Yin","Weichao Zhuang","Zhaojian Li"],"pdf_url":"https://arxiv.org/pdf/2310.10861v2.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2306.07613v2","updated":"2023-11-19T14:29:46Z","published":"2023-06-13T08:12:52Z","title":"Revisiting and Advancing Adversarial Training Through A Simple Baseline","summary":"  In this paper, we delve into the essential components of adversarial training\nwhich is a pioneering defense technique against adversarial attacks. We\nindicate that some factors such as the loss function, learning rate scheduler,\nand data augmentation, which are independent of the model architecture, will\ninfluence adversarial robustness and generalization. When these factors are\ncontrolled for, we introduce a simple baseline approach, termed SimpleAT, that\nperforms competitively with recent methods and mitigates robust overfitting. We\nconduct extensive experiments on CIFAR-10/100 and Tiny-ImageNet, which validate\nthe robustness of SimpleAT against state-of-the-art adversarial attackers such\nas AutoAttack. Our results also demonstrate that SimpleAT exhibits good\nperformance in the presence of various image corruptions, such as those found\nin the CIFAR-10-C. In addition, we empirically show that SimpleAT is capable of\nreducing the variance in model predictions, which is considered the primary\ncontributor to robust overfitting. Our results also reveal the connections\nbetween SimpleAT and many advanced state-of-the-art adversarial defense\nmethods.\n","authors":["Hong Liu"],"pdf_url":"https://arxiv.org/pdf/2306.07613v2.pdf","comment":"11 pages, 8 figures"},{"id":"http://arxiv.org/abs/2311.08059v2","updated":"2023-11-19T14:18:34Z","published":"2023-11-14T10:32:17Z","title":"FS-Net: Full Scale Network and Adaptive Threshold for Improving\n  Extraction of Micro-Retinal Vessel Structures","summary":"  Retinal vascular segmentation, is a widely researched subject in biomedical\nimage processing, aims to relieve ophthalmologists' workload when treating and\ndetecting retinal disorders. However, segmenting retinal vessels has its own\nset of challenges, with prior techniques failing to generate adequate results\nwhen segmenting branches and microvascular structures. The neural network\napproaches used recently are characterized by the inability to keep local and\nglobal properties together and the failure to capture tiny end vessels make it\nchallenging to attain the desired result. To reduce this retinal vessel\nsegmentation problem, we propose a full-scale micro-vessel extraction mechanism\nbased on an encoder-decoder neural network architecture, sigmoid smoothing, and\nan adaptive threshold method. The network consists of of residual, encoder\nbooster, bottleneck enhancement, squeeze, and excitation building blocks. All\nof these blocks together help to improve the feature extraction and prediction\nof the segmentation map. The proposed solution has been evaluated using the\nDRIVE, CHASE-DB1, and STARE datasets, and competitive results are obtained when\ncompared with previous studies. The AUC and accuracy on the DRIVE dataset are\n0.9884 and 0.9702, respectively. On the CHASE-DB1 dataset, the scores are\n0.9903 and 0.9755, respectively. On the STARE dataset, the scores are 0.9916\nand 0.9750, respectively. The performance achieved is one step ahead of what\nhas been done in previous studies, and this results in a higher chance of\nhaving this solution in real-life diagnostic centers that seek ophthalmologists\nattention.\n","authors":["Melaku N. Getahun","Oleg Y. Rogov","Dmitry V. Dylov","Andrey Somov","Ahmed Bouridane","Rifat Hamoudi"],"pdf_url":"https://arxiv.org/pdf/2311.08059v2.pdf","comment":"7 pages, 2 figures"},{"id":"http://arxiv.org/abs/2305.10925v2","updated":"2023-11-19T14:09:45Z","published":"2023-05-18T12:38:29Z","title":"Unsupervised Hyperspectral Pansharpening via Low-rank Diffusion Model","summary":"  Hyperspectral pansharpening is a process of merging a high-resolution\npanchromatic (PAN) image and a low-resolution hyperspectral (LRHS) image to\ncreate a single high-resolution hyperspectral (HRHS) image. Existing\nBayesian-based HS pansharpening methods require designing handcraft image prior\nto characterize the image features, and deep learning-based HS pansharpening\nmethods usually require a large number of paired training data and suffer from\npoor generalization ability. To address these issues, in this work, we propose\na low-rank diffusion model for hyperspectral pansharpening by simultaneously\nleveraging the power of the pre-trained deep diffusion model and better\ngeneralization ability of Bayesian methods. Specifically, we assume that the\nHRHS image can be recovered from the product of two low-rank tensors, i.e., the\nbase tensor and the coefficient matrix. The base tensor lies on the image field\nand has a low spectral dimension. Thus, we can conveniently utilize a\npre-trained remote sensing diffusion model to capture its image structures.\nAdditionally, we derive a simple yet quite effective way to pre-estimate the\ncoefficient matrix from the observed LRHS image, which preserves the spectral\ninformation of the HRHS. Experimental results demonstrate that the proposed\nmethod performs better than some popular traditional approaches and gains\nbetter generalization ability than some DL-based methods. The code is released\nin https://github.com/xyrui/PLRDiff.\n","authors":["Xiangyu Rui","Xiangyong Cao","Li Pang","Zeyu Zhu","Zongsheng Yue","Deyu Meng"],"pdf_url":"https://arxiv.org/pdf/2305.10925v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11325v1","updated":"2023-11-19T13:36:03Z","published":"2023-11-19T13:36:03Z","title":"MoVideo: Motion-Aware Video Generation with Diffusion Models","summary":"  While recent years have witnessed great progress on using diffusion models\nfor video generation, most of them are simple extensions of image generation\nframeworks, which fail to explicitly consider one of the key differences\nbetween videos and images, i.e., motion. In this paper, we propose a novel\nmotion-aware video generation (MoVideo) framework that takes motion into\nconsideration from two aspects: video depth and optical flow. The former\nregulates motion by per-frame object distances and spatial layouts, while the\nlater describes motion by cross-frame correspondences that help in preserving\nfine details and improving temporal consistency. More specifically, given a key\nframe that exists or generated from text prompts, we first design a diffusion\nmodel with spatio-temporal modules to generate the video depth and the\ncorresponding optical flows. Then, the video is generated in the latent space\nby another spatio-temporal diffusion model under the guidance of depth, optical\nflow-based warped latent video and the calculated occlusion mask. Lastly, we\nuse optical flows again to align and refine different frames for better video\ndecoding from the latent space to the pixel space. In experiments, MoVideo\nachieves state-of-the-art results in both text-to-video and image-to-video\ngeneration, showing promising prompt consistency, frame consistency and visual\nquality.\n","authors":["Jingyun Liang","Yuchen Fan","Kai Zhang","Radu Timofte","Luc Van Gool","Rakesh Ranjan"],"pdf_url":"https://arxiv.org/pdf/2311.11325v1.pdf","comment":"project homepage: https://jingyunliang.github.io/MoVideo"},{"id":"http://arxiv.org/abs/2311.11319v1","updated":"2023-11-19T13:28:01Z","published":"2023-11-19T13:28:01Z","title":"GeoSAM: Fine-tuning SAM with Sparse and Dense Visual Prompting for\n  Automated Segmentation of Mobility Infrastructure","summary":"  The Segment Anything Model (SAM) has shown impressive performance when\napplied to natural image segmentation. However, it struggles with geographical\nimages like aerial and satellite imagery, especially when segmenting mobility\ninfrastructure including roads, sidewalks, and crosswalks. This inferior\nperformance stems from the narrow features of these objects, their textures\nblending into the surroundings, and interference from objects like trees,\nbuildings, vehicles, and pedestrians - all of which can disorient the model to\nproduce inaccurate segmentation maps. To address these challenges, we propose\nGeographical SAM (GeoSAM), a novel SAM-based framework that implements a\nfine-tuning strategy using the dense visual prompt from zero-shot learning, and\nthe sparse visual prompt from a pre-trained CNN segmentation model. The\nproposed GeoSAM outperforms existing approaches for geographical image\nsegmentation, specifically by 20%, 14.29%, and 17.65% for road infrastructure,\npedestrian infrastructure, and on average, respectively, representing a\nmomentous leap in leveraging foundation models to segment mobility\ninfrastructure including both road and pedestrian infrastructure in\ngeographical images.\n","authors":["Rafi Ibn Sultan","Chengyin Li","Hui Zhu","Prashant Khanduri","Marco Brocanelli","Dongxiao Zhu"],"pdf_url":"https://arxiv.org/pdf/2311.11319v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.07273v8","updated":"2023-11-19T13:09:48Z","published":"2022-11-14T11:07:18Z","title":"MLIC: Multi-Reference Entropy Model for Learned Image Compression","summary":"  Recently, learned image compression has achieved remarkable performance. The\nentropy model, which estimates the distribution of the latent representation,\nplays a crucial role in boosting rate-distortion performance. However, most\nentropy models only capture correlations in one dimension, while the latent\nrepresentation contain channel-wise, local spatial, and global spatial\ncorrelations. To tackle this issue, we propose the Multi-Reference Entropy\nModel (MEM) and the advanced version, MEM$^+$. These models capture the\ndifferent types of correlations present in latent representation. Specifically,\nWe first divide the latent representation into slices. When decoding the\ncurrent slice, we use previously decoded slices as context and employ the\nattention map of the previously decoded slice to predict global correlations in\nthe current slice. To capture local contexts, we introduce two enhanced\ncheckerboard context capturing techniques that avoids performance degradation.\nBased on MEM and MEM$^+$, we propose image compression models MLIC and\nMLIC$^+$. Extensive experimental evaluations demonstrate that our MLIC and\nMLIC$^+$ models achieve state-of-the-art performance, reducing BD-rate by\n$8.05\\%$ and $11.39\\%$ on the Kodak dataset compared to VTM-17.0 when measured\nin PSNR. Our code is available at https://github.com/JiangWeibeta/MLIC.\n","authors":["Wei Jiang","Jiayu Yang","Yongqi Zhai","Peirong Ning","Feng Gao","Ronggang Wang"],"pdf_url":"https://arxiv.org/pdf/2211.07273v8.pdf","comment":"Accepted at ACMMM 2023"},{"id":"http://arxiv.org/abs/2311.11317v1","updated":"2023-11-19T13:07:06Z","published":"2023-11-19T13:07:06Z","title":"Discrete approximations of Gaussian smoothing and Gaussian derivatives","summary":"  This paper develops an in-depth treatment concerning the problem of\napproximating the Gaussian smoothing and Gaussian derivative computations in\nscale-space theory for application on discrete data. With close connections to\nprevious axiomatic treatments of continuous and discrete scale-space theory, we\nconsider three main ways discretizing these scale-space operations in terms of\nexplicit discrete convolutions, based on either (i) sampling the Gaussian\nkernels and the Gaussian derivative kernels, (ii) locally integrating the\nGaussian kernels and the Gaussian derivative kernels over each pixel support\nregion and (iii) basing the scale-space analysis on the discrete analogue of\nthe Gaussian kernel, and then computing derivative approximations by applying\nsmall-support central difference operators to the spatially smoothed image\ndata.\n  We study the properties of these three main discretization methods both\ntheoretically and experimentally, and characterize their performance by\nquantitative measures, including the results they give rise to with respect to\nthe task of scale selection, investigated for four different use cases, and\nwith emphasis on the behaviour at fine scales. The results show that the\nsampled Gaussian kernels and derivatives as well as the integrated Gaussian\nkernels and derivatives perform very poorly at very fine scales. At very fine\nscales, the discrete analogue of the Gaussian kernel with its corresponding\ndiscrete derivative approximations performs substantially better. The sampled\nGaussian kernel and the sampled Gaussian derivatives do, on the other hand,\nlead to numerically very good approximations of the corresponding continuous\nresults, when the scale parameter is sufficiently large, in the experiments\npresented in the paper, when the scale parameter is greater than a value of\nabout 1, in units of the grid spacing.\n","authors":["Tony Lindeberg"],"pdf_url":"https://arxiv.org/pdf/2311.11317v1.pdf","comment":"38 pages, 34 figures"},{"id":"http://arxiv.org/abs/2305.12457v2","updated":"2023-11-19T13:05:09Z","published":"2023-05-21T13:27:02Z","title":"Unsupervised Multi-view Pedestrian Detection","summary":"  With the prosperity of the video surveillance, multiple cameras have been\napplied to accurately locate pedestrians in a specific area. However, previous\nmethods rely on the human-labeled annotations in every video frame and camera\nview, leading to heavier burden than necessary camera calibration and\nsynchronization. Therefore, we propose in this paper an Unsupervised Multi-view\nPedestrian Detection approach (UMPD) to eliminate the need of annotations to\nlearn a multi-view pedestrian detector via 2D-3D mapping. 1) Firstly,\nSemantic-aware Iterative Segmentation (SIS) is proposed to extract unsupervised\nrepresentations of multi-view images, which are converted into 2D pedestrian\nmasks as pseudo labels, via our proposed iterative PCA and zero-shot semantic\nclasses from vision-language models. 2) Secondly, we propose Geometry-aware\nVolume-based Detector (GVD) to end-to-end encode multi-view 2D images into a 3D\nvolume to predict voxel-wise density and color via 2D-to-3D geometric\nprojection, trained by 3D-to-2D rendering losses with SIS pseudo labels. 3)\nThirdly, for better detection results, i.e., the 3D density projected on\nBirds-Eye-View from GVD, we propose Vertical-aware BEV Regularization (VBR) to\nconstraint them to be vertical like the natural pedestrian poses. Extensive\nexperiments on popular multi-view pedestrian detection benchmarks Wildtrack,\nTerrace, and MultiviewX, show that our proposed UMPD approach, as the first\nfully-unsupervised method to our best knowledge, performs competitively to the\nprevious state-of-the-art supervised techniques. Code will be available.\n","authors":["Mengyin Liu","Chao Zhu","Shiqi Ren","Xu-Cheng Yin"],"pdf_url":"https://arxiv.org/pdf/2305.12457v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11312v1","updated":"2023-11-19T12:25:59Z","published":"2023-11-19T12:25:59Z","title":"Optimizing rgb-d semantic segmentation through multi-modal interaction\n  and pooling attention","summary":"  Semantic segmentation of RGB-D images involves understanding the appearance\nand spatial relationships of objects within a scene, which requires careful\nconsideration of various factors. However, in indoor environments, the simple\ninput of RGB and depth images often results in a relatively limited acquisition\nof semantic and spatial information, leading to suboptimal segmentation\noutcomes. To address this, we propose the Multi-modal Interaction and Pooling\nAttention Network (MIPANet), a novel approach designed to harness the\ninteractive synergy between RGB and depth modalities, optimizing the\nutilization of complementary information. Specifically, we incorporate a\nMulti-modal Interaction Fusion Module (MIM) into the deepest layers of the\nnetwork. This module is engineered to facilitate the fusion of RGB and depth\ninformation, allowing for mutual enhancement and correction. Additionally, we\nintroduce a Pooling Attention Module (PAM) at various stages of the encoder.\nThis module serves to amplify the features extracted by the network and\nintegrates the module's output into the decoder in a targeted manner,\nsignificantly improving semantic segmentation performance. Our experimental\nresults demonstrate that MIPANet outperforms existing methods on two indoor\nscene datasets, NYUDv2 and SUN-RGBD, underscoring its effectiveness in\nenhancing RGB-D semantic segmentation.\n","authors":["Shuai Zhang","Minghong Xie"],"pdf_url":"https://arxiv.org/pdf/2311.11312v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11306v1","updated":"2023-11-19T11:57:01Z","published":"2023-11-19T11:57:01Z","title":"UMAAF: Unveiling Aesthetics via Multifarious Attributes of Images","summary":"  With the increasing prevalence of smartphones and websites, Image Aesthetic\nAssessment (IAA) has become increasingly crucial. While the significance of\nattributes in IAA is widely recognized, many attribute-based methods lack\nconsideration for the selection and utilization of aesthetic attributes. Our\ninitial step involves the acquisition of aesthetic attributes from both intra-\nand inter-perspectives. Within the intra-perspective, we extract the direct\nvisual attributes of images, constituting the absolute attribute. In the\ninter-perspective, our focus lies in modeling the relative score relationships\nbetween images within the same sequence, forming the relative attribute. Then,\nto better utilize image attributes in aesthetic assessment, we propose the\nUnified Multi-attribute Aesthetic Assessment Framework (UMAAF) to model both\nabsolute and relative attributes of images. For absolute attributes, we\nleverage multiple absolute-attribute perception modules and an\nabsolute-attribute interacting network. The absolute-attribute perception\nmodules are first pre-trained on several absolute-attribute learning tasks and\nthen used to extract corresponding absolute attribute features. The\nabsolute-attribute interacting network adaptively learns the weight of diverse\nabsolute-attribute features, effectively integrating them with generic\naesthetic features from various absolute-attribute perspectives and generating\nthe aesthetic prediction. To model the relative attribute of images, we\nconsider the relative ranking and relative distance relationships between\nimages in a Relative-Relation Loss function, which boosts the robustness of the\nUMAAF. Furthermore, UMAAF achieves state-of-the-art performance on TAD66K and\nAVA datasets, and multiple experiments demonstrate the effectiveness of each\nmodule and the model's alignment with human preference.\n","authors":["Weijie Li","Yitian Wan","Xingjiao Wu","Junjie Xu","Liang He"],"pdf_url":"https://arxiv.org/pdf/2311.11306v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11302v1","updated":"2023-11-19T11:30:43Z","published":"2023-11-19T11:30:43Z","title":"Exchanging Dual Encoder-Decoder: A New Strategy for Change Detection\n  with Semantic Guidance and Spatial Localization","summary":"  Change detection is a critical task in earth observation applications.\nRecently, deep learning-based methods have shown promising performance and are\nquickly adopted in change detection. However, the widely used multiple encoder\nand single decoder (MESD) as well as dual encoder-decoder (DED) architectures\nstill struggle to effectively handle change detection well. The former has\nproblems of bitemporal feature interference in the feature-level fusion, while\nthe latter is inapplicable to intraclass change detection and multiview\nbuilding change detection. To solve these problems, we propose a new strategy\nwith an exchanging dual encoder-decoder structure for binary change detection\nwith semantic guidance and spatial localization. The proposed strategy solves\nthe problems of bitemporal feature inference in MESD by fusing bitemporal\nfeatures in the decision level and the inapplicability in DED by determining\nchanged areas using bitemporal semantic features. We build a binary change\ndetection model based on this strategy, and then validate and compare it with\n18 state-of-the-art change detection methods on six datasets in three\nscenarios, including intraclass change detection datasets (CDD, SYSU),\nsingle-view building change detection datasets (WHU, LEVIR-CD, LEVIR-CD+) and a\nmultiview building change detection dataset (NJDS). The experimental results\ndemonstrate that our model achieves superior performance with high efficiency\nand outperforms all benchmark methods with F1-scores of 97.77%, 83.07%, 94.86%,\n92.33%, 91.39%, 74.35% on CDD, SYSU, WHU, LEVIR-CD, LEVIR- CD+, and NJDS\ndatasets, respectively. The code of this work will be available at\nhttps://github.com/NJU-LHRS/official-SGSLN.\n","authors":["Sijie Zhao","Xueliang Zhang","Pengfeng Xiao","Guangjun He"],"pdf_url":"https://arxiv.org/pdf/2311.11302v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11289v1","updated":"2023-11-19T10:29:05Z","published":"2023-11-19T10:29:05Z","title":"Pair-wise Layer Attention with Spatial Masking for Video Prediction","summary":"  Video prediction yields future frames by employing the historical frames and\nhas exhibited its great potential in many applications, e.g., meteorological\nprediction, and autonomous driving. Previous works often decode the ultimate\nhigh-level semantic features to future frames without texture details, which\ndeteriorates the prediction quality. Motivated by this, we develop a Pair-wise\nLayer Attention (PLA) module to enhance the layer-wise semantic dependency of\nthe feature maps derived from the U-shape structure in Translator, by coupling\nlow-level visual cues and high-level features. Hence, the texture details of\npredicted frames are enriched. Moreover, most existing methods capture the\nspatiotemporal dynamics by Translator, but fail to sufficiently utilize the\nspatial features of Encoder. This inspires us to design a Spatial Masking (SM)\nmodule to mask partial encoding features during pretraining, which adds the\nvisibility of remaining feature pixels by Decoder. To this end, we present a\nPair-wise Layer Attention with Spatial Masking (PLA-SM) framework for video\nprediction to capture the spatiotemporal dynamics, which reflect the motion\ntrend. Extensive experiments and rigorous ablation studies on five benchmarks\ndemonstrate the advantages of the proposed approach. The code is available at\nGitHub.\n","authors":["Ping Li","Chenhan Zhang","Zheng Yang","Xianghua Xu","Mingli Song"],"pdf_url":"https://arxiv.org/pdf/2311.11289v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11284v1","updated":"2023-11-19T09:59:09Z","published":"2023-11-19T09:59:09Z","title":"LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval\n  Score Matching","summary":"  The recent advancements in text-to-3D generation mark a significant milestone\nin generative models, unlocking new possibilities for creating imaginative 3D\nassets across various real-world scenarios. While recent advancements in\ntext-to-3D generation have shown promise, they often fall short in rendering\ndetailed and high-quality 3D models. This problem is especially prevalent as\nmany methods base themselves on Score Distillation Sampling (SDS). This paper\nidentifies a notable deficiency in SDS, that it brings inconsistent and\nlow-quality updating direction for the 3D model, causing the over-smoothing\neffect. To address this, we propose a novel approach called Interval Score\nMatching (ISM). ISM employs deterministic diffusing trajectories and utilizes\ninterval-based score matching to counteract over-smoothing. Furthermore, we\nincorporate 3D Gaussian Splatting into our text-to-3D generation pipeline.\nExtensive experiments show that our model largely outperforms the\nstate-of-the-art in quality and training efficiency.\n","authors":["Yixun Liang","Xin Yang","Jiantao Lin","Haodong Li","Xiaogang Xu","Yingcong Chen"],"pdf_url":"https://arxiv.org/pdf/2311.11284v1.pdf","comment":"The first two authors contributed equally to this work. Our code will\n  be available at: https://github.com/EnVision-Research/LucidDreamer"},{"id":"http://arxiv.org/abs/2311.11278v1","updated":"2023-11-19T09:41:10Z","published":"2023-11-19T09:41:10Z","title":"Transcending Forgery Specificity with Latent Space Augmentation for\n  Generalizable Deepfake Detection","summary":"  Deepfake detection faces a critical generalization hurdle, with performance\ndeteriorating when there is a mismatch between the distributions of training\nand testing data. A broadly received explanation is the tendency of these\ndetectors to be overfitted to forgery-specific artifacts, rather than learning\nfeatures that are widely applicable across various forgeries. To address this\nissue, we propose a simple yet effective detector called LSDA\n(\\underline{L}atent \\underline{S}pace \\underline{D}ata\n\\underline{A}ugmentation), which is based on a heuristic idea: representations\nwith a wider variety of forgeries should be able to learn a more generalizable\ndecision boundary, thereby mitigating the overfitting of method-specific\nfeatures (see Figure. 1). Following this idea, we propose to enlarge the\nforgery space by constructing and simulating variations within and across\nforgery features in the latent space. This approach encompasses the acquisition\nof enriched, domain-specific features and the facilitation of smoother\ntransitions between different forgery types, effectively bridging domain gaps.\nOur approach culminates in refining a binary classifier that leverages the\ndistilled knowledge from the enhanced features, striving for a generalizable\ndeepfake detector. Comprehensive experiments show that our proposed method is\nsurprisingly effective and transcends state-of-the-art detectors across several\nwidely used benchmarks.\n","authors":["Zhiyuan Yan","Yuhao Luo","Siwei Lyu","Qingshan Liu","Baoyuan Wu"],"pdf_url":"https://arxiv.org/pdf/2311.11278v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11273v1","updated":"2023-11-19T09:05:52Z","published":"2023-11-19T09:05:52Z","title":"Generalization and Hallucination of Large Vision-Language Models through\n  a Camouflaged Lens","summary":"  Large Vision-Language Model (LVLM) has seen burgeoning development and\nincreasing attention recently. In this paper, we propose a novel framework,\ncamo-perceptive vision-language framework (CPVLF), to explore whether LVLM can\ngeneralize to the challenging camouflaged object detection (COD) scenario in a\ntraining-free manner. During the process of generalization, we find that due to\nhallucination issues within LVLM, it can erroneously perceive objects in\ncamouflaged scenes, producing counterfactual concepts. Moreover, as LVLM is not\nspecifically trained for the precise localization of camouflaged objects, it\nexhibits a degree of uncertainty in accurately pinpointing these objects.\nTherefore, we propose chain of visual perception, which enhances LVLM's\nperception of camouflaged scenes from both linguistic and visual perspectives,\nreducing the hallucination issue and improving its capability in accurately\nlocating camouflaged objects. We validate the effectiveness of CPVLF on three\nwidely used COD datasets, and the experiments show the potential of LVLM in the\nCOD task.\n","authors":["Lv Tang","Peng-Tao Jiang","Zhihao Shen","Hao Zhang","Jinwei Chen","Bo Li"],"pdf_url":"https://arxiv.org/pdf/2311.11273v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11268v1","updated":"2023-11-19T08:41:43Z","published":"2023-11-19T08:41:43Z","title":"Towards Real-World Writing Assistance: A Chinese Character Checking\n  Benchmark with Faked and Misspelled Characters","summary":"  Writing assistance is an application closely related to human life and is\nalso a fundamental Natural Language Processing (NLP) research field. Its aim is\nto improve the correctness and quality of input texts, with character checking\nbeing crucial in detecting and correcting wrong characters. From the\nperspective of the real world where handwriting occupies the vast majority,\ncharacters that humans get wrong include faked characters (i.e., untrue\ncharacters created due to writing errors) and misspelled characters (i.e., true\ncharacters used incorrectly due to spelling errors). However, existing datasets\nand related studies only focus on misspelled characters mainly caused by\nphonological or visual confusion, thereby ignoring faked characters which are\nmore common and difficult. To break through this dilemma, we present\nVisual-C$^3$, a human-annotated Visual Chinese Character Checking dataset with\nfaked and misspelled Chinese characters. To the best of our knowledge,\nVisual-C$^3$ is the first real-world visual and the largest human-crafted\ndataset for the Chinese character checking scenario. Additionally, we also\npropose and evaluate novel baseline methods on Visual-C$^3$. Extensive\nempirical results and analyses show that Visual-C$^3$ is high-quality yet\nchallenging. The Visual-C$^3$ dataset and the baseline methods will be publicly\navailable to facilitate further research in the community.\n","authors":["Yinghui Li","Zishan Xu","Shaoshen Chen","Haojing Huang","Yangning Li","Yong Jiang","Zhongli Li","Qingyu Zhou","Hai-Tao Zheng","Ying Shen"],"pdf_url":"https://arxiv.org/pdf/2311.11268v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2311.11261v1","updated":"2023-11-19T07:47:43Z","published":"2023-11-19T07:47:43Z","title":"Adversarial Prompt Tuning for Vision-Language Models","summary":"  With the rapid advancement of multimodal learning, pre-trained\nVision-Language Models (VLMs) such as CLIP have demonstrated remarkable\ncapacities in bridging the gap between visual and language modalities. However,\nthese models remain vulnerable to adversarial attacks, particularly in the\nimage modality, presenting considerable security risks. This paper introduces\nAdversarial Prompt Tuning (AdvPT), a novel technique to enhance the adversarial\nrobustness of image encoders in VLMs. AdvPT innovatively leverages learnable\ntext prompts and aligns them with adversarial image embeddings, to address the\nvulnerabilities inherent in VLMs without the need for extensive parameter\ntraining or modification of the model architecture. We demonstrate that AdvPT\nimproves resistance against white-box and black-box adversarial attacks and\nexhibits a synergistic effect when combined with existing\nimage-processing-based defense techniques, further boosting defensive\ncapabilities. Comprehensive experimental analyses provide insights into\nadversarial prompt tuning, a novel paradigm devoted to improving resistance to\nadversarial images through textual input modifications, paving the way for\nfuture robust multimodal learning research. These findings open up new\npossibilities for enhancing the security of VLMs. Our code will be available\nupon publication of the paper.\n","authors":["Jiaming Zhang","Xingjun Ma","Xin Wang","Lingyu Qiu","Jiaqi Wang","Yu-Gang Jiang","Jitao Sang"],"pdf_url":"https://arxiv.org/pdf/2311.11261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11260v1","updated":"2023-11-19T07:47:11Z","published":"2023-11-19T07:47:11Z","title":"Radarize: Large-Scale Radar SLAM for Indoor Environments","summary":"  We present Radarize, a self-contained SLAM pipeline for indoor environments\nthat uses only a low-cost commodity single-chip mmWave radar. Our radar-native\napproach leverages phenomena unique to radio frequencies, such as doppler\nshift-based odometry, to improve performance. We evaluate our method on a\nlarge-scale dataset of 146 trajectories spanning 4 campus buildings, totaling\napproximately 4680m of travel distance. Our results show that our method\noutperforms state-of-the-art radar-based approaches by approximately 5x in\nterms of odometry and 8x in terms of end-to-end SLAM, as measured by absolute\ntrajectory error (ATE), without the need additional sensors such as IMUs or\nwheel odometry.\n","authors":["Emerson Sie","Xinyu Wu","Heyu Guo","Deepak Vasisht"],"pdf_url":"https://arxiv.org/pdf/2311.11260v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.15445v2","updated":"2023-11-19T07:43:22Z","published":"2023-03-27T17:59:55Z","title":"IRFL: Image Recognition of Figurative Language","summary":"  Figures of speech such as metaphors, similes, and idioms are integral parts\nof human communication. They are ubiquitous in many forms of discourse,\nallowing people to convey complex, abstract ideas and evoke emotion. As\nfigurative forms are often conveyed through multiple modalities (e.g., both\ntext and images), understanding multimodal figurative language is an important\nAI challenge, weaving together profound vision, language, commonsense and\ncultural knowledge.\n  In this work, we develop the Image Recognition of Figurative Language (IRFL)\ndataset. We leverage human annotation and an automatic pipeline we created to\ngenerate a multimodal dataset, and introduce two novel tasks as a benchmark for\nmultimodal figurative language understanding. We experimented with\nstate-of-the-art vision and language models and found that the best (22%)\nperformed substantially worse than humans (97%). We release our dataset,\nbenchmark, and code, in hopes of driving the development of models that can\nbetter understand figurative language.\n","authors":["Ron Yosef","Yonatan Bitton","Dafna Shahaf"],"pdf_url":"https://arxiv.org/pdf/2303.15445v2.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2311.11351v1","updated":"2023-11-19T15:26:42Z","published":"2023-11-19T15:26:42Z","title":"Scaling Law of Large Sequential Recommendation Models","summary":"  Scaling of neural networks has recently shown great potential to improve the\nmodel capacity in various fields. Specifically, model performance has a\npower-law relationship with model size or data size, which provides important\nguidance for the development of large-scale models. However, there is still\nlimited understanding on the scaling effect of user behavior models in\nrecommender systems, where the unique data characteristics (e.g. data scarcity\nand sparsity) pose new challenges to explore the scaling effect in\nrecommendation tasks. In this work, we focus on investigating the scaling laws\nin large sequential recommendation models. Specially, we consider a pure\nID-based task formulation, where the interaction history of a user is formatted\nas a chronological sequence of item IDs. We don't incorporate any side\ninformation (e.g. item text), because we would like to explore how scaling law\nholds from the perspective of user behavior. With specially improved\nstrategies, we scale up the model size to 0.8B parameters, making it feasible\nto explore the scaling effect in a diverse range of model sizes. As the major\nfindings, we empirically show that scaling law still holds for these trained\nmodels, even in data-constrained scenarios. We then fit the curve for scaling\nlaw, and successfully predict the test loss of the two largest tested model\nscales. Furthermore, we examine the performance advantage of scaling effect on\nfive challenging recommendation tasks, considering the unique issues (e.g. cold\nstart, robustness, long-term preference) in recommender systems. We find that\nscaling up the model size can greatly boost the performance on these\nchallenging tasks, which again verifies the benefits of large recommendation\nmodels.\n","authors":["Gaowei Zhang","Yupeng Hou","Hongyu Lu","Yu Chen","Wayne Xin Zhao","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2311.11351v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.01098v3","updated":"2023-11-19T14:42:39Z","published":"2023-08-02T12:05:01Z","title":"Towards Better Query Classification with Multi-Expert Knowledge\n  Condensation in JD Ads Search","summary":"  Search query classification, as an effective way to understand user intents,\nis of great importance in real-world online ads systems. To ensure a lower\nlatency, a shallow model (e.g. FastText) is widely used for efficient online\ninference. However, the representation ability of the FastText model is\ninsufficient, resulting in poor classification performance, especially on some\nlow-frequency queries and tailed categories. Using a deeper and more complex\nmodel (e.g. BERT) is an effective solution, but it will cause a higher online\ninference latency and more expensive computing costs. Thus, how to juggle both\ninference efficiency and classification performance is obviously of great\npractical importance. To overcome this challenge, in this paper, we propose\nknowledge condensation (KC), a simple yet effective knowledge distillation\nframework to boost the classification performance of the online FastText model\nunder strict low latency constraints. Specifically, we propose to train an\noffline BERT model to retrieve more potentially relevant data. Benefiting from\nits powerful semantic representation, more relevant labels not exposed in the\nhistorical data will be added into the training set for better FastText model\ntraining. Moreover, a novel distribution-diverse multi-expert learning strategy\nis proposed to further improve the mining ability of relevant data. By training\nmultiple BERT models from different data distributions, it can respectively\nperform better at high, middle, and low-frequency search queries. The model\nensemble from multi-distribution makes its retrieval ability more powerful. We\nhave deployed two versions of this framework in JD search, and both offline\nexperiments and online A/B testing from multiple datasets have validated the\neffectiveness of the proposed approach.\n","authors":["Kun-Peng Ning","Ming Pang","Zheng Fang","Xue Jiang","Xi-Wei Zhao","Chang-Ping Peng","Zhan-Gang Lin","Jing-He Hu","Jing-Ping Shao"],"pdf_url":"https://arxiv.org/pdf/2308.01098v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.16761v3","updated":"2023-11-19T07:16:19Z","published":"2023-08-31T14:29:10Z","title":"Learning Category Trees for ID-Based Recommendation: Exploring the Power\n  of Differentiable Vector Quantization","summary":"  Category information plays a crucial role in enhancing the quality and\npersonalization of recommender systems. Nevertheless, the availability of item\ncategory information is not consistently present, particularly in the context\nof ID-based recommendations. In this work, we propose a novel approach to\nautomatically learn and generate entity (i.e., user or item) category trees for\nID-based recommendation. Specifically, we devise a differentiable vector\nquantization framework for automatic category tree generation, namely CAGE,\nwhich enables the simultaneous learning and refinement of categorical code\nrepresentations and entity embeddings in an end-to-end manner, starting from\nthe randomly initialized states. With its high adaptability, CAGE can be easily\nintegrated into both sequential and non-sequential recommender systems. We\nvalidate the effectiveness of CAGE on various recommendation tasks including\nlist completion, collaborative filtering, and click-through rate prediction,\nacross different recommendation models. We release the code and data for others\nto reproduce the reported results.\n","authors":["Qijiong Liu","Jiaren Xiao","Lu Fan","Jieming Zhu","Xiao-Ming Wu"],"pdf_url":"https://arxiv.org/pdf/2308.16761v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11239v1","updated":"2023-11-19T05:59:19Z","published":"2023-11-19T05:59:19Z","title":"Dependency Relationships-Enhanced Attentive Group Recommendation in HINs","summary":"  Recommending suitable items to a group of users, commonly referred to as the\ngroup recommendation task, is becoming increasingly urgent with the development\nof group activities. The challenges within the group recommendation task\ninvolve aggregating the individual preferences of group members as the group's\npreferences and facing serious sparsity problems due to the lack of\nuser/group-item interactions. To solve these problems, we propose a novel\napproach called Dependency Relationships-Enhanced Attentive Group\nRecommendation (DREAGR) for the recommendation task of occasional groups.\nSpecifically, we introduce the dependency relationship between items as side\ninformation to enhance the user/group-item interaction and alleviate the\ninteraction sparsity problem. Then, we propose a Path-Aware Attention Embedding\n(PAAE) method to model users' preferences on different types of paths. Next, we\ndesign a gated fusion mechanism to fuse users' preferences into their\ncomprehensive preferences. Finally, we develop an attention aggregator that\naggregates users' preferences as the group's preferences for the group\nrecommendation task. We conducted experiments on two datasets to demonstrate\nthe superiority of DREAGR by comparing it with state-of-the-art group\nrecommender models. The experimental results show that DREAGR outperforms other\nmodels, especially HR@N and NDCG@N (N=5, 10), where DREAGR has improved in the\nrange of 3.64% to 7.01% and 2.57% to 3.39% on both datasets, respectively.\n","authors":["Juntao Zhang","Sheng Wang","Zhiyu Chen","Xiandi Yang","Zhiyong Peng"],"pdf_url":"https://arxiv.org/pdf/2311.11239v1.pdf","comment":"14 pages, 9 figures, This paper has been submitted to IEEE\n  Transactions on Knowledge and Data Engineering"},{"id":"http://arxiv.org/abs/2311.11226v1","updated":"2023-11-19T04:42:24Z","published":"2023-11-19T04:42:24Z","title":"An Interactive Query Generation Assistant using LLM-based Prompt\n  Modification and User Feedback","summary":"  While search is the predominant method of accessing information, formulating\neffective queries remains a challenging task, especially for situations where\nthe users are not familiar with a domain, or searching for documents in other\nlanguages, or looking for complex information such as events, which are not\neasily expressible as queries. Providing example documents or passages of\ninterest, might be easier for a user, however, such query-by-example scenarios\nare prone to concept drift, and are highly sensitive to the query generation\nmethod. This demo illustrates complementary approaches of using LLMs\ninteractively, assisting and enabling the user to provide edits and feedback at\nall stages of the query formulation process. The proposed Query Generation\nAssistant is a novel search interface which supports automatic and interactive\nquery generation over a mono-linguial or multi-lingual document collection.\nSpecifically, the proposed assistive interface enables the users to refine the\nqueries generated by different LLMs, to provide feedback on the retrieved\ndocuments or passages, and is able to incorporate the users' feedback as\nprompts to generate more effective queries. The proposed interface is a\nvaluable experimental tool for exploring fine-tuning and prompting of LLMs for\nquery generation to qualitatively evaluate the effectiveness of retrieval and\nranking models, and for conducting Human-in-the-Loop (HITL) experiments for\ncomplex search tasks where users struggle to formulate queries without such\nassistance.\n","authors":["Kaustubh D. Dhole","Ramraj Chandradevan","Eugene Agichtein"],"pdf_url":"https://arxiv.org/pdf/2311.11226v1.pdf","comment":"Intelligence Advanced Research Projects Activity (IARPA) BETTER\n  Research Program"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2307.04962v3","updated":"2023-11-19T23:30:37Z","published":"2023-07-11T01:52:08Z","title":"Intrinsically motivated graph exploration using network theories of\n  human curiosity","summary":"  Intrinsically motivated exploration has proven useful for reinforcement\nlearning, even without additional extrinsic rewards. When the environment is\nnaturally represented as a graph, how to guide exploration best remains an open\nquestion. In this work, we propose a novel approach for exploring\ngraph-structured data motivated by two theories of human curiosity: the\ninformation gap theory and the compression progress theory. The theories view\ncuriosity as an intrinsic motivation to optimize for topological features of\nsubgraphs induced by nodes visited in the environment. We use these proposed\nfeatures as rewards for graph neural-network-based reinforcement learning. On\nmultiple classes of synthetically generated graphs, we find that trained agents\ngeneralize to longer exploratory walks and larger environments than are seen\nduring training. Our method computes more efficiently than the greedy\nevaluation of the relevant topological properties. The proposed intrinsic\nmotivations bear particular relevance for recommender systems. We demonstrate\nthat next-node recommendations considering curiosity are more predictive of\nhuman choices than PageRank centrality in several real-world graph\nenvironments, including MovieLens, Amazon Books, and Wikipedia.\n","authors":["Shubhankar P. Patankar","Mathieu Ouellet","Juan Cervino","Alejandro Ribeiro","Kieran A. Murphy","Dani S. Bassett"],"pdf_url":"https://arxiv.org/pdf/2307.04962v3.pdf","comment":"15 pages, 5 figures in main text, and 18 pages, 9 figures in\n  supplement"},{"id":"http://arxiv.org/abs/2311.11452v1","updated":"2023-11-19T23:20:16Z","published":"2023-11-19T23:20:16Z","title":"Physics-Enhanced TinyML for Real-Time Detection of Ground Magnetic\n  Anomalies","summary":"  Space weather phenomena like geomagnetic disturbances (GMDs) and\ngeomagnetically induced currents (GICs) pose significant risks to critical\ntechnological infrastructure. While traditional predictive models, grounded in\nsimulation, hold theoretical robustness, they grapple with challenges, notably\nthe assimilation of imprecise data and extensive computational complexities. In\nrecent years, Tiny Machine Learning (TinyML) has been adopted to develop\nMachine Learning (ML)-enabled magnetometer systems for predicting real-time\nterrestrial magnetic perturbations as a proxy measure for GIC. While TinyML\noffers efficient, real-time data processing, its intrinsic limitations prevent\nthe utilization of robust methods with high computational needs. This paper\ndeveloped a physics-guided TinyML framework to address the above challenges.\nThis framework integrates physics-based regularization at the stages of model\ntraining and compression, thereby augmenting the reliability of predictions.\nThe developed pruning scheme within the framework harnesses the inherent\nphysical characteristics of the domain, striking a balance between model size\nand robustness. The study presents empirical results, drawing a comprehensive\ncomparison between the accuracy and reliability of the developed framework and\nits traditional counterpart. Such a comparative analysis underscores the\nprospective applicability of the developed framework in conceptualizing robust,\nML-enabled magnetometer systems for real-time space weather forecasting.\n","authors":["Talha Siddique","MD Shaad Mahmud"],"pdf_url":"https://arxiv.org/pdf/2311.11452v1.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.11446v1","updated":"2023-11-19T23:00:27Z","published":"2023-11-19T23:00:27Z","title":"Weight Norm Control","summary":"  We note that decoupled weight decay regularization is a particular case of\nweight norm control where the target norm of weights is set to 0. Any\noptimization method (e.g., Adam) which uses decoupled weight decay\nregularization (respectively, AdamW) can be viewed as a particular case of a\nmore general algorithm with weight norm control (respectively, AdamWN). We\nargue that setting the target norm of weights to 0 can be suboptimal and other\ntarget norm values can be considered. For instance, any training run where\nAdamW achieves a particular norm of weights can be challenged by AdamWN\nscheduled to achieve a comparable norm of weights. We discuss various\nimplications of introducing weight norm control instead of weight decay.\n","authors":["Ilya Loshchilov"],"pdf_url":"https://arxiv.org/pdf/2311.11446v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.11609v2","updated":"2023-11-19T22:53:59Z","published":"2023-10-17T22:05:11Z","title":"Reflection-Equivariant Diffusion for 3D Structure Determination from\n  Isotopologue Rotational Spectra in Natural Abundance","summary":"  Structure determination is necessary to identify unknown organic molecules,\nsuch as those in natural products, forensic samples, the interstellar medium,\nand laboratory syntheses. Rotational spectroscopy enables structure\ndetermination by providing accurate 3D information about small organic\nmolecules via their moments of inertia. Using these moments, Kraitchman\nanalysis determines isotopic substitution coordinates, which are the unsigned\n$|x|,|y|,|z|$ coordinates of all atoms with natural isotopic abundance,\nincluding carbon, nitrogen, and oxygen. While unsigned substitution coordinates\ncan verify guesses of structures, the missing $+/-$ signs make it challenging\nto determine the actual structure from the substitution coordinates alone. To\ntackle this inverse problem, we develop KREED (Kraitchman\nREflection-Equivariant Diffusion), a generative diffusion model that infers a\nmolecule's complete 3D structure from its molecular formula, moments of\ninertia, and unsigned substitution coordinates of heavy atoms. KREED's top-1\npredictions identify the correct 3D structure with >98% accuracy on the QM9 and\nGEOM datasets when provided with substitution coordinates of all heavy atoms\nwith natural isotopic abundance. When substitution coordinates are restricted\nto only a subset of carbons, accuracy is retained at 91% on QM9 and 32% on\nGEOM. On a test set of experimentally measured substitution coordinates\ngathered from the literature, KREED predicts the correct all-atom 3D structure\nin 25 of 33 cases, demonstrating experimental applicability for context-free 3D\nstructure determination with rotational spectroscopy.\n","authors":["Austin Cheng","Alston Lo","Santiago Miret","Brooks Pate","Alán Aspuru-Guzik"],"pdf_url":"https://arxiv.org/pdf/2310.11609v2.pdf","comment":"added software citations"},{"id":"http://arxiv.org/abs/2310.15543v2","updated":"2023-11-19T22:24:59Z","published":"2023-10-24T06:22:20Z","title":"Symmetry-preserving graph attention network to solve routing problems at\n  multiple resolutions","summary":"  Travelling Salesperson Problems (TSPs) and Vehicle Routing Problems (VRPs)\nhave achieved reasonable improvement in accuracy and computation time with the\nadaptation of Machine Learning (ML) methods. However, none of the previous\nworks completely respects the symmetries arising from TSPs and VRPs including\nrotation, translation, permutation, and scaling. In this work, we introduce the\nfirst-ever completely equivariant model and training to solve combinatorial\nproblems. Furthermore, it is essential to capture the multiscale structure\n(i.e. from local to global information) of the input graph, especially for the\ncases of large and long-range graphs, while previous methods are limited to\nextracting only local information that can lead to a local or sub-optimal\nsolution. To tackle the above limitation, we propose a Multiresolution scheme\nin combination with Equivariant Graph Attention network (mEGAT) architecture,\nwhich can learn the optimal route based on low-level and high-level graph\nresolutions in an efficient way. In particular, our approach constructs a\nhierarchy of coarse-graining graphs from the input graph, in which we try to\nsolve the routing problems on simple low-level graphs first, then utilize that\nknowledge for the more complex high-level graphs. Experimentally, we have shown\nthat our model outperforms existing baselines and proved that symmetry\npreservation and multiresolution are important recipes for solving\ncombinatorial problems in a data-driven manner. Our source code is publicly\navailable at https://github.com/HySonLab/Multires-NP-hard\n","authors":["Cong Dao Tran","Thong Bach","Truong Son Hy"],"pdf_url":"https://arxiv.org/pdf/2310.15543v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11436v1","updated":"2023-11-19T22:17:09Z","published":"2023-11-19T22:17:09Z","title":"Duality of Bures and Shape Distances with Implications for Comparing\n  Neural Representations","summary":"  A multitude of (dis)similarity measures between neural network\nrepresentations have been proposed, resulting in a fragmented research\nlandscape. Most of these measures fall into one of two categories.\n  First, measures such as linear regression, canonical correlations analysis\n(CCA), and shape distances, all learn explicit mappings between neural units to\nquantify similarity while accounting for expected invariances. Second, measures\nsuch as representational similarity analysis (RSA), centered kernel alignment\n(CKA), and normalized Bures similarity (NBS) all quantify similarity in summary\nstatistics, such as stimulus-by-stimulus kernel matrices, which are already\ninvariant to expected symmetries. Here, we take steps towards unifying these\ntwo broad categories of methods by observing that the cosine of the Riemannian\nshape distance (from category 1) is equal to NBS (from category 2). We explore\nhow this connection leads to new interpretations of shape distances and NBS,\nand draw contrasts of these measures with CKA, a popular similarity measure in\nthe deep learning literature.\n","authors":["Sarah E. Harvey","Brett W. Larsen","Alex H. Williams"],"pdf_url":"https://arxiv.org/pdf/2311.11436v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06247v3","updated":"2023-11-19T22:15:50Z","published":"2023-06-09T20:43:19Z","title":"Online Learning with Set-Valued Feedback","summary":"  We study a variant of online multiclass classification where the learner\npredicts a single label but receives a \\textit{set of labels} as feedback. In\nthis model, the learner is penalized for not outputting a label contained in\nthe revealed set. We show that unlike online multiclass learning with\nsingle-label feedback, deterministic and randomized online learnability are\n\\textit{not equivalent} in the realizable setting under set-valued feedback. In\naddition, we show that deterministic and randomized realizable learnability are\nequivalent if the Helly number of the collection of sets that can be revealed\nas feedback is finite. In light of this separation, we give two new\ncombinatorial dimensions, named the Set Littlestone and Measure Shattering\ndimension, whose finiteness characterizes deterministic and randomized\nrealizable learnability respectively. Additionally, these dimensions lower- and\nupper bound the deterministic and randomized minimax regret in the realizable\nsetting. Going beyond the realizable setting, we prove that the Measure\nshattering dimension continues to characterize learnability and quantify\nminimax regret in the agnostic setting. Finally, we use our results to\nestablish bounds on the minimax regret for three practical learning settings:\nonline multilabel ranking, online multilabel classification, and real-valued\nprediction with interval-valued response.\n","authors":["Vinod Raman","Unique Subedi","Ambuj Tewari"],"pdf_url":"https://arxiv.org/pdf/2306.06247v3.pdf","comment":"31 pages"},{"id":"http://arxiv.org/abs/2107.03920v8","updated":"2023-11-19T22:13:06Z","published":"2021-07-08T15:52:18Z","title":"Likelihood-Free Frequentist Inference: Bridging Classical Statistics and\n  Machine Learning for Reliable Simulator-Based Inference","summary":"  Many areas of science make extensive use of computer simulators that\nimplicitly encode intractable likelihood functions of complex systems.\nClassical statistical methods are poorly suited for these so-called\nlikelihood-free inference (LFI) settings, especially outside asymptotic and\nlow-dimensional regimes. At the same time, traditional LFI methods - such as\nApproximate Bayesian Computation or more recent machine learning techniques -\ndo not guarantee confidence sets with nominal coverage in general settings\n(i.e., with high-dimensional data, finite sample sizes, and for any parameter\nvalue). In addition, there are no diagnostic tools to check the empirical\ncoverage of confidence sets provided by such methods across the entire\nparameter space. In this work, we propose a unified and modular inference\nframework that bridges classical statistics and modern machine learning\nproviding (i) a practical approach to the Neyman construction of confidence\nsets with frequentist finite-sample coverage for any value of the unknown\nparameters; and (ii) interpretable diagnostics that estimate the empirical\ncoverage across the entire parameter space. We refer to the general framework\nas likelihood-free frequentist inference (LF2I). Any method that defines a test\nstatistic can leverage LF2I to create valid confidence sets and diagnostics\nwithout costly Monte Carlo samples at fixed parameter settings. We study the\npower of two likelihood-based test statistics (ACORE and BFF) and demonstrate\ntheir empirical performance on high-dimensional, complex data. Code is\navailable at https://github.com/lee-group-cmu/lf2i.\n","authors":["Niccolò Dalmasso","Luca Masserano","David Zhao","Rafael Izbicki","Ann B. Lee"],"pdf_url":"https://arxiv.org/pdf/2107.03920v8.pdf","comment":"45 pages, 6 figures, code available at\n  https://github.com/lee-group-cmu/lf2i, supplementary material available at\n  https://lucamasserano.github.io/data/LF2I_supplementary_material.pdf"},{"id":"http://arxiv.org/abs/2311.11429v1","updated":"2023-11-19T21:40:16Z","published":"2023-11-19T21:40:16Z","title":"Fast Heavy Inner Product Identification Between Weights and Inputs in\n  Neural Network Training","summary":"  In this paper, we consider a heavy inner product identification problem,\nwhich generalizes the Light Bulb problem~(\\cite{prr89}): Given two sets $A\n\\subset \\{-1,+1\\}^d$ and $B \\subset \\{-1,+1\\}^d$ with $|A|=|B| = n$, if there\nare exact $k$ pairs whose inner product passes a certain threshold, i.e.,\n$\\{(a_1, b_1), \\cdots, (a_k, b_k)\\} \\subset A \\times B$ such that $\\forall i\n\\in [k], \\langle a_i,b_i \\rangle \\geq \\rho \\cdot d$, for a threshold $\\rho \\in\n(0,1)$, the goal is to identify those $k$ heavy inner products. We provide an\nalgorithm that runs in $O(n^{2 \\omega / 3+ o(1)})$ time to find the $k$ inner\nproduct pairs that surpass $\\rho \\cdot d$ threshold with high probability,\nwhere $\\omega$ is the current matrix multiplication exponent. By solving this\nproblem, our method speed up the training of neural networks with ReLU\nactivation function.\n","authors":["Lianke Qin","Saayan Mitra","Zhao Song","Yuanyuan Yang","Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2311.11429v1.pdf","comment":"IEEE BigData 2023"},{"id":"http://arxiv.org/abs/2311.11424v1","updated":"2023-11-19T21:06:00Z","published":"2023-11-19T21:06:00Z","title":"Tensor-Aware Energy Accounting","summary":"  With the rapid growth of Artificial Intelligence (AI) applications supported\nby deep learning (DL), the energy efficiency of these applications has an\nincreasingly large impact on sustainability. We introduce Smaragdine, a new\nenergy accounting system for tensor-based DL programs implemented with\nTensorFlow. At the heart of Smaragdine is a novel white-box methodology of\nenergy accounting: Smaragdine is aware of the internal structure of the DL\nprogram, which we call tensor-aware energy accounting. With Smaragdine, the\nenergy consumption of a DL program can be broken down into units aligned with\nits logical hierarchical decomposition structure. We apply Smaragdine for\nunderstanding the energy behavior of BERT, one of the most widely used language\nmodels. Layer-by-layer and tensor-by-tensor, Smaragdine is capable of\nidentifying the highest energy/power-consuming components of BERT. Furthermore,\nwe conduct two case studies on how Smaragdine supports downstream toolchain\nbuilding, one on the comparative energy impact of hyperparameter tuning of\nBERT, the other on the energy behavior evolution when BERT evolves to its next\ngeneration, ALBERT.\n","authors":["Timur Babakol","Yu David Liu"],"pdf_url":"https://arxiv.org/pdf/2311.11424v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11423v1","updated":"2023-11-19T21:02:17Z","published":"2023-11-19T21:02:17Z","title":"Offline Reinforcement Learning for Wireless Network Optimization with\n  Mixture Datasets","summary":"  The recent development of reinforcement learning (RL) has boosted the\nadoption of online RL for wireless radio resource management (RRM). However,\nonline RL algorithms require direct interactions with the environment, which\nmay be undesirable given the potential performance loss due to the unavoidable\nexploration in RL. In this work, we first investigate the use of \\emph{offline}\nRL algorithms in solving the RRM problem. We evaluate several state-of-the-art\noffline RL algorithms, including behavior constrained Q-learning (BCQ),\nconservative Q-learning (CQL), and implicit Q-learning (IQL), for a specific\nRRM problem that aims at maximizing a linear combination {of sum and}\n5-percentile rates via user scheduling. We observe that the performance of\noffline RL for the RRM problem depends critically on the behavior policy used\nfor data collection, and further propose a novel offline RL solution that\nleverages heterogeneous datasets collected by different behavior policies. We\nshow that with a proper mixture of the datasets, offline RL can produce a\nnear-optimal RL policy even when all involved behavior policies are highly\nsuboptimal.\n","authors":["Kun Yang","Cong Shen","Jing Yang","Shu-ping Yeh","Jerry Sydir"],"pdf_url":"https://arxiv.org/pdf/2311.11423v1.pdf","comment":"This paper is the camera ready version for Asilomar 2023"},{"id":"http://arxiv.org/abs/2311.11422v1","updated":"2023-11-19T20:47:39Z","published":"2023-11-19T20:47:39Z","title":"Precision at the indistinguishability threshold: a method for evaluating\n  classification algorithms","summary":"  There exist a wide range of single number metrics for assessing performance\nof classification algorithms, including AUC and the F1-score (Wikipedia lists\n17 such metrics, with 27 different names). In this article, I propose a new\nmetric to answer the following question: when an algorithm is tuned so that it\ncan no longer distinguish labelled cats from real cats, how often does a\nrandomly chosen image that has been labelled as containing a cat actually\ncontain a cat? The steps to construct this metric are as follows. First, we set\na threshold score such that when the algorithm is shown two randomly-chosen\nimages -- one that has a score greater than the threshold (i.e. a picture\nlabelled as containing a cat) and another from those pictures that really does\ncontain a cat -- the probability that the image with the highest score is the\none chosen from the set of real cat images is 50\\%. At this decision threshold,\nthe set of positively labelled images are indistinguishable from the set of\nimages which are positive. Then, as a second step, we measure performance by\nasking how often a randomly chosen picture from those labelled as containing a\ncat actually contains a cat. This metric can be thought of as {\\it precision at\nthe indistinguishability threshold}. While this new metric doesn't address the\ntradeoff between precision and recall inherent to all such metrics, I do show\nwhy this method avoids pitfalls that can occur when using, for example AUC, and\nit is better motivated than, for example, the F1-score.\n","authors":["David J. T. Sumpter"],"pdf_url":"https://arxiv.org/pdf/2311.11422v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11420v1","updated":"2023-11-19T20:39:35Z","published":"2023-11-19T20:39:35Z","title":"LifeLearner: Hardware-Aware Meta Continual Learning System for Embedded\n  Computing Platforms","summary":"  Continual Learning (CL) allows applications such as user personalization and\nhousehold robots to learn on the fly and adapt to context. This is an important\nfeature when context, actions, and users change. However, enabling CL on\nresource-constrained embedded systems is challenging due to the limited labeled\ndata, memory, and computing capacity. In this paper, we propose LifeLearner, a\nhardware-aware meta continual learning system that drastically optimizes system\nresources (lower memory, latency, energy consumption) while ensuring high\naccuracy. Specifically, we (1) exploit meta-learning and rehearsal strategies\nto explicitly cope with data scarcity issues and ensure high accuracy, (2)\neffectively combine lossless and lossy compression to significantly reduce the\nresource requirements of CL and rehearsal samples, and (3) developed\nhardware-aware system on embedded and IoT platforms considering the hardware\ncharacteristics. As a result, LifeLearner achieves near-optimal CL performance,\nfalling short by only 2.8% on accuracy compared to an Oracle baseline. With\nrespect to the state-of-the-art (SOTA) Meta CL method, LifeLearner drastically\nreduces the memory footprint (by 178.7x), end-to-end latency by 80.8-94.2%, and\nenergy consumption by 80.9-94.2%. In addition, we successfully deployed\nLifeLearner on two edge devices and a microcontroller unit, thereby enabling\nefficient CL on resource-constrained platforms where it would be impractical to\nrun SOTA methods and the far-reaching deployment of adaptable CL in a\nubiquitous manner. Code is available at\nhttps://github.com/theyoungkwon/LifeLearner.\n","authors":["Young D. Kwon","Jagmohan Chauhan","Hong Jia","Stylianos I. Venieris","Cecilia Mascolo"],"pdf_url":"https://arxiv.org/pdf/2311.11420v1.pdf","comment":"Accepted for publication at SenSys 2023"},{"id":"http://arxiv.org/abs/2311.11415v1","updated":"2023-11-19T20:22:05Z","published":"2023-11-19T20:22:05Z","title":"A Security Risk Taxonomy for Large Language Models","summary":"  As large language models (LLMs) permeate more and more applications, an\nassessment of their associated security risks becomes increasingly necessary.\nThe potential for exploitation by malicious actors, ranging from disinformation\nto data breaches and reputation damage, is substantial. This paper addresses a\ngap in current research by focusing on the security risks posed by LLMs, which\nextends beyond the widely covered ethical and societal implications. Our work\nproposes a taxonomy of security risks along the user-model communication\npipeline, explicitly focusing on prompt-based attacks on LLMs. We categorize\nthe attacks by target and attack type within a prompt-based interaction scheme.\nThe taxonomy is reinforced with specific attack examples to showcase the\nreal-world impact of these risks. Through this taxonomy, we aim to inform the\ndevelopment of robust and secure LLM applications, enhancing their safety and\ntrustworthiness.\n","authors":["Erik Derner","Kristina Batistič","Jan Zahálka","Robert Babuška"],"pdf_url":"https://arxiv.org/pdf/2311.11415v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11413v1","updated":"2023-11-19T20:16:16Z","published":"2023-11-19T20:16:16Z","title":"Large Pre-trained time series models for cross-domain Time series\n  analysis tasks","summary":"  Large pre-trained models have been instrumental in significant advancements\nin domains like language and vision making model training for individual\ndownstream tasks more efficient as well as provide superior performance.\nHowever, tackling time-series analysis tasks usually involves designing and\ntraining a separate model from scratch leveraging training data and domain\nexpertise specific to the task. We tackle a significant challenge for\npre-training a general time-series model from multiple heterogeneous\ntime-series dataset: providing semantically useful inputs to models for\nmodeling time series of different dynamics from different domains. We observe\nthat partitioning time-series into segments as inputs to sequential models\nproduces semantically better inputs and propose a novel model LPTM that\nautomatically identifies optimal dataset-specific segmentation strategy\nleveraging self-supervised learning loss during pre-training. LPTM provides\nperformance similar to or better than domain-specific state-of-art model and is\nsignificantly more data and compute efficient taking up to 40% less data as\nwell as 50% less training time to achieve state-of-art performance in a wide\nrange of time-series analysis tasks from multiple disparate domain.\n","authors":["Harshavardhan Kamarthi","B. Aditya Prakash"],"pdf_url":"https://arxiv.org/pdf/2311.11413v1.pdf","comment":"14 pages, 3 Figures, 3 Tables"},{"id":"http://arxiv.org/abs/2311.11410v1","updated":"2023-11-19T19:53:49Z","published":"2023-11-19T19:53:49Z","title":"Negotiated Representations for Machine Mearning Application","summary":"  Overfitting is a phenomenon that occurs when a machine learning model is\ntrained for too long and focused too much on the exact fitness of the training\nsamples to the provided training labels and cannot keep track of the predictive\nrules that would be useful on the test data. This phenomenon is commonly\nattributed to memorization of particular samples, memorization of the noise,\nand forced fitness into a data set of limited samples by using a high number of\nneurons. While it is true that the model encodes various peculiarities as the\ntraining process continues, we argue that most of the overfitting occurs in the\nprocess of reconciling sharply defined membership ratios. In this study, we\npresent an approach that increases the classification accuracy of machine\nlearning models by allowing the model to negotiate output representations of\nthe samples with previously determined class labels. By setting up a\nnegotiation between the models interpretation of the inputs and the provided\nlabels, we not only increased average classification accuracy but also\ndecreased the rate of overfitting without applying any other regularization\ntricks. By implementing our negotiation paradigm approach to several low regime\nmachine learning problems by generating overfitting scenarios from publicly\navailable data sets such as CIFAR 10, CIFAR 100, and MNIST we have demonstrated\nthat the proposed paradigm has more capacity than its intended purpose. We are\nsharing the experimental results and inviting the machine learning community to\nexplore the limits of the proposed paradigm. We also aim to incentive the\ncommunity to exploit the negotiation paradigm to overcome the learning related\nchallenges in other research fields such as continual learning. The Python code\nof the experimental setup is uploaded to GitHub.\n","authors":["Nuri Korhan","Samet Bayram"],"pdf_url":"https://arxiv.org/pdf/2311.11410v1.pdf","comment":"10 pages, 10 figures, 2 tables"},{"id":"http://arxiv.org/abs/2311.07841v2","updated":"2023-11-19T19:47:36Z","published":"2023-11-14T01:40:21Z","title":"PEMS: Pre-trained Epidemic Time-series Models","summary":"  Providing accurate and reliable predictions about the future of an epidemic\nis an important problem for enabling informed public health decisions. Recent\nworks have shown that leveraging data-driven solutions that utilize advances in\ndeep learning methods to learn from past data of an epidemic often outperform\ntraditional mechanistic models. However, in many cases, the past data is sparse\nand may not sufficiently capture the underlying dynamics. While there exists a\nlarge amount of data from past epidemics, leveraging prior knowledge from\ntime-series data of other diseases is a non-trivial challenge. Motivated by the\nsuccess of pre-trained models in language and vision tasks, we tackle the\nproblem of pre-training epidemic time-series models to learn from multiple\ndatasets from different diseases and epidemics. We introduce Pre-trained\nEpidemic Time-Series Models (PEMS) that learn from diverse time-series datasets\nof a variety of diseases by formulating pre-training as a set of\nself-supervised learning (SSL) tasks. We tackle various important challenges\nspecific to pre-training for epidemic time-series such as dealing with\nheterogeneous dynamics and efficiently capturing useful patterns from multiple\nepidemic datasets by carefully designing the SSL tasks to learn important\npriors about the epidemic dynamics that can be leveraged for fine-tuning to\nmultiple downstream tasks. The resultant PEM outperforms previous\nstate-of-the-art methods in various downstream time-series tasks across\ndatasets of varying seasonal patterns, geography, and mechanism of contagion\nincluding the novel Covid-19 pandemic unseen in pre-trained data with better\nefficiency using smaller fraction of datasets.\n","authors":["Harshavardhan Kamarthi","B. Aditya Prakash"],"pdf_url":"https://arxiv.org/pdf/2311.07841v2.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2311.11396v1","updated":"2023-11-19T18:40:49Z","published":"2023-11-19T18:40:49Z","title":"Towards interpretable-by-design deep learning algorithms","summary":"  The proposed framework named IDEAL (Interpretable-by-design DEep learning\nALgorithms) recasts the standard supervised classification problem into a\nfunction of similarity to a set of prototypes derived from the training data,\nwhile taking advantage of existing latent spaces of large neural networks\nforming so-called Foundation Models (FM). This addresses the issue of\nexplainability (stage B) while retaining the benefits from the tremendous\nachievements offered by DL models (e.g., visual transformers, ViT) pre-trained\non huge data sets such as IG-3.6B + ImageNet-1K or LVD-142M (stage A). We show\nthat one can turn such DL models into conceptually simpler,\nexplainable-through-prototypes ones.\n  The key findings can be summarized as follows: (1) the proposed models are\ninterpretable through prototypes, mitigating the issue of confounded\ninterpretations, (2) the proposed IDEAL framework circumvents the issue of\ncatastrophic forgetting allowing efficient class-incremental learning, and (3)\nthe proposed IDEAL approach demonstrates that ViT architectures narrow the gap\nbetween finetuned and non-finetuned models allowing for transfer learning in a\nfraction of time \\textbf{without} finetuning of the feature space on a target\ndataset with iterative supervised methods.\n","authors":["Plamen Angelov","Dmitry Kangin","Ziyang Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.11396v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.16597v2","updated":"2023-11-19T18:30:35Z","published":"2023-10-25T12:38:36Z","title":"Beyond IID weights: sparse and low-rank deep Neural Networks are also\n  Gaussian Processes","summary":"  The infinitely wide neural network has been proven a useful and manageable\nmathematical model that enables the understanding of many phenomena appearing\nin deep learning. One example is the convergence of random deep networks to\nGaussian processes that allows a rigorous analysis of the way the choice of\nactivation function and network weights impacts the training dynamics. In this\npaper, we extend the seminal proof of Matthews et al. (2018) to a larger class\nof initial weight distributions (which we call PSEUDO-IID), including the\nestablished cases of IID and orthogonal weights, as well as the emerging\nlow-rank and structured sparse settings celebrated for their computational\nspeed-up benefits. We show that fully-connected and convolutional networks\ninitialized with PSEUDO-IID distributions are all effectively equivalent up to\ntheir variance. Using our results, one can identify the Edge-of-Chaos for a\nbroader class of neural networks and tune them at criticality in order to\nenhance their training.\n","authors":["Thiziri Nait-Saada","Alireza Naderi","Jared Tanner"],"pdf_url":"https://arxiv.org/pdf/2310.16597v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11390v1","updated":"2023-11-19T18:21:45Z","published":"2023-11-19T18:21:45Z","title":"Addressing the speed-accuracy simulation trade-off for adaptive spiking\n  neurons","summary":"  The adaptive leaky integrate-and-fire (ALIF) model is fundamental within\ncomputational neuroscience and has been instrumental in studying our brains\n$\\textit{in silico}$. Due to the sequential nature of simulating these neural\nmodels, a commonly faced issue is the speed-accuracy trade-off: either\naccurately simulate a neuron using a small discretisation time-step (DT), which\nis slow, or more quickly simulate a neuron using a larger DT and incur a loss\nin simulation accuracy. Here we provide a solution to this dilemma, by\nalgorithmically reinterpreting the ALIF model, reducing the sequential\nsimulation complexity and permitting a more efficient parallelisation on GPUs.\nWe computationally validate our implementation to obtain over a $50\\times$\ntraining speedup using small DTs on synthetic benchmarks. We also obtained a\ncomparable performance to the standard ALIF implementation on different\nsupervised classification tasks - yet in a fraction of the training time.\nLastly, we showcase how our model makes it possible to quickly and accurately\nfit real electrophysiological recordings of cortical neurons, where very fine\nsub-millisecond DTs are crucial for capturing exact spike timing.\n","authors":["Luke Taylor","Andrew J King","Nicol S Harper"],"pdf_url":"https://arxiv.org/pdf/2311.11390v1.pdf","comment":"15 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.11385v1","updated":"2023-11-19T18:09:25Z","published":"2023-11-19T18:09:25Z","title":"Multi-Task Reinforcement Learning with Mixture of Orthogonal Experts","summary":"  Multi-Task Reinforcement Learning (MTRL) tackles the long-standing problem of\nendowing agents with skills that generalize across a variety of problems. To\nthis end, sharing representations plays a fundamental role in capturing both\nunique and common characteristics of the tasks. Tasks may exhibit similarities\nin terms of skills, objects, or physical properties while leveraging their\nrepresentations eases the achievement of a universal policy. Nevertheless, the\npursuit of learning a shared set of diverse representations is still an open\nchallenge. In this paper, we introduce a novel approach for representation\nlearning in MTRL that encapsulates common structures among the tasks using\northogonal representations to promote diversity. Our method, named Mixture Of\nOrthogonal Experts (MOORE), leverages a Gram-Schmidt process to shape a shared\nsubspace of representations generated by a mixture of experts. When\ntask-specific information is provided, MOORE generates relevant representations\nfrom this shared subspace. We assess the effectiveness of our approach on two\nMTRL benchmarks, namely MiniGrid and MetaWorld, showing that MOORE surpasses\nrelated baselines and establishes a new state-of-the-art result on MetaWorld.\n","authors":["Ahmed Hendawy","Jan Peters","Carlo D'Eramo"],"pdf_url":"https://arxiv.org/pdf/2311.11385v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2208.13405v3","updated":"2023-11-19T17:14:45Z","published":"2022-08-29T07:36:17Z","title":"Interpreting Black-box Machine Learning Models for High Dimensional\n  Datasets","summary":"  Deep neural networks (DNNs) have been shown to outperform traditional machine\nlearning algorithms in a broad variety of application domains due to their\neffectiveness in modeling complex problems and handling high-dimensional\ndatasets. Many real-life datasets, however, are of increasingly high\ndimensionality, where a large number of features may be irrelevant for both\nsupervised and unsupervised learning tasks. The inclusion of such features\nwould not only introduce unwanted noise but also increase computational\ncomplexity. Furthermore, due to high non-linearity and dependency among a large\nnumber of features, DNN models tend to be unavoidably opaque and perceived as\nblack-box methods because of their not well-understood internal functioning.\nTheir algorithmic complexity is often simply beyond the capacities of humans to\nunderstand the interplay among myriads of hyperparameters. A well-interpretable\nmodel can identify statistically significant features and explain the way they\naffect the model's outcome. In this paper, we propose an efficient method to\nimprove the interpretability of black-box models for classification tasks in\nthe case of high-dimensional datasets. First, we train a black-box model on a\nhigh-dimensional dataset to learn the embeddings on which the classification is\nperformed. To decompose the inner working principles of the black-box model and\nto identify top-k important features, we employ different probing and\nperturbing techniques. We then approximate the behavior of the black-box model\nby means of an interpretable surrogate model on the top-k feature space.\nFinally, we derive decision rules and local explanations from the surrogate\nmodel to explain individual decisions. Our approach outperforms\nstate-of-the-art methods like TabNet and XGboost when tested on different\ndatasets with varying dimensionality between 50 and 20,000 w.r.t metrics and\nexplainability.\n","authors":["Md. Rezaul Karim","Md. Shajalal","Alex Graß","Till Döhmen","Sisay Adugna Chala","Christian Beecks","Stefan Decker"],"pdf_url":"https://arxiv.org/pdf/2208.13405v3.pdf","comment":"This paper is currently under review in a journal"},{"id":"http://arxiv.org/abs/2307.07975v2","updated":"2023-11-19T17:13:49Z","published":"2023-07-16T07:55:35Z","title":"Finite element inspired networks: Learning interpretable deformable\n  object dynamics from partial observations","summary":"  Accurate simulation of deformable linear object (DLO) dynamics is challenging\nif the task at hand requires a human-interpretable model that also yields fast\npredictions. To arrive at such a model, we draw inspiration from the rigid\nfinite element method (R-FEM) and model a DLO as a serial chain of rigid bodies\nwhose internal state is unrolled through time by a dynamics network. As this\nstate is not observed directly, the dynamics network is trained jointly with a\nphysics-informed encoder which maps observed motion variables to the DLO's\nhidden state. To encourage that the state acquires a physically meaningful\nrepresentation, we leverage the forward kinematics of the underlying R-FEM\nmodel as a decoder. Through robot experiments we demonstrate that the proposed\narchitecture provides an easy-to-handle, yet capable DLO dynamics model\nyielding physically interpretable predictions from partial observations.\n  The project code is available at: \\url{https://tinyurl.com/fei-networks}\n","authors":["Shamil Mamedov","A. René Geist","Jan Swevers","Sebastian Trimpe"],"pdf_url":"https://arxiv.org/pdf/2307.07975v2.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2303.07393v3","updated":"2023-11-19T17:07:39Z","published":"2023-03-13T18:15:52Z","title":"Many learning agents interacting with an agent-based market model","summary":"  We consider the dynamics and the interactions of multiple reinforcement\nlearning optimal execution trading agents interacting with a reactive\nAgent-Based Model (ABM) of a financial market in event time. The model\nrepresents a market ecology with 3-trophic levels represented by: optimal\nexecution learning agents, minimally intelligent liquidity takers, and fast\nelectronic liquidity providers. The optimal execution agent classes include\nbuying and selling agents that can either use a combination of limit orders and\nmarket orders, or only trade using market orders. The reward function\nexplicitly balances trade execution slippage against the penalty of not\nexecuting the order timeously. This work demonstrates how multiple competing\nlearning agents impact a minimally intelligent market simulation as functions\nof the number of agents, the size of agents' initial orders, and the state\nspaces used for learning. We use phase space plots to examine the dynamics of\nthe ABM, when various specifications of learning agents are included. Further,\nwe examine whether the inclusion of optimal execution agents that can learn is\nable to produce dynamics with the same complexity as empirical data. We find\nthat the inclusion of optimal execution agents changes the stylised facts\nproduced by ABM to conform more with empirical data, and are a necessary\ninclusion for ABMs investigating market micro-structure. However, including\nexecution agents to chartist-fundamentalist-noise ABMs is insufficient to\nrecover the complexity observed in empirical data.\n","authors":["Matthew Dicks","Andrew Paskaramoorthy","Tim Gebbie"],"pdf_url":"https://arxiv.org/pdf/2303.07393v3.pdf","comment":"15 pages, 9 figures"},{"id":"http://arxiv.org/abs/2311.11369v1","updated":"2023-11-19T16:35:01Z","published":"2023-11-19T16:35:01Z","title":"Optimal Locally Private Nonparametric Classification with Public Data","summary":"  In this work, we investigate the problem of public data-assisted\nnon-interactive LDP (Local Differential Privacy) learning with a focus on\nnon-parametric classification. Under the posterior drift assumption, we for the\nfirst time derive the mini-max optimal convergence rate with LDP constraint.\nThen, we present a novel approach, the locally private classification tree,\nwhich attains the mini-max optimal convergence rate. Furthermore, we design a\ndata-driven pruning procedure that avoids parameter tuning and produces a fast\nconverging estimator. Comprehensive experiments conducted on synthetic and real\ndatasets show the superior performance of our proposed method. Both our\ntheoretical and experimental findings demonstrate the effectiveness of public\ndata compared to private data, which leads to practical suggestions for\nprioritizing non-private data collection.\n","authors":["Yuheng Ma","Hanfang Yang"],"pdf_url":"https://arxiv.org/pdf/2311.11369v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11368v1","updated":"2023-11-19T16:34:56Z","published":"2023-11-19T16:34:56Z","title":"Self-Supervised Pretraining for Heterogeneous Hypergraph Neural Networks","summary":"  Recently, pretraining methods for the Graph Neural Networks (GNNs) have been\nsuccessful at learning effective representations from unlabeled graph data.\nHowever, most of these methods rely on pairwise relations in the graph and do\nnot capture the underling higher-order relations between entities. Hypergraphs\nare versatile and expressive structures that can effectively model higher-order\nrelationships among entities in the data. Despite the efforts to adapt GNNs to\nhypergraphs (HyperGNN), there are currently no fully self-supervised\npretraining methods for HyperGNN on heterogeneous hypergraphs. In this paper,\nwe present SPHH, a novel self-supervised pretraining framework for\nheterogeneous HyperGNNs. Our method is able to effectively capture higher-order\nrelations among entities in the data in a self-supervised manner. SPHH is\nconsist of two self-supervised pretraining tasks that aim to simultaneously\nlearn both local and global representations of the entities in the hypergraph\nby using informative representations derived from the hypergraph structure.\nOverall, our work presents a significant advancement in the field of\nself-supervised pretraining of HyperGNNs, and has the potential to improve the\nperformance of various graph-based downstream tasks such as node classification\nand link prediction tasks which are mapped to hypergraph configuration. Our\nexperiments on two real-world benchmarks using four different HyperGNN models\nshow that our proposed SPHH framework consistently outperforms state-of-the-art\nbaselines in various downstream tasks. The results demonstrate that SPHH is\nable to improve the performance of various HyperGNN models in various\ndownstream tasks, regardless of their architecture or complexity, which\nhighlights the robustness of our framework.\n","authors":["Abdalgader Abubaker","Takanori Maehara","Madhav Nimishakavi","Vassilis Plachouras"],"pdf_url":"https://arxiv.org/pdf/2311.11368v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11367v1","updated":"2023-11-19T16:33:42Z","published":"2023-11-19T16:33:42Z","title":"Evidential Uncertainty Quantification: A Variance-Based Perspective","summary":"  Uncertainty quantification of deep neural networks has become an active field\nof research and plays a crucial role in various downstream tasks such as active\nlearning. Recent advances in evidential deep learning shed light on the direct\nquantification of aleatoric and epistemic uncertainties with a single forward\npass of the model. Most traditional approaches adopt an entropy-based method to\nderive evidential uncertainty in classification, quantifying uncertainty at the\nsample level. However, the variance-based method that has been widely applied\nin regression problems is seldom used in the classification setting. In this\nwork, we adapt the variance-based approach from regression to classification,\nquantifying classification uncertainty at the class level. The variance\ndecomposition technique in regression is extended to class covariance\ndecomposition in classification based on the law of total covariance, and the\nclass correlation is also derived from the covariance. Experiments on\ncross-domain datasets are conducted to illustrate that the variance-based\napproach not only results in similar accuracy as the entropy-based one in\nactive domain adaptation but also brings information about class-wise\nuncertainties as well as between-class correlations. The code is available at\nhttps://github.com/KerryDRX/EvidentialADA. This alternative means of evidential\nuncertainty quantification will give researchers more options when class\nuncertainties and correlations are important in their applications.\n","authors":["Ruxiao Duan","Brian Caffo","Harrison X. Bai","Haris I. Sair","Craig Jones"],"pdf_url":"https://arxiv.org/pdf/2311.11367v1.pdf","comment":"IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)\n  2024"},{"id":"http://arxiv.org/abs/2311.11362v1","updated":"2023-11-19T16:15:53Z","published":"2023-11-19T16:15:53Z","title":"Symmetry-invariant quantum machine learning force fields","summary":"  Machine learning techniques are essential tools to compute efficient, yet\naccurate, force fields for atomistic simulations. This approach has recently\nbeen extended to incorporate quantum computational methods, making use of\nvariational quantum learning models to predict potential energy surfaces and\natomic forces from ab initio training data. However, the trainability and\nscalability of such models are still limited, due to both theoretical and\npractical barriers. Inspired by recent developments in geometric classical and\nquantum machine learning, here we design quantum neural networks that\nexplicitly incorporate, as a data-inspired prior, an extensive set of\nphysically relevant symmetries. We find that our invariant quantum learning\nmodels outperform their more generic counterparts on individual molecules of\ngrowing complexity. Furthermore, we study a water dimer as a minimal example of\na system with multiple components, showcasing the versatility of our proposed\napproach and opening the way towards larger simulations. Our results suggest\nthat molecular force fields generation can significantly profit from leveraging\nthe framework of geometric quantum machine learning, and that chemical systems\nrepresent, in fact, an interesting and rich playground for the development and\napplication of advanced quantum machine learning tools.\n","authors":["Isabel Nha Minh Le","Oriel Kiss","Julian Schuhmacher","Ivano Tavernelli","Francesco Tacchino"],"pdf_url":"https://arxiv.org/pdf/2311.11362v1.pdf","comment":"12 pages, 8 figures"}],"Multimedia":[{"id":"http://arxiv.org/abs/2306.16359v3","updated":"2023-11-19T20:21:48Z","published":"2023-06-28T16:41:42Z","title":"Mulsemedia Communication Research Challenges for Metaverse in 6G\n  Wireless Systems","summary":"  Although humans have five basic senses, sight, hearing, touch, smell, and\ntaste, most multimedia systems in current systems only capture two of them,\nnamely, sight and hearing. With the development of the metaverse and related\ntechnologies, there is a growing need for a more immersive media format that\nleverages all human senses. Multisensory media(Mulsemedia) that can stimulate\nmultiple senses will play a critical role in the near future. This paper\nprovides an overview of the history, background, use cases, existing research,\ndevices, and standards of mulsemedia. Emerging mulsemedia technologies such as\nExtended Reality (XR) and Holographic-Type Communication (HTC) are introduced.\nAdditionally, the challenges in mulsemedia research from the perspective of\nwireless communication and networking are discussed. The potential of 6G\nwireless systems to address these challenges is highlighted, and several\nresearch directions that can advance mulsemedia communications are identified.\n","authors":["Ian F. Akyildiz","Hongzhi Guo","Rui Dai","Wolfgang Gerstacker"],"pdf_url":"https://arxiv.org/pdf/2306.16359v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.12457v2","updated":"2023-11-19T13:05:09Z","published":"2023-05-21T13:27:02Z","title":"Unsupervised Multi-view Pedestrian Detection","summary":"  With the prosperity of the video surveillance, multiple cameras have been\napplied to accurately locate pedestrians in a specific area. However, previous\nmethods rely on the human-labeled annotations in every video frame and camera\nview, leading to heavier burden than necessary camera calibration and\nsynchronization. Therefore, we propose in this paper an Unsupervised Multi-view\nPedestrian Detection approach (UMPD) to eliminate the need of annotations to\nlearn a multi-view pedestrian detector via 2D-3D mapping. 1) Firstly,\nSemantic-aware Iterative Segmentation (SIS) is proposed to extract unsupervised\nrepresentations of multi-view images, which are converted into 2D pedestrian\nmasks as pseudo labels, via our proposed iterative PCA and zero-shot semantic\nclasses from vision-language models. 2) Secondly, we propose Geometry-aware\nVolume-based Detector (GVD) to end-to-end encode multi-view 2D images into a 3D\nvolume to predict voxel-wise density and color via 2D-to-3D geometric\nprojection, trained by 3D-to-2D rendering losses with SIS pseudo labels. 3)\nThirdly, for better detection results, i.e., the 3D density projected on\nBirds-Eye-View from GVD, we propose Vertical-aware BEV Regularization (VBR) to\nconstraint them to be vertical like the natural pedestrian poses. Extensive\nexperiments on popular multi-view pedestrian detection benchmarks Wildtrack,\nTerrace, and MultiviewX, show that our proposed UMPD approach, as the first\nfully-unsupervised method to our best knowledge, performs competitively to the\nprevious state-of-the-art supervised techniques. Code will be available.\n","authors":["Mengyin Liu","Chao Zhu","Shiqi Ren","Xu-Cheng Yin"],"pdf_url":"https://arxiv.org/pdf/2305.12457v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11284v1","updated":"2023-11-19T09:59:09Z","published":"2023-11-19T09:59:09Z","title":"LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval\n  Score Matching","summary":"  The recent advancements in text-to-3D generation mark a significant milestone\nin generative models, unlocking new possibilities for creating imaginative 3D\nassets across various real-world scenarios. While recent advancements in\ntext-to-3D generation have shown promise, they often fall short in rendering\ndetailed and high-quality 3D models. This problem is especially prevalent as\nmany methods base themselves on Score Distillation Sampling (SDS). This paper\nidentifies a notable deficiency in SDS, that it brings inconsistent and\nlow-quality updating direction for the 3D model, causing the over-smoothing\neffect. To address this, we propose a novel approach called Interval Score\nMatching (ISM). ISM employs deterministic diffusing trajectories and utilizes\ninterval-based score matching to counteract over-smoothing. Furthermore, we\nincorporate 3D Gaussian Splatting into our text-to-3D generation pipeline.\nExtensive experiments show that our model largely outperforms the\nstate-of-the-art in quality and training efficiency.\n","authors":["Yixun Liang","Xin Yang","Jiantao Lin","Haodong Li","Xiaogang Xu","Yingcong Chen"],"pdf_url":"https://arxiv.org/pdf/2311.11284v1.pdf","comment":"The first two authors contributed equally to this work. Our code will\n  be available at: https://github.com/EnVision-Research/LucidDreamer"},{"id":"http://arxiv.org/abs/2311.11269v1","updated":"2023-11-19T08:47:20Z","published":"2023-11-19T08:47:20Z","title":"OperARtistry: An AR-based Interactive Application to Assist the Learning\n  of Chinese Traditional Opera (Xiqu) Makeup","summary":"  Chinese Traditional Opera (Xiqu) is an important type of intangible cultural\nheritage and one key characteristic of Xiqu is its visual effects on face\nachieved via makeup. However, Xiqu makeup process, especially the eye-area\nmakeup process, is complex and time-consuming, which poses a learning challenge\nfor potential younger inheritors. We introduce OperARtistry, an interactive\napplication based on Augmented Reality (AR) that offers in-situ Xiqu makeup\nguidance for beginners. Our application provides a step-by-step guide for Xiqu\neye-area makeup, incorporating AR effects at each stage. Furthermore, we\nconducted an initial user study (n=6) to compare our approach with existing\nvideo-based tutorials to assess the effectiveness and usefulness of our\napproach. Our findings show that OperARtisty helped participants achieve\nhigh-quality eye-area makeup effects with less learning time.\n","authors":["Zeyu Xiong","Shihan Fu","Mingming Fan"],"pdf_url":"https://arxiv.org/pdf/2311.11269v1.pdf","comment":"11 pages, 9 figures, In Proceedings of The Eleventh International\n  Symposium of Chinese CHI (Chinese CHI 2023)"},{"id":"http://arxiv.org/abs/2311.11268v1","updated":"2023-11-19T08:41:43Z","published":"2023-11-19T08:41:43Z","title":"Towards Real-World Writing Assistance: A Chinese Character Checking\n  Benchmark with Faked and Misspelled Characters","summary":"  Writing assistance is an application closely related to human life and is\nalso a fundamental Natural Language Processing (NLP) research field. Its aim is\nto improve the correctness and quality of input texts, with character checking\nbeing crucial in detecting and correcting wrong characters. From the\nperspective of the real world where handwriting occupies the vast majority,\ncharacters that humans get wrong include faked characters (i.e., untrue\ncharacters created due to writing errors) and misspelled characters (i.e., true\ncharacters used incorrectly due to spelling errors). However, existing datasets\nand related studies only focus on misspelled characters mainly caused by\nphonological or visual confusion, thereby ignoring faked characters which are\nmore common and difficult. To break through this dilemma, we present\nVisual-C$^3$, a human-annotated Visual Chinese Character Checking dataset with\nfaked and misspelled Chinese characters. To the best of our knowledge,\nVisual-C$^3$ is the first real-world visual and the largest human-crafted\ndataset for the Chinese character checking scenario. Additionally, we also\npropose and evaluate novel baseline methods on Visual-C$^3$. Extensive\nempirical results and analyses show that Visual-C$^3$ is high-quality yet\nchallenging. The Visual-C$^3$ dataset and the baseline methods will be publicly\navailable to facilitate further research in the community.\n","authors":["Yinghui Li","Zishan Xu","Shaoshen Chen","Haojing Huang","Yangning Li","Yong Jiang","Zhongli Li","Qingyu Zhou","Hai-Tao Zheng","Ying Shen"],"pdf_url":"https://arxiv.org/pdf/2311.11268v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2311.11255v1","updated":"2023-11-19T06:50:52Z","published":"2023-11-19T06:50:52Z","title":"M$^{2}$UGen: Multi-modal Music Understanding and Generation with the\n  Power of Large Language Models","summary":"  The current landscape of research leveraging large language models (LLMs) is\nexperiencing a surge. Many works harness the powerful reasoning capabilities of\nthese models to comprehend various modalities, such as text, speech, images,\nvideos, etc. They also utilize LLMs to understand human intention and generate\ndesired outputs like images, videos, and music. However, research that combines\nboth understanding and generation using LLMs is still limited and in its\nnascent stage. To address this gap, we introduce a Multi-modal Music\nUnderstanding and Generation (M$^{2}$UGen) framework that integrates LLM's\nabilities to comprehend and generate music for different modalities. The\nM$^{2}$UGen framework is purpose-built to unlock creative potential from\ndiverse sources of inspiration, encompassing music, image, and video through\nthe use of pretrained MERT, ViT, and ViViT models, respectively. To enable\nmusic generation, we explore the use of AudioLDM 2 and MusicGen. Bridging\nmulti-modal understanding and music generation is accomplished through the\nintegration of the LLaMA 2 model. Furthermore, we make use of the MU-LLaMA\nmodel to generate extensive datasets that support text/image/video-to-music\ngeneration, facilitating the training of our M$^{2}$UGen framework. We conduct\na thorough evaluation of our proposed framework. The experimental results\ndemonstrate that our model achieves or surpasses the performance of the current\nstate-of-the-art models.\n","authors":["Atin Sakkeer Hussain","Shansong Liu","Chenshuo Sun","Ying Shan"],"pdf_url":"https://arxiv.org/pdf/2311.11255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04216v2","updated":"2023-11-19T05:09:42Z","published":"2023-06-07T07:43:11Z","title":"MMSum: A Dataset for Multimodal Summarization and Thumbnail Generation\n  of Videos","summary":"  Multimodal summarization with multimodal output (MSMO) has emerged as a\npromising research direction. Nonetheless, numerous limitations exist within\nexisting public MSMO datasets, including insufficient maintenance, data\ninaccessibility, limited size, and the absence of proper categorization, which\npose significant challenges. To address these challenges and provide a\ncomprehensive dataset for this new direction, we have meticulously curated the\n\\textbf{MMSum} dataset. Our new dataset features (1) Human-validated summaries\nfor both video and textual content, providing superior human instruction and\nlabels for multimodal learning. (2) Comprehensively and meticulously arranged\ncategorization, spanning 17 principal categories and 170 subcategories to\nencapsulate a diverse array of real-world scenarios. (3) Benchmark tests\nperformed on the proposed dataset to assess various tasks and methods,\nincluding \\textit{video summarization}, \\textit{text summarization}, and\n\\textit{multimodal summarization}. To champion accessibility and collaboration,\nwe will release the \\textbf{MMSum} dataset and the data collection tool as\nfully open-source resources, fostering transparency and accelerating future\ndevelopments. Our project website can be found\nat~\\url{https://mmsum-dataset.github.io/}\n","authors":["Jielin Qiu","Jiacheng Zhu","William Han","Aditesh Kumar","Karthik Mittal","Claire Jin","Zhengyuan Yang","Linjie Li","Jianfeng Wang","Ding Zhao","Bo Li","Lijuan Wang"],"pdf_url":"https://arxiv.org/pdf/2306.04216v2.pdf","comment":"Project website: https://mmsum-dataset.github.io/"}]},"2023-11-18T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2311.04666v2","updated":"2023-11-18T22:14:48Z","published":"2023-11-08T13:13:23Z","title":"Pre-training LLMs using human-like development data corpus","summary":"  Pre-trained Large Language Models (LLMs) have shown success in a diverse set\nof language inference and understanding tasks. The pre-training stage of LLMs\nlooks at a large corpus of raw textual data. The BabyLM shared task compares\nLLM pre-training to human language acquisition, where the number of tokens seen\nby 13-year-old kids is magnitudes smaller than the number of tokens seen by\nLLMs. In this work, we pre-train and evaluate LLMs on their ability to learn\ncontextual word representations using roughly the same number of tokens as seen\nby children. We provide a strong set of baselines; with different\narchitectures, evaluation of changes in performance across epochs, and reported\npre-training metrics for the strict small and strict tracks of the task. We\nalso try to loosely replicate the RoBERTa baseline given by the task organizers\nto observe the training robustness to hyperparameter selection and\nreplicability. We provide the submission details to the strict and strict-small\ntracks in this report.\n","authors":["Khushi Bhardwaj","Raj Sanjay Shah","Sashank Varma"],"pdf_url":"https://arxiv.org/pdf/2311.04666v2.pdf","comment":"CoNLL and CMCL 2023"},{"id":"http://arxiv.org/abs/2302.03169v3","updated":"2023-11-18T21:33:01Z","published":"2023-02-06T23:57:56Z","title":"Data Selection for Language Models via Importance Resampling","summary":"  Selecting a suitable pretraining dataset is crucial for both general-domain\n(e.g., GPT-3) and domain-specific (e.g., Codex) language models (LMs). We\nformalize this problem as selecting a subset of a large raw unlabeled dataset\nto match a desired target distribution given unlabeled target samples. Due to\nthe scale and dimensionality of the raw text data, existing methods use simple\nheuristics or require human experts to manually curate data. Instead, we extend\nthe classic importance resampling approach used in low-dimensions for LM data\nselection. We propose Data Selection with Importance Resampling (DSIR), an\nefficient and scalable framework that estimates importance weights in a reduced\nfeature space for tractability and selects data with importance resampling\naccording to these weights. We instantiate the DSIR framework with hashed\nn-gram features for efficiency, enabling the selection of 100M documents from\nthe full Pile dataset in 4.5 hours. To measure whether hashed n-gram features\npreserve the aspects of the data that are relevant to the target, we define KL\nreduction, a data metric that measures the proximity between the selected\npretraining data and the target on some feature space. Across 8 data selection\nmethods (including expert selection), KL reduction on hashed n-gram features\nhighly correlates with average downstream accuracy (r=0.82). When selecting\ndata for continued pretraining on a specific domain, DSIR performs comparably\nto expert curation across 8 target distributions. When pretraining\ngeneral-domain models (target is Wikipedia and books), DSIR improves over\nrandom selection and heuristic filtering baselines by 2-2.5% on the GLUE\nbenchmark. Code is available at https://github.com/p-lambda/dsir.\n","authors":["Sang Michael Xie","Shibani Santurkar","Tengyu Ma","Percy Liang"],"pdf_url":"https://arxiv.org/pdf/2302.03169v3.pdf","comment":"NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.11161v1","updated":"2023-11-18T20:32:59Z","published":"2023-11-18T20:32:59Z","title":"Experts-in-the-Loop: Establishing an Effective Workflow in Crafting\n  Privacy Q&A","summary":"  Privacy policies play a vital role in safeguarding user privacy as legal\njurisdictions worldwide emphasize the need for transparent data processing.\nWhile the suitability of privacy policies to enhance transparency has been\ncritically discussed, employing conversational AI systems presents unique\nchallenges in informing users effectively. In this position paper, we propose a\ndynamic workflow for transforming privacy policies into privacy\nquestion-and-answer (Q&A) pairs to make privacy policies easily accessible\nthrough conversational AI. Thereby, we facilitate interdisciplinary\ncollaboration among legal experts and conversation designers, while also\nconsidering the utilization of large language models' generative capabilities\nand addressing associated challenges. Our proposed workflow underscores\ncontinuous improvement and monitoring throughout the construction of privacy\nQ&As, advocating for comprehensive review and refinement through an\nexperts-in-the-loop approach.\n","authors":["Zahra Kolagar","Anna Katharina Leschanowsky","Birgit Popp"],"pdf_url":"https://arxiv.org/pdf/2311.11161v1.pdf","comment":"Position paper presented at CONVERSATIONS 2023 - the 7th\n  International Workshop on Chatbot Research and Design, hosted by the\n  University of Oslo, Norway, November 22-23, 2023"},{"id":"http://arxiv.org/abs/2311.11159v1","updated":"2023-11-18T20:22:44Z","published":"2023-11-18T20:22:44Z","title":"Evaluating the Inclusiveness of Artificial Intelligence Software in\n  Enhancing Project Management Efficiency -- A Review","summary":"  The rise of advanced technology in project management (PM) highlights a\ncrucial need for inclusiveness. This work examines the enhancement of both\ninclusivity and efficiency in PM through technological integration, focusing on\ndefining and measuring inclusiveness. This approach illuminates how\ninclusivity-centered technology can significantly elevate project outcomes. The\nresearch navigates through the challenges of achieving inclusivity, mainly\nbiases in learning databases and the design process of these technologies,\nassessment of transformative potential of these technologies, particularly in\nautomating tasks like data collection and analysis, thus enabling managers to\nprioritize human-centric aspects of projects. However, the integration of such\ntechnology transcends efficiency, indicating a paradigm shift in understanding\ntheir societal roles. This shift necessitates a new approach in the development\nof these systems to prevent perpetuating social inequalities. We proposed a\nmethodology involving criteria development for evaluating the inclusiveness and\neffectiveness of these technologies. This methodical approach is vital to\ncomprehensively address the challenges and limitations inherent in these\nsystems. Emphasizing the importance of inclusivity, the study advocates for a\nbalance between technological advancement and ethical considerations, calling\nfor a holistic understanding and regulation. In conclusion, the paper\nunderscores that while these technologies can significantly improve outcomes,\ntheir mindful integration, ensuring inclusivity, is paramount. This exploration\ninto the ethical and practical aspects of technology in PM contributes to a\nmore informed and balanced approach within the field.\n","authors":["Vasileios Alevizos","Ilias Georgousis","Akebu Simasiku","Sotiria Karypidou","Antonis Messinis"],"pdf_url":"https://arxiv.org/pdf/2311.11159v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07772v3","updated":"2023-11-18T19:58:27Z","published":"2023-11-13T21:42:38Z","title":"In-context Learning and Gradient Descent Revisited","summary":"  In-context learning (ICL) has shown impressive results in few-shot learning\ntasks, yet its underlying mechanism is still not fully understood. Recent works\nsuggest that ICL can be thought of as a gradient descent (GD) based\noptimization process. While promising, these results mainly focus on simplified\nsettings of ICL and provide only a preliminary evaluation of the similarities\nbetween the two methods. In this work, we revisit the comparison between ICL\nand GD-based finetuning and study what properties of ICL an equivalent process\nmust follow. We highlight a major difference in the flow of information between\nICL and standard finetuning. Namely, ICL can only rely on information from\nlower layers at every point, while finetuning depends on loss gradients from\ndeeper layers. We refer to this discrepancy as Layer Causality and show that a\nlayer causal variant of the finetuning process aligns with ICL on par with\nvanilla finetuning and is even better in most cases across relevant metrics. To\nthe best of our knowledge, this is the first work to discuss this discrepancy\nexplicitly and suggest a solution that tackles this problem with minimal\nchanges.\n","authors":["Gilad Deutch","Nadav Magar","Tomer Bar Natan","Guy Dar"],"pdf_url":"https://arxiv.org/pdf/2311.07772v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11142v1","updated":"2023-11-18T18:36:16Z","published":"2023-11-18T18:36:16Z","title":"Vashantor: A Large-scale Multilingual Benchmark Dataset for Automated\n  Translation of Bangla Regional Dialects to Bangla Language","summary":"  The Bangla linguistic variety is a fascinating mix of regional dialects that\nadds to the cultural diversity of the Bangla-speaking community. Despite\nextensive study into translating Bangla to English, English to Bangla, and\nBanglish to Bangla in the past, there has been a noticeable gap in translating\nBangla regional dialects into standard Bangla. In this study, we set out to\nfill this gap by creating a collection of 32,500 sentences, encompassing\nBangla, Banglish, and English, representing five regional Bangla dialects. Our\naim is to translate these regional dialects into standard Bangla and detect\nregions accurately. To achieve this, we proposed models known as mT5 and\nBanglaT5 for translating regional dialects into standard Bangla. Additionally,\nwe employed mBERT and Bangla-bert-base to determine the specific regions from\nwhere these dialects originated. Our experimental results showed the highest\nBLEU score of 69.06 for Mymensingh regional dialects and the lowest BLEU score\nof 36.75 for Chittagong regional dialects. We also observed the lowest average\nword error rate of 0.1548 for Mymensingh regional dialects and the highest of\n0.3385 for Chittagong regional dialects. For region detection, we achieved an\naccuracy of 85.86% for Bangla-bert-base and 84.36% for mBERT. This is the first\nlarge-scale investigation of Bangla regional dialects to Bangla machine\ntranslation. We believe our findings will not only pave the way for future work\non Bangla regional dialects to Bangla machine translation, but will also be\nuseful in solving similar language-related challenges in low-resource language\nconditions.\n","authors":["Fatema Tuj Johora Faria","Mukaffi Bin Moin","Ahmed Al Wase","Mehidi Ahmmed","Md. Rabius Sani","Tashreef Muhammad"],"pdf_url":"https://arxiv.org/pdf/2311.11142v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.14360v3","updated":"2023-11-18T18:10:34Z","published":"2023-10-22T17:03:56Z","title":"Is ChatGPT a game changer for geocoding -- a benchmark for geocoding\n  address parsing techniques","summary":"  The remarkable success of GPT models across various tasks, including toponymy\nrecognition motivates us to assess the performance of the GPT-3 model in the\ngeocoding address parsing task. To ensure that the evaluation more accurately\nmirrors performance in real-world scenarios with diverse user input qualities\nand resolve the pressing need for a 'gold standard' evaluation dataset for\ngeocoding systems, we introduce a benchmark dataset of low-quality address\ndescriptions synthesized based on human input patterns mining from actual input\nlogs of a geocoding system in production. This dataset has 21 different input\nerrors and variations; contains over 239,000 address records that are uniquely\nselected from streets across all U.S. 50 states and D.C.; and consists of three\nsubsets to be used as training, validation, and testing sets. Building on this,\nwe train and gauge the performance of the GPT-3 model in extracting address\ncomponents, contrasting its performance with transformer-based and LSTM-based\nmodels. The evaluation results indicate that Bidirectional LSTM-CRF model has\nachieved the best performance over these transformer-based models and GPT-3\nmodel. Transformer-based models demonstrate very comparable results compared to\nthe Bidirectional LSTM-CRF model. The GPT-3 model, though trailing in\nperformance, showcases potential in the address parsing task with few-shot\nexamples, exhibiting room for improvement with additional fine-tuning. We open\nsource the code and data of this presented benchmark so that researchers can\nutilize it for future model development or extend it to evaluate similar tasks,\nsuch as document geocoding.\n","authors":["Zhengcong Yin","Diya Li","Daniel W. Goldberg"],"pdf_url":"https://arxiv.org/pdf/2310.14360v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11135v1","updated":"2023-11-18T18:10:02Z","published":"2023-11-18T18:10:02Z","title":"A Principled Framework for Knowledge-enhanced Large Language Model","summary":"  Large Language Models (LLMs) are versatile, yet they often falter in tasks\nrequiring deep and reliable reasoning due to issues like hallucinations,\nlimiting their applicability in critical scenarios. This paper introduces a\nrigorously designed framework for creating LLMs that effectively anchor\nknowledge and employ a closed-loop reasoning process, enhancing their\ncapability for in-depth analysis. We dissect the framework to illustrate the\ncontribution of each component to the LLMs' performance, offering a theoretical\nassurance of improved reasoning under well-defined assumptions.\n","authors":["Saizhuo Wang","Zhihan Liu","Zhaoran Wang","Jian Guo"],"pdf_url":"https://arxiv.org/pdf/2311.11135v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2201.01140v4","updated":"2023-11-18T17:20:23Z","published":"2022-01-04T14:05:49Z","title":"Predicting Influenza A Viral Host Using PSSM and Word Embeddings","summary":"  The rapid mutation of the influenza virus threatens public health.\nReassortment among viruses with different hosts can lead to a fatal pandemic.\nHowever, it is difficult to detect the original host of the virus during or\nafter an outbreak as influenza viruses can circulate between different species.\nTherefore, early and rapid detection of the viral host would help reduce the\nfurther spread of the virus. We use various machine learning models with\nfeatures derived from the position-specific scoring matrix (PSSM) and features\nlearned from word embedding and word encoding to infer the origin host of\nviruses. The results show that the performance of the PSSM-based model reaches\nthe MCC around 95%, and the F1 around 96%. The MCC obtained using the model\nwith word embedding is around 96%, and the F1 is around 97%.\n","authors":["Yanhua Xu","Dominik Wojtczak"],"pdf_url":"https://arxiv.org/pdf/2201.01140v4.pdf","comment":"Accepted for publication at CIBCB 2021. V1: accepted version + minor\n  correction to table 1; V2: corrected a minor typo; V3: update the formula of\n  error rate; V4: replacing 'nested cv' with 'nested k-fold cv' for better\n  clarity"},{"id":"http://arxiv.org/abs/2311.11123v1","updated":"2023-11-18T17:11:12Z","published":"2023-11-18T17:11:12Z","title":"(Why) Is My Prompt Getting Worse? Rethinking Regression Testing for\n  Evolving LLM APIs","summary":"  Large Language Models (LLMs) are increasingly integrated into software\napplications. Downstream application developers often access LLMs through APIs\nprovided as a service. However, LLM APIs are often updated silently and\nscheduled to be deprecated, forcing users to continuously adapt to evolving\nmodels. This can cause performance regression and affect prompt design choices,\nas evidenced by our case study on toxicity detection. Based on our case study,\nwe emphasize the need for and re-examine the concept of regression testing for\nevolving LLM APIs. We argue that regression testing LLMs requires fundamental\nchanges to traditional testing approaches, due to different correctness\nnotions, prompting brittleness, and non-determinism in LLM APIs.\n","authors":["Wanqin Ma","Chenyang Yang","Christian Kästner"],"pdf_url":"https://arxiv.org/pdf/2311.11123v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.19727v2","updated":"2023-11-18T17:10:29Z","published":"2023-10-30T16:53:11Z","title":"Generating Medical Prescriptions with Conditional Transformer","summary":"  Access to real-world medication prescriptions is essential for medical\nresearch and healthcare quality improvement. However, access to real medication\nprescriptions is often limited due to the sensitive nature of the information\nexpressed. Additionally, manually labelling these instructions for training and\nfine-tuning Natural Language Processing (NLP) models can be tedious and\nexpensive. We introduce a novel task-specific model architecture,\nLabel-To-Text-Transformer (\\textbf{LT3}), tailored to generate synthetic\nmedication prescriptions based on provided labels, such as a vocabulary list of\nmedications and their attributes. LT3 is trained on a set of around 2K lines of\nmedication prescriptions extracted from the MIMIC-III database, allowing the\nmodel to produce valuable synthetic medication prescriptions. We evaluate LT3's\nperformance by contrasting it with a state-of-the-art Pre-trained Language\nModel (PLM), T5, analysing the quality and diversity of generated texts. We\ndeploy the generated synthetic data to train the SpacyNER model for the Named\nEntity Recognition (NER) task over the n2c2-2018 dataset. The experiments show\nthat the model trained on synthetic data can achieve a 96-98\\% F1 score at\nLabel Recognition on Drug, Frequency, Route, Strength, and Form. LT3 codes and\ndata will be shared at\n\\url{https://github.com/HECTA-UoM/Label-To-Text-Transformer}\n","authors":["Samuel Belkadi","Nicolo Micheletti","Lifeng Han","Warren Del-Pinto","Goran Nenadic"],"pdf_url":"https://arxiv.org/pdf/2310.19727v2.pdf","comment":"Accepted to: Workshop on Synthetic Data Generation with Generative AI\n  (SyntheticData4ML Workshop) at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.11116v1","updated":"2023-11-18T16:35:55Z","published":"2023-11-18T16:35:55Z","title":"Utilizing Speech Emotion Recognition and Recommender Systems for\n  Negative Emotion Handling in Therapy Chatbots","summary":"  Emotional well-being significantly influences mental health and overall\nquality of life. As therapy chatbots become increasingly prevalent, their\nability to comprehend and respond empathetically to users' emotions remains\nlimited. This paper addresses this limitation by proposing an approach to\nenhance therapy chatbots with auditory perception, enabling them to understand\nusers' feelings and provide human-like empathy. The proposed method\nincorporates speech emotion recognition (SER) techniques using Convolutional\nNeural Network (CNN) models and the ShEMO dataset to accurately detect and\nclassify negative emotions, including anger, fear, and sadness. The SER model\nachieves a validation accuracy of 88%, demonstrating its effectiveness in\nrecognizing emotional states from speech signals. Furthermore, a recommender\nsystem is developed, leveraging the SER model's output to generate personalized\nrecommendations for managing negative emotions, for which a new bilingual\ndataset was generated as well since there is no such dataset available for this\ntask. The recommender model achieves an accuracy of 98% by employing a\ncombination of global vectors for word representation (GloVe) and LSTM models.\nTo provide a more immersive and empathetic user experience, a text-to-speech\nmodel called GlowTTS is integrated, enabling the therapy chatbot to audibly\ncommunicate the generated recommendations to users in both English and Persian.\nThe proposed approach offers promising potential to enhance therapy chatbots by\nproviding them with the ability to recognize and respond to users' emotions,\nultimately improving the delivery of mental health support for both English and\nPersian-speaking users.\n","authors":["Farideh Majidi","Marzieh Bahrami"],"pdf_url":"https://arxiv.org/pdf/2311.11116v1.pdf","comment":"Accepted at the First National Conference of Artificial Intelligence\n  and Software Engineering"},{"id":"http://arxiv.org/abs/2311.11103v1","updated":"2023-11-18T15:35:36Z","published":"2023-11-18T15:35:36Z","title":"Responsible AI Considerations in Text Summarization Research: A Review\n  of Current Practices","summary":"  AI and NLP publication venues have increasingly encouraged researchers to\nreflect on possible ethical considerations, adverse impacts, and other\nresponsible AI issues their work might engender. However, for specific NLP\ntasks our understanding of how prevalent such issues are, or when and why these\nissues are likely to arise, remains limited. Focusing on text summarization --\na common NLP task largely overlooked by the responsible AI community -- we\nexamine research and reporting practices in the current literature. We conduct\na multi-round qualitative analysis of 333 summarization papers from the ACL\nAnthology published between 2020-2022. We focus on how, which, and when\nresponsible AI issues are covered, which relevant stakeholders are considered,\nand mismatches between stated and realized research goals. We also discuss\ncurrent evaluation practices and consider how authors discuss the limitations\nof both prior work and their own work. Overall, we find that relatively few\npapers engage with possible stakeholders or contexts of use, which limits their\nconsideration of potential downstream adverse impacts or other responsible AI\nissues. Based on our findings, we make recommendations on concrete practices\nand research directions.\n","authors":["Yu Lu Liu","Meng Cao","Su Lin Blodgett","Jackie Chi Kit Cheung","Alexandra Olteanu","Adam Trischler"],"pdf_url":"https://arxiv.org/pdf/2311.11103v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11097v1","updated":"2023-11-18T14:52:26Z","published":"2023-11-18T14:52:26Z","title":"Radiology Report Generation Using Transformers Conditioned with\n  Non-imaging Data","summary":"  Medical image interpretation is central to most clinical applications such as\ndisease diagnosis, treatment planning, and prognostication. In clinical\npractice, radiologists examine medical images and manually compile their\nfindings into reports, which can be a time-consuming process. Automated\napproaches to radiology report generation, therefore, can reduce radiologist\nworkload and improve efficiency in the clinical pathway. While recent\ndeep-learning approaches for automated report generation from medical images\nhave seen some success, most studies have relied on image-derived features\nalone, ignoring non-imaging patient data. Although a few studies have included\nthe word-level contexts along with the image, the use of patient demographics\nis still unexplored. This paper proposes a novel multi-modal transformer\nnetwork that integrates chest x-ray (CXR) images and associated patient\ndemographic information, to synthesise patient-specific radiology reports. The\nproposed network uses a convolutional neural network to extract visual features\nfrom CXRs and a transformer-based encoder-decoder network that combines the\nvisual features with semantic text embeddings of patient demographic\ninformation, to synthesise full-text radiology reports. Data from two public\ndatabases were used to train and evaluate the proposed approach. CXRs and\nreports were extracted from the MIMIC-CXR database and combined with\ncorresponding patients' data MIMIC-IV. Based on the evaluation metrics used\nincluding patient demographic information was found to improve the quality of\nreports generated using the proposed approach, relative to a baseline network\ntrained using CXRs alone. The proposed approach shows potential for enhancing\nradiology report generation by leveraging rich patient metadata and combining\nsemantic text embeddings derived thereof, with medical image-derived visual\nfeatures.\n","authors":["Nurbanu Aksoy","Nishant Ravikumar","Alejandro F Frangi"],"pdf_url":"https://arxiv.org/pdf/2311.11097v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11090v1","updated":"2023-11-18T14:37:53Z","published":"2023-11-18T14:37:53Z","title":"Beyond Images: An Integrative Multi-modal Approach to Chest X-Ray Report\n  Generation","summary":"  Image-to-text radiology report generation aims to automatically produce\nradiology reports that describe the findings in medical images. Most existing\nmethods focus solely on the image data, disregarding the other patient\ninformation accessible to radiologists. In this paper, we present a novel\nmulti-modal deep neural network framework for generating chest X-rays reports\nby integrating structured patient data, such as vital signs and symptoms,\nalongside unstructured clinical notes.We introduce a conditioned\ncross-multi-head attention module to fuse these heterogeneous data modalities,\nbridging the semantic gap between visual and textual data. Experiments\ndemonstrate substantial improvements from using additional modalities compared\nto relying on images alone. Notably, our model achieves the highest reported\nperformance on the ROUGE-L metric compared to relevant state-of-the-art models\nin the literature. Furthermore, we employed both human evaluation and clinical\nsemantic similarity measurement alongside word-overlap metrics to improve the\ndepth of quantitative analysis. A human evaluation, conducted by a\nboard-certified radiologist, confirms the model's accuracy in identifying\nhigh-level findings, however, it also highlights that more improvement is\nneeded to capture nuanced details and clinical context.\n","authors":["Nurbanu Aksoy","Serge Sharoff","Selcuk Baser","Nishant Ravikumar","Alejandro F Frangi"],"pdf_url":"https://arxiv.org/pdf/2311.11090v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11088v1","updated":"2023-11-18T14:35:26Z","published":"2023-11-18T14:35:26Z","title":"Combining EEG and NLP Features for Predicting Students' Lecture\n  Comprehension using Ensemble Classification","summary":"  Electroencephalography (EEG) and Natural Language Processing (NLP) can be\napplied for education to measure students' comprehension in classroom lectures;\ncurrently, the two measures have been used separately. In this work, we propose\na classification framework for predicting students' lecture comprehension in\ntwo tasks: (i) students' confusion after listening to the simulated lecture and\n(ii) the correctness of students' responses to the post-lecture assessment. The\nproposed framework includes EEG and NLP feature extraction, processing, and\nclassification. EEG and NLP features are extracted to construct integrated\nfeatures obtained from recorded EEG signals and sentence-level syntactic\nanalysis, which provide information about specific biomarkers and sentence\nstructures. An ensemble stacking classification method -- a combination of\nmultiple individual models that produces an enhanced predictive model -- is\nstudied to learn from the features to make predictions accurately. Furthermore,\nwe also utilized subjective confusion ratings as another integrated feature to\nenhance classification performance. By doing so, experiment results show that\nthis framework performs better than the baselines, which achieved F1 up to 0.65\nfor predicting confusion and 0.78 for predicting correctness, highlighting that\nutilizing this has helped improve the classification performance.\n","authors":["Phantharach Natnithikarat","Theerawit Wilaiprasitporn","Supavit Kongwudhikunakorn"],"pdf_url":"https://arxiv.org/pdf/2311.11088v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10057v2","updated":"2023-11-18T14:14:40Z","published":"2023-11-16T17:52:21Z","title":"The Song Describer Dataset: a Corpus of Audio Captions for\n  Music-and-Language Evaluation","summary":"  We introduce the Song Describer dataset (SDD), a new crowdsourced corpus of\nhigh-quality audio-caption pairs, designed for the evaluation of\nmusic-and-language models. The dataset consists of 1.1k human-written natural\nlanguage descriptions of 706 music recordings, all publicly accessible and\nreleased under Creative Common licenses. To showcase the use of our dataset, we\nbenchmark popular models on three key music-and-language tasks (music\ncaptioning, text-to-music generation and music-language retrieval). Our\nexperiments highlight the importance of cross-dataset evaluation and offer\ninsights into how researchers can use SDD to gain a broader understanding of\nmodel performance.\n","authors":["Ilaria Manco","Benno Weck","SeungHeon Doh","Minz Won","Yixiao Zhang","Dmitry Bodganov","Yusong Wu","Ke Chen","Philip Tovstogan","Emmanouil Benetos","Elio Quinton","György Fazekas","Juhan Nam"],"pdf_url":"https://arxiv.org/pdf/2311.10057v2.pdf","comment":"Accepted to NeurIPS 2023 Workshop on Machine Learning for Audio"},{"id":"http://arxiv.org/abs/2311.11077v1","updated":"2023-11-18T13:53:26Z","published":"2023-11-18T13:53:26Z","title":"Adapters: A Unified Library for Parameter-Efficient and Modular Transfer\n  Learning","summary":"  We introduce Adapters, an open-source library that unifies\nparameter-efficient and modular transfer learning in large language models. By\nintegrating 10 diverse adapter methods into a unified interface, Adapters\noffers ease of use and flexible configuration. Our library allows researchers\nand practitioners to leverage adapter modularity through composition blocks,\nenabling the design of complex adapter setups. We demonstrate the library's\nefficacy by evaluating its performance against full fine-tuning on various NLP\ntasks. Adapters provides a powerful tool for addressing the challenges of\nconventional fine-tuning paradigms and promoting more efficient and modular\ntransfer learning. The library is available via https://adapterhub.ml/adapters.\n","authors":["Clifton Poth","Hannah Sterz","Indraneil Paul","Sukannya Purkayastha","Leon Engländer","Timo Imhof","Ivan Vulić","Sebastian Ruder","Iryna Gurevych","Jonas Pfeiffer"],"pdf_url":"https://arxiv.org/pdf/2311.11077v1.pdf","comment":"EMNLP 2023: Systems Demonstrations"},{"id":"http://arxiv.org/abs/2310.16676v2","updated":"2023-11-18T11:50:52Z","published":"2023-10-25T14:41:14Z","title":"SSLCL: An Efficient Model-Agnostic Supervised Contrastive Learning\n  Framework for Emotion Recognition in Conversations","summary":"  Emotion recognition in conversations (ERC) is a rapidly evolving task within\nthe natural language processing community, which aims to detect the emotions\nexpressed by speakers during a conversation. Recently, a growing number of ERC\nmethods have focused on leveraging supervised contrastive learning (SCL) to\nenhance the robustness and generalizability of learned features. However,\ncurrent SCL-based approaches in ERC are impeded by the constraint of large\nbatch sizes and the lack of compatibility with most existing ERC models. To\naddress these challenges, we propose an efficient and model-agnostic SCL\nframework named Supervised Sample-Label Contrastive Learning with Soft-HGR\nMaximal Correlation (SSLCL), which eliminates the need for a large batch size\nand can be seamlessly integrated with existing ERC models without introducing\nany model-specific assumptions. Specifically, we introduce a novel perspective\non utilizing label representations by projecting discrete labels into dense\nembeddings through a shallow multilayer perceptron, and formulate the training\nobjective to maximize the similarity between sample features and their\ncorresponding ground-truth label embeddings, while minimizing the similarity\nbetween sample features and label embeddings of disparate classes. Moreover, we\ninnovatively adopt the Soft-HGR maximal correlation as a measure of similarity\nbetween sample features and label embeddings, leading to significant\nperformance improvements over conventional similarity measures. Additionally,\nmultimodal cues of utterances are effectively leveraged by SSLCL as data\naugmentations to boost model performances. Extensive experiments on two ERC\nbenchmark datasets, IEMOCAP and MELD, demonstrate the compatibility and\nsuperiority of our proposed SSLCL framework compared to existing\nstate-of-the-art SCL methods. Our code is available at\n\\url{https://github.com/TaoShi1998/SSLCL}.\n","authors":["Tao Shi","Xiao Liang","Yaoyuan Liang","Xinyi Tong","Shao-Lun Huang"],"pdf_url":"https://arxiv.org/pdf/2310.16676v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02080v3","updated":"2023-11-18T08:51:08Z","published":"2023-06-03T11:05:04Z","title":"Benchmarking Robustness of Adaptation Methods on Pre-trained\n  Vision-Language Models","summary":"  Various adaptation methods, such as LoRA, prompts, and adapters, have been\nproposed to enhance the performance of pre-trained vision-language models in\nspecific domains. The robustness of these adaptation methods against\ndistribution shifts have not been studied. In this study, we assess the\nrobustness of 11 widely-used adaptation methods across 4 vision-language\ndatasets under multimodal corruptions. Concretely, we introduce 7 benchmark\ndatasets, including 96 visual and 87 textual corruptions, to investigate the\nrobustness of different adaptation methods, the impact of available adaptation\nexamples, and the influence of trainable parameter size during adaptation. Our\nanalysis reveals that: 1) Adaptation methods are more sensitive to text\ncorruptions than visual corruptions. 2) Full fine-tuning does not consistently\nprovide the highest robustness; instead, adapters can achieve better robustness\nwith comparable clean performance. 3) Contrary to expectations, our findings\nindicate that increasing the number of adaptation data and parameters does not\nguarantee enhanced robustness; instead it results in even lower robustness. We\nhope this study could benefit future research in the development of robust\nmultimodal adaptation methods. The benchmark, code, and dataset used in this\nstudy can be accessed at https://adarobustness.github.io .\n","authors":["Shuo Chen","Jindong Gu","Zhen Han","Yunpu Ma","Philip Torr","Volker Tresp"],"pdf_url":"https://arxiv.org/pdf/2306.02080v3.pdf","comment":"Accepted at NeurIPS 2023 Datasets and Benchmarks Track; 9 pages, 5\n  figures"},{"id":"http://arxiv.org/abs/2311.11012v1","updated":"2023-11-18T08:47:35Z","published":"2023-11-18T08:47:35Z","title":"Bit Cipher -- A Simple yet Powerful Word Representation System that\n  Integrates Efficiently with Language Models","summary":"  While Large Language Models (LLMs) become ever more dominant, classic\npre-trained word embeddings sustain their relevance through computational\nefficiency and nuanced linguistic interpretation. Drawing from recent studies\ndemonstrating that the convergence of GloVe and word2vec optimizations all tend\ntowards log-co-occurrence matrix variants, we construct a novel word\nrepresentation system called Bit-cipher that eliminates the need of\nbackpropagation while leveraging contextual information and hyper-efficient\ndimensionality reduction techniques based on unigram frequency, providing\nstrong interpretability, alongside efficiency. We use the bit-cipher algorithm\nto train word vectors via a two-step process that critically relies on a\nhyperparameter -- bits -- that controls the vector dimension. While the first\nstep trains the bit-cipher, the second utilizes it under two different\naggregation modes -- summation or concatenation -- to produce contextually rich\nrepresentations from word co-occurrences. We extend our investigation into\nbit-cipher's efficacy, performing probing experiments on part-of-speech (POS)\ntagging and named entity recognition (NER) to assess its competitiveness with\nclassic embeddings like word2vec and GloVe. Additionally, we explore its\napplicability in LM training and fine-tuning. By replacing embedding layers\nwith cipher embeddings, our experiments illustrate the notable efficiency of\ncipher in accelerating the training process and attaining better optima\ncompared to conventional training paradigms. Experiments on the integration of\nbit-cipher embedding layers with Roberta, T5, and OPT, prior to or as a\nsubstitute for fine-tuning, showcase a promising enhancement to transfer\nlearning, allowing rapid model convergence while preserving competitive\nperformance.\n","authors":["Haoran Zhao","Jake Ryland Williams"],"pdf_url":"https://arxiv.org/pdf/2311.11012v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11009v1","updated":"2023-11-18T08:21:42Z","published":"2023-11-18T08:21:42Z","title":"Joyful: Joint Modality Fusion and Graph Contrastive Learning for\n  Multimodal Emotion Recognition","summary":"  Multimodal emotion recognition aims to recognize emotions for each utterance\nof multiple modalities, which has received increasing attention for its\napplication in human-machine interaction. Current graph-based methods fail to\nsimultaneously depict global contextual features and local diverse uni-modal\nfeatures in a dialogue. Furthermore, with the number of graph layers\nincreasing, they easily fall into over-smoothing. In this paper, we propose a\nmethod for joint modality fusion and graph contrastive learning for multimodal\nemotion recognition (Joyful), where multimodality fusion, contrastive learning,\nand emotion recognition are jointly optimized. Specifically, we first design a\nnew multimodal fusion mechanism that can provide deep interaction and fusion\nbetween the global contextual and uni-modal specific features. Then, we\nintroduce a graph contrastive learning framework with inter-view and intra-view\ncontrastive losses to learn more distinguishable representations for samples\nwith different sentiments. Extensive experiments on three benchmark datasets\nindicate that Joyful achieved state-of-the-art (SOTA) performance compared to\nall baselines.\n","authors":["Dongyuan Li","Yusong Wang","Kotaro Funakoshi","Manabu Okumura"],"pdf_url":"https://arxiv.org/pdf/2311.11009v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11001v1","updated":"2023-11-18T07:46:59Z","published":"2023-11-18T07:46:59Z","title":"Gendec: A Machine Learning-based Framework for Gender Detection from\n  Japanese Names","summary":"  Every human has their own name, a fundamental aspect of their identity and\ncultural heritage. The name often conveys a wealth of information, including\ndetails about an individual's background, ethnicity, and, especially, their\ngender. By detecting gender through the analysis of names, researchers can\nunlock valuable insights into linguistic patterns and cultural norms, which can\nbe applied to practical applications. Hence, this work presents a novel dataset\nfor Japanese name gender detection comprising 64,139 full names in romaji,\nhiragana, and kanji forms, along with their biological genders. Moreover, we\npropose Gendec, a framework for gender detection from Japanese names that\nleverages diverse approaches, including traditional machine learning techniques\nor cutting-edge transfer learning models, to predict the gender associated with\nJapanese names accurately. Through a thorough investigation, the proposed\nframework is expected to be effective and serve potential applications in\nvarious domains.\n","authors":["Duong Tien Pham","Luan Thanh Nguyen"],"pdf_url":"https://arxiv.org/pdf/2311.11001v1.pdf","comment":"This paper is accepted for presentation at ISDA'23"},{"id":"http://arxiv.org/abs/2311.10995v1","updated":"2023-11-18T07:07:38Z","published":"2023-11-18T07:07:38Z","title":"Behavior Optimized Image Generation","summary":"  The last few years have witnessed great success on image generation, which\nhas crossed the acceptance thresholds of aesthetics, making it directly\napplicable to personal and commercial applications. However, images, especially\nin marketing and advertising applications, are often created as a means to an\nend as opposed to just aesthetic concerns. The goal can be increasing sales,\ngetting more clicks, likes, or image sales (in the case of stock businesses).\nTherefore, the generated images need to perform well on these key performance\nindicators (KPIs), in addition to being aesthetically good. In this paper, we\nmake the first endeavor to answer the question of \"How can one infuse the\nknowledge of the end-goal within the image generation process itself to create\nnot just better-looking images but also \"better-performing'' images?''. We\npropose BoigLLM, an LLM that understands both image content and user behavior.\nBoigLLM knows how an image should look to get a certain required KPI. We show\nthat BoigLLM outperforms 13x larger models such as GPT-3.5 and GPT-4 in this\ntask, demonstrating that while these state-of-the-art models can understand\nimages, they lack information on how these images perform in the real world. To\ngenerate actual pixels of behavior-conditioned images, we train a\ndiffusion-based model (BoigSD) to align with a proposed BoigLLM-defined reward.\nWe show the performance of the overall pipeline on two datasets covering two\ndifferent behaviors: a stock dataset with the number of forward actions as the\nKPI and a dataset containing tweets with the total likes as the KPI, denoted as\nBoigBench. To advance research in the direction of utility-driven image\ngeneration and understanding, we release BoigBench, a benchmark dataset\ncontaining 168 million enterprise tweets with their media, brand account names,\ntime of post, and total likes.\n","authors":["Varun Khurana","Yaman K Singla","Jayakumar Subramanian","Rajiv Ratn Shah","Changyou Chen","Zhiqiang Xu","Balaji Krishnamurthy"],"pdf_url":"https://arxiv.org/pdf/2311.10995v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11489v3","updated":"2023-11-18T04:26:35Z","published":"2023-01-27T01:54:16Z","title":"Talk the Walk: Synthetic Data Generation for Conversational Music\n  Recommendation","summary":"  Recommender systems are ubiquitous yet often difficult for users to control,\nand adjust if recommendation quality is poor. This has motivated conversational\nrecommender systems (CRSs), with control provided through natural language\nfeedback. However, as with most application domains, building robust CRSs\nrequires training data that reflects system usage$\\unicode{x2014}$here\nconversations with user utterances paired with items that cover a wide range of\npreferences. This has proved challenging to collect scalably using conventional\nmethods. We address the question of whether it can be generated synthetically,\nbuilding on recent advances in natural language. We evaluate in the setting of\nitem set recommendation, noting the increasing attention to this task motivated\nby use cases like music, news, and recipe recommendation. We present\nTalkTheWalk, which synthesizes realistic high-quality conversational data by\nleveraging domain expertise encoded in widely available curated item\ncollections, generating a sequence of hypothetical yet plausible item sets,\nthen using a language model to produce corresponding user utterances. We\ngenerate over one million diverse playlist curation conversations in the music\ndomain, and show these contain consistent utterances with relevant item sets\nnearly matching the quality of an existing but small human-collected dataset\nfor this task. We demonstrate the utility of the generated synthetic dataset on\na conversational item retrieval task and show that it improves over both\nunsupervised baselines and systems trained on a real dataset.\n","authors":["Megan Leszczynski","Shu Zhang","Ravi Ganti","Krisztian Balog","Filip Radlinski","Fernando Pereira","Arun Tejasvi Chaganty"],"pdf_url":"https://arxiv.org/pdf/2301.11489v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10961v1","updated":"2023-11-18T03:55:59Z","published":"2023-11-18T03:55:59Z","title":"Journey of Hallucination-minimized Generative AI Solutions for Financial\n  Decision Makers","summary":"  Generative AI has significantly reduced the entry barrier to the domain of AI\nowing to the ease of use and core capabilities of automation, translation, and\nintelligent actions in our day to day lives. Currently, Large language models\n(LLMs) that power such chatbots are being utilized primarily for their\nautomation capabilities for software monitoring, report generation etc. and for\nspecific personalized question answering capabilities, on a limited scope and\nscale. One major limitation of the currently evolving family of LLMs is\n'hallucinations', wherein inaccurate responses are reported as factual.\nHallucinations are primarily caused by biased training data, ambiguous prompts\nand inaccurate LLM parameters, and they majorly occur while combining\nmathematical facts with language-based context. Thus, monitoring and\ncontrolling for hallucinations becomes necessary when designing solutions that\nare meant for decision makers. In this work we present the three major stages\nin the journey of designing hallucination-minimized LLM-based solutions that\nare specialized for the decision makers of the financial domain, namely:\nprototyping, scaling and LLM evolution using human feedback. These three stages\nand the novel data to answer generation modules presented in this work are\nnecessary to ensure that the Generative AI chatbots, autonomous reports and\nalerts are reliable and high-quality to aid key decision-making processes.\n","authors":["Sohini Roychowdhury"],"pdf_url":"https://arxiv.org/pdf/2311.10961v1.pdf","comment":"4 pages, 2 Figures"},{"id":"http://arxiv.org/abs/2311.10945v1","updated":"2023-11-18T02:48:41Z","published":"2023-11-18T02:48:41Z","title":"An Empirical Bayes Framework for Open-Domain Dialogue Generation","summary":"  To engage human users in meaningful conversation, open-domain dialogue agents\nare required to generate diverse and contextually coherent dialogue. Despite\nrecent advancements, which can be attributed to the usage of pretrained\nlanguage models, the generation of diverse and coherent dialogue remains an\nopen research problem. A popular approach to address this issue involves the\nadaptation of variational frameworks. However, while these approaches\nsuccessfully improve diversity, they tend to compromise on contextual\ncoherence. Hence, we propose the Bayesian Open-domain Dialogue with Empirical\nBayes (BODEB) framework, an empirical bayes framework for constructing an\nBayesian open-domain dialogue agent by leveraging pretrained parameters to\ninform the prior and posterior parameter distributions. Empirical results show\nthat BODEB achieves better results in terms of both diversity and coherence\ncompared to variational frameworks.\n","authors":["Jing Yang Lee","Kong Aik Lee","Woon-Seng Gan"],"pdf_url":"https://arxiv.org/pdf/2311.10945v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10944v1","updated":"2023-11-18T02:44:33Z","published":"2023-11-18T02:44:33Z","title":"Deception Detection from Linguistic and Physiological Data Streams Using\n  Bimodal Convolutional Neural Networks","summary":"  Deception detection is gaining increasing interest due to ethical and\nsecurity concerns. This paper explores the application of convolutional neural\nnetworks for the purpose of multimodal deception detection. We use a dataset\nbuilt by interviewing 104 subjects about two topics, with one truthful and one\nfalsified response from each subject about each topic. In particular, we make\nthree main contributions. First, we extract linguistic and physiological\nfeatures from this data to train and construct the neural network models.\nSecond, we propose a fused convolutional neural network model using both\nmodalities in order to achieve an improved overall performance. Third, we\ncompare our new approach with earlier methods designed for multimodal deception\ndetection. We find that our system outperforms regular classification methods;\nour results indicate the feasibility of using neural networks for deception\ndetection even in the presence of limited amounts of data.\n","authors":["Panfeng Li","Mohamed Abouelenien","Rada Mihalcea"],"pdf_url":"https://arxiv.org/pdf/2311.10944v1.pdf","comment":"Submitted to NAACL HLT 2018"},{"id":"http://arxiv.org/abs/2311.10943v1","updated":"2023-11-18T02:40:11Z","published":"2023-11-18T02:40:11Z","title":"Partially Randomizing Transformer Weights for Dialogue Response\n  Diversity","summary":"  Despite recent progress in generative open-domain dialogue, the issue of low\nresponse diversity persists. Prior works have addressed this issue via either\nnovel objective functions, alternative learning approaches such as variational\nframeworks, or architectural extensions such as the Randomized Link (RL)\nTransformer. However, these approaches typically entail either additional\ndifficulties during training/inference, or a significant increase in model size\nand complexity. Hence, we propose the \\underline{Pa}rtially\n\\underline{Ra}ndomized trans\\underline{Former} (PaRaFormer), a simple extension\nof the transformer which involves freezing the weights of selected layers after\nrandom initialization. Experimental results reveal that the performance of the\nPaRaformer is comparable to that of the aforementioned approaches, despite not\nentailing any additional training difficulty or increase in model complexity.\n","authors":["Jing Yang Lee","Kong Aik Lee","Woon-Seng Gan"],"pdf_url":"https://arxiv.org/pdf/2311.10943v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.18365v2","updated":"2023-11-18T02:05:27Z","published":"2023-10-25T01:07:50Z","title":"Using GPT-4 to Augment Unbalanced Data for Automatic Scoring","summary":"  Machine learning-based automatic scoring can be challenging if students'\nresponses are unbalanced across scoring categories, as it introduces\nuncertainty in the machine training process. To meet this challenge, we\nintroduce a novel text data augmentation framework using GPT-4, a generative\nlarge language model, specifically tailored for unbalanced datasets in\nautomatic scoring. Our experimental dataset comprised student-written responses\nto two science items. We crafted prompts for GPT-4 to generate responses\nresembling student-written answers, particularly for the minority scoring\nclasses, to augment the data. We then finetuned DistillBERT for automatic\nscoring based on the augmented and original datasets. Model performance was\nassessed using accuracy, precision, recall, and F1 score. We incorporate varied\namounts of augmented data to examine scoring performance, and our findings\nrevealed remarkedly improved model performance. The average maximum increase\nobserved across two items is: 3.5% for accuracy, 30.6% for precision, 21.1% for\nrecall, and 24.2% for F1 score. Notably, using just 5% of the augmented data\nled to substantial improvements: 2.6%, 29.2%, 15.1%, and 19.6%. Interestingly,\nthe extent of improvement varied depending on specific datasets. Moreover, we\nfound that a varying amount of augmented data (5%-40%) was needed to obtain a\nstable improvement. We also compare models trained with GPT-4 augmented data\nand those trained with additional student-written responses. The findings\nindicate that former ones match or even exceed the performance of the latter.\nSpecifically, there is an average difference of 1.7%, 1.9%, 11.0%, and 7.8% for\nfour metrics separately. This research underscores the potential and\neffectiveness of data augmentation techniques utilizing GPT-4 in addressing\nunbalanced datasets within automated assessment.\n","authors":["Luyang Fang","Gyeong-Geon Lee","Xiaoming Zhai"],"pdf_url":"https://arxiv.org/pdf/2310.18365v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10933v1","updated":"2023-11-18T02:00:20Z","published":"2023-11-18T02:00:20Z","title":"Representing visual classification as a linear combination of words","summary":"  Explainability is a longstanding challenge in deep learning, especially in\nhigh-stakes domains like healthcare. Common explainability methods highlight\nimage regions that drive an AI model's decision. Humans, however, heavily rely\non language to convey explanations of not only \"where\" but \"what\".\nAdditionally, most explainability approaches focus on explaining individual AI\npredictions, rather than describing the features used by an AI model in\ngeneral. The latter would be especially useful for model and dataset auditing,\nand potentially even knowledge generation as AI is increasingly being used in\nnovel tasks. Here, we present an explainability strategy that uses a\nvision-language model to identify language-based descriptors of a visual\nclassification task. By leveraging a pre-trained joint embedding space between\nimages and text, our approach estimates a new classification task as a linear\ncombination of words, resulting in a weight for each word that indicates its\nalignment with the vision-based classifier. We assess our approach using two\nmedical imaging classification tasks, where we find that the resulting\ndescriptors largely align with clinical knowledge despite a lack of\ndomain-specific language training. However, our approach also identifies the\npotential for 'shortcut connections' in the public datasets used. Towards a\nfunctional measure of explainability, we perform a pilot reader study where we\nfind that the AI-identified words can enable non-expert humans to perform a\nspecialized medical task at a non-trivial level. Altogether, our results\nemphasize the potential of using multimodal foundational models to deliver\nintuitive, language-based explanations of visual tasks.\n","authors":["Shobhit Agarwal","Yevgeniy R. Semenov","William Lotter"],"pdf_url":"https://arxiv.org/pdf/2311.10933v1.pdf","comment":"To be published in the Proceedings of the 3rd Machine Learning for\n  Health symposium, Proceedings of Machine Learning Research (PMLR)"},{"id":"http://arxiv.org/abs/2311.10928v1","updated":"2023-11-18T01:26:04Z","published":"2023-11-18T01:26:04Z","title":"CAMRA: Copilot for AMR Annotation","summary":"  In this paper, we introduce CAMRA (Copilot for AMR Annotatations), a\ncutting-edge web-based tool designed for constructing Abstract Meaning\nRepresentation (AMR) from natural language text. CAMRA offers a novel approach\nto deep lexical semantics annotation such as AMR, treating AMR annotation akin\nto coding in programming languages. Leveraging the familiarity of programming\nparadigms, CAMRA encompasses all essential features of existing AMR editors,\nincluding example lookup, while going a step further by integrating Propbank\nroleset lookup as an autocomplete feature within the tool. Notably, CAMRA\nincorporates AMR parser models as coding co-pilots, greatly enhancing the\nefficiency and accuracy of AMR annotators. To demonstrate the tool's\ncapabilities, we provide a live demo accessible at: https://camra.colorado.edu\n","authors":["Jon Z. Cai","Shafiuddin Rehan Ahmed","Julia Bonn","Kristin Wright-Bettner","Martha Palmer","James H. Martin"],"pdf_url":"https://arxiv.org/pdf/2311.10928v1.pdf","comment":"EMNLP 2023 System Demonstration"},{"id":"http://arxiv.org/abs/2308.04823v3","updated":"2023-11-18T01:01:50Z","published":"2023-08-09T09:22:56Z","title":"Evaluating the Generation Capabilities of Large Chinese Language Models","summary":"  This paper presents CG-Eval, the first comprehensive evaluation of the\ngeneration capabilities of large Chinese language models across a wide range of\nacademic disciplines. The models' performance was assessed based on their\nability to generate accurate and relevant responses to different types of\nquestions in six disciplines, namely, Science and Engineering, Humanities and\nSocial Sciences, Mathematical Calculations, Medical Practitioner Qualification\nExamination, Judicial Examination, and Certified Public Accountant Examination.\nThis paper also presents Gscore, a composite index derived from the weighted\nsum of multiple metrics to measure the quality of model's generation against a\nreference. The test data and test results can be found at\nhttp://cgeval.besteasy.com/.\n","authors":["Hui Zeng","Jingyuan Xue","Meng Hao","Chen Sun","Bin Ning","Na Zhang"],"pdf_url":"https://arxiv.org/pdf/2308.04823v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10922v1","updated":"2023-11-18T00:33:48Z","published":"2023-11-18T00:33:48Z","title":"Explainable Product Classification for Customs","summary":"  The task of assigning internationally accepted commodity codes (aka HS codes)\nto traded goods is a critical function of customs offices. Like court decisions\nmade by judges, this task follows the doctrine of precedent and can be\nnontrivial even for experienced officers. Together with the Korea Customs\nService (KCS), we propose a first-ever explainable decision supporting model\nthat suggests the most likely subheadings (i.e., the first six digits) of the\nHS code. The model also provides reasoning for its suggestion in the form of a\ndocument that is interpretable by customs officers. We evaluated the model\nusing 5,000 cases that recently received a classification request. The results\nshowed that the top-3 suggestions made by our model had an accuracy of 93.9\\%\nwhen classifying 925 challenging subheadings. A user study with 32 customs\nexperts further confirmed that our algorithmic suggestions accompanied by\nexplainable reasonings, can substantially reduce the time and effort taken by\ncustoms officers for classification reviews.\n","authors":["Eunji Lee","Sihyeon Kim","Sundong Kim","Soyeon Jung","Heeja Kim","Meeyoung Cha"],"pdf_url":"https://arxiv.org/pdf/2311.10922v1.pdf","comment":"24 pages, Accepted to ACM Transactions on Intelligent Systems and\n  Technology"},{"id":"http://arxiv.org/abs/2311.10920v1","updated":"2023-11-18T00:24:26Z","published":"2023-11-18T00:24:26Z","title":"Understanding and Mitigating Classification Errors Through Interpretable\n  Token Patterns","summary":"  State-of-the-art NLP methods achieve human-like performance on many tasks,\nbut make errors nevertheless. Characterizing these errors in easily\ninterpretable terms gives insight into whether a classifier is prone to making\nsystematic errors, but also gives a way to act and improve the classifier. We\npropose to discover those patterns of tokens that distinguish correct and\nerroneous predictions as to obtain global and interpretable descriptions for\narbitrary NLP classifiers. We formulate the problem of finding a succinct and\nnon-redundant set of such patterns in terms of the Minimum Description Length\nprinciple. Through an extensive set of experiments, we show that our method,\nPremise, performs well in practice. Unlike existing solutions, it recovers\nground truth, even on highly imbalanced data over large vocabularies. In VQA\nand NER case studies, we confirm that it gives clear and actionable insight\ninto the systematic errors made by NLP classifiers.\n","authors":["Michael A. Hedderich","Jonas Fischer","Dietrich Klakow","Jilles Vreeken"],"pdf_url":"https://arxiv.org/pdf/2311.10920v1.pdf","comment":"Extended abstract at BlackboxNLP'23"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2311.11157v1","updated":"2023-11-18T20:18:18Z","published":"2023-11-18T20:18:18Z","title":"Contextualizing Internet Memes Across Social Media Platforms","summary":"  Internet memes have emerged as a novel format for communication and\nexpressing ideas on the web. Their fluidity and creative nature are reflected\nin their widespread use, often across platforms and occasionally for unethical\nor harmful purposes. While computational work has already analyzed their\nhigh-level virality over time and developed specialized classifiers for hate\nspeech detection, there have been no efforts to date that aim to holistically\ntrack, identify, and map internet memes posted on social media. To bridge this\ngap, we investigate whether internet memes across social media platforms can be\ncontextualized by using a semantic repository of knowledge, namely, a knowledge\ngraph. We collect thousands of potential internet meme posts from two social\nmedia platforms, namely Reddit and Discord, and perform an\nextract-transform-load procedure to create a data lake with candidate meme\nposts. By using vision transformer-based similarity, we match these candidates\nagainst the memes cataloged in a recently released knowledge graph of internet\nmemes, IMKG. We provide evidence that memes published online can be identified\nby mapping them to IMKG. We leverage this grounding to study the prevalence of\nmemes on different platforms, discover popular memes, and select common meme\nchannels and subreddits. Finally, we illustrate how the grounding can enable\nusers to get context about memes on social media thanks to their link to the\nknowledge graph.\n","authors":["Saurav Joshi","Filip Ilievski","Luca Luceri"],"pdf_url":"https://arxiv.org/pdf/2311.11157v1.pdf","comment":"16 pages, 7 figures, 4 tables"},{"id":"http://arxiv.org/abs/2311.06444v2","updated":"2023-11-18T19:09:35Z","published":"2023-11-11T00:22:57Z","title":"Mitigating Pooling Bias in E-commerce Search via False Negative\n  Estimation","summary":"  Efficient and accurate product relevance assessment is critical for user\nexperiences and business success. Training a proficient relevance assessment\nmodel requires high-quality query-product pairs, often obtained through\nnegative sampling strategies. Unfortunately, current methods introduce pooling\nbias by mistakenly sampling false negatives, diminishing performance and\nbusiness impact. To address this, we present Bias-mitigating Hard Negative\nSampling (BHNS), a novel negative sampling strategy tailored to identify and\nadjust for false negatives, building upon our original False Negative\nEstimation algorithm. Our experiments in the Instacart search setting confirm\nBHNS as effective for practical e-commerce use. Furthermore, comparative\nanalyses on public dataset showcase its domain-agnostic potential for diverse\napplications.\n","authors":["Xiaochen Wang","Xiao Xiao","Ruhan Zhang","Xuan Zhang","Taesik Na","Tejaswi Tenneti","Haixun Wang","Fenglong Ma"],"pdf_url":"https://arxiv.org/pdf/2311.06444v2.pdf","comment":"Submitted to WWW'24 Industry Track"},{"id":"http://arxiv.org/abs/2304.09161v2","updated":"2023-11-18T18:16:41Z","published":"2023-04-13T13:08:38Z","title":"Perspectives on Large Language Models for Relevance Judgment","summary":"  When asked, large language models (LLMs) like ChatGPT claim that they can\nassist with relevance judgments but it is not clear whether automated judgments\ncan reliably be used in evaluations of retrieval systems. In this perspectives\npaper, we discuss possible ways for LLMs to support relevance judgments along\nwith concerns and issues that arise. We devise a human--machine collaboration\nspectrum that allows to categorize different relevance judgment strategies,\nbased on how much humans rely on machines. For the extreme point of \"fully\nautomated judgments\", we further include a pilot experiment on whether\nLLM-based relevance judgments correlate with judgments from trained human\nassessors. We conclude the paper by providing opposing perspectives for and\nagainst the use of~LLMs for automatic relevance judgments, and a compromise\nperspective, informed by our analyses of the literature, our preliminary\nexperimental evidence, and our experience as IR researchers.\n","authors":["Guglielmo Faggioli","Laura Dietz","Charles Clarke","Gianluca Demartini","Matthias Hagen","Claudia Hauff","Noriko Kando","Evangelos Kanoulas","Martin Potthast","Benno Stein","Henning Wachsmuth"],"pdf_url":"https://arxiv.org/pdf/2304.09161v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07878v3","updated":"2023-11-18T14:34:50Z","published":"2023-11-14T03:15:48Z","title":"Evaluating LLMs on Document-Based QA: Exact Answer Selection and\n  Numerical Extraction using Cogtale dataset","summary":"  Document-based Question-Answering (QA) tasks are crucial for precise\ninformation retrieval. While some existing work focus on evaluating large\nlanguage model's performance on retrieving and answering questions from\ndocuments, assessing the LLMs' performance on QA types that require exact\nanswer selection from predefined options and numerical extraction is yet to be\nfully assessed. In this paper, we specifically focus on this underexplored\ncontext and conduct empirical analysis of LLMs (GPT-4 and GPT 3.5) on question\ntypes, including single-choice, yes-no, multiple-choice, and number extraction\nquestions from documents. We use the Cogtale dataset for evaluation, which\nprovide human expert-tagged responses, offering a robust benchmark for\nprecision and factual grounding. We found that LLMs, particularly GPT-4, can\nprecisely answer many single-choice and yes-no questions given relevant\ncontext, demonstrating their efficacy in information retrieval tasks. However,\ntheir performance diminishes when confronted with multiple-choice and number\nextraction formats, lowering the overall performance of the model on this task,\nindicating that these models may not be reliable for the task. This limits the\napplications of LLMs on applications demanding precise information extraction\nfrom documents, such as meta-analysis tasks. However, these findings hinge on\nthe assumption that the retrievers furnish pertinent context necessary for\naccurate responses, emphasizing the need for further research on the efficacy\nof retriever mechanisms in enhancing question-answering performance. Our work\noffers a framework for ongoing dataset evaluation, ensuring that LLM\napplications for information retrieval and document analysis continue to meet\nevolving standards.\n","authors":["Zafaryab Rasool","Scott Barnett","Stefanus Kurniawan","Sherwin Balugo","Rajesh Vasa","Courtney Chesser","Alex Bahar-Fuchs"],"pdf_url":"https://arxiv.org/pdf/2311.07878v3.pdf","comment":"14 pages, 1 figure, 8 tables"},{"id":"http://arxiv.org/abs/2311.11071v1","updated":"2023-11-18T13:30:01Z","published":"2023-11-18T13:30:01Z","title":"SBTRec- A Transformer Framework for Personalized Tour Recommendation\n  Problem with Sentiment Analysis","summary":"  When traveling to an unfamiliar city for holidays, tourists often rely on\nguidebooks, travel websites, or recommendation systems to plan their daily\nitineraries and explore popular points of interest (POIs). However, these\napproaches may lack optimization in terms of time feasibility, localities, and\nuser preferences. In this paper, we propose the SBTRec algorithm: a BERT-based\nTrajectory Recommendation with sentiment analysis, for recommending\npersonalized sequences of POIs as itineraries. The key contributions of this\nwork include analyzing users' check-ins and uploaded photos to understand the\nrelationship between POI visits and distance. We introduce SBTRec, which\nencompasses sentiment analysis to improve recommendation accuracy by\nunderstanding users' preferences and satisfaction levels from reviews and\ncomments about different POIs. Our proposed algorithms are evaluated against\nother sequence prediction methods using datasets from 8 cities. The results\ndemonstrate that SBTRec achieves an average F1 score of 61.45%, outperforming\nbaseline algorithms.\n  The paper further discusses the flexibility of the SBTRec algorithm, its\nability to adapt to different scenarios and cities without modification, and\nits potential for extension by incorporating additional information for more\nreliable predictions. Overall, SBTRec provides personalized and relevant POI\nrecommendations, enhancing tourists' overall trip experiences. Future work\nincludes fine-tuning personalized embeddings for users, with evaluation of\nusers' comments on POIs,~to further enhance prediction accuracy.\n","authors":["Ngai Lam Ho","Roy Ka-Wei Lee","Kwan Hui Lim"],"pdf_url":"https://arxiv.org/pdf/2311.11071v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11489v3","updated":"2023-11-18T04:26:35Z","published":"2023-01-27T01:54:16Z","title":"Talk the Walk: Synthetic Data Generation for Conversational Music\n  Recommendation","summary":"  Recommender systems are ubiquitous yet often difficult for users to control,\nand adjust if recommendation quality is poor. This has motivated conversational\nrecommender systems (CRSs), with control provided through natural language\nfeedback. However, as with most application domains, building robust CRSs\nrequires training data that reflects system usage$\\unicode{x2014}$here\nconversations with user utterances paired with items that cover a wide range of\npreferences. This has proved challenging to collect scalably using conventional\nmethods. We address the question of whether it can be generated synthetically,\nbuilding on recent advances in natural language. We evaluate in the setting of\nitem set recommendation, noting the increasing attention to this task motivated\nby use cases like music, news, and recipe recommendation. We present\nTalkTheWalk, which synthesizes realistic high-quality conversational data by\nleveraging domain expertise encoded in widely available curated item\ncollections, generating a sequence of hypothetical yet plausible item sets,\nthen using a language model to produce corresponding user utterances. We\ngenerate over one million diverse playlist curation conversations in the music\ndomain, and show these contain consistent utterances with relevant item sets\nnearly matching the quality of an existing but small human-collected dataset\nfor this task. We demonstrate the utility of the generated synthetic dataset on\na conversational item retrieval task and show that it improves over both\nunsupervised baselines and systems trained on a real dataset.\n","authors":["Megan Leszczynski","Shu Zhang","Ravi Ganti","Krisztian Balog","Filip Radlinski","Fernando Pereira","Arun Tejasvi Chaganty"],"pdf_url":"https://arxiv.org/pdf/2301.11489v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10947v1","updated":"2023-11-18T03:05:43Z","published":"2023-11-18T03:05:43Z","title":"RecExplainer: Aligning Large Language Models for Recommendation Model\n  Interpretability","summary":"  Recommender systems are widely used in various online services, with\nembedding-based models being particularly popular due to their expressiveness\nin representing complex signals. However, these models often lack\ninterpretability, making them less reliable and transparent for both users and\ndevelopers. With the emergence of large language models (LLMs), we find that\ntheir capabilities in language expression, knowledge-aware reasoning, and\ninstruction following are exceptionally powerful. Based on this, we propose a\nnew model interpretation approach for recommender systems, by using LLMs as\nsurrogate models and learn to mimic and comprehend target recommender models.\nSpecifically, we introduce three alignment methods: behavior alignment,\nintention alignment, and hybrid alignment. Behavior alignment operates in the\nlanguage space, representing user preferences and item information as text to\nlearn the recommendation model's behavior; intention alignment works in the\nlatent space of the recommendation model, using user and item representations\nto understand the model's behavior; hybrid alignment combines both language and\nlatent spaces for alignment training. To demonstrate the effectiveness of our\nmethods, we conduct evaluation from two perspectives: alignment effect, and\nexplanation generation ability on three public datasets. Experimental results\nindicate that our approach effectively enables LLMs to comprehend the patterns\nof recommendation models and generate highly credible recommendation\nexplanations.\n","authors":["Yuxuan Lei","Jianxun Lian","Jing Yao","Xu Huang","Defu Lian","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2311.10947v1.pdf","comment":"12 pages, 8 figures, 4 tables"},{"id":"http://arxiv.org/abs/2311.10922v1","updated":"2023-11-18T00:33:48Z","published":"2023-11-18T00:33:48Z","title":"Explainable Product Classification for Customs","summary":"  The task of assigning internationally accepted commodity codes (aka HS codes)\nto traded goods is a critical function of customs offices. Like court decisions\nmade by judges, this task follows the doctrine of precedent and can be\nnontrivial even for experienced officers. Together with the Korea Customs\nService (KCS), we propose a first-ever explainable decision supporting model\nthat suggests the most likely subheadings (i.e., the first six digits) of the\nHS code. The model also provides reasoning for its suggestion in the form of a\ndocument that is interpretable by customs officers. We evaluated the model\nusing 5,000 cases that recently received a classification request. The results\nshowed that the top-3 suggestions made by our model had an accuracy of 93.9\\%\nwhen classifying 925 challenging subheadings. A user study with 32 customs\nexperts further confirmed that our algorithmic suggestions accompanied by\nexplainable reasonings, can substantially reduce the time and effort taken by\ncustoms officers for classification reviews.\n","authors":["Eunji Lee","Sihyeon Kim","Sundong Kim","Soyeon Jung","Heeja Kim","Meeyoung Cha"],"pdf_url":"https://arxiv.org/pdf/2311.10922v1.pdf","comment":"24 pages, Accepted to ACM Transactions on Intelligent Systems and\n  Technology"}],"Multimedia":[{"id":"http://arxiv.org/abs/2302.05087v2","updated":"2023-11-18T16:09:43Z","published":"2023-02-10T07:11:37Z","title":"Generalized Video Anomaly Event Detection: Systematic Taxonomy and\n  Comparison of Deep Models","summary":"  Video Anomaly Detection (VAD) serves as a pivotal technology in the\nintelligent surveillance systems, enabling the temporal or spatial\nidentification of anomalous events within videos. While existing reviews\npredominantly concentrate on conventional unsupervised methods, they often\noverlook the emergence of weakly-supervised and fully-unsupervised approaches.\nTo address this gap, this survey extends the conventional scope of VAD beyond\nunsupervised methods, encompassing a broader spectrum termed Generalized Video\nAnomaly Event Detection (GVAED). By skillfully incorporating recent\nadvancements rooted in diverse assumptions and learning frameworks, this survey\nintroduces an intuitive taxonomy that seamlessly navigates through\nunsupervised, weakly-supervised, supervised and fully-unsupervised VAD\nmethodologies, elucidating the distinctions and interconnections within these\nresearch trajectories. In addition, this survey facilitates prospective\nresearchers by assembling a compilation of research resources, including public\ndatasets, available codebases, programming tools, and pertinent literature.\nFurthermore, this survey quantitatively assesses model performance, delves into\nresearch challenges and directions, and outlines potential avenues for future\nexploration.\n","authors":["Yang Liu","Dingkang Yang","Yan Wang","Jing Liu","Jun Liu","Azzedine Boukerche","Peng Sun","Liang Song"],"pdf_url":"https://arxiv.org/pdf/2302.05087v2.pdf","comment":"Revised to ACM Computing Surveys, under review"},{"id":"http://arxiv.org/abs/2311.11074v1","updated":"2023-11-18T13:45:40Z","published":"2023-11-18T13:45:40Z","title":"The Persian Piano Corpus: A Collection Of Instrument-Based Feature\n  Extracted Data Considering Dastgah","summary":"  The research in the field of music is rapidly growing, and this trend\nemphasizes the need for comprehensive data. Though researchers have made an\neffort to contribute their own datasets, many data collections lack the\nrequisite inclusivity for comprehensive study because they are frequently\nfocused on particular components of music or other specific topics. We have\nendeavored to address data scarcity by employing an instrument-based approach\nto provide a complete corpus related to the Persian piano. Our piano corpus\nincludes relevant labels for Persian music mode (Dastgah) and comprehensive\nmetadata, allowing for utilization in various popular research areas. The\nfeatures extracted from 2022 Persian piano pieces in The Persian Piano Corpus\n(PPC) have been collected and made available to researchers, aiming for a more\nthorough understanding of Persian music and the role of the piano in it in\nsubsequent steps.\n","authors":["Parsa Rasouli","Azam Bastanfard"],"pdf_url":"https://arxiv.org/pdf/2311.11074v1.pdf","comment":"including 11 pages and 6 figures. we want to inform related data PPC\n  is submitted to Harvard Dataverse: https://doi.org/10.7910/DVN/YY7SVD"},{"id":"http://arxiv.org/abs/2311.11059v1","updated":"2023-11-18T12:33:19Z","published":"2023-11-18T12:33:19Z","title":"HIDRO-VQA: High Dynamic Range Oracle for Video Quality Assessment","summary":"  We introduce HIDRO-VQA, a no-reference (NR) video quality assessment model\ndesigned to provide precise quality evaluations of High Dynamic Range (HDR)\nvideos. HDR videos exhibit a broader spectrum of luminance, detail, and color\nthan Standard Dynamic Range (SDR) videos. As HDR content becomes increasingly\npopular, there is a growing demand for video quality assessment (VQA)\nalgorithms that effectively address distortions unique to HDR content. To\naddress this challenge, we propose a self-supervised contrastive fine-tuning\napproach to transfer quality-aware features from the SDR to the HDR domain,\nutilizing unlabeled HDR videos. Our findings demonstrate that self-supervised\npre-trained neural networks on SDR content can be further fine-tuned in a\nself-supervised setting using limited unlabeled HDR videos to achieve\nstate-of-the-art performance on the only publicly available VQA database for\nHDR content, the LIVE-HDR VQA database. Moreover, our algorithm can be extended\nto the Full Reference VQA setting, also achieving state-of-the-art performance.\nOur code is available publicly at https://github.com/avinabsaha/HIDRO-VQA.\n","authors":["Shreshth Saini","Avinab Saha","Alan C. Bovik"],"pdf_url":"https://arxiv.org/pdf/2311.11059v1.pdf","comment":"WACV 2024 Workshop Paper. Shreshth Saini, Avinab Saha contributed\n  equally to this work. Code coming soon"},{"id":"http://arxiv.org/abs/2311.11019v1","updated":"2023-11-18T09:42:03Z","published":"2023-11-18T09:42:03Z","title":"Hyperbolic Space with Hierarchical Margin Boosts Fine-Grained Learning\n  from Coarse Labels","summary":"  Learning fine-grained embeddings from coarse labels is a challenging task due\nto limited label granularity supervision, i.e., lacking the detailed\ndistinctions required for fine-grained tasks. The task becomes even more\ndemanding when attempting few-shot fine-grained recognition, which holds\npractical significance in various applications. To address these challenges, we\npropose a novel method that embeds visual embeddings into a hyperbolic space\nand enhances their discriminative ability with a hierarchical cosine margins\nmanner. Specifically, the hyperbolic space offers distinct advantages,\nincluding the ability to capture hierarchical relationships and increased\nexpressive power, which favors modeling fine-grained objects. Based on the\nhyperbolic space, we further enforce relatively large/small similarity margins\nbetween coarse/fine classes, respectively, yielding the so-called hierarchical\ncosine margins manner. While enforcing similarity margins in the regular\nEuclidean space has become popular for deep embedding learning, applying it to\nthe hyperbolic space is non-trivial and validating the benefit for\ncoarse-to-fine generalization is valuable. Extensive experiments conducted on\nfive benchmark datasets showcase the effectiveness of our proposed method,\nyielding state-of-the-art results surpassing competing methods.\n","authors":["Shu-Lin Xu","Yifan Sun","Faen Zhang","Anqi Xu","Xiu-Shen Wei","Yi Yang"],"pdf_url":"https://arxiv.org/pdf/2311.11019v1.pdf","comment":"Accepted by NeurIPS 2023"}]},"2023-11-21T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2311.09387v2","updated":"2023-11-21T18:31:57Z","published":"2023-11-15T21:30:26Z","title":"Banach-Tarski Embeddings and Transformers","summary":"  We introduce a new construction of embeddings of arbitrary recursive data\nstructures into high dimensional vectors. These embeddings provide an\ninterpretable model for the latent state vectors of transformers. We\ndemonstrate that these embeddings can be decoded to the original data structure\nwhen the embedding dimension is sufficiently large. This decoding algorithm has\na natural implementation as a transformer. We also show that these embedding\nvectors can be manipulated directly to perform computations on the underlying\ndata without decoding. As an example we present an algorithm that constructs\nthe embedded parse tree of an embedded token sequence using only vector\noperations in embedding space.\n","authors":["Joshua Maher"],"pdf_url":"https://arxiv.org/pdf/2311.09387v2.pdf","comment":"22 pages, 7 figures. v2: Fixed order of matrix multiplication in\n  section 2.4"},{"id":"http://arxiv.org/abs/2310.02168v2","updated":"2023-11-21T18:18:49Z","published":"2023-10-03T16:02:36Z","title":"Editing Personality for LLMs","summary":"  This paper introduces an innovative task focused on editing the personality\ntraits of Large Language Models (LLMs). This task seeks to adjust the models'\nresponses to opinion-related questions on specified topics since an\nindividual's personality often manifests in the form of their expressed\nopinions, thereby showcasing different personality traits. Specifically, we\nconstruct a new benchmark dataset PersonalityEdit to address this task. Drawing\non the theory in Social Psychology, we isolate three representative traits,\nnamely Neuroticism, Extraversion, and Agreeableness, as the foundation for our\nbenchmark. We then gather data using GPT-4, generating responses that not only\nalign with a specified topic but also embody the targeted personality trait. We\nconduct comprehensive experiments involving various baselines and discuss the\nrepresentation of personality behavior in LLMs. Our intriguing findings uncover\npotential challenges of the proposed task, illustrating several remaining\nissues. We anticipate that our work can provide the NLP community with\ninsights. Code and datasets will be released at\nhttps://github.com/zjunlp/EasyEdit.\n","authors":["Shengyu Mao","Ningyu Zhang","Xiaohan Wang","Mengru Wang","Yunzhi Yao","Yong Jiang","Pengjun Xie","Fei Huang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2310.02168v2.pdf","comment":"Work in progress, add more experiments"},{"id":"http://arxiv.org/abs/2310.02129v2","updated":"2023-11-21T17:59:04Z","published":"2023-10-03T15:10:46Z","title":"Unveiling the Pitfalls of Knowledge Editing for Large Language Models","summary":"  As the cost associated with fine-tuning Large Language Models (LLMs)\ncontinues to rise, recent research efforts have pivoted towards developing\nmethodologies to edit implicit knowledge embedded within LLMs. Yet, there's\nstill a dark cloud lingering overhead -- will knowledge editing trigger\nbutterfly effect? since it is still unclear whether knowledge editing might\nintroduce side effects that pose potential risks or not. This paper pioneers\nthe investigation into the potential pitfalls associated with knowledge editing\nfor LLMs. To achieve this, we introduce new benchmark datasets and propose\ninnovative evaluation metrics. Our results underline two pivotal concerns: (1)\nKnowledge Conflict: Editing groups of facts that logically clash can magnify\nthe inherent inconsistencies in LLMs-a facet neglected by previous methods. (2)\nKnowledge Distortion: Altering parameters with the aim of editing factual\nknowledge can irrevocably warp the innate knowledge structure of LLMs.\nExperimental results vividly demonstrate that knowledge editing might\ninadvertently cast a shadow of unintended consequences on LLMs, which warrant\nattention and efforts for future works. Code is available at\nhttps://github.com/zjunlp/PitfallsKnowledgeEditing.\n","authors":["Zhoubo Li","Ningyu Zhang","Yunzhi Yao","Mengru Wang","Xi Chen","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2310.02129v2.pdf","comment":"Work in progress, add more experiments"},{"id":"http://arxiv.org/abs/2311.12735v1","updated":"2023-11-21T17:21:15Z","published":"2023-11-21T17:21:15Z","title":"LowResource at BLP-2023 Task 2: Leveraging BanglaBert for Low Resource\n  Sentiment Analysis of Bangla Language","summary":"  This paper describes the system of the LowResource Team for Task 2 of\nBLP-2023, which involves conducting sentiment analysis on a dataset composed of\npublic posts and comments from diverse social media platforms. Our primary aim\nis to utilize BanglaBert, a BERT model pre-trained on a large Bangla corpus,\nusing various strategies including fine-tuning, dropping random tokens, and\nusing several external datasets. Our final model is an ensemble of the three\nbest BanglaBert variations. Our system has achieved overall 3rd in the Test Set\namong 30 participating teams with a score of 0.718. Additionally, we discuss\nthe promising systems that didn't perform well namely task-adaptive pertaining\nand paraphrasing using BanglaT5. Training codes and external datasets which are\nused for our system are publicly available at\nhttps://github.com/Aunabil4602/bnlp-workshop-task2-2023\n","authors":["Aunabil Chakma","Masum Hasan"],"pdf_url":"https://arxiv.org/pdf/2311.12735v1.pdf","comment":"Accepted at BLP Workshop @EMNLP2023"},{"id":"http://arxiv.org/abs/2311.12727v1","updated":"2023-11-21T17:03:21Z","published":"2023-11-21T17:03:21Z","title":"Soft Random Sampling: A Theoretical and Empirical Analysis","summary":"  Soft random sampling (SRS) is a simple yet effective approach for efficient\ntraining of large-scale deep neural networks when dealing with massive data.\nSRS selects a subset uniformly at random with replacement from the full data\nset in each epoch. In this paper, we conduct a theoretical and empirical\nanalysis of SRS. First, we analyze its sampling dynamics including data\ncoverage and occupancy. Next, we investigate its convergence with non-convex\nobjective functions and give the convergence rate. Finally, we provide its\ngeneralization performance. We empirically evaluate SRS for image recognition\non CIFAR10 and automatic speech recognition on Librispeech and an in-house\npayload dataset to demonstrate its effectiveness. Compared to existing\ncoreset-based data selection methods, SRS offers a better accuracy-efficiency\ntrade-off. Especially on real-world industrial scale data sets, it is shown to\nbe a powerful training strategy with significant speedup and competitive\nperformance with almost no additional computing cost.\n","authors":["Xiaodong Cui","Ashish Mittal","Songtao Lu","Wei Zhang","George Saon","Brian Kingsbury"],"pdf_url":"https://arxiv.org/pdf/2311.12727v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.10852v6","updated":"2023-11-21T16:36:43Z","published":"2022-05-22T15:30:18Z","title":"Relphormer: Relational Graph Transformer for Knowledge Graph\n  Representations","summary":"  Transformers have achieved remarkable performance in widespread fields,\nincluding natural language processing, computer vision and graph mining.\nHowever, vanilla Transformer architectures have not yielded promising\nimprovements in the Knowledge Graph (KG) representations, where the\ntranslational distance paradigm dominates this area. Note that vanilla\nTransformer architectures struggle to capture the intrinsically heterogeneous\nstructural and semantic information of knowledge graphs. To this end, we\npropose a new variant of Transformer for knowledge graph representations dubbed\nRelphormer. Specifically, we introduce Triple2Seq which can dynamically sample\ncontextualized sub-graph sequences as the input to alleviate the heterogeneity\nissue. We propose a novel structure-enhanced self-attention mechanism to encode\nthe relational information and keep the semantic information within entities\nand relations. Moreover, we utilize masked knowledge modeling for general\nknowledge graph representation learning, which can be applied to various\nKG-based tasks including knowledge graph completion, question answering, and\nrecommendation. Experimental results on six datasets show that Relphormer can\nobtain better performance compared with baselines. Code is available in\nhttps://github.com/zjunlp/Relphormer.\n","authors":["Zhen Bi","Siyuan Cheng","Jing Chen","Xiaozhuan Liang","Feiyu Xiong","Ningyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2205.10852v6.pdf","comment":"Neurocomputing 2023"},{"id":"http://arxiv.org/abs/2306.17103v3","updated":"2023-11-21T16:32:41Z","published":"2023-06-29T17:01:51Z","title":"LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by\n  Whispering to ChatGPT","summary":"  We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic\nlyrics transcription method achieving state-of-the-art performance on various\nlyrics transcription datasets, even in challenging genres such as rock and\nmetal. Our novel, training-free approach utilizes Whisper, a weakly supervised\nrobust speech recognition model, and GPT-4, today's most performant chat-based\nlarge language model. In the proposed method, Whisper functions as the \"ear\" by\ntranscribing the audio, while GPT-4 serves as the \"brain,\" acting as an\nannotator with a strong performance for contextualized output selection and\ncorrection. Our experiments show that LyricWhiz significantly reduces Word\nError Rate compared to existing methods in English and can effectively\ntranscribe lyrics across multiple languages. Furthermore, we use LyricWhiz to\ncreate the first publicly available, large-scale, multilingual lyrics\ntranscription dataset with a CC-BY-NC-SA copyright license, based on\nMTG-Jamendo, and offer a human-annotated subset for noise level estimation and\nevaluation. We anticipate that our proposed method and dataset will advance the\ndevelopment of multilingual lyrics transcription, a challenging and emerging\ntask.\n","authors":["Le Zhuo","Ruibin Yuan","Jiahao Pan","Yinghao Ma","Yizhi LI","Ge Zhang","Si Liu","Roger Dannenberg","Jie Fu","Chenghua Lin","Emmanouil Benetos","Wenhu Chen","Wei Xue","Yike Guo"],"pdf_url":"https://arxiv.org/pdf/2306.17103v3.pdf","comment":"9 pages, 2 figures, 5 tables, accepted by ISMIR 2023"},{"id":"http://arxiv.org/abs/2311.12707v1","updated":"2023-11-21T16:20:49Z","published":"2023-11-21T16:20:49Z","title":"Keeping Users Engaged During Repeated Administration of the Same\n  Questionnaire: Using Large Language Models to Reliably Diversify Questions","summary":"  Standardized, validated questionnaires are vital tools in HCI research and\nhealthcare, offering dependable self-report data. However, their repeated use\nin longitudinal or pre-post studies can induce respondent fatigue, impacting\ndata quality via response biases and decreased response rates. We propose\nutilizing large language models (LLMs) to generate diverse questionnaire\nversions while retaining good psychometric properties. In a longitudinal study,\nparticipants engaged with our agent system and responded daily for two weeks to\neither a standardized depression questionnaire or one of two LLM-generated\nquestionnaire variants, alongside a validated depression questionnaire.\nPsychometric testing revealed consistent covariation between the external\ncriterion and the focal measure administered across the three conditions,\ndemonstrating the reliability and validity of the LLM-generated variants.\nParticipants found the repeated administration of the standardized\nquestionnaire significantly more repetitive compared to the variants. Our\nfindings highlight the potential of LLM-generated variants to invigorate\nquestionnaires, fostering engagement and interest without compromising\nvalidity.\n","authors":["Hye Sun Yun","Mehdi Arjmand","Phillip Raymond Sherlock","Michael Paasche-Orlow","James W. Griffith","Timothy Bickmore"],"pdf_url":"https://arxiv.org/pdf/2311.12707v1.pdf","comment":"22 pages, preprint"},{"id":"http://arxiv.org/abs/2311.12699v1","updated":"2023-11-21T16:03:51Z","published":"2023-11-21T16:03:51Z","title":"Can Large Language Models Understand Content and Propagation for\n  Misinformation Detection: An Empirical Study","summary":"  Large Language Models (LLMs) have garnered significant attention for their\npowerful ability in natural language understanding and reasoning. In this\npaper, we present a comprehensive empirical study to explore the performance of\nLLMs on misinformation detection tasks. This study stands as the pioneering\ninvestigation into the understanding capabilities of multiple LLMs regarding\nboth content and propagation across social media platforms. Our empirical\nstudies on five misinformation detection datasets show that LLMs with diverse\nprompts achieve comparable performance in text-based misinformation detection\nbut exhibit notably constrained capabilities in comprehending propagation\nstructure compared to existing models in propagation-based misinformation\ndetection. Besides, we further design four instruction-tuned strategies to\nenhance LLMs for both content and propagation-based misinformation detection.\nThese strategies boost LLMs to actively learn effective features from multiple\ninstances or hard instances, and eliminate irrelevant propagation structures,\nthereby achieving better detection performance. Extensive experiments further\ndemonstrate LLMs would play a better capacity in content and propagation\nstructure under these proposed strategies and achieve promising detection\nperformance. These findings highlight the potential ability of LLMs to detect\nmisinformation.\n","authors":["Mengyang Chen","Lingwei Wei","Han Cao","Wei Zhou","Songlin Hu"],"pdf_url":"https://arxiv.org/pdf/2311.12699v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12689v1","updated":"2023-11-21T15:51:06Z","published":"2023-11-21T15:51:06Z","title":"Fair Text Classification with Wasserstein Independence","summary":"  Group fairness is a central research topic in text classification, where\nreaching fair treatment between sensitive groups (e.g. women vs. men) remains\nan open challenge. This paper presents a novel method for mitigating biases in\nneural text classification, agnostic to the model architecture. Considering the\ndifficulty to distinguish fair from unfair information in a text encoder, we\ntake inspiration from adversarial training to induce Wasserstein independence\nbetween representations learned to predict our target label and the ones\nlearned to predict some sensitive attribute. Our approach provides two\nsignificant advantages. Firstly, it does not require annotations of sensitive\nattributes in both testing and training data. This is more suitable for\nreal-life scenarios compared to existing methods that require annotations of\nsensitive attributes at train time. Second, our approach exhibits a comparable\nor better fairness-accuracy trade-off compared to existing methods.\n","authors":["Thibaud Leteno","Antoine Gourru","Charlotte Laclau","Rémi Emonet","Christophe Gravier"],"pdf_url":"https://arxiv.org/pdf/2311.12689v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.12311v3","updated":"2023-11-21T15:40:54Z","published":"2020-12-22T19:32:52Z","title":"Influencer Videos: Unboxing the Mystique","summary":"  Influencer marketing has become a very popular tool to reach customers.\nDespite the rapid growth in influencer videos, there has been little research\non the effectiveness of their constituent features in explaining video\nengagement. We study YouTube influencers and analyze their unstructured video\ndata across text, audio and images using an \"interpretable deep learning\"\nframework that accomplishes both goals of prediction and interpretation. Our\nprediction-based approach analyzes unstructured data and finds that \"what is\nsaid\" in words (text) is more influential than \"how it is said\" in imagery\n(images) or acoustics (audio). Our novel interpretation-based approach is\nimplemented after completion of model prediction by analyzing the same source\nof unstructured data to measure importance attributed to the video features. We\neliminate several spurious relationships in two steps, identifying a subset of\nrelationships which are confirmed using theory. We uncover novel findings that\nestablish distinct associations for measures of shallow and deep engagement\nbased on the dual-system framework of human thinking. Our approach is validated\nusing simulated data, and we discuss the learnings from our findings for\ninfluencers and brands.\n","authors":["Prashant Rajaram","Puneet Manchanda"],"pdf_url":"https://arxiv.org/pdf/2012.12311v3.pdf","comment":"45 pages, Online Appendix"},{"id":"http://arxiv.org/abs/2311.12664v1","updated":"2023-11-21T15:14:54Z","published":"2023-11-21T15:14:54Z","title":"The DURel Annotation Tool: Human and Computational Measurement of\n  Semantic Proximity, Sense Clusters and Semantic Change","summary":"  We present the DURel tool that implements the annotation of semantic\nproximity between uses of words into an online, open source interface. The tool\nsupports standardized human annotation as well as computational annotation,\nbuilding on recent advances with Word-in-Context models. Annotator judgments\nare clustered with automatic graph clustering techniques and visualized for\nanalysis. This allows to measure word senses with simple and intuitive\nmicro-task judgments between use pairs, requiring minimal preparation efforts.\nThe tool offers additional functionalities to compare the agreement between\nannotators to guarantee the inter-subjectivity of the obtained judgments and to\ncalculate summary statistics giving insights into sense frequency\ndistributions, semantic variation or changes of senses over time.\n","authors":["Dominik Schlechtweg","Shafqat Mumtaz Virk","Pauline Sander","Emma Sköldberg","Lukas Theuer Linke","Tuo Zhang","Nina Tahmasebi","Jonas Kuhn","Sabine Schulte im Walde"],"pdf_url":"https://arxiv.org/pdf/2311.12664v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2311.12649v1","updated":"2023-11-21T14:49:00Z","published":"2023-11-21T14:49:00Z","title":"MathGloss: Building mathematical glossaries from text","summary":"  MathGloss is a project to create a knowledge graph (KG) for undergraduate\nmathematics from text, automatically, using modern natural language processing\n(NLP) tools and resources already available on the web. MathGloss is a linked\ndatabase of undergraduate concepts in mathematics. So far, it combines five\nresources: (i) Wikidata, a collaboratively edited, multilingual knowledge graph\nhosted by the Wikimedia Foundation, (ii) terms covered in mathematics courses\nat the University of Chicago, (iii) the syllabus of the French undergraduate\nmathematics curriculum which includes hyperlinks to the automated theorem\nprover Lean 4, (iv) MuLiMa, a multilingual dictionary of mathematics curated by\nmathematicians, and (v) the nLab, a wiki for category theory also curated by\nmathematicians. MathGloss's goal is to bring together resources for learning\nmathematics and to allow every mathematician to tailor their learning to their\nown preferences. Moreover, by organizing different resources for learning\nundergraduate mathematics alongside those for learning formal mathematics, we\nhope to make it easier for mathematicians and formal tools (theorem provers,\ncomputer algebra systems, etc) experts to \"understand\" each other and break\ndown some of the barriers to formal math.\n","authors":["Lucy Horowitz","Valeria de Paiva"],"pdf_url":"https://arxiv.org/pdf/2311.12649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.01446v3","updated":"2023-11-21T14:02:33Z","published":"2023-09-04T08:54:20Z","title":"Open Sesame! Universal Black Box Jailbreaking of Large Language Models","summary":"  Large language models (LLMs), designed to provide helpful and safe responses,\noften rely on alignment techniques to align with user intent and social\nguidelines. Unfortunately, this alignment can be exploited by malicious actors\nseeking to manipulate an LLM's outputs for unintended purposes. In this paper\nwe introduce a novel approach that employs a genetic algorithm (GA) to\nmanipulate LLMs when model architecture and parameters are inaccessible. The GA\nattack works by optimizing a universal adversarial prompt that -- when combined\nwith a user's query -- disrupts the attacked model's alignment, resulting in\nunintended and potentially harmful outputs. Our novel approach systematically\nreveals a model's limitations and vulnerabilities by uncovering instances where\nits responses deviate from expected behavior. Through extensive experiments we\ndemonstrate the efficacy of our technique, thus contributing to the ongoing\ndiscussion on responsible AI development by providing a diagnostic tool for\nevaluating and enhancing alignment of LLMs with human intent. To our knowledge\nthis is the first automated universal black box jailbreak attack.\n","authors":["Raz Lapid","Ron Langberg","Moshe Sipper"],"pdf_url":"https://arxiv.org/pdf/2309.01446v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12574v1","updated":"2023-11-21T12:40:01Z","published":"2023-11-21T12:40:01Z","title":"IMGTB: A Framework for Machine-Generated Text Detection Benchmarking","summary":"  In the era of large language models generating high quality texts, it is a\nnecessity to develop methods for detection of machine-generated text to avoid\nharmful use or simply due to annotation purposes. It is, however, also\nimportant to properly evaluate and compare such developed methods. Recently, a\nfew benchmarks have been proposed for this purpose; however, integration of\nnewest detection methods is rather challenging, since new methods appear each\nmonth and provide slightly different evaluation pipelines. In this paper, we\npresent the IMGTB framework, which simplifies the benchmarking of\nmachine-generated text detection methods by easy integration of custom (new)\nmethods and evaluation datasets. Its configurability and flexibility makes\nresearch and development of new detection methods easier, especially their\ncomparison to the existing state-of-the-art detectors. The default set of\nanalyses, metrics and visualizations offered by the tool follows the\nestablished practices of machine-generated text detection benchmarking found in\nstate-of-the-art literature.\n","authors":["Michal Spiegel","Dominik Macko"],"pdf_url":"https://arxiv.org/pdf/2311.12574v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12538v1","updated":"2023-11-21T11:33:03Z","published":"2023-11-21T11:33:03Z","title":"In-Context Learning Functions with Varying Number of Minima","summary":"  Large Language Models (LLMs) have proven effective at In-Context Learning\n(ICL), an ability that allows them to create predictors from labeled examples.\nFew studies have explored the interplay between ICL and specific properties of\nfunctions it attempts to approximate. In our study, we use a formal framework\nto explore ICL and propose a new task of approximating functions with varying\nnumber of minima. We implement a method that allows for producing functions\nwith given inputs as minima. We find that increasing the number of minima\ndegrades ICL performance. At the same time, our evaluation shows that ICL\noutperforms 2-layer Neural Network (2NN) model. Furthermore, ICL learns faster\nthan 2NN in all settings. We validate the findings through a set of few-shot\nexperiments across various hyperparameter configurations.\n","authors":["David Oniani","Yanshan Wang"],"pdf_url":"https://arxiv.org/pdf/2311.12538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12537v1","updated":"2023-11-21T11:32:23Z","published":"2023-11-21T11:32:23Z","title":"Oasis: Data Curation and Assessment System for Pretraining of Large\n  Language Models","summary":"  Data is one of the most critical elements in building a large language model.\nHowever, existing systems either fail to customize a corpus curation pipeline\nor neglect to leverage comprehensive corpus assessment for iterative\noptimization of the curation. To this end, we present a pretraining corpus\ncuration and assessment platform called Oasis -- a one-stop system for data\nquality improvement and quantification with user-friendly interactive\ninterfaces. Specifically, the interactive modular rule filter module can devise\ncustomized rules according to explicit feedback. The debiased neural filter\nmodule builds the quality classification dataset in a negative-centric manner\nto remove the undesired bias. The adaptive document deduplication module could\nexecute large-scale deduplication with limited memory resources. These three\nparts constitute the customized data curation module. And in the holistic data\nassessment module, a corpus can be assessed in local and global views, with\nthree evaluation means including human, GPT-4, and heuristic metrics. We\nexhibit a complete process to use Oasis for the curation and assessment of\npretraining data. In addition, an 800GB bilingual corpus curated by Oasis is\npublicly released.\n","authors":["Tong Zhou","Yubo Chen","Pengfei Cao","Kang Liu","Jun Zhao","Shengping Liu"],"pdf_url":"https://arxiv.org/pdf/2311.12537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.05140v2","updated":"2023-11-21T11:28:24Z","published":"2023-10-08T12:21:24Z","title":"Harnessing the Power of Large Language Models for Empathetic Response\n  Generation: Empirical Investigations and Improvements","summary":"  Empathetic dialogue is an indispensable part of building harmonious social\nrelationships and contributes to the development of a helpful AI. Previous\napproaches are mainly based on fine small-scale language models. With the\nadvent of ChatGPT, the application effect of large language models (LLMs) in\nthis field has attracted great attention. This work empirically investigates\nthe performance of LLMs in generating empathetic responses and proposes three\nimprovement methods of semantically similar in-context learning, two-stage\ninteractive generation, and combination with the knowledge base. Extensive\nexperiments show that LLMs can significantly benefit from our proposed methods\nand is able to achieve state-of-the-art performance in both automatic and human\nevaluations. Additionally, we explore the possibility of GPT-4 simulating human\nevaluators.\n","authors":["Yushan Qian","Wei-Nan Zhang","Ting Liu"],"pdf_url":"https://arxiv.org/pdf/2310.05140v2.pdf","comment":"the Findings of EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.12534v1","updated":"2023-11-21T11:26:26Z","published":"2023-11-21T11:26:26Z","title":"Evaluation Metrics of Language Generation Models for Synthetic Traffic\n  Generation Tasks","summary":"  Many Natural Language Generation (NLG) tasks aim to generate a single output\ntext given an input prompt. Other settings require the generation of multiple\ntexts, e.g., for Synthetic Traffic Generation (STG). This generation task is\ncrucial for training and evaluating QA systems as well as conversational\nagents, where the goal is to generate multiple questions or utterances\nresembling the linguistic variability of real users. In this paper, we show\nthat common NLG metrics, like BLEU, are not suitable for evaluating STG. We\npropose and evaluate several metrics designed to compare the generated traffic\nto the distribution of real user texts. We validate our metrics with an\nautomatic procedure to verify whether they capture different types of quality\nissues of generated data; we also run human annotations to verify the\ncorrelation with human judgements. Experiments on three tasks, i.e., Shopping\nUtterance Generation, Product Question Generation and Query Auto Completion,\ndemonstrate that our metrics are effective for evaluating STG tasks, and\nimprove the agreement with human judgement up to 20% with respect to common NLG\nmetrics. We believe these findings can pave the way towards better solutions\nfor estimating the representativeness of synthetic text data.\n","authors":["Simone Filice","Jason Ingyu Choi","Giuseppe Castellucci","Eugene Agichtein","Oleg Rokhlenko"],"pdf_url":"https://arxiv.org/pdf/2311.12534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.18098v3","updated":"2023-11-21T11:01:24Z","published":"2023-05-29T14:07:52Z","title":"BigTranslate: Augmenting Large Language Models with Multilingual\n  Translation Capability over 100 Languages","summary":"  Large language models (LLMs) demonstrate promising translation performance\namong various natural languages. However, many LLMs especially the open-sourced\nones, such as BLOOM and LLaMA, are English-dominant and support only dozens of\nnatural languages, making the potential of LLMs on language translation less\nexplored. In this work, we present BigTranslate which adapts LLaMA that covers\nonly 20 languages and enhances it with multilingual translation capability on\nmore than 100 languages. BigTranslate is built upon LLaMA-13B and it is\noptimized in three steps. First, we continue training LLaMA with massive\nChinese monolingual data. Second, we continue training the model with a\nlarge-scale parallel dataset that covers 102 natural languages. Third, we\ninstruct-tune the foundation model with multilingual translation instructions,\nleading to our BigTranslate model. The preliminary experiments on multilingual\ntranslation show that BigTranslate performs comparably with ChatGPT and Google\nTranslate in many languages and even outperforms ChatGPT in 8 language pairs.\nWe release the BigTranslate model and hope it can advance the research\nprogress.\n","authors":["Wen Yang","Chong Li","Jiajun Zhang","Chengqing Zong"],"pdf_url":"https://arxiv.org/pdf/2305.18098v3.pdf","comment":"16 pages, 4 figures. Our model is available at\n  https://github.com/ZNLP/BigTranslate"},{"id":"http://arxiv.org/abs/2311.12489v1","updated":"2023-11-21T09:59:29Z","published":"2023-11-21T09:59:29Z","title":"Multilingual Word Embeddings for Low-Resource Languages using Anchors\n  and a Chain of Related Languages","summary":"  Very low-resource languages, having only a few million tokens worth of data,\nare not well-supported by multilingual NLP approaches due to poor quality\ncross-lingual word representations. Recent work showed that good cross-lingual\nperformance can be achieved if a source language is related to the low-resource\ntarget language. However, not all language pairs are related. In this paper, we\npropose to build multilingual word embeddings (MWEs) via a novel language\nchain-based approach, that incorporates intermediate related languages to\nbridge the gap between the distant source and target. We build MWEs one\nlanguage at a time by starting from the resource rich source and sequentially\nadding each language in the chain till we reach the target. We extend a\nsemi-joint bilingual approach to multiple languages in order to eliminate the\nmain weakness of previous works, i.e., independently trained monolingual\nembeddings, by anchoring the target language around the multilingual space. We\nevaluate our method on bilingual lexicon induction for 4 language families,\ninvolving 4 very low-resource (<5M tokens) and 4 moderately low-resource (<50M)\ntarget languages, showing improved performance in both categories.\nAdditionally, our analysis reveals the importance of good quality embeddings\nfor intermediate languages as well as the importance of leveraging anchor\npoints from all languages in the multilingual space.\n","authors":["Viktor Hangya","Silvia Severini","Radoslav Ralev","Alexander Fraser","Hinrich Schütze"],"pdf_url":"https://arxiv.org/pdf/2311.12489v1.pdf","comment":"Accepted at the MRL 2023 workshop"},{"id":"http://arxiv.org/abs/2310.17940v3","updated":"2023-11-21T09:47:04Z","published":"2023-10-27T07:34:51Z","title":"Unified Segment-to-Segment Framework for Simultaneous Sequence\n  Generation","summary":"  Simultaneous sequence generation is a pivotal task for real-time scenarios,\nsuch as streaming speech recognition, simultaneous machine translation and\nsimultaneous speech translation, where the target sequence is generated while\nreceiving the source sequence. The crux of achieving high-quality generation\nwith low latency lies in identifying the optimal moments for generating,\naccomplished by learning a mapping between the source and target sequences.\nHowever, existing methods often rely on task-specific heuristics for different\nsequence types, limiting the model's capacity to adaptively learn the\nsource-target mapping and hindering the exploration of multi-task learning for\nvarious simultaneous tasks. In this paper, we propose a unified\nsegment-to-segment framework (Seg2Seg) for simultaneous sequence generation,\nwhich learns the mapping in an adaptive and unified manner. During the process\nof simultaneous generation, the model alternates between waiting for a source\nsegment and generating a target segment, making the segment serve as the\nnatural bridge between the source and target. To accomplish this, Seg2Seg\nintroduces a latent segment as the pivot between source to target and explores\nall potential source-target mappings via the proposed expectation training,\nthereby learning the optimal moments for generating. Experiments on multiple\nsimultaneous generation tasks demonstrate that Seg2Seg achieves\nstate-of-the-art performance and exhibits better generality across various\ntasks.\n","authors":["Shaolei Zhang","Yang Feng"],"pdf_url":"https://arxiv.org/pdf/2310.17940v3.pdf","comment":"Grammatical errors prevent the article from being indexed. This is\n  not a problem that can be solved by replacing a new version"},{"id":"http://arxiv.org/abs/2311.12480v1","updated":"2023-11-21T09:44:33Z","published":"2023-11-21T09:44:33Z","title":"Speaker-Adapted End-to-End Visual Speech Recognition for Continuous\n  Spanish","summary":"  Different studies have shown the importance of visual cues throughout the\nspeech perception process. In fact, the development of audiovisual approaches\nhas led to advances in the field of speech technologies. However, although\nnoticeable results have recently been achieved, visual speech recognition\nremains an open research problem. It is a task in which, by dispensing with the\nauditory sense, challenges such as visual ambiguities and the complexity of\nmodeling silence must be faced. Nonetheless, some of these challenges can be\nalleviated when the problem is approached from a speaker-dependent perspective.\nThus, this paper studies, using the Spanish LIP-RTVE database, how the\nestimation of specialized end-to-end systems for a specific person could affect\nthe quality of speech recognition. First, different adaptation strategies based\non the fine-tuning technique were proposed. Then, a pre-trained CTC/Attention\narchitecture was used as a baseline throughout our experiments. Our findings\nshowed that a two-step fine-tuning process, where the VSR system is first\nadapted to the task domain, provided significant improvements when the speaker\nadaptation was addressed. Furthermore, results comparable to the current state\nof the art were reached even when only a limited amount of data was available.\n","authors":["David Gimeno-Gómez","Carlos-D. Martínez-Hinarejos"],"pdf_url":"https://arxiv.org/pdf/2311.12480v1.pdf","comment":"Accepted in Proceedings of IberSpeech 2022 (\n  https://www.isca-speech.org/archive/iberspeech_2022/gimenogomez22_iberspeech.html\n  )"},{"id":"http://arxiv.org/abs/2311.12475v1","updated":"2023-11-21T09:37:42Z","published":"2023-11-21T09:37:42Z","title":"PhayaThaiBERT: Enhancing a Pretrained Thai Language Model with\n  Unassimilated Loanwords","summary":"  While WangchanBERTa has become the de facto standard in transformer-based\nThai language modeling, it still has shortcomings in regard to the\nunderstanding of foreign words, most notably English words, which are often\nborrowed without orthographic assimilation into Thai in many contexts. We\nidentify the lack of foreign vocabulary in WangchanBERTa's tokenizer as the\nmain source of these shortcomings. We then expand WangchanBERTa's vocabulary\nvia vocabulary transfer from XLM-R's pretrained tokenizer and pretrain a new\nmodel using the expanded tokenizer, starting from WangchanBERTa's checkpoint,\non a new dataset that is larger than the one used to train WangchanBERTa. Our\nresults show that our new pretrained model, PhayaThaiBERT, outperforms\nWangchanBERTa in many downstream tasks and datasets.\n","authors":["Panyut Sriwirote","Jalinee Thapiang","Vasan Timtong","Attapol T. Rutherford"],"pdf_url":"https://arxiv.org/pdf/2311.12475v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12474v1","updated":"2023-11-21T09:36:11Z","published":"2023-11-21T09:36:11Z","title":"CSMeD: Bridging the Dataset Gap in Automated Citation Screening for\n  Systematic Literature Reviews","summary":"  Systematic literature reviews (SLRs) play an essential role in summarising,\nsynthesising and validating scientific evidence. In recent years, there has\nbeen a growing interest in using machine learning techniques to automate the\nidentification of relevant studies for SLRs. However, the lack of standardised\nevaluation datasets makes comparing the performance of such automated\nliterature screening systems difficult. In this paper, we analyse the citation\nscreening evaluation datasets, revealing that many of the available datasets\nare either too small, suffer from data leakage or have limited applicability to\nsystems treating automated literature screening as a classification task, as\nopposed to, for example, a retrieval or question-answering task. To address\nthese challenges, we introduce CSMeD, a meta-dataset consolidating nine\npublicly released collections, providing unified access to 325 SLRs from the\nfields of medicine and computer science. CSMeD serves as a comprehensive\nresource for training and evaluating the performance of automated citation\nscreening models. Additionally, we introduce CSMeD-FT, a new dataset designed\nexplicitly for evaluating the full text publication screening task. To\ndemonstrate the utility of CSMeD, we conduct experiments and establish\nbaselines on new datasets.\n","authors":["Wojciech Kusa","Oscar E. Mendoza","Matthias Samwald","Petr Knoth","Allan Hanbury"],"pdf_url":"https://arxiv.org/pdf/2311.12474v1.pdf","comment":"Accepted at NeurIPS 2023 Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2311.12468v1","updated":"2023-11-21T09:28:00Z","published":"2023-11-21T09:28:00Z","title":"Analysis of Visual Features for Continuous Lipreading in Spanish","summary":"  During a conversation, our brain is responsible for combining information\nobtained from multiple senses in order to improve our ability to understand the\nmessage we are perceiving. Different studies have shown the importance of\npresenting visual information in these situations. Nevertheless, lipreading is\na complex task whose objective is to interpret speech when audio is not\navailable. By dispensing with a sense as crucial as hearing, it will be\nnecessary to be aware of the challenge that this lack presents. In this paper,\nwe propose an analysis of different speech visual features with the intention\nof identifying which of them is the best approach to capture the nature of lip\nmovements for natural Spanish and, in this way, dealing with the automatic\nvisual speech recognition task. In order to estimate our system, we present an\naudiovisual corpus compiled from a subset of the RTVE database, which has been\nused in the Albayz\\'in evaluations. We employ a traditional system based on\nHidden Markov Models with Gaussian Mixture Models. Results show that, although\nthe task is difficult, in restricted conditions we obtain recognition results\nwhich determine that using eigenlips in combination with deep features is the\nbest visual approach.\n","authors":["David Gimeno-Gómez","Carlos-D. Martínez-Hinarejos"],"pdf_url":"https://arxiv.org/pdf/2311.12468v1.pdf","comment":"Accepted in Proceedings of IberSpeech 2020 (\n  https://www.isca-speech.org/archive/iberspeech_2021/gimenogomez21_iberspeech.html\n  )"},{"id":"http://arxiv.org/abs/2310.18168v3","updated":"2023-11-21T09:19:03Z","published":"2023-10-27T14:27:43Z","title":"Personas as a Way to Model Truthfulness in Language Models","summary":"  Large Language Models (LLMs) are trained on vast amounts of text from the\ninternet, which contains both factual and misleading information about the\nworld. Can language models discern truth from falsehood in this contradicting\ndata? Expanding on the view that LLMs can model different communicative agents,\nwe present the persona hypothesis: LLMs can cluster agents into personas using\ncommon features of their generations. For instance, a truthful persona is a\ngroup of agents that are likely to produce truthful text and that share similar\nfeatures like formal writing styles and scientific references. By modeling this\npersona, LLMs can generalize truthfulness beyond the specific contexts in which\neach agent generated the training text. For example, the model can infer that\nthe agent ``Wikipedia'' will behave truthfully on topics that were only\ngenerated by ``Science'' because they both belong to the truthful persona. We\nshow evidence for the persona hypothesis via two observations: (1) we can probe\nwhether a model's answer will be truthful before it is generated; (2)\nfinetuning a model on a set of facts improves its truthfulness on unseen\ntopics. Next, using arithmetics as a synthetic environment, we show that\nlanguage models can separate true and false statements, and generalize\ntruthfulness across agents; but only if agents in the training data share a\ntruthful generative process that enables the creation of a truthful persona.\nOverall, our findings suggest that models can exploit hierarchical structures\nin the data to learn abstract concepts like truthfulness.\n","authors":["Nitish Joshi","Javier Rando","Abulhair Saparov","Najoung Kim","He He"],"pdf_url":"https://arxiv.org/pdf/2310.18168v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12457v1","updated":"2023-11-21T09:12:21Z","published":"2023-11-21T09:12:21Z","title":"LIP-RTVE: An Audiovisual Database for Continuous Spanish in the Wild","summary":"  Speech is considered as a multi-modal process where hearing and vision are\ntwo fundamentals pillars. In fact, several studies have demonstrated that the\nrobustness of Automatic Speech Recognition systems can be improved when audio\nand visual cues are combined to represent the nature of speech. In addition,\nVisual Speech Recognition, an open research problem whose purpose is to\ninterpret speech by reading the lips of the speaker, has been a focus of\ninterest in the last decades. Nevertheless, in order to estimate these systems\nin the currently Deep Learning era, large-scale databases are required. On the\nother hand, while most of these databases are dedicated to English, other\nlanguages lack sufficient resources. Thus, this paper presents a\nsemi-automatically annotated audiovisual database to deal with unconstrained\nnatural Spanish, providing 13 hours of data extracted from Spanish television.\nFurthermore, baseline results for both speaker-dependent and\nspeaker-independent scenarios are reported using Hidden Markov Models, a\ntraditional paradigm that has been widely used in the field of Speech\nTechnologies.\n","authors":["David Gimeno-Gómez","Carlos-D. Martínez-Hinarejos"],"pdf_url":"https://arxiv.org/pdf/2311.12457v1.pdf","comment":"Accepted in Proceedings of LREC 2022 (\n  https://aclanthology.org/2022.lrec-1.294 )"},{"id":"http://arxiv.org/abs/2311.12420v1","updated":"2023-11-21T08:20:39Z","published":"2023-11-21T08:20:39Z","title":"How Far Have We Gone in Vulnerability Detection Using Large Language\n  Models","summary":"  As software becomes increasingly complex and prone to vulnerabilities,\nautomated vulnerability detection is critically important, yet challenging.\nGiven the significant successes of Large Language Models (LLMs) in various\ntasks, there is growing anticipation of their efficacy in vulnerability\ndetection. However, a quantitative understanding of their potential in\nvulnerability detection is still missing. To bridge this gap, we introduce a\ncomprehensive vulnerability benchmark VulBench. This benchmark aggregates\nhigh-quality data from a wide range of CTF (Capture-the-Flag) challenges and\nreal-world applications, with annotations for each vulnerable function\ndetailing the vulnerability type and its root cause. Through our experiments\nencompassing 16 LLMs and 6 state-of-the-art (SOTA) deep learning-based models\nand static analyzers, we find that several LLMs outperform traditional deep\nlearning approaches in vulnerability detection, revealing an untapped potential\nin LLMs. This work contributes to the understanding and utilization of LLMs for\nenhanced software security.\n","authors":["Zeyu Gao","Hao Wang","Yuchen Zhou","Wenyu Zhu","Chao Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12418v1","updated":"2023-11-21T08:15:01Z","published":"2023-11-21T08:15:01Z","title":"Visual Analytics for Generative Transformer Models","summary":"  While transformer-based models have achieved state-of-the-art results in a\nvariety of classification and generation tasks, their black-box nature makes\nthem challenging for interpretability. In this work, we present a novel visual\nanalytical framework to support the analysis of transformer-based generative\nnetworks. In contrast to previous work, which has mainly focused on\nencoder-based models, our framework is one of the first dedicated to supporting\nthe analysis of transformer-based encoder-decoder models and decoder-only\nmodels for generative and classification tasks. Hence, we offer an intuitive\noverview that allows the user to explore different facets of the model through\ninteractive visualization. To demonstrate the feasibility and usefulness of our\nframework, we present three detailed case studies based on real-world NLP\nresearch problems.\n","authors":["Raymond Li","Ruixin Yang","Wen Xiao","Ahmed AbuRaed","Gabriel Murray","Giuseppe Carenini"],"pdf_url":"https://arxiv.org/pdf/2311.12418v1.pdf","comment":"6 pages (reference excluded), 7 figures"},{"id":"http://arxiv.org/abs/2311.12410v1","updated":"2023-11-21T07:56:30Z","published":"2023-11-21T07:56:30Z","title":"nach0: Multimodal Natural and Chemical Languages Foundation Model","summary":"  Large Language Models (LLMs) have substantially driven scientific progress in\nvarious domains, and many papers have demonstrated their ability to tackle\ncomplex problems with creative solutions. Our paper introduces a new foundation\nmodel, nach0, capable of solving various chemical and biological tasks:\nbiomedical question answering, named entity recognition, molecular generation,\nmolecular synthesis, attributes prediction, and others. nach0 is a multi-domain\nand multi-task encoder-decoder LLM pre-trained on unlabeled text from\nscientific literature, patents, and molecule strings to incorporate a range of\nchemical and linguistic knowledge. We employed instruction tuning, where\nspecific task-related instructions are utilized to fine-tune nach0 for the\nfinal set of tasks. To train nach0 effectively, we leverage the NeMo framework,\nenabling efficient parallel optimization of both base and large model versions.\nExtensive experiments demonstrate that our model outperforms state-of-the-art\nbaselines on single-domain and cross-domain tasks. Furthermore, it can generate\nhigh-quality outputs in molecular and textual formats, showcasing its\neffectiveness in multi-domain setups.\n","authors":["Micha Livne","Zulfat Miftahutdinov","Elena Tutubalina","Maksim Kuznetsov","Daniil Polykovskiy","Annika Brundyn","Aastha Jhunjhunwala","Anthony Costa","Alex Aliper","Alex Zhavoronkov"],"pdf_url":"https://arxiv.org/pdf/2311.12410v1.pdf","comment":"Submitted to Nature Communications"},{"id":"http://arxiv.org/abs/2310.07161v2","updated":"2023-11-21T07:54:34Z","published":"2023-10-11T03:19:22Z","title":"Psychoacoustic Challenges Of Speech Enhancement On VoIP Platforms","summary":"  Within the ambit of VoIP (Voice over Internet Protocol) telecommunications,\nthe complexities introduced by acoustic transformations merit rigorous\nanalysis. This research, rooted in the exploration of proprietary sender-side\ndenoising effects, meticulously evaluates platforms such as Google Meets and\nZoom. The study draws upon the Deep Noise Suppression (DNS) 2020 dataset,\nensuring a structured examination tailored to various denoising settings and\nreceiver interfaces. A methodological novelty is introduced via the Oaxaca\ndecomposition, traditionally an econometric tool, repurposed herein to analyze\nacoustic-phonetic perturbations within VoIP systems. To further ground the\nimplications of these transformations, psychoacoustic metrics, specifically\nPESQ and STOI, were harnessed to furnish a comprehensive understanding of\nspeech alterations. Cumulatively, the insights garnered underscore the\nintricate landscape of VoIP-influenced acoustic dynamics. In addition to the\nprimary findings, a multitude of metrics are reported, extending the research\npurview. Moreover, out-of-domain benchmarking for both time and time-frequency\ndomain speech enhancement models is included, thereby enhancing the depth and\napplicability of this inquiry. Repository:\ngithub.com/deepology/VoIP-DNS-Challenge\n","authors":["Joseph Konan","Ojas Bhargave","Shikhar Agnihotri","Shuo Han","Yunyang Zeng","Ankit Shah","Bhiksha Raj"],"pdf_url":"https://arxiv.org/pdf/2310.07161v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12405v1","updated":"2023-11-21T07:50:53Z","published":"2023-11-21T07:50:53Z","title":"IndoRobusta: Towards Robustness Against Diverse Code-Mixed Indonesian\n  Local Languages","summary":"  Significant progress has been made on Indonesian NLP. Nevertheless,\nexploration of the code-mixing phenomenon in Indonesian is limited, despite\nmany languages being frequently mixed with Indonesian in daily conversation. In\nthis work, we explore code-mixing in Indonesian with four embedded languages,\ni.e., English, Sundanese, Javanese, and Malay; and introduce IndoRobusta, a\nframework to evaluate and improve the code-mixing robustness. Our analysis\nshows that the pre-training corpus bias affects the model's ability to better\nhandle Indonesian-English code-mixing when compared to other local languages,\ndespite having higher language diversity.\n","authors":["Muhammad Farid Adilazuarda","Samuel Cahyawijaya","Genta Indra Winata","Pascale Fung","Ayu Purwarianti"],"pdf_url":"https://arxiv.org/pdf/2311.12405v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12404v1","updated":"2023-11-21T07:43:50Z","published":"2023-11-21T07:43:50Z","title":"InterPrompt: Interpretable Prompting for Interrelated Interpersonal Risk\n  Factors in Reddit Posts","summary":"  Mental health professionals and clinicians have observed the upsurge of\nmental disorders due to Interpersonal Risk Factors (IRFs). To simulate the\nhuman-in-the-loop triaging scenario for early detection of mental health\ndisorders, we recognized textual indications to ascertain these IRFs : Thwarted\nBelongingness (TBe) and Perceived Burdensomeness (PBu) within personal\nnarratives. In light of this, we use N-shot learning with GPT-3 model on the\nIRF dataset, and underscored the importance of fine-tuning GPT-3 model to\nincorporate the context-specific sensitivity and the interconnectedness of\ntextual cues that represent both IRFs.\n  In this paper, we introduce an Interpretable Prompting (InterPrompt)} method\nto boost the attention mechanism by fine-tuning the GPT-3 model. This allows a\nmore sophisticated level of language modification by adjusting the pre-trained\nweights. Our model learns to detect usual patterns and underlying connections\nacross both the IRFs, which leads to better system-level explainability and\ntrustworthiness. The results of our research demonstrate that all four variants\nof GPT-3 model, when fine-tuned with InterPrompt, perform considerably better\nas compared to the baseline methods, both in terms of classification and\nexplanation generation.\n","authors":["MSVPJ Sathvik","Surjodeep Sarkar","Chandni Saxena","Sunghwan Sohn","Muskan Garg"],"pdf_url":"https://arxiv.org/pdf/2311.12404v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2311.12399v1","updated":"2023-11-21T07:22:48Z","published":"2023-11-21T07:22:48Z","title":"A Survey of Graph Meets Large Language Model: Progress and Future\n  Directions","summary":"  Graph plays a significant role in representing and analyzing complex\nrelationships in real-world applications such as citation networks, social\nnetworks, and biological data. Recently, Large Language Models (LLMs), which\nhave achieved tremendous success in various domains, have also been leveraged\nin graph-related tasks to surpass traditional Graph Neural Networks (GNNs)\nbased methods and yield state-of-the-art performance. In this survey, we first\npresent a comprehensive review and analysis of existing methods that integrate\nLLMs with graphs. First of all, we propose a new taxonomy, which organizes\nexisting methods into three categories based on the role (i.e., enhancer,\npredictor, and alignment component) played by LLMs in graph-related tasks. Then\nwe systematically survey the representative methods along the three categories\nof the taxonomy. Finally, we discuss the remaining limitations of existing\nstudies and highlight promising avenues for future research. The relevant\npapers are summarized and will be consistently updated at:\nhttps://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks.\n","authors":["Yuhan Li","Zhixun Li","Peisong Wang","Jia Li","Xiangguo Sun","Hong Cheng","Jeffrey Xu Yu"],"pdf_url":"https://arxiv.org/pdf/2311.12399v1.pdf","comment":"Work in progress; 13 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.10777v2","updated":"2023-11-21T07:15:57Z","published":"2023-11-16T06:01:47Z","title":"A Systematic Review of Aspect-based Sentiment Analysis (ABSA): Domains,\n  Methods, and Trends","summary":"  Aspect-based Sentiment Analysis (ABSA) is a type of fine-grained sentiment\nanalysis (SA) that identifies aspects and the associated opinions from a given\ntext. In the digital era, ABSA gained increasing popularity and applications in\nmining opinionated text data to obtain insights and support decisions. ABSA\nresearch employs linguistic, statistical, and machine-learning approaches and\nutilises resources such as labelled datasets, aspect and sentiment lexicons and\nontology. By its nature, ABSA is domain-dependent and can be sensitive to the\nimpact of misalignment between the resource and application domains. However,\nto our knowledge, this topic has not been explored by the existing ABSA\nliterature reviews. In this paper, we present a Systematic Literature Review\n(SLR) of ABSA studies with a focus on the research application domain, dataset\ndomain, and the research methods to examine their relationships and identify\ntrends over time. Our results suggest a number of potential systemic issues in\nthe ABSA research literature, including the predominance of the\n``product/service review'' dataset domain among the majority of studies that\ndid not have a specific research application domain, coupled with the\nprevalence of dataset-reliant methods such as supervised machine learning. This\nreview makes a number of unique contributions to the ABSA research field: 1) To\nour knowledge, it is the first SLR that links the research domain, dataset\ndomain, and research method through a systematic perspective; 2) it is one of\nthe largest scoped SLR on ABSA, with 519 eligible studies filtered from 4191\nsearch results without time constraint; and 3) our review methodology adopted\nan innovative automatic filtering process based on PDF-mining, which enhanced\nscreening quality and reliability. Suggestions and our review limitations are\nalso discussed.\n","authors":["Yan Cathy Hua","Paul Denny","Katerina Taskova","Jörg Wicker"],"pdf_url":"https://arxiv.org/pdf/2311.10777v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12395v1","updated":"2023-11-21T07:11:39Z","published":"2023-11-21T07:11:39Z","title":"Problems of Non-equivalent Words in Technical Translation","summary":"  Translating words which do not have equivalent in target language is not easy\nand finding proper equivalent of those words are very important to render\ncorrectly and understandably, the article defines some thoughts and ideas of\nscientists on the common problems of non-equivalent words from English to\nRussian language and includes English and Russian examples and ideas of certain\nscientist. The English language is worldwide spoken and there are 1.35 billion\nEnglish speakers and over 258 million Russian speakers according to the 2021s\nstatistics. Inevitably, these billions of speakers around the world have\nconnection and they may have deal in different criteria. In order to understand\none another they need to have a pure and fully-understood language. These pure\nlanguages understanding directly relates to translation knowledge where\nlinguists and translators need to work and research to eradicate\nmisunderstanding. Misunderstandings mostly appear in non-equivalent words\nbecause there are different local and internal words like food, garment,\ncultural and traditional words and others in every notion. Truly, most of these\nwords do not have equivalent in the target language and these words need to be\nworked and find their equivalent in the target language to fully understand the\nboth languages. However, some of these non-equivalent words are already\nprofessionally rendered to the target language but still there many other words\nto be rendered. Hence, this research paper includes different ways and rules of\nrendering non-equivalent words from source language to the target language.\n","authors":["Mohammad Ibrahim Qani"],"pdf_url":"https://arxiv.org/pdf/2311.12395v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2311.10770v2","updated":"2023-11-21T06:59:59Z","published":"2023-11-15T18:42:50Z","title":"Exponentially Faster Language Modelling","summary":"  Language models only really need to use an exponential fraction of their\nneurons for individual inferences. As proof, we present UltraFastBERT, a BERT\nvariant that uses 0.3% of its neurons during inference while performing on par\nwith similar BERT models. UltraFastBERT selectively engages just 12 out of 4095\nneurons for each layer inference. This is achieved by replacing feedforward\nnetworks with fast feedforward networks (FFFs). While no truly efficient\nimplementation currently exists to unlock the full acceleration potential of\nconditional neural execution, we provide high-level CPU code achieving 78x\nspeedup over the optimized baseline feedforward implementation, and a PyTorch\nimplementation delivering 40x speedup over the equivalent batched feedforward\ninference. We publish our training code, benchmarking setup, and model weights.\n","authors":["Peter Belcak","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2311.10770v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12375v1","updated":"2023-11-21T06:27:25Z","published":"2023-11-21T06:27:25Z","title":"The Obscure Limitation of Modular Multilingual Language Models","summary":"  We expose the limitation of modular multilingual language models (MLMs) in\nmultilingual inference scenarios with unknown languages. Existing evaluations\nof modular MLMs exclude the involvement of language identification (LID)\nmodules, which obscures the performance of real-case multilingual scenarios of\nmodular MLMs. In this work, we showcase the effect of adding LID on the\nmultilingual evaluation of modular MLMs and provide discussions for closing the\nperformance gap of caused by the pipelined approach of LID and modular MLMs.\n","authors":["Muhammad Farid Adilazuarda","Samuel Cahyawijaya","Ayu Purwarianti"],"pdf_url":"https://arxiv.org/pdf/2311.12375v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12373v1","updated":"2023-11-21T06:23:38Z","published":"2023-11-21T06:23:38Z","title":"Beyond Turing: A Comparative Analysis of Approaches for Detecting\n  Machine-Generated Text","summary":"  Significant progress has been made on text generation by pre-trained language\nmodels (PLMs), yet distinguishing between human and machine-generated text\nposes an escalating challenge. This paper offers an in-depth evaluation of\nthree distinct methods used to address this task: traditional shallow learning,\nLanguage Model (LM) fine-tuning, and Multilingual Model fine-tuning. These\napproaches are rigorously tested on a wide range of machine-generated texts,\nproviding a benchmark of their competence in distinguishing between\nhuman-authored and machine-authored linguistic constructs. The results reveal\nconsiderable differences in performance across methods, thus emphasizing the\ncontinued need for advancement in this crucial area of NLP. This study offers\nvaluable insights and paves the way for future research aimed at creating\nrobust and highly discriminative models.\n","authors":["Muhammad Farid Adilazuarda","Nikolaos Nektarios Arkoulis","Oleksii Chumakov"],"pdf_url":"https://arxiv.org/pdf/2311.12373v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12355v1","updated":"2023-11-21T05:15:56Z","published":"2023-11-21T05:15:56Z","title":"Utilizing Language Models for Tour Itinerary Recommendation","summary":"  Tour itinerary recommendation involves planning a sequence of relevant\nPoint-of-Interest (POIs), which combines challenges from the fields of both\nOperations Research (OR) and Recommendation Systems (RS). As an OR problem,\nthere is the need to maximize a certain utility (e.g., popularity of POIs in\nthe tour) while adhering to some constraints (e.g., maximum time for the tour).\nAs a RS problem, it is heavily related to problem or filtering or ranking a\nsubset of POIs that are relevant to a user and recommending it as part of an\nitinerary. In this paper, we explore the use of language models for the task of\ntour itinerary recommendation and planning. This task has the unique\nrequirement of recommending personalized POIs relevant to users and planning\nthese POIs as an itinerary that satisfies various constraints. We discuss some\napproaches in this area, such as using word embedding techniques like Word2Vec\nand GloVe for learning POI embeddings and transformer-based techniques like\nBERT for generating\n  itineraries.\n","authors":["Ngai Lam Ho","Kwan Hui Lim"],"pdf_url":"https://arxiv.org/pdf/2311.12355v1.pdf","comment":"PMAI23 @IJCAI 2023 2nd International Workshop on Process Management\n  in the AI era"},{"id":"http://arxiv.org/abs/2309.17453v2","updated":"2023-11-21T05:04:49Z","published":"2023-09-29T17:59:56Z","title":"Efficient Streaming Language Models with Attention Sinks","summary":"  Deploying Large Language Models (LLMs) in streaming applications such as\nmulti-round dialogue, where long interactions are expected, is urgently needed\nbut poses two major challenges. Firstly, during the decoding stage, caching\nprevious tokens' Key and Value states (KV) consumes extensive memory. Secondly,\npopular LLMs cannot generalize to longer texts than the training sequence\nlength. Window attention, where only the most recent KVs are cached, is a\nnatural approach -- but we show that it fails when the text length surpasses\nthe cache size. We observe an interesting phenomenon, namely attention sink,\nthat keeping the KV of initial tokens will largely recover the performance of\nwindow attention. In this paper, we first demonstrate that the emergence of\nattention sink is due to the strong attention scores towards initial tokens as\na ``sink'' even if they are not semantically important. Based on the above\nanalysis, we introduce StreamingLLM, an efficient framework that enables LLMs\ntrained with a finite length attention window to generalize to infinite\nsequence lengths without any fine-tuning. We show that StreamingLLM can enable\nLlama-2, MPT, Falcon, and Pythia to perform stable and efficient language\nmodeling with up to 4 million tokens and more. In addition, we discover that\nadding a placeholder token as a dedicated attention sink during pre-training\ncan further improve streaming deployment. In streaming settings, StreamingLLM\noutperforms the sliding window recomputation baseline by up to 22.2x speedup.\nCode and datasets are provided at https://github.com/mit-han-lab/streaming-llm.\n","authors":["Guangxuan Xiao","Yuandong Tian","Beidi Chen","Song Han","Mike Lewis"],"pdf_url":"https://arxiv.org/pdf/2309.17453v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12351v1","updated":"2023-11-21T04:59:17Z","published":"2023-11-21T04:59:17Z","title":"Advancing Transformer Architecture in Long-Context Large Language\n  Models: A Comprehensive Survey","summary":"  With the bomb ignited by ChatGPT, Transformer-based Large Language Models\n(LLMs) have paved a revolutionary path toward Artificial General Intelligence\n(AGI) and have been applied in diverse areas as knowledge bases, human\ninterfaces, and dynamic agents. However, a prevailing limitation exists: many\ncurrent LLMs, constrained by resources, are primarily pre-trained on shorter\ntexts, rendering them less effective for longer-context prompts, commonly\nencountered in real-world settings. In this paper, we present a comprehensive\nsurvey focusing on the advancement of model architecture in Transformer-based\nLLMs to optimize long-context capabilities across all stages from pre-training\nto inference. We firstly delineate and analyze the problems of handling\nlong-context input and output with the current Transformer-based models. Then,\nwe mainly offer a holistic taxonomy to navigate the landscape of Transformer\nupgrades on architecture to solve these problems. Afterward, we provide the\ninvestigation on wildly used evaluation necessities tailored for long-context\nLLMs, including datasets, metrics, and baseline models, as well as some amazing\noptimization toolkits like libraries, systems, and compilers to augment LLMs'\nefficiency and efficacy across different stages. Finally, we further discuss\nthe predominant challenges and potential avenues for future research in this\ndomain. Additionally, we have established a repository where we curate relevant\nliterature with real-time updates at\nhttps://github.com/Strivin0311/long-llms-learning.\n","authors":["Yunpeng Huang","Jingwei Xu","Zixu Jiang","Junyu Lai","Zenan Li","Yuan Yao","Taolue Chen","Lijuan Yang","Zhou Xin","Xiaoxing Ma"],"pdf_url":"https://arxiv.org/pdf/2311.12351v1.pdf","comment":"35 pages, 3 figures, 4 tables"},{"id":"http://arxiv.org/abs/2311.12337v1","updated":"2023-11-21T04:06:08Z","published":"2023-11-21T04:06:08Z","title":"Do Smaller Language Models Answer Contextualised Questions Through\n  Memorisation Or Generalisation?","summary":"  A distinction is often drawn between a model's ability to predict a label for\nan evaluation sample that is directly memorised from highly similar training\nsamples versus an ability to predict the label via some method of\ngeneralisation. In the context of using Language Models for question-answering,\ndiscussion continues to occur as to the extent to which questions are answered\nthrough memorisation. We consider this issue for questions that would ideally\nbe answered through reasoning over an associated context. We propose a method\nof identifying evaluation samples for which it is very unlikely our model would\nhave memorised the answers. Our method is based on semantic similarity of input\ntokens and label tokens between training and evaluation samples. We show that\nour method offers advantages upon some prior approaches in that it is able to\nsurface evaluation-train pairs that have overlap in either contiguous or\ndiscontiguous sequences of tokens. We use this method to identify unmemorisable\nsubsets of our evaluation datasets. We train two Language Models in a multitask\nfashion whereby the second model differs from the first only in that it has two\nadditional datasets added to the training regime that are designed to impart\nsimple numerical reasoning strategies of a sort known to improve performance on\nsome of our evaluation datasets but not on others. We then show that there is\nperformance improvement between the two models on the unmemorisable subsets of\nthe evaluation datasets that were expected to benefit from the additional\ntraining datasets. Specifically, performance on unmemorisable subsets of two of\nour evaluation datasets, DROP and ROPES significantly improves by 9.0%, and\n25.7% respectively while other evaluation datasets have no significant change\nin performance.\n","authors":["Tim Hartill","Joshua Bensemann","Michael Witbrock","Patricia J. Riddle"],"pdf_url":"https://arxiv.org/pdf/2311.12337v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12323v1","updated":"2023-11-21T03:34:20Z","published":"2023-11-21T03:34:20Z","title":"Modeling Political Orientation of Social Media Posts: An Extended\n  Analysis","summary":"  Developing machine learning models to characterize political polarization on\nonline social media presents significant challenges. These challenges mainly\nstem from various factors such as the lack of annotated data, presence of noise\nin social media datasets, and the sheer volume of data. The common research\npractice typically examines the biased structure of online user communities for\na given topic or qualitatively measuring the impacts of polarized topics on\nsocial media. However, there is limited work focusing on analyzing polarization\nat the ground-level, specifically in the social media posts themselves. Such\nexisting analysis heavily relies on annotated data, which often requires\nlaborious human labeling, offers labels only to specific problems, and lacks\nthe ability to determine the near-future bias state of a social media\nconversations. Understanding the degree of political orientation conveyed in\nsocial media posts is crucial for quantifying the bias of online user\ncommunities and investigating the spread of polarized content. In this work, we\nfirst introduce two heuristic methods that leverage on news media bias and post\ncontent to label social media posts. Next, we compare the efficacy and quality\nof heuristically labeled dataset with a randomly sampled human-annotated\ndataset. Additionally, we demonstrate that current machine learning models can\nexhibit improved performance in predicting political orientation of social\nmedia posts, employing both traditional supervised learning and few-shot\nlearning setups. We conduct experiments using the proposed heuristic methods\nand machine learning approaches to predict the political orientation of posts\ncollected from two social media forums with diverse political ideologies: Gab\nand Twitter.\n","authors":["Sadia Kamal","Brenner Little","Jade Gullic","Trevor Harms","Kristin Olofsson","Arunkumar Bagavathi"],"pdf_url":"https://arxiv.org/pdf/2311.12323v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12315v1","updated":"2023-11-21T03:17:14Z","published":"2023-11-21T03:17:14Z","title":"AcademicGPT: Empowering Academic Research","summary":"  Large Language Models (LLMs) have demonstrated exceptional capabilities\nacross various natural language processing tasks. Yet, many of these advanced\nLLMs are tailored for broad, general-purpose applications. In this technical\nreport, we introduce AcademicGPT, designed specifically to empower academic\nresearch. AcademicGPT is a continual training model derived from LLaMA2-70B.\nOur training corpus mainly consists of academic papers, thesis, content from\nsome academic domain, high-quality Chinese data and others. While it may not be\nextensive in data scale, AcademicGPT marks our initial venture into a\ndomain-specific GPT tailored for research area. We evaluate AcademicGPT on\nseveral established public benchmarks such as MMLU and CEval, as well as on\nsome specialized academic benchmarks like PubMedQA, SCIEval, and our\nnewly-created ComputerScienceQA, to demonstrate its ability from general\nknowledge ability, to Chinese ability, and to academic ability. Building upon\nAcademicGPT's foundation model, we also developed several applications catered\nto the academic area, including General Academic Question Answering,\nAI-assisted Paper Reading, Paper Review, and AI-assisted Title and Abstract\nGeneration.\n","authors":["Shufa Wei","Xiaolong Xu","Xianbiao Qi","Xi Yin","Jun Xia","Jingyi Ren","Peijun Tang","Yuxiang Zhong","Yihao Chen","Xiaoqin Ren","Yuxin Liang","Liankai Huang","Kai Xie","Weikang Gui","Wei Tan","Shuanglong Sun","Yongquan Hu","Qinxian Liu","Nanjin Li","Chihao Dai","Lihua Wang","Xiaohui Liu","Lei Zhang","Yutao Xie"],"pdf_url":"https://arxiv.org/pdf/2311.12315v1.pdf","comment":"Technical Report. arXiv admin note: text overlap with\n  arXiv:2310.12081, arXiv:2310.10053 by other authors"},{"id":"http://arxiv.org/abs/2304.03898v2","updated":"2023-11-21T02:39:06Z","published":"2023-04-08T03:24:05Z","title":"The Short Text Matching Model Enhanced with Knowledge via Contrastive\n  Learning","summary":"  In recent years, short Text Matching tasks have been widely applied in the\nfields ofadvertising search and recommendation. The difficulty lies in the lack\nof semantic information and word ambiguity caused by the short length of the\ntext. Previous works have introduced complement sentences or knowledge bases to\nprovide additional feature information. However, these methods have not fully\ninteracted between the original sentence and the complement sentence, and have\nnot considered the noise issue that may arise from the introduction of external\nknowledge bases. Therefore, this paper proposes a short Text Matching model\nthat combines contrastive learning and external knowledge. The model uses a\ngenerative model to generate corresponding complement sentences and uses the\ncontrastive learning method to guide the model to obtain more semantically\nmeaningful encoding of the original sentence. In addition, to avoid noise, we\nuse keywords as the main semantics of the original sentence to retrieve\ncorresponding knowledge words in the knowledge base, and construct a knowledge\ngraph. The graph encoding model is used to integrate the knowledge base\ninformation into the model. Our designed model achieves state-of-the-art\nperformance on two publicly available Chinese Text Matching datasets,\ndemonstrating the effectiveness of our model.\n","authors":["Ruiqiang Liu","Mengmeng Cui","Hanjie Mai","Qiang Zhang","Shaohua Xu","Xiangzheng Liu","Yanlong Du"],"pdf_url":"https://arxiv.org/pdf/2304.03898v2.pdf","comment":"11 pages,2 figures"},{"id":"http://arxiv.org/abs/2311.12298v1","updated":"2023-11-21T02:35:09Z","published":"2023-11-21T02:35:09Z","title":"Noise in Relation Classification Dataset TACRED: Characterization and\n  Reduction","summary":"  The overarching objective of this paper is two-fold. First, to explore\nmodel-based approaches to characterize the primary cause of the noise. in the\nRE dataset TACRED Second, to identify the potentially noisy instances. Towards\nthe first objective, we analyze predictions and performance of state-of-the-art\n(SOTA) models to identify the root cause of noise in the dataset. Our analysis\nof TACRED shows that the majority of the noise in the dataset originates from\nthe instances labeled as no-relation which are negative examples. For the\nsecond objective, we explore two nearest-neighbor-based strategies to\nautomatically identify potentially noisy examples for elimination and\nreannotation. Our first strategy, referred to as Intrinsic Strategy (IS), is\nbased on the assumption that positive examples are clean. Thus, we have used\nfalse-negative predictions to identify noisy negative examples. Whereas, our\nsecond approach, referred to as Extrinsic Strategy, is based on using a clean\nsubset of the dataset to identify potentially noisy negative examples. Finally,\nwe retrained the SOTA models on the eliminated and reannotated dataset. Our\nempirical results based on two SOTA models trained on TACRED-E following the IS\nshow an average 4% F1-score improvement, whereas reannotation (TACRED-R) does\nnot improve the original results. However, following ES, SOTA models show the\naverage F1-score improvement of 3.8% and 4.4% when trained on respective\neliminated (TACRED-EN) and reannotated (TACRED-RN) datasets respectively. We\nfurther extended the ES for cleaning positive examples as well, which resulted\nin an average performance improvement of 5.8% and 5.6% for the eliminated\n(TACRED-ENP) and reannotated (TACRED-RNP) datasets respectively.\n","authors":["Akshay Parekh","Ashish Anand","Amit Awekar"],"pdf_url":"https://arxiv.org/pdf/2311.12298v1.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2311.10899v2","updated":"2023-11-21T02:16:27Z","published":"2023-11-17T22:44:05Z","title":"Extraction and Summarization of Explicit Video Content using Multi-Modal\n  Deep Learning","summary":"  With the increase in video-sharing platforms across the internet, it is\ndifficult for humans to moderate the data for explicit content. Hence, an\nautomated pipeline to scan through video data for explicit content has become\nthe need of the hour. We propose a novel pipeline that uses multi-modal deep\nlearning to first extract the explicit segments of input videos and then\nsummarize their content using text to determine its age appropriateness and age\nrating. We also evaluate our pipeline's effectiveness in the end using standard\nmetrics.\n","authors":["Shaunak Joshi","Raghav Gaggar"],"pdf_url":"https://arxiv.org/pdf/2311.10899v2.pdf","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.12289v1","updated":"2023-11-21T02:02:46Z","published":"2023-11-21T02:02:46Z","title":"ATLANTIC: Structure-Aware Retrieval-Augmented Language Model for\n  Interdisciplinary Science","summary":"  Large language models record impressive performance on many natural language\nprocessing tasks. However, their knowledge capacity is limited to the\npretraining corpus. Retrieval augmentation offers an effective solution by\nretrieving context from external knowledge sources to complement the language\nmodel. However, existing retrieval augmentation techniques ignore the\nstructural relationships between these documents. Furthermore, retrieval models\nare not explored much in scientific tasks, especially in regard to the\nfaithfulness of retrieved documents. In this paper, we propose a novel\nstructure-aware retrieval augmented language model that accommodates document\nstructure during retrieval augmentation. We create a heterogeneous document\ngraph capturing multiple types of relationships (e.g., citation, co-authorship,\netc.) that connect documents from more than 15 scientific disciplines (e.g.,\nPhysics, Medicine, Chemistry, etc.). We train a graph neural network on the\ncurated document graph to act as a structural encoder for the corresponding\npassages retrieved during the model pretraining. Particularly, along with text\nembeddings of the retrieved passages, we obtain structural embeddings of the\ndocuments (passages) and fuse them together before feeding them to the language\nmodel. We evaluate our model extensively on various scientific benchmarks that\ninclude science question-answering and scientific document classification\ntasks. Experimental results demonstrate that structure-aware retrieval improves\nretrieving more coherent, faithful and contextually relevant passages, while\nshowing a comparable performance in the overall accuracy.\n","authors":["Sai Munikoti","Anurag Acharya","Sridevi Wagle","Sameera Horawalavithana"],"pdf_url":"https://arxiv.org/pdf/2311.12289v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.10429v4","updated":"2023-11-21T02:01:53Z","published":"2023-05-17T17:58:13Z","title":"DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining","summary":"  The mixture proportions of pretraining data domains (e.g., Wikipedia, books,\nweb text) greatly affect language model (LM) performance. In this paper, we\npropose Domain Reweighting with Minimax Optimization (DoReMi), which first\ntrains a small proxy model using group distributionally robust optimization\n(Group DRO) over domains to produce domain weights (mixture proportions)\nwithout knowledge of downstream tasks. We then resample a dataset with these\ndomain weights and train a larger, full-sized model. In our experiments, we use\nDoReMi on a 280M-parameter proxy model to set the domain weights for training\nan 8B-parameter model (30x larger) more efficiently. On The Pile, DoReMi\nimproves perplexity across all domains, even when it downweights a domain.\nDoReMi improves average few-shot downstream accuracy by 6.5% points over a\nbaseline model trained using The Pile's default domain weights and reaches the\nbaseline accuracy with 2.6x fewer training steps. On the GLaM dataset, DoReMi,\nwhich has no knowledge of downstream tasks, even matches the performance of\nusing domain weights tuned on downstream tasks.\n","authors":["Sang Michael Xie","Hieu Pham","Xuanyi Dong","Nan Du","Hanxiao Liu","Yifeng Lu","Percy Liang","Quoc V. Le","Tengyu Ma","Adams Wei Yu"],"pdf_url":"https://arxiv.org/pdf/2305.10429v4.pdf","comment":"NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.12275v1","updated":"2023-11-21T01:34:02Z","published":"2023-11-21T01:34:02Z","title":"Enabling On-Device Large Language Model Personalization with\n  Self-Supervised Data Selection and Synthesis","summary":"  After a large language model (LLM) is deployed on edge devices, it is\ndesirable for these devices to learn from user-generated conversation data to\ngenerate user-specific and personalized responses in real-time. However,\nuser-generated data usually contains sensitive and private information, and\nuploading such data to the cloud for annotation is not preferred if not\nprohibited. While it is possible to obtain annotation locally by directly\nasking users to provide preferred responses, such annotations have to be sparse\nto not affect user experience. In addition, the storage of edge devices is\nusually too limited to enable large-scale fine-tuning with full user-generated\ndata. It remains an open question how to enable on-device LLM personalization,\nconsidering sparse annotation and limited on-device storage. In this paper, we\npropose a novel framework to select and store the most representative data\nonline in a self-supervised way. Such data has a small memory footprint and\nallows infrequent requests of user annotations for further fine-tuning. To\nenhance fine-tuning quality, multiple semantically similar pairs of question\ntexts and expected responses are generated using the LLM. Our experiments show\nthat the proposed framework achieves the best user-specific content-generating\ncapability (accuracy) and fine-tuning speed (performance) compared with vanilla\nbaselines. To the best of our knowledge, this is the very first on-device LLM\npersonalization framework.\n","authors":["Ruiyang Qin","Jun Xia","Zhenge Jia","Meng Jiang","Ahmed Abbasi","Peipei Zhou","Jingtong Hu","Yiyu Shi"],"pdf_url":"https://arxiv.org/pdf/2311.12275v1.pdf","comment":"6 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2311.13061v1","updated":"2023-11-21T23:50:33Z","published":"2023-11-21T23:50:33Z","title":"Attribution and Alignment: Effects of Local Context Repetition on\n  Utterance Production and Comprehension in Dialogue","summary":"  Language models are often used as the backbone of modern dialogue systems.\nThese models are pre-trained on large amounts of written fluent language.\nRepetition is typically penalised when evaluating language model generations.\nHowever, it is a key component of dialogue. Humans use local and partner\nspecific repetitions; these are preferred by human users and lead to more\nsuccessful communication in dialogue. In this study, we evaluate (a) whether\nlanguage models produce human-like levels of repetition in dialogue, and (b)\nwhat are the processing mechanisms related to lexical re-use they use during\ncomprehension. We believe that such joint analysis of model production and\ncomprehension behaviour can inform the development of cognitively inspired\ndialogue generation systems.\n","authors":["Aron Molnar","Jaap Jumelet","Mario Giulianelli","Arabella Sinclair"],"pdf_url":"https://arxiv.org/pdf/2311.13061v1.pdf","comment":"CoNLL 2023"},{"id":"http://arxiv.org/abs/2311.13053v1","updated":"2023-11-21T23:26:05Z","published":"2023-11-21T23:26:05Z","title":"Beyond Text: Unveiling Multimodal Proficiency of Large Language Models\n  with MultiAPI Benchmark","summary":"  The proliferation of Large Language Models like ChatGPT has significantly\nadvanced language understanding and generation, impacting a broad spectrum of\napplications. However, these models predominantly excel in text-based tasks,\noverlooking the complexity of real-world multimodal information. This study\nintroduces MultiAPI, a pioneering comprehensive large-scale API benchmark\ndataset aimed at expanding LLMs' proficiency in multimodal contexts. Developed\ncollaboratively through ChatGPT, MultiAPI consists of 235 diverse API calls and\n2,038 contextual prompts, offering a unique platform evaluation of\ntool-augmented LLMs handling multimodal tasks. Through comprehensive\nexperiments, our findings reveal that while LLMs demonstrate proficiency in API\ncall decision-making, they face challenges in domain identification, function\nselection, and argument generation. What's more, we surprisingly notice that\nauxiliary context can actually impair the performance. An in-depth error\nanalysis paves the way for a new paradigm to address these challenges,\nsuggesting a potential direction for future LLM research.\n","authors":["Xiao Liu","Jianfeng Lin","Jiawei Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.13053v1.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2211.08371v3","updated":"2023-11-21T23:04:53Z","published":"2022-11-15T18:21:46Z","title":"Pragmatics in Language Grounding: Phenomena, Tasks, and Modeling\n  Approaches","summary":"  People rely heavily on context to enrich meaning beyond what is literally\nsaid, enabling concise but effective communication. To interact successfully\nand naturally with people, user-facing artificial intelligence systems will\nrequire similar skills in pragmatics: relying on various types of context --\nfrom shared linguistic goals and conventions, to the visual and embodied world\n-- to use language effectively. We survey existing grounded settings and\npragmatic modeling approaches and analyze how the task goals, environmental\ncontexts, and communicative affordances in each work enrich linguistic meaning.\nWe present recommendations for future grounded task design to naturally elicit\npragmatic phenomena, and suggest directions that focus on a broader range of\ncommunicative contexts and affordances.\n","authors":["Daniel Fried","Nicholas Tomlin","Jennifer Hu","Roma Patel","Aida Nematzadeh"],"pdf_url":"https://arxiv.org/pdf/2211.08371v3.pdf","comment":"Findings of EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.13029v1","updated":"2023-11-21T22:30:37Z","published":"2023-11-21T22:30:37Z","title":"Systematic word meta-sense extension","summary":"  The meaning of polysemous words often varies in a highly productive yet\npredictable way. Generalizing the regularity between conventional senses to\nderive novel word meaning is crucial for automated processing of non-literal\nlanguage uses such as figurative expressions. We introduce a novel task called\nsystematic word meta-sense extension (SWORME) to test and improve language\nmodels' ability to extend word meaning to denote new semantic domains (also\ncalled meta-senses) that bear regular semantic relations with existing senses.\nWe found that language models prefer incremental lexical semantic change toward\nconceptually similar meta-senses such as logical metonymy, and are much worse\nat predicting highly non-literal meaning extensions such as metaphors. We\npropose a novel analogy-based method of word meaning extension, and show that\nit effectively improves language model systematicity in making both gradual and\nradical types of meta-sense extension. We further demonstrate that learning\nsystematic meta-sense extensions benefits language models on multiple\nbenchmarks of figurative language understanding.\n","authors":["Lei Yu"],"pdf_url":"https://arxiv.org/pdf/2311.13029v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.11603v3","updated":"2023-11-21T22:23:43Z","published":"2022-05-23T20:00:22Z","title":"Representation Projection Invariance Mitigates Representation Collapse","summary":"  Fine-tuning contextualized representations learned by pre-trained language\nmodels remains a prevalent practice in NLP. However, fine-tuning can lead to\nrepresentation degradation (also known as representation collapse), which may\nresult in instability, sub-optimal performance, and weak generalization.\n  In this paper, we propose Representation Projection Invariance (REPINA), a\nnovel regularization method to maintain the information content of\nrepresentation and reduce representation collapse during fine-tuning by\ndiscouraging undesirable changes in the representations. We study the empirical\nbehavior of the proposed regularization in comparison to 5 comparable baselines\nacross 13 language understanding tasks (GLUE benchmark and six additional\ndatasets). When evaluating in-domain performance, REPINA consistently\noutperforms other baselines on most tasks (10 out of 13). We also demonstrate\nits effectiveness in few-shot settings and robustness to label perturbation. As\na by-product, we extend previous studies of representation collapse and propose\nseveral metrics to quantify it. Our empirical findings show that our approach\nis significantly more effective at mitigating representation collapse.\n","authors":["Anastasia Razdaibiedina","Ashish Khetan","Zohar Karnin","Daniel Khashabi","Vishaal Kapoor","Vivek Madan"],"pdf_url":"https://arxiv.org/pdf/2205.11603v3.pdf","comment":"41 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.12986v1","updated":"2023-11-21T20:45:55Z","published":"2023-11-21T20:45:55Z","title":"Unsupervised Graph Attention Autoencoder for Attributed Networks using\n  K-means Loss","summary":"  Multimodal Sentiment Analysis (MSA) has recently become a centric research\ndirection for many real-world applications. This proliferation is due to the\nfact that opinions are central to almost all human activities and are key\ninfluencers of our behaviors. In addition, the recent deployment of Deep\nLearning-based (DL) models has proven their high efficiency for a wide range of\nWestern languages. In contrast, Arabic DL-based multimodal sentiment analysis\n(MSA) is still in its infantile stage due, mainly, to the lack of standard\ndatasets. % The contribution In this paper, our investigation is twofold.\nFirst, we design a pipeline that helps building our Arabic Multimodal dataset\nleveraging both state-of-the-art transformers and feature extraction tools\nwithin word alignment techniques. Thereafter, we validate our dataset using\nstate-of-the-art transformer-based model dealing with multimodality. Despite\nthe small size of the outcome dataset, experiments show that Arabic\nmultimodality is very promising.\n","authors":["Abdelfateh Bekkaira","Slimane Bellaouar","Slimane Oulad-Naoui"],"pdf_url":"https://arxiv.org/pdf/2311.12986v1.pdf","comment":"7 pages, 5 Figures"},{"id":"http://arxiv.org/abs/2305.14457v3","updated":"2023-11-21T20:38:22Z","published":"2023-05-23T18:28:42Z","title":"Pre-training Language Models for Comparative Reasoning","summary":"  Comparative reasoning is a process of comparing objects, concepts, or\nentities to draw conclusions, which constitutes a fundamental cognitive\nability. In this paper, we propose a novel framework to pre-train language\nmodels for enhancing their abilities of comparative reasoning over texts. While\nthere have been approaches for NLP tasks that require comparative reasoning,\nthey suffer from costly manual data labeling and limited generalizability to\ndifferent tasks. Our approach introduces a novel method of collecting scalable\ndata for text-based entity comparison, which leverages both structured and\nunstructured data. Moreover, we present a framework of pre-training language\nmodels via three novel objectives on comparative reasoning. Evaluation on\ndownstream tasks including comparative question answering, question generation,\nand summarization shows that our pre-training framework significantly improves\nthe comparative reasoning abilities of language models, especially under\nlow-resource conditions. This work also releases the first integrated benchmark\nfor comparative reasoning.\n","authors":["Mengxia Yu","Zhihan Zhang","Wenhao Yu","Meng Jiang"],"pdf_url":"https://arxiv.org/pdf/2305.14457v3.pdf","comment":"EMNLP 2023 - Camera Ready"},{"id":"http://arxiv.org/abs/2311.12983v1","updated":"2023-11-21T20:34:47Z","published":"2023-11-21T20:34:47Z","title":"GAIA: a benchmark for General AI Assistants","summary":"  We introduce GAIA, a benchmark for General AI Assistants that, if solved,\nwould represent a milestone in AI research. GAIA proposes real-world questions\nthat require a set of fundamental abilities such as reasoning, multi-modality\nhandling, web browsing, and generally tool-use proficiency. GAIA questions are\nconceptually simple for humans yet challenging for most advanced AIs: we show\nthat human respondents obtain 92\\% vs. 15\\% for GPT-4 equipped with plugins.\nThis notable performance disparity contrasts with the recent trend of LLMs\noutperforming humans on tasks requiring professional skills in e.g. law or\nchemistry. GAIA's philosophy departs from the current trend in AI benchmarks\nsuggesting to target tasks that are ever more difficult for humans. We posit\nthat the advent of Artificial General Intelligence (AGI) hinges on a system's\ncapability to exhibit similar robustness as the average human does on such\nquestions. Using GAIA's methodology, we devise 466 questions and their answer.\nWe release our questions while retaining answers to 300 of them to power a\nleader-board available at https://huggingface.co/gaia-benchmark.\n","authors":["Grégoire Mialon","Clémentine Fourrier","Craig Swift","Thomas Wolf","Yann LeCun","Thomas Scialom"],"pdf_url":"https://arxiv.org/pdf/2311.12983v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.09832v3","updated":"2023-11-21T20:30:00Z","published":"2023-10-15T13:28:42Z","title":"Merging Experts into One: Improving Computational Efficiency of Mixture\n  of Experts","summary":"  Scaling the size of language models usually leads to remarkable advancements\nin NLP tasks. But it often comes with a price of growing computational cost.\nAlthough a sparse Mixture of Experts (MoE) can reduce the cost by activating a\nsmall subset of parameters (e.g., one expert) for each input, its computation\nescalates significantly if increasing the number of activated experts, limiting\nits practical utility. Can we retain the advantages of adding more experts\nwithout substantially increasing the computational costs? In this paper, we\nfirst demonstrate the superiority of selecting multiple experts and then\npropose a computation-efficient approach called \\textbf{\\texttt{Merging Experts\ninto One}} (MEO), which reduces the computation cost to that of a single\nexpert. Extensive experiments show that MEO significantly improves\ncomputational efficiency, e.g., FLOPS drops from 72.0G of vanilla MoE to 28.6G\n(MEO). Moreover, we propose a token-level attention block that further enhances\nthe efficiency and performance of token-level MEO, e.g., 83.3\\% (MEO) vs.\n82.6\\% (vanilla MoE) average score on the GLUE benchmark. Our code will be\nreleased upon acceptance. Code will be released at:\n\\url{https://github.com/Shwai-He/MEO}.\n","authors":["Shwai He","Run-Ze Fan","Liang Ding","Li Shen","Tianyi Zhou","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2310.09832v3.pdf","comment":"EMNLP 2023 Main Conference (Oral)"},{"id":"http://arxiv.org/abs/2305.11731v2","updated":"2023-11-21T19:19:10Z","published":"2023-05-19T15:05:39Z","title":"Persian Typographical Error Type Detection Using Deep Neural Networks on\n  Algorithmically-Generated Misspellings","summary":"  Spelling correction is a remarkable challenge in the field of natural\nlanguage processing. The objective of spelling correction tasks is to recognize\nand rectify spelling errors automatically. The development of applications that\ncan effectually diagnose and correct Persian spelling and grammatical errors\nhas become more important in order to improve the quality of Persian text. The\nTypographical Error Type Detection in Persian is a relatively understudied\narea. Therefore, this paper presents a compelling approach for detecting\ntypographical errors in Persian texts. Our work includes the presentation of a\npublicly available dataset called FarsTypo, which comprises 3.4 million words\narranged in chronological order and tagged with their corresponding\npart-of-speech. These words cover a wide range of topics and linguistic styles.\nWe develop an algorithm designed to apply Persian-specific errors to a scalable\nportion of these words, resulting in a parallel dataset of correct and\nincorrect words. By leveraging FarsTypo, we establish a strong foundation and\nconduct a thorough comparison of various methodologies employing different\narchitectures. Additionally, we introduce a groundbreaking Deep Sequential\nNeural Network that utilizes both word and character embeddings, along with\nbidirectional LSTM layers, for token classification aimed at detecting\ntypographical errors across 51 distinct classes. Our approach is contrasted\nwith highly advanced industrial systems that, unlike this study, have been\ndeveloped using a diverse range of resources. The outcomes of our final method\nproved to be highly competitive, achieving an accuracy of 97.62%, precision of\n98.83%, recall of 98.61%, and surpassing others in terms of speed.\n","authors":["Mohammad Dehghani","Heshaam Faili"],"pdf_url":"https://arxiv.org/pdf/2305.11731v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10813v2","updated":"2023-11-21T01:24:36Z","published":"2023-11-17T18:59:56Z","title":"A Language Agent for Autonomous Driving","summary":"  Human-level driving is an ultimate goal of autonomous driving. Conventional\napproaches formulate autonomous driving as a perception-prediction-planning\nframework, yet their systems do not capitalize on the inherent reasoning\nability and experiential knowledge of humans. In this paper, we propose a\nfundamental paradigm shift from current pipelines, exploiting Large Language\nModels (LLMs) as a cognitive agent to integrate human-like intelligence into\nautonomous driving systems. Our approach, termed Agent-Driver, transforms the\ntraditional autonomous driving pipeline by introducing a versatile tool library\naccessible via function calls, a cognitive memory of common sense and\nexperiential knowledge for decision-making, and a reasoning engine capable of\nchain-of-thought reasoning, task planning, motion planning, and\nself-reflection. Powered by LLMs, our Agent-Driver is endowed with intuitive\ncommon sense and robust reasoning capabilities, thus enabling a more nuanced,\nhuman-like approach to autonomous driving. We evaluate our approach on the\nlarge-scale nuScenes benchmark, and extensive experiments substantiate that our\nAgent-Driver significantly outperforms the state-of-the-art driving methods by\na large margin. Our approach also demonstrates superior interpretability and\nfew-shot learning ability to these methods. Code will be released.\n","authors":["Jiageng Mao","Junjie Ye","Yuxi Qian","Marco Pavone","Yue Wang"],"pdf_url":"https://arxiv.org/pdf/2311.10813v2.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2311.12796v1","updated":"2023-11-21T18:59:58Z","published":"2023-11-21T18:59:58Z","title":"Physics-guided Shape-from-Template: Monocular Video Perception through\n  Neural Surrogate Models","summary":"  3D reconstruction of dynamic scenes is a long-standing problem in computer\ngraphics and increasingly difficult the less information is available.\nShape-from-Template (SfT) methods aim to reconstruct a template-based geometry\nfrom RGB images or video sequences, often leveraging just a single monocular\ncamera without depth information, such as regular smartphone recordings.\nUnfortunately, existing reconstruction methods are either unphysical and noisy\nor slow in optimization. To solve this problem, we propose a novel SfT\nreconstruction algorithm for cloth using a pre-trained neural surrogate model\nthat is fast to evaluate, stable, and produces smooth reconstructions due to a\nregularizing physics simulation. Differentiable rendering of the simulated mesh\nenables pixel-wise comparisons between the reconstruction and a target video\nsequence that can be used for a gradient-based optimization procedure to\nextract not only shape information but also physical parameters such as\nstretching, shearing, or bending stiffness of the cloth. This allows to retain\na precise, stable, and smooth reconstructed geometry while reducing the runtime\nby a factor of 400-500 compared to $\\phi$-SfT, a state-of-the-art physics-based\nSfT approach.\n","authors":["David Stotko","Nils Wandel","Reinhard Klein"],"pdf_url":"https://arxiv.org/pdf/2311.12796v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12793v1","updated":"2023-11-21T18:58:11Z","published":"2023-11-21T18:58:11Z","title":"ShareGPT4V: Improving Large Multi-Modal Models with Better Captions","summary":"  In the realm of large multi-modal models (LMMs), efficient modality alignment\nis crucial yet often constrained by the scarcity of high-quality image-text\ndata. To address this bottleneck, we introduce the ShareGPT4V dataset, a\npioneering large-scale resource featuring 1.2 million highly descriptive\ncaptions, which surpasses existing datasets in diversity and information\ncontent, covering world knowledge, object properties, spatial relationships,\nand aesthetic evaluations. Specifically, ShareGPT4V originates from a curated\n100K high-quality captions collected from advanced GPT4-Vision and has been\nexpanded to 1.2M with a superb caption model trained on this subset. ShareGPT4V\nfirst demonstrates its effectiveness for the Supervised Fine-Tuning (SFT)\nphase, by substituting an equivalent quantity of detailed captions in existing\nSFT datasets with a subset of our high-quality captions, significantly\nenhancing the LMMs like LLaVA-7B, LLaVA-1.5-13B, and Qwen-VL-Chat-7B on the MME\nand MMBench benchmarks, with respective gains of 222.8/22.0/22.3 and\n2.7/1.3/1.5. We further incorporate ShareGPT4V data into both the pre-training\nand SFT phases, obtaining ShareGPT4V-7B, a superior LMM based on a simple\narchitecture that has remarkable performance across a majority of the\nmulti-modal benchmarks. This project is available at\nhttps://ShareGPT4V.github.io to serve as a pivotal resource for advancing the\nLMMs community.\n","authors":["Lin Chen","Jisong Li","Xiaoyi Dong","Pan Zhang","Conghui He","Jiaqi Wang","Feng Zhao","Dahua Lin"],"pdf_url":"https://arxiv.org/pdf/2311.12793v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12792v1","updated":"2023-11-21T18:58:01Z","published":"2023-11-21T18:58:01Z","title":"Intrinsic Image Decomposition via Ordinal Shading","summary":"  Intrinsic decomposition is a fundamental mid-level vision problem that plays\na crucial role in various inverse rendering and computational photography\npipelines. Generating highly accurate intrinsic decompositions is an inherently\nunder-constrained task that requires precisely estimating continuous-valued\nshading and albedo. In this work, we achieve high-resolution intrinsic\ndecomposition by breaking the problem into two parts. First, we present a dense\nordinal shading formulation using a shift- and scale-invariant loss in order to\nestimate ordinal shading cues without restricting the predictions to obey the\nintrinsic model. We then combine low- and high-resolution ordinal estimations\nusing a second network to generate a shading estimate with both global\ncoherency and local details. We encourage the model to learn an accurate\ndecomposition by computing losses on the estimated shading as well as the\nalbedo implied by the intrinsic model. We develop a straightforward method for\ngenerating dense pseudo ground truth using our model's predictions and\nmulti-illumination data, enabling generalization to in-the-wild imagery. We\npresent an exhaustive qualitative and quantitative analysis of our predicted\nintrinsic components against state-of-the-art methods. Finally, we demonstrate\nthe real-world applicability of our estimations by performing otherwise\ndifficult editing tasks such as recoloring and relighting.\n","authors":["Chris Careaga","Yağız Aksoy"],"pdf_url":"https://arxiv.org/pdf/2311.12792v1.pdf","comment":"24 pages, 23 figures, Accepted to ACM Transactions on Graphics\n  (2023). Project page: https://yaksoy.github.io/intrinsic/"},{"id":"http://arxiv.org/abs/2305.11818v2","updated":"2023-11-21T18:55:24Z","published":"2023-05-19T16:53:15Z","title":"MaGIC: Multi-modality Guided Image Completion","summary":"  Vanilla image completion approaches exhibit sensitivity to large missing\nregions, attributed to the limited availability of reference information for\nplausible generation. To mitigate this, existing methods incorporate the extra\ncue as a guidance for image completion. Despite improvements, these approaches\nare often restricted to employing a single modality (e.g., segmentation or\nsketch maps), which lacks scalability in leveraging multi-modality for more\nplausible completion. In this paper, we propose a novel, simple yet effective\nmethod for Multi-modal Guided Image Completion, dubbed MaGIC, which not only\nsupports a wide range of single modality as the guidance (e.g., text, canny\nedge, sketch, segmentation, depth, and pose), but also adapts to arbitrarily\ncustomized combination of these modalities (i.e., arbitrary multi-modality) for\nimage completion. For building MaGIC, we first introduce a modality-specific\nconditional U-Net (MCU-Net) that injects single-modal signal into a U-Net\ndenoiser for single-modal guided image completion. Then, we devise a consistent\nmodality blending (CMB) method to leverage modality signals encoded in multiple\nlearned MCU-Nets through gradient guidance in latent space. Our CMB is\ntraining-free, thereby avoids the cumbersome joint re-training of different\nmodalities, which is the secret of MaGIC to achieve exceptional flexibility in\naccommodating new modalities for completion. Experiments show the superiority\nof MaGIC over state-of-the-art methods and its generalization to various\ncompletion tasks. Our project with code and models is available at\nyeates.github.io/MaGIC-Page/.\n","authors":["Yongsheng Yu","Hao Wang","Tiejian Luo","Heng Fan","Libo Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.11818v2.pdf","comment":"23 pages, 15 figures"},{"id":"http://arxiv.org/abs/2211.13807v2","updated":"2023-11-21T18:47:51Z","published":"2022-11-24T21:41:52Z","title":"GEFF: Improving Any Clothes-Changing Person ReID Model using Gallery\n  Enrichment with Face Features","summary":"  In the Clothes-Changing Re-Identification (CC-ReID) problem, given a query\nsample of a person, the goal is to determine the correct identity based on a\nlabeled gallery in which the person appears in different clothes. Several\nmodels tackle this challenge by extracting clothes-independent features.\nHowever, the performance of these models is still lower for the\nclothes-changing setting compared to the same-clothes setting in which the\nperson appears with the same clothes in the labeled gallery. As\nclothing-related features are often dominant features in the data, we propose a\nnew process we call Gallery Enrichment, to utilize these features. In this\nprocess, we enrich the original gallery by adding to it query samples based on\ntheir face features, using an unsupervised algorithm. Additionally, we show\nthat combining ReID and face feature extraction modules alongside an enriched\ngallery results in a more accurate ReID model, even for query samples with new\noutfits that do not include faces. Moreover, we claim that existing CC-ReID\nbenchmarks do not fully represent real-world scenarios, and propose a new video\nCC-ReID dataset called 42Street, based on a theater play that includes crowded\nscenes and numerous clothes changes. When applied to multiple ReID models, our\nmethod (GEFF) achieves an average improvement of 33.5% and 6.7% in the Top-1\nclothes-changing metric on the PRCC and LTCC benchmarks. Combined with the\nlatest ReID models, our method achieves new SOTA results on the PRCC, LTCC,\nCCVID, LaST and VC-Clothes benchmarks and the proposed 42Street dataset.\n","authors":["Daniel Arkushin","Bar Cohen","Shmuel Peleg","Ohad Fried"],"pdf_url":"https://arxiv.org/pdf/2211.13807v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.12827v3","updated":"2023-11-21T18:43:43Z","published":"2023-05-22T08:39:25Z","title":"Task Arithmetic in the Tangent Space: Improved Editing of Pre-Trained\n  Models","summary":"  Task arithmetic has recently emerged as a cost-effective and scalable\napproach to edit pre-trained models directly in weight space: By adding the\nfine-tuned weights of different tasks, the model's performance can be improved\non these tasks, while negating them leads to task forgetting. Yet, our\nunderstanding of the effectiveness of task arithmetic and its underlying\nprinciples remains limited. We present a comprehensive study of task arithmetic\nin vision-language models and show that weight disentanglement is the crucial\nfactor that makes it effective. This property arises during pre-training and\nmanifests when distinct directions in weight space govern separate, localized\nregions in function space associated with the tasks. Notably, we show that\nfine-tuning models in their tangent space by linearizing them amplifies weight\ndisentanglement. This leads to substantial performance improvements across\nmultiple task arithmetic benchmarks and diverse models. Building on these\nfindings, we provide theoretical and empirical analyses of the neural tangent\nkernel (NTK) of these models and establish a compelling link between task\narithmetic and the spatial localization of the NTK eigenfunctions. Overall, our\nwork uncovers novel insights into the fundamental mechanisms of task arithmetic\nand offers a more reliable and effective approach to edit pre-trained models\nthrough the NTK linearization.\n","authors":["Guillermo Ortiz-Jimenez","Alessandro Favero","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2305.12827v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12775v1","updated":"2023-11-21T18:38:03Z","published":"2023-11-21T18:38:03Z","title":"SuGaR: Surface-Aligned Gaussian Splatting for Efficient 3D Mesh\n  Reconstruction and High-Quality Mesh Rendering","summary":"  We propose a method to allow precise and extremely fast mesh extraction from\n3D Gaussian Splatting. Gaussian Splatting has recently become very popular as\nit yields realistic rendering while being significantly faster to train than\nNeRFs. It is however challenging to extract a mesh from the millions of tiny 3D\ngaussians as these gaussians tend to be unorganized after optimization and no\nmethod has been proposed so far. Our first key contribution is a regularization\nterm that encourages the gaussians to align well with the surface of the scene.\nWe then introduce a method that exploits this alignment to extract a mesh from\nthe Gaussians using Poisson reconstruction, which is fast, scalable, and\npreserves details, in contrast to the Marching Cubes algorithm usually applied\nto extract meshes from Neural SDFs. Finally, we introduce an optional\nrefinement strategy that binds gaussians to the surface of the mesh, and\njointly optimizes these Gaussians and the mesh through Gaussian splatting\nrendering. This enables easy editing, sculpting, rigging, animating,\ncompositing and relighting of the Gaussians using traditional softwares by\nmanipulating the mesh instead of the gaussians themselves. Retrieving such an\neditable mesh for realistic rendering is done within minutes with our method,\ncompared to hours with the state-of-the-art methods on neural SDFs, while\nproviding a better rendering quality.\n","authors":["Antoine Guédon","Vincent Lepetit"],"pdf_url":"https://arxiv.org/pdf/2311.12775v1.pdf","comment":"Project Webpage: https://imagine.enpc.fr/~guedona/sugar/"},{"id":"http://arxiv.org/abs/2311.12773v1","updated":"2023-11-21T18:35:21Z","published":"2023-11-21T18:35:21Z","title":"Iris Presentation Attack: Assessing the Impact of Combining Vanadium\n  Dioxide Films with Artificial Eyes","summary":"  Iris recognition systems, operating in the near infrared spectrum (NIR), have\ndemonstrated vulnerability to presentation attacks, where an adversary uses\nartifacts such as cosmetic contact lenses, artificial eyes or printed iris\nimages in order to circumvent the system. At the same time, a number of\neffective presentation attack detection (PAD) methods have been developed.\nThese methods have demonstrated success in detecting artificial eyes (e.g.,\nfake Van Dyke eyes) as presentation attacks. In this work, we seek to alter the\noptical characteristics of artificial eyes by affixing Vanadium Dioxide (VO2)\nfilms on their surface in various spatial configurations. VO2 films can be used\nto selectively transmit NIR light and can, therefore, be used to regulate the\namount of NIR light from the object that is captured by the iris sensor. We\nstudy the impact of such images produced by the sensor on two state-of-the-art\niris PA detection methods. We observe that the addition of VO2 films on the\nsurface of artificial eyes can cause the PA detection methods to misclassify\nthem as bonafide eyes in some cases. This represents a vulnerability that must\nbe systematically analyzed and effectively addressed.\n","authors":["Darshika Jauhari","Renu Sharma","Cunjian Chen","Nelson Sepulveda","Arun Ross"],"pdf_url":"https://arxiv.org/pdf/2311.12773v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.11057v3","updated":"2023-11-21T18:34:09Z","published":"2021-11-22T08:55:25Z","title":"Learning to Aggregate Multi-Scale Context for Instance Segmentation in\n  Remote Sensing Images","summary":"  The task of instance segmentation in remote sensing images, aiming at\nperforming per-pixel labeling of objects at instance level, is of great\nimportance for various civil applications. Despite previous successes, most\nexisting instance segmentation methods designed for natural images encounter\nsharp performance degradations when they are directly applied to top-view\nremote sensing images. Through careful analysis, we observe that the challenges\nmainly come from the lack of discriminative object features due to severe scale\nvariations, low contrasts, and clustered distributions. In order to address\nthese problems, a novel context aggregation network (CATNet) is proposed to\nimprove the feature extraction process. The proposed model exploits three\nlightweight plug-and-play modules, namely dense feature pyramid network\n(DenseFPN), spatial context pyramid (SCP), and hierarchical region of interest\nextractor (HRoIE), to aggregate global visual context at feature, spatial, and\ninstance domains, respectively. DenseFPN is a multi-scale feature propagation\nmodule that establishes more flexible information flows by adopting inter-level\nresidual connections, cross-level dense connections, and feature re-weighting\nstrategy. Leveraging the attention mechanism, SCP further augments the features\nby aggregating global spatial context into local regions. For each instance,\nHRoIE adaptively generates RoI features for different downstream tasks.\nExtensive evaluations of the proposed scheme on iSAID, DIOR, NWPU VHR-10, and\nHRSID datasets demonstrate that the proposed approach outperforms\nstate-of-the-arts under similar computational costs. Source code and\npre-trained models are available at https://github.com/yeliudev/CATNet.\n","authors":["Ye Liu","Huifang Li","Chao Hu","Shuang Luo","Yan Luo","Chang Wen Chen"],"pdf_url":"https://arxiv.org/pdf/2111.11057v3.pdf","comment":"Accepted to IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS), 2023"},{"id":"http://arxiv.org/abs/2311.12770v1","updated":"2023-11-21T18:30:40Z","published":"2023-11-21T18:30:40Z","title":"Swift Parameter-free Attention Network for Efficient Super-Resolution","summary":"  Single Image Super-Resolution (SISR) is a crucial task in low-level computer\nvision, aiming to reconstruct high-resolution images from low-resolution\ncounterparts. Conventional attention mechanisms have significantly improved\nSISR performance but often result in complex network structures and large\nnumber of parameters, leading to slow inference speed and large model size. To\naddress this issue, we propose the Swift Parameter-free Attention Network\n(SPAN), a highly efficient SISR model that balances parameter count, inference\nspeed, and image quality. SPAN employs a novel parameter-free attention\nmechanism, which leverages symmetric activation functions and residual\nconnections to enhance high-contribution information and suppress redundant\ninformation. Our theoretical analysis demonstrates the effectiveness of this\ndesign in achieving the attention mechanism's purpose. We evaluate SPAN on\nmultiple benchmarks, showing that it outperforms existing efficient\nsuper-resolution models in terms of both image quality and inference speed,\nachieving a significant quality-speed trade-off. This makes SPAN highly\nsuitable for real-world applications, particularly in resource-constrained\nscenarios. Notably, our model attains the best PSNR of 27.09 dB, and the test\nruntime of our team is reduced by 7.08ms in the NTIRE 2023 efficient\nsuper-resolution challenge. Our code and models are made publicly available at\n\\url{https://github.com/hongyuanyu/SPAN}.\n","authors":["Cheng Wan","Hongyuan Yu","Zhiqi Li","Yihang Chen","Yajun Zou","Yuqing Liu","Xuanwu Yin","Kunlong Zuo"],"pdf_url":"https://arxiv.org/pdf/2311.12770v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12764v1","updated":"2023-11-21T18:18:50Z","published":"2023-11-21T18:18:50Z","title":"Investigating Weight-Perturbed Deep Neural Networks With Application in\n  Iris Presentation Attack Detection","summary":"  Deep neural networks (DNNs) exhibit superior performance in various machine\nlearning tasks, e.g., image classification, speech recognition, biometric\nrecognition, object detection, etc. However, it is essential to analyze their\nsensitivity to parameter perturbations before deploying them in real-world\napplications. In this work, we assess the sensitivity of DNNs against\nperturbations to their weight and bias parameters. The sensitivity analysis\ninvolves three DNN architectures (VGG, ResNet, and DenseNet), three types of\nparameter perturbations (Gaussian noise, weight zeroing, and weight scaling),\nand two settings (entire network and layer-wise). We perform experiments in the\ncontext of iris presentation attack detection and evaluate on two publicly\navailable datasets: LivDet-Iris-2017 and LivDet-Iris-2020. Based on the\nsensitivity analysis, we propose improved models simply by perturbing\nparameters of the network without undergoing training. We further combine these\nperturbed models at the score-level and at the parameter-level to improve the\nperformance over the original model. The ensemble at the parameter-level shows\nan average improvement of 43.58% on the LivDet-Iris-2017 dataset and 9.25% on\nthe LivDet-Iris-2020 dataset. The source code is available at\n\\href{https://github.com/redwankarimsony/WeightPerturbation-MSU}{https://github.com/redwankarimsony/WeightPerturbation-MSU}.\n","authors":["Renu Sharma","Redwan Sony","Arun Ross"],"pdf_url":"https://arxiv.org/pdf/2311.12764v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12760v1","updated":"2023-11-21T18:11:26Z","published":"2023-11-21T18:11:26Z","title":"High-resolution Image-based Malware Classification using Multiple\n  Instance Learning","summary":"  This paper proposes a novel method of classifying malware into families using\nhigh-resolution greyscale images and multiple instance learning to overcome\nadversarial binary enlargement. Current methods of visualisation-based malware\nclassification largely rely on lossy transformations of inputs such as resizing\nto handle the large, variable-sized images. Through empirical analysis and\nexperimentation, it is shown that these approaches cause crucial information\nloss that can be exploited. The proposed solution divides the images into\npatches and uses embedding-based multiple instance learning with a\nconvolutional neural network and an attention aggregation function for\nclassification. The implementation is evaluated on the Microsoft Malware\nClassification dataset and achieves accuracies of up to $96.6\\%$ on\nadversarially enlarged samples compared to the baseline of $22.8\\%$. The Python\ncode is available online at https://github.com/timppeters/MIL-Malware-Images .\n","authors":["Tim Peters","Hikmat Farhat"],"pdf_url":"https://arxiv.org/pdf/2311.12760v1.pdf","comment":"14 pages, 13 figures, 2 tables"},{"id":"http://arxiv.org/abs/2211.09945v7","updated":"2023-11-21T18:03:06Z","published":"2022-11-17T23:42:10Z","title":"VeriCompress: A Tool to Streamline the Synthesis of Verified Robust\n  Compressed Neural Networks from Scratch","summary":"  AI's widespread integration has led to neural networks (NNs) deployment on\nedge and similar limited-resource platforms for safety-critical scenarios. Yet,\nNN's fragility raises concerns about reliable inference. Moreover, constrained\nplatforms demand compact networks. This study introduces VeriCompress, a tool\nthat automates the search and training of compressed models with robustness\nguarantees. These models are well-suited for safety-critical applications and\nadhere to predefined architecture and size limitations, making them deployable\non resource-restricted platforms. The method trains models 2-3 times faster\nthan the state-of-the-art approaches, surpassing relevant baseline approaches\nby average accuracy and robustness gains of 15.1 and 9.8 percentage points,\nrespectively. When deployed on a resource-restricted generic platform, these\nmodels require 5-8 times less memory and 2-4 times less inference time than\nmodels used in verified robustness literature. Our comprehensive evaluation\nacross various model architectures and datasets, including MNIST, CIFAR, SVHN,\nand a relevant pedestrian detection dataset, showcases VeriCompress's capacity\nto identify compressed verified robust models with reduced computation overhead\ncompared to current standards. This underscores its potential as a valuable\ntool for end users, such as developers of safety-critical applications on edge\nor Internet of Things platforms, empowering them to create suitable models for\nsafety-critical, resource-constrained platforms in their respective domains.\n","authors":["Sawinder Kaur","Yi Xiao","Asif Salekin"],"pdf_url":"https://arxiv.org/pdf/2211.09945v7.pdf","comment":"9 pages, 5 tables, 2 figures"},{"id":"http://arxiv.org/abs/2311.12754v1","updated":"2023-11-21T17:59:14Z","published":"2023-11-21T17:59:14Z","title":"SelfOcc: Self-Supervised Vision-Based 3D Occupancy Prediction","summary":"  3D occupancy prediction is an important task for the robustness of\nvision-centric autonomous driving, which aims to predict whether each point is\noccupied in the surrounding 3D space. Existing methods usually require 3D\noccupancy labels to produce meaningful results. However, it is very laborious\nto annotate the occupancy status of each voxel. In this paper, we propose\nSelfOcc to explore a self-supervised way to learn 3D occupancy using only video\nsequences. We first transform the images into the 3D space (e.g., bird's eye\nview) to obtain 3D representation of the scene. We directly impose constraints\non the 3D representations by treating them as signed distance fields. We can\nthen render 2D images of previous and future frames as self-supervision signals\nto learn the 3D representations. We propose an MVS-embedded strategy to\ndirectly optimize the SDF-induced weights with multiple depth proposals. Our\nSelfOcc outperforms the previous best method SceneRF by 58.7% using a single\nframe as input on SemanticKITTI and is the first self-supervised work that\nproduces reasonable 3D occupancy for surround cameras on Occ3D. SelfOcc\nproduces high-quality depth and achieves state-of-the-art results on novel\ndepth synthesis, monocular depth estimation, and surround-view depth estimation\non the SemanticKITTI, KITTI-2015, and nuScenes, respectively. Code:\nhttps://github.com/huang-yh/SelfOcc.\n","authors":["Yuanhui Huang","Wenzhao Zheng","Borui Zhang","Jie Zhou","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2311.12754v1.pdf","comment":"Code is available at: https://github.com/huang-yh/SelfOcc"},{"id":"http://arxiv.org/abs/2310.02129v2","updated":"2023-11-21T17:59:04Z","published":"2023-10-03T15:10:46Z","title":"Unveiling the Pitfalls of Knowledge Editing for Large Language Models","summary":"  As the cost associated with fine-tuning Large Language Models (LLMs)\ncontinues to rise, recent research efforts have pivoted towards developing\nmethodologies to edit implicit knowledge embedded within LLMs. Yet, there's\nstill a dark cloud lingering overhead -- will knowledge editing trigger\nbutterfly effect? since it is still unclear whether knowledge editing might\nintroduce side effects that pose potential risks or not. This paper pioneers\nthe investigation into the potential pitfalls associated with knowledge editing\nfor LLMs. To achieve this, we introduce new benchmark datasets and propose\ninnovative evaluation metrics. Our results underline two pivotal concerns: (1)\nKnowledge Conflict: Editing groups of facts that logically clash can magnify\nthe inherent inconsistencies in LLMs-a facet neglected by previous methods. (2)\nKnowledge Distortion: Altering parameters with the aim of editing factual\nknowledge can irrevocably warp the innate knowledge structure of LLMs.\nExperimental results vividly demonstrate that knowledge editing might\ninadvertently cast a shadow of unintended consequences on LLMs, which warrant\nattention and efforts for future works. Code is available at\nhttps://github.com/zjunlp/PitfallsKnowledgeEditing.\n","authors":["Zhoubo Li","Ningyu Zhang","Yunzhi Yao","Mengru Wang","Xi Chen","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2310.02129v2.pdf","comment":"Work in progress, add more experiments"},{"id":"http://arxiv.org/abs/2311.12751v1","updated":"2023-11-21T17:52:30Z","published":"2023-11-21T17:52:30Z","title":"Towards Natural Language-Guided Drones: GeoText-1652 Benchmark with\n  Spatially Relation Matching","summary":"  Drone navigation through natural language commands remains a significant\nchallenge due to the lack of publicly available multi-modal datasets and the\nintricate demands of fine-grained visual-text alignment. In response to this\npressing need, we present a new human-computer interaction annotation benchmark\ncalled GeoText-1652, meticulously curated through a robust Large Language Model\n(LLM)-based data generation framework and the expertise of pre-trained vision\nmodels. This new dataset seamlessly extends the existing image dataset, \\ie,\nUniversity-1652, with spatial-aware text annotations, encompassing intricate\nimage-text-bounding box associations. Besides, we introduce a new optimization\nobjective to leverage fine-grained spatial associations, called blending\nspatial matching, for region-level spatial relation matching. Extensive\nexperiments reveal that our approach maintains an exceptional recall rate under\nvarying description complexities. This underscores the promising potential of\nour approach in elevating drone control and navigation through the seamless\nintegration of natural language commands in real-world scenarios.\n","authors":["Meng Chu","Zhedong Zheng","Wei Ji","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2311.12751v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.06185v2","updated":"2023-11-21T17:42:42Z","published":"2023-11-10T17:06:28Z","title":"An Automated Pipeline for Tumour-Infiltrating Lymphocyte Scoring in\n  Breast Cancer","summary":"  Tumour-infiltrating lymphocytes (TILs) are considered as a valuable\nprognostic markers in both triple-negative and human epidermal growth factor\nreceptor 2 (HER2) positive breast cancer. In this study, we introduce an\ninnovative deep learning pipeline based on the Efficient-UNet architecture to\npredict the TILs score for breast cancer whole-slide images (WSIs). We first\nsegment tumour and stromal regions in order to compute a tumour bulk mask. We\nthen detect TILs within the tumour-associated stroma, generating a TILs score\nby closely mirroring the pathologist's workflow. Our method exhibits\nstate-of-the-art performance in segmenting tumour/stroma areas and TILs\ndetection, as demonstrated by internal cross-validation on the TiGER Challenge\ntraining dataset and evaluation on the final leaderboards. Additionally, our\nTILs score proves competitive in predicting survival outcomes within the same\nchallenge, underscoring the clinical relevance and potential of our automated\nTILs scoring pipeline as a breast cancer prognostic tool.\n","authors":["Adam J Shephard","Mostafa Jahanifar","Ruoyu Wang","Muhammad Dawood","Simon Graham","Kastytis Sidlauskas","Syed Ali Khurram","Nasir M Rajpoot","Shan E Ahmed Raza"],"pdf_url":"https://arxiv.org/pdf/2311.06185v2.pdf","comment":"5 pages, 1 figure, 2 tables"},{"id":"http://arxiv.org/abs/2304.14408v3","updated":"2023-11-21T17:21:28Z","published":"2023-03-16T17:30:51Z","title":"Using Scalable Computer Vision to Automate High-throughput Semiconductor\n  Characterization","summary":"  High-throughput materials synthesis methods have risen in popularity due to\ntheir potential to accelerate the design and discovery of novel functional\nmaterials, such as solution-processed semiconductors. After synthesis, key\nmaterial properties must be measured and characterized to validate discovery\nand provide feedback to optimization cycles. However, with the boom in\ndevelopment of high-throughput synthesis tools that champion production rates\nup to $10^4$ samples per hour with flexible form factors, most sample\ncharacterization methods are either slow (conventional rates of $10^1$ samples\nper hour, approximately 1000x slower) or rigid (e.g., designed for\nstandard-size microplates), resulting in a bottleneck that impedes the\nmaterials-design process. To overcome this challenge, we propose a set of\nautomated material property characterization (autocharacterization) tools that\nleverage the adaptive, parallelizable, and scalable nature of computer vision\nto accelerate the throughput of characterization by 85x compared to the\nnon-automated workflow. We demonstrate a generalizable composition mapping tool\nfor high-throughput synthesized binary material systems as well as two scalable\nautocharacterization algorithms that (1) autonomously compute the band gap of\n200 unique compositions in 6 minutes and (2) autonomously compute the degree of\ndegradation in 200 unique compositions in 20 minutes, generating ultra-high\ncompositional resolution trends of band gap and stability. We demonstrate that\nthe developed band gap and degradation detection autocharacterization methods\nachieve 98.5% accuracy and 96.9% accuracy, respectively, on the\nFA$_{1-x}$MA$_{x}$PbI$_3$, $0\\leq x \\leq 1$ perovskite semiconductor system.\n","authors":["Alexander E. Siemenn","Eunice Aissi","Fang Sheng","Armi Tiihonen","Hamide Kavak","Basita Das","Tonio Buonassisi"],"pdf_url":"https://arxiv.org/pdf/2304.14408v3.pdf","comment":"Manuscript 18 pages; Supplemental 20 pages"},{"id":"http://arxiv.org/abs/2303.17646v2","updated":"2023-11-21T17:07:46Z","published":"2023-03-30T18:23:20Z","title":"XPert: Peripheral Circuit & Neural Architecture Co-search for Area and\n  Energy-efficient Xbar-based Computing","summary":"  The hardware-efficiency and accuracy of Deep Neural Networks (DNNs)\nimplemented on In-memory Computing (IMC) architectures primarily depend on the\nDNN architecture and the peripheral circuit parameters. It is therefore\nessential to holistically co-search the network and peripheral parameters to\nachieve optimal performance. To this end, we propose XPert, which co-searches\nnetwork architecture in tandem with peripheral parameters such as the type and\nprecision of analog-to-digital converters, crossbar column sharing and the\nlayer-specific input precision using an optimization-based design space\nexploration. Compared to VGG16 baselines, XPert achieves 10.24x (4.7x) lower\nEDAP, 1.72x (1.62x) higher TOPS/W,1.93x (3x) higher TOPS/mm2 at 92.46% (56.7%)\naccuracy for CIFAR10 (TinyImagenet) datasets. The code for this paper is\navailable at https://github.com/Intelligent-Computing-Lab-Yale/XPert.\n","authors":["Abhishek Moitra","Abhiroop Bhattacharjee","Youngeun Kim","Priyadarshini Panda"],"pdf_url":"https://arxiv.org/pdf/2303.17646v2.pdf","comment":"Accepted to Design and Automation Conference (DAC)"},{"id":"http://arxiv.org/abs/2311.12722v1","updated":"2023-11-21T16:51:33Z","published":"2023-11-21T16:51:33Z","title":"Attacking Motion Planners Using Adversarial Perception Errors","summary":"  Autonomous driving (AD) systems are often built and tested in a modular\nfashion, where the performance of different modules is measured using\ntask-specific metrics. These metrics should be chosen so as to capture the\ndownstream impact of each module and the performance of the system as a whole.\nFor example, high perception quality should enable prediction and planning to\nbe performed safely. Even though this is true in general, we show here that it\nis possible to construct planner inputs that score very highly on various\nperception quality metrics but still lead to planning failures. In an analogy\nto adversarial attacks on image classifiers, we call such inputs\n\\textbf{adversarial perception errors} and show they can be systematically\nconstructed using a simple boundary-attack algorithm. We demonstrate the\neffectiveness of this algorithm by finding attacks for two different black-box\nplanners in several urban and highway driving scenarios using the CARLA\nsimulator. Finally, we analyse the properties of these attacks and show that\nthey are isolated in the input space of the planner, and discuss their\nimplications for AD system deployment and testing.\n","authors":["Jonathan Sadeghi","Nicholas A. Lord","John Redford","Romain Mueller"],"pdf_url":"https://arxiv.org/pdf/2311.12722v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.05088v3","updated":"2023-11-21T16:35:26Z","published":"2023-04-11T09:31:07Z","title":"WEAR: An Outdoor Sports Dataset for Wearable and Egocentric Activity\n  Recognition","summary":"  Though research has shown the complementarity of camera- and inertial-based\ndata, datasets which offer both egocentric video and inertial-based sensor data\nremain scarce. In this paper, we introduce WEAR, an outdoor sports dataset for\nboth vision- and inertial-based human activity recognition (HAR). The dataset\ncomprises data from 18 participants performing a total of 18 different workout\nactivities with untrimmed inertial (acceleration) and camera (egocentric video)\ndata recorded at 10 different outside locations. Unlike previous egocentric\ndatasets, WEAR provides a challenging prediction scenario marked by purposely\nintroduced activity variations as well as an overall small information overlap\nacross modalities. Benchmark results obtained using each modality separately\nshow that each modality interestingly offers complementary strengths and\nweaknesses in their prediction performance. Further, in light of the recent\nsuccess of temporal action localization models following the architecture\ndesign of the ActionFormer, we demonstrate their versatility by applying them\nin a plain fashion using vision, inertial and combined (vision + inertial)\nfeatures as input. Results demonstrate both the applicability of vision-based\ntemporal action localization models for inertial data and fusing both\nmodalities by means of simple concatenation, with the combined approach (vision\n+ inertial features) being able to produce the highest mean average precision\nand close-to-best F1-score. The dataset and code to reproduce experiments is\npublicly available via: https://mariusbock.github.io/wear/\n","authors":["Marius Bock","Hilde Kuehne","Kristof Van Laerhoven","Michael Moeller"],"pdf_url":"https://arxiv.org/pdf/2304.05088v3.pdf","comment":"15 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2309.12969v2","updated":"2023-11-21T16:27:11Z","published":"2023-09-22T16:07:16Z","title":"Detect Every Thing with Few Examples","summary":"  Open-set object detection aims at detecting arbitrary categories beyond those\nseen during training. Most recent advancements have adopted the open-vocabulary\nparadigm, utilizing vision-language backbones to represent categories with\nlanguage. In this paper, we introduce DE-ViT, an open-set object detector that\nemploys vision-only DINOv2 backbones and learns new categories through example\nimages instead of language. To improve general detection ability, we transform\nmulti-classification tasks into binary classification tasks while bypassing\nper-class inference, and propose a novel region propagation technique for\nlocalization. We evaluate DE-ViT on open-vocabulary, few-shot, and one-shot\nobject detection benchmark with COCO and LVIS. For COCO, DE-ViT outperforms the\nopen-vocabulary SoTA by 6.9 AP50 and achieves 50 AP50 in novel classes. DE-ViT\nsurpasses the few-shot SoTA by 15 mAP on 10-shot and 7.2 mAP on 30-shot and\none-shot SoTA by 2.8 AP50. For LVIS, DE-ViT outperforms the open-vocabulary\nSoTA by 2.2 mask AP and reaches 34.3 mask APr. Code is available at\nhttps://github.com/mlzxy/devit.\n","authors":["Xinyu Zhang","Yuting Wang","Abdeslam Boularias"],"pdf_url":"https://arxiv.org/pdf/2309.12969v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12704v1","updated":"2023-11-21T16:19:14Z","published":"2023-11-21T16:19:14Z","title":"Cascade Learning Localises Discriminant Features in Visual Scene\n  Classification","summary":"  Lack of interpretability of deep convolutional neural networks (DCNN) is a\nwell-known problem particularly in the medical domain as clinicians want\ntrustworthy automated decisions. One way to improve trust is to demonstrate the\nlocalisation of feature representations with respect to expert labeled regions\nof interest. In this work, we investigate the localisation of features learned\nvia two varied learning paradigms and demonstrate the superiority of one\nlearning approach with respect to localisation. Our analysis on medical and\nnatural datasets show that the traditional end-to-end (E2E) learning strategy\nhas a limited ability to localise discriminative features across multiple\nnetwork layers. We show that a layer-wise learning strategy, namely cascade\nlearning (CL), results in more localised features. Considering localisation\naccuracy, we not only show that CL outperforms E2E but that it is a promising\nmethod of predicting regions. On the YOLO object detection framework, our best\nresult shows that CL outperforms the E2E scheme by $2\\%$ in mAP.\n","authors":["Junwen Wang","Katayoun Farrahi"],"pdf_url":"https://arxiv.org/pdf/2311.12704v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08942v2","updated":"2023-11-21T16:14:54Z","published":"2022-11-16T14:44:27Z","title":"Differentially Private Optimizers Can Learn Adversarially Robust Models","summary":"  Machine learning models have shone in a variety of domains and attracted\nincreasing attention from both the security and the privacy communities. One\nimportant yet worrying question is: Will training models under the differential\nprivacy (DP) constraint have an unfavorable impact on their adversarial\nrobustness? While previous works have postulated that privacy comes at the cost\nof worse robustness, we give the first theoretical analysis to show that DP\nmodels can indeed be robust and accurate, even sometimes more robust than their\nnaturally-trained non-private counterparts. We observe three key factors that\ninfluence the privacy-robustness-accuracy tradeoff: (1) hyper-parameters for DP\noptimizers are critical; (2) pre-training on public data significantly\nmitigates the accuracy and robustness drop; (3) choice of DP optimizers makes a\ndifference. With these factors set properly, we achieve 90\\% natural accuracy,\n72\\% robust accuracy ($+9\\%$ than the non-private model) under $l_2(0.5)$\nattack, and 69\\% robust accuracy ($+16\\%$ than the non-private model) with\npre-trained SimCLRv2 model under $l_\\infty(4/255)$ attack on CIFAR10 with\n$\\epsilon=2$. In fact, we show both theoretically and empirically that DP\nmodels are Pareto optimal on the accuracy-robustness tradeoff. Empirically, the\nrobustness of DP models is consistently observed across various datasets and\nmodels. We believe our encouraging results are a significant step towards\ntraining models that are private as well as robust.\n","authors":["Yuan Zhang","Zhiqi Bu"],"pdf_url":"https://arxiv.org/pdf/2211.08942v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.12311v3","updated":"2023-11-21T15:40:54Z","published":"2020-12-22T19:32:52Z","title":"Influencer Videos: Unboxing the Mystique","summary":"  Influencer marketing has become a very popular tool to reach customers.\nDespite the rapid growth in influencer videos, there has been little research\non the effectiveness of their constituent features in explaining video\nengagement. We study YouTube influencers and analyze their unstructured video\ndata across text, audio and images using an \"interpretable deep learning\"\nframework that accomplishes both goals of prediction and interpretation. Our\nprediction-based approach analyzes unstructured data and finds that \"what is\nsaid\" in words (text) is more influential than \"how it is said\" in imagery\n(images) or acoustics (audio). Our novel interpretation-based approach is\nimplemented after completion of model prediction by analyzing the same source\nof unstructured data to measure importance attributed to the video features. We\neliminate several spurious relationships in two steps, identifying a subset of\nrelationships which are confirmed using theory. We uncover novel findings that\nestablish distinct associations for measures of shallow and deep engagement\nbased on the dual-system framework of human thinking. Our approach is validated\nusing simulated data, and we discuss the learnings from our findings for\ninfluencers and brands.\n","authors":["Prashant Rajaram","Puneet Manchanda"],"pdf_url":"https://arxiv.org/pdf/2012.12311v3.pdf","comment":"45 pages, Online Appendix"},{"id":"http://arxiv.org/abs/2311.12682v1","updated":"2023-11-21T15:39:21Z","published":"2023-11-21T15:39:21Z","title":"Transferring to Real-World Layouts: A Depth-aware Framework for Scene\n  Adaptation","summary":"  Scene segmentation via unsupervised domain adaptation (UDA) enables the\ntransfer of knowledge acquired from source synthetic data to real-world target\ndata, which largely reduces the need for manual pixel-level annotations in the\ntarget domain. To facilitate domain-invariant feature learning, existing\nmethods typically mix data from both the source domain and target domain by\nsimply copying and pasting the pixels. Such vanilla methods are usually\nsub-optimal since they do not take into account how well the mixed layouts\ncorrespond to real-world scenarios. Real-world scenarios are with an inherent\nlayout. We observe that semantic categories, such as sidewalks, buildings, and\nsky, display relatively consistent depth distributions, and could be clearly\ndistinguished in a depth map. Based on such observation, we propose a\ndepth-aware framework to explicitly leverage depth estimation to mix the\ncategories and facilitate the two complementary tasks, i.e., segmentation and\ndepth learning in an end-to-end manner. In particular, the framework contains a\nDepth-guided Contextual Filter (DCF) forndata augmentation and a cross-task\nencoder for contextual learning. DCF simulates the real-world layouts, while\nthe cross-task encoder further adaptively fuses the complementing features\nbetween two tasks. Besides, it is worth noting that several public datasets do\nnot provide depth annotation. Therefore, we leverage the off-the-shelf depth\nestimation network to generate the pseudo depth. Extensive experiments show\nthat our proposed methods, even with pseudo depth, achieve competitive\nperformance on two widely-used bench-marks, i.e. 77.7 mIoU on GTA to Cityscapes\nand 69.3 mIoU on Synthia to Cityscapes.\n","authors":["Mu Chen","Zhedong Zheng","Yi Yang"],"pdf_url":"https://arxiv.org/pdf/2311.12682v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12679v1","updated":"2023-11-21T15:37:19Z","published":"2023-11-21T15:37:19Z","title":"BundleMoCap: Efficient, Robust and Smooth Motion Capture from Sparse\n  Multiview Videos","summary":"  Capturing smooth motions from videos using markerless techniques typically\ninvolves complex processes such as temporal constraints, multiple stages with\ndata-driven regression and optimization, and bundle solving over temporal\nwindows. These processes can be inefficient and require tuning multiple\nobjectives across stages. In contrast, BundleMoCap introduces a novel and\nefficient approach to this problem. It solves the motion capture task in a\nsingle stage, eliminating the need for temporal smoothness objectives while\nstill delivering smooth motions. BundleMoCap outperforms the state-of-the-art\nwithout increasing complexity. The key concept behind BundleMoCap is manifold\ninterpolation between latent keyframes. By relying on a local manifold\nsmoothness assumption, we can efficiently solve a bundle of frames using a\nsingle code. Additionally, the method can be implemented as a sliding window\noptimization and requires only the first frame to be properly initialized,\nreducing the overall computational burden. BundleMoCap's strength lies in its\nability to achieve high-quality motion capture results with simplicity and\nefficiency. More details can be found at https://moverseai.github.io/bundle/.\n","authors":["Georgios Albanis","Nikolaos Zioulis","Kostas Kolomvatsos"],"pdf_url":"https://arxiv.org/pdf/2311.12679v1.pdf","comment":"Published in European Conference on Visual Media Production (CVMP\n  '23)"},{"id":"http://arxiv.org/abs/2311.00187v2","updated":"2023-11-21T15:25:15Z","published":"2023-10-31T23:19:30Z","title":"Decodable and Sample Invariant Continuous Object Encoder","summary":"  We propose Hyper-Dimensional Function Encoding (HDFE). Given samples of a\ncontinuous object (e.g. a function), HDFE produces an explicit vector\nrepresentation of the given object, invariant to the sample distribution and\ndensity. Sample distribution and density invariance enables HDFE to\nconsistently encode continuous objects regardless of their sampling, and\ntherefore allows neural networks to receive continuous objects as inputs for\nmachine learning tasks, such as classification and regression. Besides, HDFE\ndoes not require any training and is proved to map the object into an organized\nembedding space, which facilitates the training of the downstream tasks. In\naddition, the encoding is decodable, which enables neural networks to regress\ncontinuous objects by regressing their encodings. Therefore, HDFE serves as an\ninterface for processing continuous objects.\n  We apply HDFE to function-to-function mapping, where vanilla HDFE achieves\ncompetitive performance as the state-of-the-art algorithm. We apply HDFE to\npoint cloud surface normal estimation, where a simple replacement from PointNet\nto HDFE leads to immediate 12% and 15% error reductions in two benchmarks. In\naddition, by integrating HDFE into the PointNet-based SOTA network, we improve\nthe SOTA baseline by 2.5% and 1.7% in the same benchmarks.\n","authors":["Dehao Yuan","Furong Huang","Cornelia Fermüller","Yiannis Aloimonos"],"pdf_url":"https://arxiv.org/pdf/2311.00187v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2004.07780v5","updated":"2023-11-21T15:22:43Z","published":"2020-04-16T17:18:49Z","title":"Shortcut Learning in Deep Neural Networks","summary":"  Deep learning has triggered the current rise of artificial intelligence and\nis the workhorse of today's machine intelligence. Numerous success stories have\nrapidly spread all over science, industry and society, but its limitations have\nonly recently come into focus. In this perspective we seek to distill how many\nof deep learning's problems can be seen as different symptoms of the same\nunderlying problem: shortcut learning. Shortcuts are decision rules that\nperform well on standard benchmarks but fail to transfer to more challenging\ntesting conditions, such as real-world scenarios. Related issues are known in\nComparative Psychology, Education and Linguistics, suggesting that shortcut\nlearning may be a common characteristic of learning systems, biological and\nartificial alike. Based on these observations, we develop a set of\nrecommendations for model interpretation and benchmarking, highlighting recent\nadvances in machine learning to improve robustness and transferability from the\nlab to real-world applications.\n","authors":["Robert Geirhos","Jörn-Henrik Jacobsen","Claudio Michaelis","Richard Zemel","Wieland Brendel","Matthias Bethge","Felix A. Wichmann"],"pdf_url":"https://arxiv.org/pdf/2004.07780v5.pdf","comment":"perspective article published at Nature Machine Intelligence\n  (https://doi.org/10.1038/s42256-020-00257-z)"},{"id":"http://arxiv.org/abs/2311.11908v2","updated":"2023-11-21T15:17:00Z","published":"2023-11-20T16:40:29Z","title":"Continual Learning: Applications and the Road Forward","summary":"  Continual learning is a sub-field of machine learning, which aims to allow\nmachine learning models to continuously learn on new data, by accumulating\nknowledge without forgetting what was learned in the past. In this work, we\ntake a step back, and ask: \"Why should one care about continual learning in the\nfirst place?\". We set the stage by surveying recent continual learning papers\npublished at three major machine learning conferences, and show that\nmemory-constrained settings dominate the field. Then, we discuss five open\nproblems in machine learning, and even though they seem unrelated to continual\nlearning at first sight, we show that continual learning will inevitably be\npart of their solution. These problems are model-editing, personalization,\non-device learning, faster (re-)training and reinforcement learning. Finally,\nby comparing the desiderata from these unsolved problems and the current\nassumptions in continual learning, we highlight and discuss four future\ndirections for continual learning research. We hope that this work offers an\ninteresting perspective on the future of continual learning, while displaying\nits potential value and the paths we have to pursue in order to make it\nsuccessful. This work is the result of the many discussions the authors had at\nthe Dagstuhl seminar on Deep Continual Learning, in March 2023.\n","authors":["Eli Verwimp","Rahaf Aljundi","Shai Ben-David","Matthias Bethge","Andrea Cossu","Alexander Gepperth","Tyler L. Hayes","Eyke Hüllermeier","Christopher Kanan","Dhireesha Kudithipudi","Christoph H. Lampert","Martin Mundt","Razvan Pascanu","Adrian Popescu","Andreas S. Tolias","Joost van de Weijer","Bing Liu","Vincenzo Lomonaco","Tinne Tuytelaars","Gido M. van de Ven"],"pdf_url":"https://arxiv.org/pdf/2311.11908v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12663v1","updated":"2023-11-21T15:13:18Z","published":"2023-11-21T15:13:18Z","title":"Similar Document Template Matching Algorithm","summary":"  This study outlines a comprehensive methodology for verifying medical\ndocuments, integrating advanced techniques in template extraction, comparison,\nand fraud detection. It begins with template extraction using sophisticated\nregion-of-interest (ROI) methods, incorporating contour analysis and edge\nidentification. Pre-processing steps ensure template clarity through\nmorphological operations and adaptive thresholding. The template comparison\nalgorithm utilizes advanced feature matching with key points and descriptors,\nenhancing robustness through histogram-based analysis for accounting\nvariations. Fraud detection involves the SSIM computation and OCR for textual\ninformation extraction. The SSIM quantifies structural similarity, aiding in\npotential match identification. OCR focuses on critical areas like patient\ndetails, provider information, and billing amounts. Extracted information is\ncompared with a reference dataset, and confidence thresholding ensures reliable\nfraud detection. Adaptive parameters enhance system flexibility for dynamic\nadjustments to varying document layouts. This methodology provides a robust\napproach to medical document verification, addressing complexities in template\nextraction, comparison, fraud detection, and adaptability to diverse document\nstructures.\n","authors":["Harshitha Yenigalla","Bommareddy Revanth Srinivasa Reddy","Batta Venkata Rahul","Nannapuraju Hemanth Raju"],"pdf_url":"https://arxiv.org/pdf/2311.12663v1.pdf","comment":"8 pages,8 figures"},{"id":"http://arxiv.org/abs/2311.12660v1","updated":"2023-11-21T15:08:17Z","published":"2023-11-21T15:08:17Z","title":"Visually Guided Object Grasping","summary":"  In this paper we present a visual servoing approach to the problem of object\ngrasping and more generally, to the problem of aligning an end-effector with an\nobject. First we extend the method proposed by Espiau et al. [1] to the case of\na camera which is not mounted onto the robot being controlled and we stress the\nimportance of the real-time estimation of the image Jacobian. Second, we show\nhow to represent a grasp or more generally, an alignment between two solids in\n3-D projective space using an uncalibrated stereo rig. Such a 3-D projective\nrepresentation is view-invariant in the sense that it can be easily mapped into\nan image set-point without any knowledge about the camera parameters. Third, we\nperform an analysis of the performances of the visual servoing algorithm and of\nthe grasping precision that can be expected from this type of approach.\n","authors":["Radu Horaud","Fadi Dornaika","Bernard Espiau"],"pdf_url":"https://arxiv.org/pdf/2311.12660v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12655v1","updated":"2023-11-21T14:57:24Z","published":"2023-11-21T14:57:24Z","title":"Hand-Eye Calibration","summary":"  Whenever a sensor is mounted on a robot hand it is important to know the\nrelationship between the sensor and the hand. The problem of determining this\nrelationship is referred to as hand-eye calibration, which is important in at\nleast two types of tasks: (i) map sensor centered measurements into the robot\nworkspace and (ii) allow the robot to precisely move the sensor. In the past\nsome solutions were proposed in the particular case of a camera. With almost no\nexception, all existing solutions attempt to solve the homogeneous matrix\nequation AX=XB. First we show that there are two possible formulations of the\nhand-eye calibration problem. One formulation is the classical one that we just\nmentioned. A second formulation takes the form of the following homogeneous\nmatrix equation: MY=M'YB. The advantage of the latter is that the extrinsic and\nintrinsic camera parameters need not be made explicit. Indeed, this formulation\ndirectly uses the 3 by 4 perspective matrices (M and M') associated with two\npositions of the camera. Moreover, this formulation together with the classical\none cover a wider range of camera-based sensors to be calibrated with respect\nto the robot hand. Second, we develop a common mathematical framework to solve\nfor the hand-eye calibration problem using either of the two formulations. We\npresent two methods, (i) a rotation then translation and (ii) a non-linear\nsolver for rotation and translation. Third, we perform a stability analysis\nboth for our two methods and for the classical linear method developed. In the\nlight of this comparison, the non-linear optimization method, that solves for\nrotation and translation simultaneously, seems to be the most robust one with\nrespect to noise and to measurement errors.\n","authors":["Radu Horaud","Fadi Dornaika"],"pdf_url":"https://arxiv.org/pdf/2311.12655v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.06504v2","updated":"2023-11-21T14:57:09Z","published":"2023-11-11T08:01:40Z","title":"SCL-VI: Self-supervised Context Learning for Visual Inspection of\n  Industrial Defects","summary":"  The unsupervised visual inspection of defects in industrial products poses a\nsignificant challenge due to substantial variations in product surfaces.\nCurrent unsupervised models struggle to strike a balance between detecting\ntexture and object defects, lacking the capacity to discern latent\nrepresentations and intricate features. In this paper, we present a novel\nself-supervised learning algorithm designed to derive an optimal encoder by\ntackling the renowned jigsaw puzzle. Our approach involves dividing the target\nimage into nine patches, tasking the encoder with predicting the relative\nposition relationships between any two patches to extract rich semantics.\nSubsequently, we introduce an affinity-augmentation method to accentuate\ndifferences between normal and abnormal latent representations. Leveraging the\nclassic support vector data description algorithm yields final detection\nresults. Experimental outcomes demonstrate that our proposed method achieves\noutstanding detection and segmentation performance on the widely used MVTec AD\ndataset, with rates of 95.8% and 96.8%, respectively, establishing a\nstate-of-the-art benchmark for both texture and object defects. Comprehensive\nexperimentation underscores the effectiveness of our approach in diverse\nindustrial applications.\n","authors":["Peng Wang","Haiming Yao","Wenyong Yu"],"pdf_url":"https://arxiv.org/pdf/2311.06504v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12651v1","updated":"2023-11-21T14:53:02Z","published":"2023-11-21T14:53:02Z","title":"Mobile-Seed: Joint Semantic Segmentation and Boundary Detection for\n  Mobile Robots","summary":"  Precise and rapid delineation of sharp boundaries and robust semantics is\nessential for numerous downstream robotic tasks, such as robot grasping and\nmanipulation, real-time semantic mapping, and online sensor calibration\nperformed on edge computing units. Although boundary detection and semantic\nsegmentation are complementary tasks, most studies focus on lightweight models\nfor semantic segmentation but overlook the critical role of boundary detection.\nIn this work, we introduce Mobile-Seed, a lightweight, dual-task framework\ntailored for simultaneous semantic segmentation and boundary detection. Our\nframework features a two-stream encoder, an active fusion decoder (AFD) and a\ndual-task regularization approach. The encoder is divided into two pathways:\none captures category-aware semantic information, while the other discerns\nboundaries from multi-scale features. The AFD module dynamically adapts the\nfusion of semantic and boundary information by learning channel-wise\nrelationships, allowing for precise weight assignment of each channel.\nFurthermore, we introduce a regularization loss to mitigate the conflicts in\ndual-task learning and deep diversity supervision. Compared to existing\nmethods, the proposed Mobile-Seed offers a lightweight framework to\nsimultaneously improve semantic segmentation performance and accurately locate\nobject boundaries. Experiments on the Cityscapes dataset have shown that\nMobile-Seed achieves notable improvement over the state-of-the-art (SOTA)\nbaseline by 2.2 percentage points (pp) in mIoU and 4.2 pp in mF-score, while\nmaintaining an online inference speed of 23.9 frames-per-second (FPS) with\n1024x2048 resolution input on an RTX 2080 Ti GPU. Additional experiments on\nCamVid and PASCAL Context datasets confirm our method's generalizability. Code\nand additional results are publicly available at\n\\url{https://martin-liao.github.io/Mobile-Seed/}.\n","authors":["Youqi Liao","Shuhao Kang","Jianping Li","Yang Liu","Yun Liu","Zhen Dong","Bisheng Yang","Xieyuanli Chen"],"pdf_url":"https://arxiv.org/pdf/2311.12651v1.pdf","comment":"8 pages, IEEE conference/letter underreview. Code and additional\n  results are available at: \\url{https://martin-liao.github.io/Mobile-Seed/}"},{"id":"http://arxiv.org/abs/2311.12641v1","updated":"2023-11-21T14:41:21Z","published":"2023-11-21T14:41:21Z","title":"Polyhedral Object Recognition by Indexing","summary":"  In computer vision, the indexing problem is the problem of recognizing a few\nobjects in a large database of objects while avoiding the help of the classical\nimage-feature-to-object-feature matching paradigm. In this paper we address the\nproblem of recognizing 3-D polyhedral objects from 2-D images by indexing. Both\nthe objects to be recognized and the images are represented by weighted graphs.\nThe indexing problem is therefore the problem of determining whether a graph\nextracted from the image is present or absent in a database of model graphs. We\nintroduce a novel method for performing this graph indexing process which is\nbased both on polynomial characterization of binary and weighted graphs and on\nhashing. We describe in detail this polynomial characterization and then we\nshow how it can be used in the context of polyhedral object recognition. Next\nwe describe a practical recognition-by-indexing system that includes the\norganization of the database, the representation of polyhedral objects in terms\nof 2-D characteristic views, the representation of this views in terms of\nweighted graphs, and the associated image processing. Finally, some\nexperimental results allow the evaluation of the system performance.\n","authors":["Radu Horaud","Humberto Sossa"],"pdf_url":"https://arxiv.org/pdf/2311.12641v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12639v1","updated":"2023-11-21T14:39:18Z","published":"2023-11-21T14:39:18Z","title":"KNVQA: A Benchmark for evaluation knowledge-based VQA","summary":"  Within the multimodal field, large vision-language models (LVLMs) have made\nsignificant progress due to their strong perception and reasoning capabilities\nin the visual and language systems. However, LVLMs are still plagued by the two\ncritical issues of object hallucination and factual accuracy, which limit the\npracticality of LVLMs in different scenarios. Furthermore, previous evaluation\nmethods focus more on the comprehension and reasoning of language content but\nlack a comprehensive evaluation of multimodal interactions, thereby resulting\nin potential limitations. To this end, we propose a novel KNVQA-Eval, which is\ndevoted to knowledge-based VQA task evaluation to reflect the factuality of\nmultimodal LVLMs. To ensure the robustness and scalability of the evaluation,\nwe develop a new KNVQA dataset by incorporating human judgment and perception,\naiming to evaluate the accuracy of standard answers relative to AI-generated\nanswers in knowledge-based VQA. This work not only comprehensively evaluates\nthe contextual information of LVLMs using reliable human annotations, but also\nfurther analyzes the fine-grained capabilities of current methods to reveal\npotential avenues for subsequent optimization of LVLMs-based estimators. Our\nproposed VQA-Eval and corresponding dataset KNVQA will facilitate the\ndevelopment of automatic evaluation tools with the advantages of low cost,\nprivacy protection, and reproducibility. Our code will be released upon\npublication.\n","authors":["Sirui Cheng","Siyu Zhang","Jiayi Wu","Muchen Lan"],"pdf_url":"https://arxiv.org/pdf/2311.12639v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10122v2","updated":"2023-11-21T14:37:30Z","published":"2023-11-16T10:59:44Z","title":"Video-LLaVA: Learning United Visual Representation by Alignment Before\n  Projection","summary":"  The Large Vision-Language Model (LVLM) has enhanced the performance of\nvarious downstream tasks in visual-language understanding. Most existing\napproaches encode images and videos into separate feature spaces, which are\nthen fed as inputs to large language models. However, due to the lack of\nunified tokenization for images and videos, namely misalignment before\nprojection, it becomes challenging for a Large Language Model (LLM) to learn\nmulti-modal interactions from several poor projection layers. In this work, we\nunify visual representation into the language feature space to advance the\nfoundational LLM towards a unified LVLM. As a result, we establish a simple but\nrobust LVLM baseline, Video-LLaVA, which learns from a mixed dataset of images\nand videos, mutually enhancing each other. Video-LLaVA achieves superior\nperformances on a broad range of 9 image benchmarks across 5 image\nquestion-answering datasets and 4 image benchmark toolkits. Additionally, our\nVideo-LLaVA also outperforms Video-ChatGPT by 5.8%, 9.9%, 18.6%, and 10.1% on\nMSRVTT, MSVD, TGIF, and ActivityNet, respectively. Notably, extensive\nexperiments demonstrate that Video-LLaVA mutually benefits images and videos\nwithin a unified visual representation, outperforming models designed\nspecifically for images or videos. We aim for this work to provide modest\ninsights into the multi-modal inputs for the LLM.\n","authors":["Bin Lin","Yang Ye","Bin Zhu","Jiaxi Cui","Munan Ning","Peng Jin","Li Yuan"],"pdf_url":"https://arxiv.org/pdf/2311.10122v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12631v1","updated":"2023-11-21T14:24:37Z","published":"2023-11-21T14:24:37Z","title":"GPT4Motion: Scripting Physical Motions in Text-to-Video Generation via\n  Blender-Oriented GPT Planning","summary":"  Recent advances in text-to-video generation have harnessed the power of\ndiffusion models to create visually compelling content conditioned on text\nprompts. However, they usually encounter high computational costs and often\nstruggle to produce videos with coherent physical motions. To tackle these\nissues, we propose GPT4Motion, a training-free framework that leverages the\nplanning capability of large language models such as GPT, the physical\nsimulation strength of Blender, and the excellent image generation ability of\ntext-to-image diffusion models to enhance the quality of video synthesis.\nSpecifically, GPT4Motion employs GPT-4 to generate a Blender script based on a\nuser textual prompt, which commands Blender's built-in physics engine to craft\nfundamental scene components that encapsulate coherent physical motions across\nframes. Then these components are inputted into Stable Diffusion to generate a\nvideo aligned with the textual prompt. Experimental results on three basic\nphysical motion scenarios, including rigid object drop and collision, cloth\ndraping and swinging, and liquid flow, demonstrate that GPT4Motion can generate\nhigh-quality videos efficiently in maintaining motion coherency and entity\nconsistency. GPT4Motion offers new insights in text-to-video research,\nenhancing its quality and broadening its horizon for future explorations.\n","authors":["Jiaxi Lv","Yi Huang","Mingfu Yan","Jiancheng Huang","Jianzhuang Liu","Yifan Liu","Yafei Wen","Xiaoxin Chen","Shifeng Chen"],"pdf_url":"https://arxiv.org/pdf/2311.12631v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12623v1","updated":"2023-11-21T14:16:57Z","published":"2023-11-21T14:16:57Z","title":"Bridging Generalization Gaps in High Content Imaging Through Online\n  Self-Supervised Domain Adaptation","summary":"  High Content Imaging (HCI) plays a vital role in modern drug discovery and\ndevelopment pipelines, facilitating various stages from hit identification to\ncandidate drug characterization. Applying machine learning models to these\ndatasets can prove challenging as they typically consist of multiple batches,\naffected by experimental variation, especially if different imaging equipment\nhave been used. Moreover, as new data arrive, it is preferable that they are\nanalyzed in an online fashion. To overcome this, we propose CODA, an online\nself-supervised domain adaptation approach. CODA divides the classifier's role\ninto a generic feature extractor and a task-specific model. We adapt the\nfeature extractor's weights to the new domain using cross-batch\nself-supervision while keeping the task-specific model unchanged. Our results\ndemonstrate that this strategy significantly reduces the generalization gap,\nachieving up to a 300% improvement when applied to data from different labs\nutilizing different microscopes. CODA can be applied to new, unlabeled\nout-of-domain data sources of different sizes, from a single plate to multiple\nexperimental batches.\n","authors":["Johan Fredin Haslum","Christos Matsoukas","Karl-Johan Leuchowius","Kevin Smith"],"pdf_url":"https://arxiv.org/pdf/2311.12623v1.pdf","comment":"IEEE/CVF Winter Conference on Applications of Computer Vision (WACV\n  2024)"},{"id":"http://arxiv.org/abs/2311.12621v1","updated":"2023-11-21T14:12:17Z","published":"2023-11-21T14:12:17Z","title":"Crowd management, crime detection, work monitoring using aiml","summary":"  This research endeavors to harness the potential of existing Closed-Circuit\nTelevision (CCTV) networks for a comprehensive approach to crowd management,\ncrime prevention, and workplace monitoring through the integration of\nArtificial Intelligence (AI) and Machine Learning (ML) technologies. The\nprimary objective is to develop and implement advanced algorithms capable of\nreal-time analysis of video feeds, enabling the identification and assessment\nof crowd dynamics, early detection of potential criminal activities, and\ncontinuous monitoring of workplace environments. By leveraging AI/ML, the\nproject aims to optimize surveillance capabilities, thereby enhancing public\nsafety measures and improving organizational productivity. This initiative\nunderscores the transformative impact that intelligent video analytics can have\non existing infrastructure, mitigating the need for extensive system overhauls\nwhile significantly advancing security and operational efficiency.\n","authors":["P. R. Adithya","Dheepak. S","B. Akash","Harshini. V","Sai Lakshana"],"pdf_url":"https://arxiv.org/pdf/2311.12621v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12617v1","updated":"2023-11-21T14:03:16Z","published":"2023-11-21T14:03:16Z","title":"Leveraging Unlabeled Data for 3D Medical Image Segmentation through\n  Self-Supervised Contrastive Learning","summary":"  Current 3D semi-supervised segmentation methods face significant challenges\nsuch as limited consideration of contextual information and the inability to\ngenerate reliable pseudo-labels for effective unsupervised data use. To address\nthese challenges, we introduce two distinct subnetworks designed to explore and\nexploit the discrepancies between them, ultimately correcting the erroneous\nprediction results. More specifically, we identify regions of inconsistent\npredictions and initiate a targeted verification training process. This\nprocedure strategically fine-tunes and harmonizes the predictions of the\nsubnetworks, leading to enhanced utilization of contextual information.\nFurthermore, to adaptively fine-tune the network's representational capacity\nand reduce prediction uncertainty, we employ a self-supervised contrastive\nlearning paradigm. For this, we use the network's confidence to distinguish\nbetween reliable and unreliable predictions. The model is then trained to\neffectively minimize unreliable predictions. Our experimental results for organ\nsegmentation, obtained from clinical MRI and CT scans, demonstrate the\neffectiveness of our approach when compared to state-of-the-art methods. The\ncodebase is accessible on\n\\href{https://github.com/xmindflow/SSL-contrastive}{GitHub}.\n","authors":["Sanaz Karimijafarbigloo","Reza Azad","Yury Velichko","Ulas Bagci","Dorit Merhof"],"pdf_url":"https://arxiv.org/pdf/2311.12617v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.01446v3","updated":"2023-11-21T14:02:33Z","published":"2023-09-04T08:54:20Z","title":"Open Sesame! Universal Black Box Jailbreaking of Large Language Models","summary":"  Large language models (LLMs), designed to provide helpful and safe responses,\noften rely on alignment techniques to align with user intent and social\nguidelines. Unfortunately, this alignment can be exploited by malicious actors\nseeking to manipulate an LLM's outputs for unintended purposes. In this paper\nwe introduce a novel approach that employs a genetic algorithm (GA) to\nmanipulate LLMs when model architecture and parameters are inaccessible. The GA\nattack works by optimizing a universal adversarial prompt that -- when combined\nwith a user's query -- disrupts the attacked model's alignment, resulting in\nunintended and potentially harmful outputs. Our novel approach systematically\nreveals a model's limitations and vulnerabilities by uncovering instances where\nits responses deviate from expected behavior. Through extensive experiments we\ndemonstrate the efficacy of our technique, thus contributing to the ongoing\ndiscussion on responsible AI development by providing a diagnostic tool for\nevaluating and enhancing alignment of LLMs with human intent. To our knowledge\nthis is the first automated universal black box jailbreak attack.\n","authors":["Raz Lapid","Ron Langberg","Moshe Sipper"],"pdf_url":"https://arxiv.org/pdf/2309.01446v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11306v2","updated":"2023-11-21T13:59:31Z","published":"2023-11-19T11:57:01Z","title":"UMAAF: Unveiling Aesthetics via Multifarious Attributes of Images","summary":"  With the increasing prevalence of smartphones and websites, Image Aesthetic\nAssessment (IAA) has become increasingly crucial. While the significance of\nattributes in IAA is widely recognized, many attribute-based methods lack\nconsideration for the selection and utilization of aesthetic attributes. Our\ninitial step involves the acquisition of aesthetic attributes from both intra-\nand inter-perspectives. Within the intra-perspective, we extract the direct\nvisual attributes of images, constituting the absolute attribute. In the\ninter-perspective, our focus lies in modeling the relative score relationships\nbetween images within the same sequence, forming the relative attribute. Then,\nto better utilize image attributes in aesthetic assessment, we propose the\nUnified Multi-attribute Aesthetic Assessment Framework (UMAAF) to model both\nabsolute and relative attributes of images. For absolute attributes, we\nleverage multiple absolute-attribute perception modules and an\nabsolute-attribute interacting network. The absolute-attribute perception\nmodules are first pre-trained on several absolute-attribute learning tasks and\nthen used to extract corresponding absolute attribute features. The\nabsolute-attribute interacting network adaptively learns the weight of diverse\nabsolute-attribute features, effectively integrating them with generic\naesthetic features from various absolute-attribute perspectives and generating\nthe aesthetic prediction. To model the relative attribute of images, we\nconsider the relative ranking and relative distance relationships between\nimages in a Relative-Relation Loss function, which boosts the robustness of the\nUMAAF. Furthermore, UMAAF achieves state-of-the-art performance on TAD66K and\nAVA datasets, and multiple experiments demonstrate the effectiveness of each\nmodule and the model's alignment with human preference.\n","authors":["Weijie Li","Yitian Wan","Xingjiao Wu","Junjie Xu","Cheng Jin","Liang He"],"pdf_url":"https://arxiv.org/pdf/2311.11306v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.05858v2","updated":"2023-11-21T13:55:33Z","published":"2023-11-10T03:54:40Z","title":"Layer-wise Auto-Weighting for Non-Stationary Test-Time Adaptation","summary":"  Given the inevitability of domain shifts during inference in real-world\napplications, test-time adaptation (TTA) is essential for model adaptation\nafter deployment. However, the real-world scenario of continuously changing\ntarget distributions presents challenges including catastrophic forgetting and\nerror accumulation. Existing TTA methods for non-stationary domain shifts,\nwhile effective, incur excessive computational load, making them impractical\nfor on-device settings. In this paper, we introduce a layer-wise auto-weighting\nalgorithm for continual and gradual TTA that autonomously identifies layers for\npreservation or concentrated adaptation. By leveraging the Fisher Information\nMatrix (FIM), we first design the learning weight to selectively focus on\nlayers associated with log-likelihood changes while preserving unrelated ones.\nThen, we further propose an exponential min-max scaler to make certain layers\nnearly frozen while mitigating outliers. This minimizes forgetting and error\naccumulation, leading to efficient adaptation to non-stationary target\ndistribution. Experiments on CIFAR-10C, CIFAR-100C, and ImageNet-C show our\nmethod outperforms conventional continual and gradual TTA approaches while\nsignificantly reducing computational load, highlighting the importance of\nFIM-based learning weight in adapting to continuously or gradually shifting\ntarget domains.\n","authors":["Junyoung Park","Jin Kim","Hyeongjun Kwon","Ilhoon Yoon","Kwanghoon Sohn"],"pdf_url":"https://arxiv.org/pdf/2311.05858v2.pdf","comment":"Accepted to WACV 2024"},{"id":"http://arxiv.org/abs/2311.12610v1","updated":"2023-11-21T13:52:31Z","published":"2023-11-21T13:52:31Z","title":"ChessVision -- A Dataset for Logically Coherent Multi-label\n  Classification","summary":"  Starting with early successes in computer vision tasks, deep learning based\ntechniques have since overtaken state of the art approaches in a multitude of\ndomains. However, it has been demonstrated time and again that these techniques\nfail to capture semantic context and logical constraints, instead often relying\non spurious correlations to arrive at the answer. Since application of deep\nlearning techniques to critical scenarios are dependent on adherence to domain\nspecific constraints, several attempts have been made to address this issue.\nOne limitation holding back a thorough exploration of this area, is a lack of\nsuitable datasets which feature a rich set of rules. In order to address this,\nwe present the ChessVision Dataset, consisting of 200,000+ images of annotated\nchess games in progress, requiring recreation of the game state from its\ncorresponding image. This is accompanied by a curated set of rules which\nconstrains the set of predictions to \"reasonable\" game states, and are designed\nto probe key semantic abilities like localization and enumeration. Alongside\nstandard metrics, additional metrics to measure performance with regards to\nlogical consistency is presented. We analyze several popular and state of the\nart vision models on this task, and show that, although their performance on\nstandard metrics are laudable, they produce a plethora of incoherent results,\nindicating that this dataset presents a significant challenge for future works.\n","authors":["Soumadeep Saha","Utpal Garain"],"pdf_url":"https://arxiv.org/pdf/2311.12610v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12608v1","updated":"2023-11-21T13:49:28Z","published":"2023-11-21T13:49:28Z","title":"Adaptive Dense Pseudo Label Selection for Semi-supervised Oriented\n  Object Detection","summary":"  Recently, dense pseudo-label, which directly selects pseudo labels from the\noriginal output of the teacher model without any complicated post-processing\nsteps, has received considerable attention in semi-supervised object detection\n(SSOD). However, for the multi-oriented and dense objects that are common in\naerial scenes, existing dense pseudo-label selection methods are inefficient\nand impede the performance in semi-supervised oriented object detection.\nTherefore, we propose Adaptive Dense Pseudo Label Selection (ADPLS) for\nsemi-supervised oriented object detection. In ADPLS, we design a simple but\neffective adaptive mechanism to guide the selection of dense pseudo labels.\nSpecifically, we propose the mean Feature-Richness Score (mFRS) to estimate the\ndensity of potential objects and use this score to adjust the number of dense\npseudo labels. On the DOTA-v1.5 benchmark, the proposed method outperforms\nprevious methods especially when labeled data are scarce. For example, it\nachieves 49.78 mAP given only 5% of annotated data, which surpasses previous\nstate-of-the-art method given 10% of annotated data by 1.15 mAP. Our codes will\nbe available soon.\n","authors":["Tong Zhao","Qiang Fang","Shuohao Shi","Xin Xu"],"pdf_url":"https://arxiv.org/pdf/2311.12608v1.pdf","comment":"9 pages, 6 figures"},{"id":"http://arxiv.org/abs/2207.04934v2","updated":"2023-11-21T13:46:46Z","published":"2022-07-11T15:15:33Z","title":"Multi-level Geometric Optimization for Regularised Constrained Linear\n  Inverse Problems","summary":"  We present a geometric multilevel optimization approach that smoothly\nincorporates box constraints. Given a box constrained optimization problem, we\nconsider a hierarchy of models with varying discretization levels. Finer models\nare accurate but expensive to compute, while coarser models are less accurate\nbut cheaper to compute. When working at the fine level, multilevel optimisation\ncomputes the search direction based on a coarser model which speeds up updates\nat the fine level. Moreover, exploiting geometry induced by the hierarchy the\nfeasibility of the updates is preserved. In particular, our approach extends\nclassical components of multigrid methods like restriction and prolongation to\nthe Riemannian structure of our constraints.\n","authors":["Sebastian Müller","Stefania Petra","Matthias Zisler"],"pdf_url":"https://arxiv.org/pdf/2207.04934v2.pdf","comment":"25 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.12603v1","updated":"2023-11-21T13:43:16Z","published":"2023-11-21T13:43:16Z","title":"Surgical Temporal Action-aware Network with Sequence Regularization for\n  Phase Recognition","summary":"  To assist surgeons in the operating theatre, surgical phase recognition is\ncritical for developing computer-assisted surgical systems, which requires\ncomprehensive understanding of surgical videos. Although existing studies made\ngreat progress, there are still two significant limitations worthy of\nimprovement. First, due to the compromise of resource consumption, frame-wise\nvisual features are extracted by 2D networks and disregard spatial and temporal\nknowledge of surgical actions, which hinders subsequent inter-frame modeling\nfor phase prediction. Second, these works simply utilize ordinary\nclassification loss with one-hot phase labels to optimize the phase\npredictions, and cannot fully explore surgical videos under inadequate\nsupervision. To overcome these two limitations, we propose a Surgical Temporal\nAction-aware Network with sequence Regularization, named STAR-Net, to recognize\nsurgical phases more accurately from input videos. Specifically, we propose an\nefficient multi-scale surgical temporal action (MS-STA) module, which\nintegrates visual features with spatial and temporal knowledge of surgical\nactions at the cost of 2D networks. Moreover, we devise the dual-classifier\nsequence regularization (DSR) to facilitate the training of STAR-Net by the\nsequence guidance of an auxiliary classifier with a smaller capacity. Our\nSTAR-Net with MS-STA and DSR can exploit visual features of surgical actions\nwith effective regularization, thereby leading to the superior performance of\nsurgical phase recognition. Extensive experiments on a large-scale gastrectomy\nsurgery dataset and the public Cholec80 benchmark prove that our STAR-Net\nsignificantly outperforms state-of-the-arts of surgical phase recognition.\n","authors":["Zhen Chen","Yuhao Zhai","Jun Zhang","Jinqiao Wang"],"pdf_url":"https://arxiv.org/pdf/2311.12603v1.pdf","comment":"Accepted by 2023 IEEE International Conference on Bioinformatics and\n  Biomedicine (BIBM 2023)"},{"id":"http://arxiv.org/abs/2311.12602v1","updated":"2023-11-21T13:43:06Z","published":"2023-11-21T13:43:06Z","title":"TouchSDF: A DeepSDF Approach for 3D Shape Reconstruction using\n  Vision-Based Tactile Sensing","summary":"  Humans rely on their visual and tactile senses to develop a comprehensive 3D\nunderstanding of their physical environment. Recently, there has been a growing\ninterest in exploring and manipulating objects using data-driven approaches\nthat utilise high-resolution vision-based tactile sensors. However, 3D shape\nreconstruction using tactile sensing has lagged behind visual shape\nreconstruction because of limitations in existing techniques, including the\ninability to generalise over unseen shapes, the absence of real-world testing,\nand limited expressive capacity imposed by discrete representations. To address\nthese challenges, we propose TouchSDF, a Deep Learning approach for tactile 3D\nshape reconstruction that leverages the rich information provided by a\nvision-based tactile sensor and the expressivity of the implicit neural\nrepresentation DeepSDF. Our technique consists of two components: (1) a\nConvolutional Neural Network that maps tactile images into local meshes\nrepresenting the surface at the touch location, and (2) an implicit neural\nfunction that predicts a signed distance function to extract the desired 3D\nshape. This combination allows TouchSDF to reconstruct smooth and continuous 3D\nshapes from tactile inputs in simulation and real-world settings, opening up\nresearch avenues for robust 3D-aware representations and improved multimodal\nperception in robotics. Code and supplementary material are available at:\nhttps://touchsdf.github.io/\n","authors":["Mauro Comi","Yijiong Lin","Alex Church","Alessio Tonioni","Laurence Aitchison","Nathan F. Lepora"],"pdf_url":"https://arxiv.org/pdf/2311.12602v1.pdf","comment":"10 pages, 8 figures"},{"id":"http://arxiv.org/abs/2311.12601v1","updated":"2023-11-21T13:42:40Z","published":"2023-11-21T13:42:40Z","title":"Deep learning-based detection of morphological features associated with\n  hypoxia in H&E breast cancer whole slide images","summary":"  Hypoxia occurs when tumour cells outgrow their blood supply, leading to\nregions of low oxygen levels within the tumour. Calculating hypoxia levels can\nbe an important step in understanding the biology of tumours, their clinical\nprogression and response to treatment. This study demonstrates a novel\napplication of deep learning to evaluate hypoxia in the context of breast\ncancer histomorphology. More precisely, we show that Weakly Supervised Deep\nLearning (WSDL) models can accurately detect hypoxia associated features in\nroutine Hematoxylin and Eosin (H&E) whole slide images (WSI). We trained and\nevaluated a deep Multiple Instance Learning model on tiles from WSI H&E tissue\nfrom breast cancer primary sites (n=240) obtaining on average an AUC of 0.87 on\na left-out test set. We also showed significant differences between features of\nhypoxic and normoxic tissue regions as distinguished by the WSDL models. Such\nDL hypoxia H&E WSI detection models could potentially be extended to other\ntumour types and easily integrated into the pathology workflow without\nrequiring additional costly assays.\n","authors":["Petru Manescu","Joseph Geradts","Delmiro Fernandez-Reyes"],"pdf_url":"https://arxiv.org/pdf/2311.12601v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2311.12589v1","updated":"2023-11-21T13:26:13Z","published":"2023-11-21T13:26:13Z","title":"Improving Source-Free Target Adaptation with Vision Transformers\n  Leveraging Domain Representation Images","summary":"  Unsupervised Domain Adaptation (UDA) methods facilitate knowledge transfer\nfrom a labeled source domain to an unlabeled target domain, navigating the\nobstacle of domain shift. While Convolutional Neural Networks (CNNs) are a\nstaple in UDA, the rise of Vision Transformers (ViTs) provides new avenues for\ndomain generalization. This paper presents an innovative method to bolster ViT\nperformance in source-free target adaptation, beginning with an evaluation of\nhow key, query, and value elements affect ViT outcomes. Experiments indicate\nthat altering the key component has negligible effects on Transformer\nperformance. Leveraging this discovery, we introduce Domain Representation\nImages (DRIs), feeding embeddings through the key element. DRIs act as\ndomain-specific markers, effortlessly merging with the training regimen. To\nassess our method, we perform target adaptation tests on the Cross Instance DRI\nsource-only (SO) control. We measure the efficacy of target adaptation with and\nwithout DRIs, against existing benchmarks like SHOT-B* and adaptations via\nCDTrans. Findings demonstrate that excluding DRIs offers limited gains over\nSHOT-B*, while their inclusion in the key segment boosts average precision\npromoting superior domain generalization. This research underscores the vital\nrole of DRIs in enhancing ViT efficiency in UDA scenarios, setting a precedent\nfor further domain adaptation explorations.\n","authors":["Gauransh Sawhney","Daksh Dave","Adeel Ahmed","Jiechao Gao","Khalid Saleem"],"pdf_url":"https://arxiv.org/pdf/2311.12589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12588v1","updated":"2023-11-21T13:21:22Z","published":"2023-11-21T13:21:22Z","title":"HiPose: Hierarchical Binary Surface Encoding and Correspondence Pruning\n  for RGB-D 6DoF Object Pose Estimation","summary":"  In this work, we present a novel dense-correspondence method for 6DoF object\npose estimation from a single RGB-D image. While many existing data-driven\nmethods achieve impressive performance, they tend to be time-consuming due to\ntheir reliance on rendering-based refinement approaches. To circumvent this\nlimitation, we present HiPose, which establishes 3D-3D correspondences in a\ncoarse-to-fine manner with a hierarchical binary surface encoding. Unlike\nprevious dense-correspondence methods, we estimate the correspondence surface\nby employing point-to-surface matching and iteratively constricting the surface\nuntil it becomes a correspondence point while gradually removing outliers.\nExtensive experiments on public benchmarks LM-O, YCB-V, and T-Less demonstrate\nthat our method surpasses all refinement-free methods and is even on par with\nexpensive refinement-based approaches. Crucially, our approach is\ncomputationally efficient and enables real-time critical applications with high\naccuracy requirements. Code and models will be released.\n","authors":["Yongliang Lin","Yongzhi Su","Praveen Nathan","Sandeep Inuganti","Yan Di","Martin Sundermeyer","Fabian Manhardt","Didier Stricke","Jason Rambach","Yu Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12588v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12582v1","updated":"2023-11-21T13:00:03Z","published":"2023-11-21T13:00:03Z","title":"Echocardiogram Foundation Model -- Application 1: Estimating Ejection\n  Fraction","summary":"  Cardiovascular diseases stand as the primary global cause of mortality. Among\nthe various imaging techniques available for visualising the heart and\nevaluating its function, echocardiograms emerge as the preferred choice due to\ntheir safety and low cost. Quantifying cardiac function based on\nechocardiograms is very laborious, time-consuming and subject to high\ninteroperator variability. In this work, we introduce EchoAI, an echocardiogram\nfoundation model, that is trained using self-supervised learning (SSL) on 1.5\nmillion echocardiograms. We evaluate our approach by fine-tuning EchoAI to\nestimate the ejection fraction achieving a mean absolute percentage error of\n9.40%. This level of accuracy aligns with the performance of expert\nsonographers.\n","authors":["Adil Dahlan","Cyril Zakka","Abhinav Kumar","Laura Tang","Rohan Shad","Robyn Fong","William Hiesinger"],"pdf_url":"https://arxiv.org/pdf/2311.12582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12581v1","updated":"2023-11-21T12:56:42Z","published":"2023-11-21T12:56:42Z","title":"A Region of Interest Focused Triple UNet Architecture for Skin Lesion\n  Segmentation","summary":"  Skin lesion segmentation is of great significance for skin lesion analysis\nand subsequent treatment. It is still a challenging task due to the irregular\nand fuzzy lesion borders, and diversity of skin lesions. In this paper, we\npropose Triple-UNet to automatically segment skin lesions. It is an organic\ncombination of three UNet architectures with suitable modules. In order to\nconcatenate the first and second sub-networks more effectively, we design a\nregion of interest enhancement module (ROIE). The ROIE enhances the target\nobject region of the image by using the predicted score map of the first UNet.\nThe features learned by the first UNet and the enhanced image help the second\nUNet obtain a better score map. Finally, the results are fine-tuned by the\nthird UNet. We evaluate our algorithm on a publicly available dataset of skin\nlesion segmentation. Experiments show that Triple-UNet outperforms the\nstate-of-the-art on skin lesion segmentation.\n","authors":["Guoqing Liu","Yu Guo","Caiying Wu","Guoqing Chen","Barintag Saheya","Qiyu Jin"],"pdf_url":"https://arxiv.org/pdf/2311.12581v1.pdf","comment":"15 pages, 5 figures"},{"id":"http://arxiv.org/abs/2212.02081v2","updated":"2023-11-21T12:43:30Z","published":"2022-12-05T07:52:08Z","title":"YolOOD: Utilizing Object Detection Concepts for Multi-Label\n  Out-of-Distribution Detection","summary":"  Out-of-distribution (OOD) detection has attracted a large amount of attention\nfrom the machine learning research community in recent years due to its\nimportance in deployed systems. Most of the previous studies focused on the\ndetection of OOD samples in the multi-class classification task. However, OOD\ndetection in the multi-label classification task, a more common real-world use\ncase, remains an underexplored domain. In this research, we propose YolOOD - a\nmethod that utilizes concepts from the object detection domain to perform OOD\ndetection in the multi-label classification task. Object detection models have\nan inherent ability to distinguish between objects of interest\n(in-distribution) and irrelevant objects (e.g., OOD objects) in images that\ncontain multiple objects belonging to different class categories. These\nabilities allow us to convert a regular object detection model into an image\nclassifier with inherent OOD detection capabilities with just minor changes. We\ncompare our approach to state-of-the-art OOD detection methods and demonstrate\nYolOOD's ability to outperform these methods on a comprehensive suite of\nin-distribution and OOD benchmark datasets.\n","authors":["Alon Zolfi","Guy Amit","Amit Baras","Satoru Koda","Ikuya Morikawa","Yuval Elovici","Asaf Shabtai"],"pdf_url":"https://arxiv.org/pdf/2212.02081v2.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.12562v1","updated":"2023-11-21T12:17:51Z","published":"2023-11-21T12:17:51Z","title":"Multi-Resolution Planar Region Extraction for Uneven Terrains","summary":"  This paper studies the problem of extracting planar regions in uneven\nterrains from unordered point cloud measurements. Such a problem is critical in\nvarious robotic applications such as robotic perceptive locomotion. While\nexisting approaches have shown promising results in effectively extracting\nplanar regions from the environment, they often suffer from issues such as low\ncomputational efficiency or loss of resolution. To address these issues, we\npropose a multi-resolution planar region extraction strategy in this paper that\nbalances the accuracy in boundaries and computational efficiency. Our method\nbegins with a pointwise classification preprocessing module, which categorizes\nall sampled points according to their local geometric properties to facilitate\nmulti-resolution segmentation. Subsequently, we arrange the categorized points\nusing an octree, followed by an in-depth analysis of nodes to finish\nmulti-resolution plane segmentation. The efficiency and robustness of the\nproposed approach are verified via synthetic and real-world experiments,\ndemonstrating our method's ability to generalize effectively across various\nuneven terrains while maintaining real-time performance, achieving frame rates\nexceeding 35 FPS.\n","authors":["Yinghan Sun","Linfang Zheng","Hua Chen","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12562v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12561v1","updated":"2023-11-21T12:15:28Z","published":"2023-11-21T12:15:28Z","title":"Convolutional Neural Networks for Neuroimaging in Parkinson's Disease:\n  Is Preprocessing Needed?","summary":"  Spatial and intensity normalization are nowadays a prerequisite for\nneuroimaging analysis. Influenced by voxel-wise and other univariate\ncomparisons, where these corrections are key, they are commonly applied to any\ntype of analysis and imaging modalities. Nuclear imaging modalities such as\nPET-FDG or FP-CIT SPECT, a common modality used in Parkinson's Disease\ndiagnosis, are especially dependent on intensity normalization. However, these\nsteps are computationally expensive and furthermore, they may introduce\ndeformations in the images, altering the information contained in them.\nConvolutional Neural Networks (CNNs), for their part, introduce position\ninvariance to pattern recognition, and have been proven to classify objects\nregardless of their orientation, size, angle, etc. Therefore, a question\narises: how well can CNNs account for spatial and intensity differences when\nanalysing nuclear brain imaging? Are spatial and intensity normalization still\nneeded? To answer this question, we have trained four different CNN models\nbased on well-established architectures, using or not different spatial and\nintensity normalization preprocessing. The results show that a sufficiently\ncomplex model such as our three-dimensional version of the ALEXNET can\neffectively account for spatial differences, achieving a diagnosis accuracy of\n94.1% with an area under the ROC curve of 0.984. The visualization of the\ndifferences via saliency maps shows that these models are correctly finding\npatterns that match those found in the literature, without the need of applying\nany complex spatial normalization procedure. However, the intensity\nnormalization -- and its type -- is revealed as very influential in the results\nand accuracy of the trained model, and therefore must be well accounted.\n","authors":["Francisco J. Martinez-Murcia","Juan M. Górriz","Javier Ramírez","Andrés Ortiz"],"pdf_url":"https://arxiv.org/pdf/2311.12561v1.pdf","comment":"19 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.12560v1","updated":"2023-11-21T12:12:19Z","published":"2023-11-21T12:12:19Z","title":"Benchmarking bias: Expanding clinical AI model card to incorporate bias\n  reporting of social and non-social factors","summary":"  Clinical AI model reporting cards should be expanded to incorporate a broad\nbias reporting of both social and non-social factors. Non-social factors\nconsider the role of other factors, such as disease dependent, anatomic, or\ninstrument factors on AI model bias, which are essential to ensure safe\ndeployment.\n","authors":["Carolina A. M. Heming","Mohamed Abdalla","Monish Ahluwalia","Linglin Zhang","Hari Trivedi","MinJae Woo","Benjamin Fine","Judy Wawira Gichoya","Leo Anthony Celi","Laleh Seyyed-Kalantari"],"pdf_url":"https://arxiv.org/pdf/2311.12560v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12553v1","updated":"2023-11-21T12:05:56Z","published":"2023-11-21T12:05:56Z","title":"\"HoVer-UNet\": Accelerating HoVerNet with UNet-based multi-class nuclei\n  segmentation via knowledge distillation","summary":"  We present \"HoVer-UNet\", an approach to distill the knowledge of the\nmulti-branch HoVerNet framework for nuclei instance segmentation and\nclassification in histopathology. We propose a compact, streamlined single UNet\nnetwork with a Mix Vision Transformer backbone, and equip it with a custom loss\nfunction to optimally encode the distilled knowledge of HoVerNet, reducing\ncomputational requirements without compromising performances. We show that our\nmodel achieved results comparable to HoVerNet on the public PanNuke and Consep\ndatasets with a three-fold reduction in inference time. We make the code of our\nmodel publicly available at https://github.com/DIAGNijmegen/HoVer-UNet.\n","authors":["Cristian Tommasino","Cristiano Russo","Antonio Maria Rinaldi","Francesco Ciompi"],"pdf_url":"https://arxiv.org/pdf/2311.12553v1.pdf","comment":"4 pages, 2 figures, submitted to ISBI 2024"},{"id":"http://arxiv.org/abs/2304.01716v3","updated":"2023-11-21T12:05:50Z","published":"2023-04-04T11:25:44Z","title":"Decoupling Dynamic Monocular Videos for Dynamic View Synthesis","summary":"  The challenge of dynamic view synthesis from dynamic monocular videos, i.e.,\nsynthesizing novel views for free viewpoints given a monocular video of a\ndynamic scene captured by a moving camera, mainly lies in accurately modeling\nthe dynamic objects of a scene using limited 2D frames, each with a varying\ntimestamp and viewpoint. Existing methods usually require pre-processed 2D\noptical flow and depth maps by off-the-shelf methods to supervise the network,\nmaking them suffer from the inaccuracy of the pre-processed supervision and the\nambiguity when lifting the 2D information to 3D. In this paper, we tackle this\nchallenge in an unsupervised fashion. Specifically, we decouple the motion of\nthe dynamic objects into object motion and camera motion, respectively\nregularized by proposed unsupervised surface consistency and patch-based\nmulti-view constraints. The former enforces the 3D geometric surfaces of moving\nobjects to be consistent over time, while the latter regularizes their\nappearances to be consistent across different viewpoints. Such a fine-grained\nmotion formulation can alleviate the learning difficulty for the network, thus\nenabling it to produce not only novel views with higher quality but also more\naccurate scene flows and depth than existing methods requiring extra\nsupervision.\n","authors":["Meng You","Junhui Hou"],"pdf_url":"https://arxiv.org/pdf/2304.01716v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12539v1","updated":"2023-11-21T11:33:15Z","published":"2023-11-21T11:33:15Z","title":"GMISeg: General Medical Image Segmentation without Re-Training","summary":"  Although deep learning models have become the main method for medical image\nsegmentation, they often cannot be extended to unknown segmentation tasks\ninvolving new anatomical structures, image shapes, or labels. For new\nsegmentation tasks, researchers often have to retrain or fine-tune the model,\nwhich is time-consuming and poses a significant obstacle to clinical\nresearchers, who often lack the resources and professional knowledge to train\nneural networks. Therefore, we proposed a general method that can solve unknown\nmedical image segmentation tasks without requiring additional training. Given\nan example set of images and prompts for defining new segmentation tasks,\nGMISeg applies a novel low-rank fine-tuning strategy based on the proposed\napproach to the SAM (Segment Anything Model) image encoder, and works with the\nprompt encoder and mask decoder to fine-tune the labeled dataset without the\nneed for additional training. To achieve generalization of new tasks, we used\nmedical image datasets with different imaging modes for different parts. We\ntrained and generalized GMISeg on a different set of anatomical and imaging\nmodes using cardiac images on other site datasets. We have demonstrated that\nGMISeg outperforms the latest methods on unknown tasks and have conducted a\ncomprehensive analysis and summary of the important performance of the proposed\nmethod.\n","authors":["Jing Xu"],"pdf_url":"https://arxiv.org/pdf/2311.12539v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2304.06131 by other authors"},{"id":"http://arxiv.org/abs/2309.06255v2","updated":"2023-11-21T11:11:57Z","published":"2023-09-12T14:16:34Z","title":"Enhancing Multi-modal Cooperation via Fine-grained Modality Valuation","summary":"  One primary topic of multi-modal learning is to jointly incorporate\nheterogeneous information from different modalities. However, most models often\nsuffer from unsatisfactory multi-modal cooperation, which could not jointly\nutilize all modalities well. Some methods are proposed to identify and enhance\nthe worse learnt modality, but are often hard to provide the fine-grained\nobservation of multi-modal cooperation at sample-level with theoretical\nsupport. Hence, it is essential to reasonably observe and improve the\nfine-grained cooperation between modalities, especially when facing realistic\nscenarios where the modality discrepancy could vary across different samples.\nTo this end, we introduce a fine-grained modality valuation metric to evaluate\nthe contribution of each modality at sample-level. Via modality valuation, we\nregretfully observe that the multi-modal model tends to rely on one specific\nmodality, resulting in other modalities being low-contributing. We further\nanalyze this issue and improve cooperation between modalities by enhancing the\ndiscriminative ability of low-contributing modalities in a targeted manner.\nOverall, our methods reasonably observe the fine-grained uni-modal contribution\nat sample-level and achieve considerable improvement on different multi-modal\nmodels.\n","authors":["Yake Wei","Ruoxuan Feng","Zihe Wang","Di Hu"],"pdf_url":"https://arxiv.org/pdf/2309.06255v2.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2302.10396v3","updated":"2023-11-21T10:56:24Z","published":"2023-02-21T02:07:13Z","title":"Assessing Domain Gap for Continual Domain Adaptation in Object Detection","summary":"  To ensure reliable object detection in autonomous systems, the detector must\nbe able to adapt to changes in appearance caused by environmental factors such\nas time of day, weather, and seasons. Continually adapting the detector to\nincorporate these changes is a promising solution, but it can be\ncomputationally costly. Our proposed approach is to selectively adapt the\ndetector only when necessary, using new data that does not have the same\ndistribution as the current training data. To this end, we investigate three\npopular metrics for domain gap evaluation and find that there is a correlation\nbetween the domain gap and detection accuracy. Therefore, we apply the domain\ngap as a criterion to decide when to adapt the detector. Our experiments show\nthat our approach has the potential to improve the efficiency of the detector's\noperation in real-world scenarios, where environmental conditions change in a\ncyclical manner, without sacrificing the overall performance of the detector.\nOur code is publicly available at https://github.com/dadung/DGE-CDA.\n","authors":["Anh-Dzung Doan","Bach Long Nguyen","Surabhi Gupta","Ian Reid","Markus Wagner","Tat-Jun Chin"],"pdf_url":"https://arxiv.org/pdf/2302.10396v3.pdf","comment":"Accepted to CVIU"},{"id":"http://arxiv.org/abs/2310.00582v2","updated":"2023-11-21T10:32:13Z","published":"2023-10-01T05:53:15Z","title":"Pink: Unveiling the Power of Referential Comprehension for Multi-modal\n  LLMs","summary":"  Multi-modal Large Language Models (MLLMs) have shown remarkable capabilities\nin various multi-modal tasks. Nevertheless, their performance in fine-grained\nimage understanding tasks is still limited. To address this issue, this paper\nproposes a new framework to enhance the fine-grained image understanding\nabilities of MLLMs. Specifically, we present a new method for constructing the\ninstruction tuning dataset at a low cost by leveraging annotations in existing\ndatasets. A self-consistent bootstrapping method is also introduced to extend\nexisting dense object annotations into high-quality\nreferring-expression-bounding-box pairs. These methods enable the generation of\nhigh-quality instruction data which includes a wide range of fundamental\nabilities essential for fine-grained image perception. Moreover, we argue that\nthe visual encoder should be tuned during instruction tuning to mitigate the\ngap between full image perception and fine-grained image perception.\nExperimental results demonstrate the superior performance of our method. For\ninstance, our model exhibits a 5.2% accuracy improvement over Qwen-VL on GQA\nand surpasses the accuracy of Kosmos-2 by 24.7% on RefCOCO_val. We also attain\nthe top rank on the leaderboard of MMBench. This promising performance is\nachieved by training on only publicly available data, making it easily\nreproducible. The models, datasets, and codes are publicly available at\nhttps://github.com/SY-Xuan/Pink.\n","authors":["Shiyu Xuan","Qingpei Guo","Ming Yang","Shiliang Zhang"],"pdf_url":"https://arxiv.org/pdf/2310.00582v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05258v3","updated":"2023-11-21T10:30:07Z","published":"2022-12-10T10:19:53Z","title":"Image augmentation with conformal mappings for a convolutional neural\n  network","summary":"  For augmentation of the square-shaped image data of a convolutional neural\nnetwork (CNN), we introduce a new method, in which the original images are\nmapped onto a disk with a conformal mapping, rotated around the center of this\ndisk and mapped under such a M\\\"obius transformation that preserves the disk,\nand then mapped back onto their original square shape. This process does not\nresult the loss of information caused by removing areas from near the edges of\nthe original images unlike the typical transformations used in the data\naugmentation for a CNN. We offer here the formulas of all the mappings needed\ntogether with detailed instructions how to write a code for transforming the\nimages. The new method is also tested with simulated data and, according the\nresults, using this method to augment the training data of 10 images into 40\nimages decreases the amount of the error in the predictions by a CNN for a test\nset of 160 images in a statistically significant way (p-value=0.0360).\n","authors":["Oona Rainio","Mohamed M. S. Nasser","Matti Vuorinen","Riku Klén"],"pdf_url":"https://arxiv.org/pdf/2212.05258v3.pdf","comment":"14 pages, 3 figures"},{"id":"http://arxiv.org/abs/2305.05546v2","updated":"2023-11-21T10:02:03Z","published":"2023-05-09T15:32:50Z","title":"ColonMapper: topological mapping and localization for colonoscopy","summary":"  We propose a topological mapping and localization system able to operate on\nreal human colonoscopies, despite significant shape and illumination changes.\nThe map is a graph where each node codes a colon location by a set of real\nimages, while edges represent traversability between nodes. For close-in-time\nimages, where scene changes are minor, place recognition can be successfully\nmanaged with the recent transformers-based local feature matching algorithms.\nHowever, under long-term changes -- such as different colonoscopies of the same\npatient -- feature-based matching fails. To address this, we train on real\ncolonoscopies a deep global descriptor achieving high recall with significant\nchanges in the scene. The addition of a Bayesian filter boosts the accuracy of\nlong-term place recognition, enabling relocalization in a previously built map.\nOur experiments show that ColonMapper is able to autonomously build a map and\nlocalize against it in two important use cases: localization within the same\ncolonoscopy or within different colonoscopies of the same patient. Code will be\navailable upon acceptance.\n","authors":["Javier Morlana","Juan D. Tardós","J. M. M. Montiel"],"pdf_url":"https://arxiv.org/pdf/2305.05546v2.pdf","comment":"Under review. ICRA 2024"},{"id":"http://arxiv.org/abs/2311.12490v1","updated":"2023-11-21T10:01:08Z","published":"2023-11-21T10:01:08Z","title":"Hyb-NeRF: A Multiresolution Hybrid Encoding for Neural Radiance Fields","summary":"  Recent advances in Neural radiance fields (NeRF) have enabled high-fidelity\nscene reconstruction for novel view synthesis. However, NeRF requires hundreds\nof network evaluations per pixel to approximate a volume rendering integral,\nmaking it slow to train. Caching NeRFs into explicit data structures can\neffectively enhance rendering speed but at the cost of higher memory usage. To\naddress these issues, we present Hyb-NeRF, a novel neural radiance field with a\nmulti-resolution hybrid encoding that achieves efficient neural modeling and\nfast rendering, which also allows for high-quality novel view synthesis. The\nkey idea of Hyb-NeRF is to represent the scene using different encoding\nstrategies from coarse-to-fine resolution levels. Hyb-NeRF exploits\nmemory-efficiency learnable positional features at coarse resolutions and the\nfast optimization speed and local details of hash-based feature grids at fine\nresolutions. In addition, to further boost performance, we embed cone\ntracing-based features in our learnable positional encoding that eliminates\nencoding ambiguity and reduces aliasing artifacts. Extensive experiments on\nboth synthetic and real-world datasets show that Hyb-NeRF achieves faster\nrendering speed with better rending quality and even a lower memory footprint\nin comparison to previous state-of-the-art methods.\n","authors":["Yifan Wang","Yi Gong","Yuan Zeng"],"pdf_url":"https://arxiv.org/pdf/2311.12490v1.pdf","comment":"WACV2024"},{"id":"http://arxiv.org/abs/2311.12486v1","updated":"2023-11-21T09:58:39Z","published":"2023-11-21T09:58:39Z","title":"HCA-Net: Hierarchical Context Attention Network for Intervertebral Disc\n  Semantic Labeling","summary":"  Accurate and automated segmentation of intervertebral discs (IVDs) in medical\nimages is crucial for assessing spine-related disorders, such as osteoporosis,\nvertebral fractures, or IVD herniation. We present HCA-Net, a novel contextual\nattention network architecture for semantic labeling of IVDs, with a special\nfocus on exploiting prior geometric information. Our approach excels at\nprocessing features across different scales and effectively consolidating them\nto capture the intricate spatial relationships within the spinal cord. To\nachieve this, HCA-Net models IVD labeling as a pose estimation problem, aiming\nto minimize the discrepancy between each predicted IVD location and its\ncorresponding actual joint location. In addition, we introduce a skeletal loss\nterm to reinforce the model's geometric dependence on the spine. This loss\nfunction is designed to constrain the model's predictions to a range that\nmatches the general structure of the human vertebral skeleton. As a result, the\nnetwork learns to reduce the occurrence of false predictions and adaptively\nimproves the accuracy of IVD location estimation. Through extensive\nexperimental evaluation on multi-center spine datasets, our approach\nconsistently outperforms previous state-of-the-art methods on both MRI T1w and\nT2w modalities. The codebase is accessible to the public on\n\\href{https://github.com/xmindflow/HCA-Net}{GitHub}.\n","authors":["Afshin Bozorgpour","Bobby Azad","Reza Azad","Yury Velichko","Ulas Bagci","Dorit Merhof"],"pdf_url":"https://arxiv.org/pdf/2311.12486v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.04071v2","updated":"2023-11-21T09:58:34Z","published":"2023-11-07T15:35:56Z","title":"Energy-Calibrated VAE with Test Time Free Lunch","summary":"  In this paper, we propose a novel generative model that utilizes a\nconditional Energy-Based Model (EBM) for enhancing Variational Autoencoder\n(VAE), termed Energy-Calibrated VAE (EC-VAE). Specifically, VAEs often suffer\nfrom blurry generated samples due to the lack of a tailored training on the\nsamples generated in the generative direction. On the other hand, EBMs can\ngenerate high-quality samples but require expensive Markov Chain Monte Carlo\n(MCMC) sampling. To address these issues, we introduce a conditional EBM for\ncalibrating the generative direction of VAE during training, without requiring\nit for the generation at test time. In particular, we train EC-VAE upon both\nthe input data and the calibrated samples with adaptive weight to enhance\nefficacy while avoiding MCMC sampling at test time. Furthermore, we extend the\ncalibration idea of EC-VAE to variational learning and normalizing flows, and\napply EC-VAE to an additional application of zero-shot image restoration via\nneural transport prior and range-null theory. We evaluate the proposed method\nwith two applications, including image generation and zero-shot image\nrestoration, and the experimental results show that our method achieves the\nstate-of-the-art performance over single-step non-adversarial generation.\n","authors":["Yihong Luo","Siya Qiu","Xingjian Tao","Yujun Cai","Jing Tang"],"pdf_url":"https://arxiv.org/pdf/2311.04071v2.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2311.12480v1","updated":"2023-11-21T09:44:33Z","published":"2023-11-21T09:44:33Z","title":"Speaker-Adapted End-to-End Visual Speech Recognition for Continuous\n  Spanish","summary":"  Different studies have shown the importance of visual cues throughout the\nspeech perception process. In fact, the development of audiovisual approaches\nhas led to advances in the field of speech technologies. However, although\nnoticeable results have recently been achieved, visual speech recognition\nremains an open research problem. It is a task in which, by dispensing with the\nauditory sense, challenges such as visual ambiguities and the complexity of\nmodeling silence must be faced. Nonetheless, some of these challenges can be\nalleviated when the problem is approached from a speaker-dependent perspective.\nThus, this paper studies, using the Spanish LIP-RTVE database, how the\nestimation of specialized end-to-end systems for a specific person could affect\nthe quality of speech recognition. First, different adaptation strategies based\non the fine-tuning technique were proposed. Then, a pre-trained CTC/Attention\narchitecture was used as a baseline throughout our experiments. Our findings\nshowed that a two-step fine-tuning process, where the VSR system is first\nadapted to the task domain, provided significant improvements when the speaker\nadaptation was addressed. Furthermore, results comparable to the current state\nof the art were reached even when only a limited amount of data was available.\n","authors":["David Gimeno-Gómez","Carlos-D. Martínez-Hinarejos"],"pdf_url":"https://arxiv.org/pdf/2311.12480v1.pdf","comment":"Accepted in Proceedings of IberSpeech 2022 (\n  https://www.isca-speech.org/archive/iberspeech_2022/gimenogomez22_iberspeech.html\n  )"},{"id":"http://arxiv.org/abs/2211.15513v2","updated":"2023-11-21T09:42:12Z","published":"2022-11-25T09:41:07Z","title":"Composite Score for Anomaly Detection in Imbalanced Real-World\n  Industrial Dataset","summary":"  In recent years, the industrial sector has evolved towards its fourth\nrevolution. The quality control domain is particularly interested in advanced\nmachine learning for computer vision anomaly detection. Nevertheless, several\nchallenges have to be faced, including imbalanced datasets, the image\ncomplexity, and the zero-false-negative (ZFN) constraint to guarantee the\nhigh-quality requirement. This paper illustrates a use case for an industrial\npartner, where Printed Circuit Board Assembly (PCBA) images are first\nreconstructed with a Vector Quantized Generative Adversarial Network (VQGAN)\ntrained on normal products. Then, several multi-level metrics are extracted on\na few normal and abnormal images, highlighting anomalies through reconstruction\ndifferences. Finally, a classifer is trained to build a composite anomaly score\nthanks to the metrics extracted. This three-step approach is performed on the\npublic MVTec-AD datasets and on the partner PCBA dataset, where it achieves a\nregular accuracy of 95.69% and 87.93% under the ZFN constraint.\n","authors":["Arnaud Bougaham","Mohammed El Adoui","Isabelle Linden","Benoît Frénay"],"pdf_url":"https://arxiv.org/pdf/2211.15513v2.pdf","comment":"This version of the article has been accepted for publication, after\n  peer review and is subject to Springer Nature AM terms of use, but is not the\n  Version of Record and does not reflect post-acceptance improvements, or any\n  corrections. The Version of Record is available online at:\n  https://doi.org/10.1007/s10994-023-06415-9"},{"id":"http://arxiv.org/abs/2306.00917v2","updated":"2023-11-21T09:38:21Z","published":"2023-06-01T17:19:43Z","title":"Vocabulary-free Image Classification","summary":"  Recent advances in large vision-language models have revolutionized the image\nclassification paradigm. Despite showing impressive zero-shot capabilities, a\npre-defined set of categories, a.k.a. the vocabulary, is assumed at test time\nfor composing the textual prompts. However, such assumption can be impractical\nwhen the semantic context is unknown and evolving. We thus formalize a novel\ntask, termed as Vocabulary-free Image Classification (VIC), where we aim to\nassign to an input image a class that resides in an unconstrained\nlanguage-induced semantic space, without the prerequisite of a known\nvocabulary. VIC is a challenging task as the semantic space is extremely large,\ncontaining millions of concepts, with hard-to-discriminate fine-grained\ncategories. In this work, we first empirically verify that representing this\nsemantic space by means of an external vision-language database is the most\neffective way to obtain semantically relevant content for classifying the\nimage. We then propose Category Search from External Databases (CaSED), a\nmethod that exploits a pre-trained vision-language model and an external\nvision-language database to address VIC in a training-free manner. CaSED first\nextracts a set of candidate categories from captions retrieved from the\ndatabase based on their semantic similarity to the image, and then assigns to\nthe image the best matching candidate category according to the same\nvision-language model. Experiments on benchmark datasets validate that CaSED\noutperforms other complex vision-language frameworks, while being efficient\nwith much fewer parameters, paving the way for future research in this\ndirection.\n","authors":["Alessandro Conti","Enrico Fini","Massimiliano Mancini","Paolo Rota","Yiming Wang","Elisa Ricci"],"pdf_url":"https://arxiv.org/pdf/2306.00917v2.pdf","comment":"Accepted at NeurIPS2023, 19 pages, 8 figures, code is available at\n  https://github.com/altndrr/vic"},{"id":"http://arxiv.org/abs/2311.12476v1","updated":"2023-11-21T09:37:49Z","published":"2023-11-21T09:37:49Z","title":"MaskFlow: Object-Aware Motion Estimation","summary":"  We introduce a novel motion estimation method, MaskFlow, that is capable of\nestimating accurate motion fields, even in very challenging cases with small\nobjects, large displacements and drastic appearance changes. In addition to\nlower-level features, that are used in other Deep Neural Network (DNN)-based\nmotion estimation methods, MaskFlow draws from object-level features and\nsegmentations. These features and segmentations are used to approximate the\nobjects' translation motion field. We propose a novel and effective way of\nincorporating the incomplete translation motion field into a subsequent motion\nestimation network for refinement and completion. We also produced a new\nchallenging synthetic dataset with motion field ground truth, and also provide\nextra ground truth for the object-instance matchings and corresponding\nsegmentation masks. We demonstrate that MaskFlow outperforms state of the art\nmethods when evaluated on our new challenging dataset, whilst still producing\ncomparable results on the popular FlyingThings3D benchmark dataset.\n","authors":["Aria Ahmadi","David R. Walton","Tim Atherton","Cagatay Dikici"],"pdf_url":"https://arxiv.org/pdf/2311.12476v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12468v1","updated":"2023-11-21T09:28:00Z","published":"2023-11-21T09:28:00Z","title":"Analysis of Visual Features for Continuous Lipreading in Spanish","summary":"  During a conversation, our brain is responsible for combining information\nobtained from multiple senses in order to improve our ability to understand the\nmessage we are perceiving. Different studies have shown the importance of\npresenting visual information in these situations. Nevertheless, lipreading is\na complex task whose objective is to interpret speech when audio is not\navailable. By dispensing with a sense as crucial as hearing, it will be\nnecessary to be aware of the challenge that this lack presents. In this paper,\nwe propose an analysis of different speech visual features with the intention\nof identifying which of them is the best approach to capture the nature of lip\nmovements for natural Spanish and, in this way, dealing with the automatic\nvisual speech recognition task. In order to estimate our system, we present an\naudiovisual corpus compiled from a subset of the RTVE database, which has been\nused in the Albayz\\'in evaluations. We employ a traditional system based on\nHidden Markov Models with Gaussian Mixture Models. Results show that, although\nthe task is difficult, in restricted conditions we obtain recognition results\nwhich determine that using eigenlips in combination with deep features is the\nbest visual approach.\n","authors":["David Gimeno-Gómez","Carlos-D. Martínez-Hinarejos"],"pdf_url":"https://arxiv.org/pdf/2311.12468v1.pdf","comment":"Accepted in Proceedings of IberSpeech 2020 (\n  https://www.isca-speech.org/archive/iberspeech_2021/gimenogomez21_iberspeech.html\n  )"},{"id":"http://arxiv.org/abs/2311.12467v1","updated":"2023-11-21T09:27:30Z","published":"2023-11-21T09:27:30Z","title":"GLAD: Global-Local View Alignment and Background Debiasing for\n  Unsupervised Video Domain Adaptation with Large Domain Gap","summary":"  In this work, we tackle the challenging problem of unsupervised video domain\nadaptation (UVDA) for action recognition. We specifically focus on scenarios\nwith a substantial domain gap, in contrast to existing works primarily deal\nwith small domain gaps between labeled source domains and unlabeled target\ndomains. To establish a more realistic setting, we introduce a novel UVDA\nscenario, denoted as Kinetics->BABEL, with a more considerable domain gap in\nterms of both temporal dynamics and background shifts. To tackle the temporal\nshift, i.e., action duration difference between the source and target domains,\nwe propose a global-local view alignment approach. To mitigate the background\nshift, we propose to learn temporal order sensitive representations by temporal\norder learning and background invariant representations by background\naugmentation. We empirically validate that the proposed method shows\nsignificant improvement over the existing methods on the Kinetics->BABEL\ndataset with a large domain gap. The code is available at\nhttps://github.com/KHUVLL/GLAD.\n","authors":["Hyogun Lee","Kyungho Bae","Seongjong Ha","Yumin Ko","Gyeongmoon Park","Jinwoo Choi"],"pdf_url":"https://arxiv.org/pdf/2311.12467v1.pdf","comment":"This is an accepted WACV 2024 paper"},{"id":"http://arxiv.org/abs/2309.00018v2","updated":"2023-11-21T09:22:28Z","published":"2023-08-31T07:53:02Z","title":"Unsupervised discovery of Interpretable Visual Concepts","summary":"  Providing interpretability of deep-learning models to non-experts, while\nfundamental for a responsible real-world usage, is challenging. Attribution\nmaps from xAI techniques, such as Integrated Gradients, are a typical example\nof a visualization technique containing a high level of information, but with\ndifficult interpretation. In this paper, we propose two methods, Maximum\nActivation Groups Extraction (MAGE) and Multiscale Interpretable Visualization\n(Ms-IV), to explain the model's decision, enhancing global interpretability.\nMAGE finds, for a given CNN, combinations of features which, globally, form a\nsemantic meaning, that we call concepts. We group these similar feature\npatterns by clustering in ``concepts'', that we visualize through Ms-IV. This\nlast method is inspired by Occlusion and Sensitivity analysis (incorporating\ncausality), and uses a novel metric, called Class-aware Order Correlation\n(CaOC), to globally evaluate the most important image regions according to the\nmodel's decision space. We compare our approach to xAI methods such as LIME and\nIntegrated Gradients. Experimental results evince the Ms-IV higher localization\nand faithfulness values. Finally, qualitative evaluation of combined MAGE and\nMs-IV demonstrates humans' ability to agree, based on the visualization, with\nthe decision of clusters' concepts; and, to detect, among a given set of\nnetworks, the existence of bias.\n","authors":["Caroline Mazini Rodrigues","Nicolas Boutry","Laurent Najman"],"pdf_url":"https://arxiv.org/pdf/2309.00018v2.pdf","comment":null},{"id":"http://arxiv.org/abs/1810.12813v3","updated":"2023-11-21T09:19:21Z","published":"2018-10-30T15:33:47Z","title":"Contextual Hourglass Network for Semantic Segmentation of High\n  Resolution Aerial Imagery","summary":"  Semantic segmentation for aerial imagery is a challenging and important\nproblem in remotely sensed imagery analysis. In recent years, with the success\nof deep learning, various convolutional neural network (CNN) based models have\nbeen developed. However, due to the varying sizes of the objects and imbalanced\nclass labels, it can be challenging to obtain accurate pixel-wise semantic\nsegmentation results. To address those challenges, we develop a novel semantic\nsegmentation method and call it Contextual Hourglass Network. In our method, in\norder to improve the robustness of the prediction, we design a new contextual\nhourglass module which incorporates attention mechanism on processed\nlow-resolution featuremaps to exploit the contextual semantics. We further\nexploit the stacked encoder-decoder structure by connecting multiple contextual\nhourglass modules from end to end. This architecture can effectively extract\nrich multi-scale features and add more feedback loops for better learning\ncontextual semantics through intermediate supervision. To demonstrate the\nefficacy of our semantic segmentation method, we test it on Potsdam and\nVaihingen datasets. Through the comparisons to other baseline methods, our\nmethod yields the best results on overall performance.\n","authors":["Panfeng Li","Youzuo Lin","Emily Schultz-Fellenz"],"pdf_url":"https://arxiv.org/pdf/1810.12813v3.pdf","comment":"Accepted by ICIP 2019,\n  https://cmsworkshops.com/ICIP2019/Papers/AcceptedPapers.asp"},{"id":"http://arxiv.org/abs/2301.05246v2","updated":"2023-11-21T09:18:52Z","published":"2023-01-12T19:00:27Z","title":"Online Class-Incremental Learning For Real-World Food Classification","summary":"  Food image classification is essential for monitoring health and tracking\ndietary in image-based dietary assessment methods. However, conventional\nsystems often rely on static datasets with fixed classes and uniform\ndistribution. In contrast, real-world food consumption patterns, shaped by\ncultural, economic, and personal influences, involve dynamic and evolving data.\nThus, require the classification system to cope with continuously evolving\ndata. Online Class Incremental Learning (OCIL) addresses the challenge of\nlearning continuously from a single-pass data stream while adapting to the new\nknowledge and reducing catastrophic forgetting. Experience Replay (ER) based\nOCIL methods store a small portion of previous data and have shown encouraging\nperformance. However, most existing OCIL works assume that the distribution of\nencountered data is perfectly balanced, which rarely happens in real-world\nscenarios. In this work, we explore OCIL for real-world food image\nclassification by first introducing a probabilistic framework to simulate\nrealistic food consumption scenarios. Subsequently, we present an attachable\nDynamic Model Update (DMU) module designed for existing ER methods, which\nenables the selection of relevant images for model training, addressing\nchallenges arising from data repetition and imbalanced sample occurrences\ninherent in realistic food consumption patterns within the OCIL framework. Our\nperformance evaluation demonstrates significant enhancements compared to\nestablished ER methods, showing great potential for lifelong learning in\nreal-world food image classification scenarios. The code of our method is\npublicly accessible at\n\\href{https://gitlab.com/viper-purdue/OCIL-real-world-food-image-classification}{https://gitlab.com/viper-purdue/OCIL-real-world-food-image-classification}\n","authors":["Siddeshwar Raghavan","Jiangpeng He","Fengqing Zhu"],"pdf_url":"https://arxiv.org/pdf/2301.05246v2.pdf","comment":"Accepted at IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV 2024)"},{"id":"http://arxiv.org/abs/2311.11808v2","updated":"2023-11-21T09:18:14Z","published":"2023-11-20T14:41:44Z","title":"Robot Hand-Eye Calibration using Structure-from-Motion","summary":"  In this paper we propose a new flexible method for hand-eye calibration. The\nvast majority of existing hand-eye calibration techniques requires a\ncalibration rig which is used in conjunction with camera pose estimation\nmethods. Instead, we combine structure-from-motion with known robot motions and\nwe show that the solution can be obtained in linear form. The latter solves for\nboth the hand-eye parameters and for the unknown scale factor inherent with\nstructure-from-motion methods. The algebraic analysis that is made possible\nwith such a linear formulation allows to investigate not only the well known\ncase of general screw motions but also such singular motions as pure\ntranslations, pure rotations, and planar motions. In essence, the robot-mounted\ncamera looks to an unknown rigid layout, tracks points over an image sequence\nand estimates the camera-to-robot relationship. Such a self calibration process\nis relevant for unmanned vehicles, robots working in remote places, and so\nforth. We conduct a large number of experiments which validate the quality of\nthe method by comparing it with existing ones.\n","authors":["Nicolas Andreff","Radu Horaud","Bernard Espiau"],"pdf_url":"https://arxiv.org/pdf/2311.11808v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12461v1","updated":"2023-11-21T09:15:24Z","published":"2023-11-21T09:15:24Z","title":"HiFi-Syn: Hierarchical Granularity Discrimination for High-Fidelity\n  Synthesis of MR Images with Structure Preservation","summary":"  Synthesizing medical images while preserving their structural information is\ncrucial in medical research. In such scenarios, the preservation of anatomical\ncontent becomes especially important. Although recent advances have been made\nby incorporating instance-level information to guide translation, these methods\noverlook the spatial coherence of structural-level representation and the\nanatomical invariance of content during translation. To address these issues,\nwe introduce hierarchical granularity discrimination, which exploits various\nlevels of semantic information present in medical images. Our strategy utilizes\nthree levels of discrimination granularity: pixel-level discrimination using a\nBrain Memory Bank, structure-level discrimination on each brain structure with\na re-weighting strategy to focus on hard samples, and global-level\ndiscrimination to ensure anatomical consistency during translation. The image\ntranslation performance of our strategy has been evaluated on three independent\ndatasets (UK Biobank, IXI, and BraTS 2018), and it has outperformed\nstate-of-the-art algorithms. Particularly, our model excels not only in\nsynthesizing normal structures but also in handling abnormal (pathological)\nstructures, such as brain tumors, despite the variations in contrast observed\nacross different imaging modalities due to their pathological characteristics.\nThe diagnostic value of synthesized MR images containing brain tumors has been\nevaluated by radiologists. This indicates that our model may offer an\nalternative solution in scenarios where specific MR modalities of patients are\nunavailable. Extensive experiments further demonstrate the versatility of our\nmethod, providing unique insights into medical image translation.\n","authors":["Ziqi Yu","Botao Zhao","Shengjie Zhang","Xiang Chen","Jianfeng Feng","Tingying Peng","Xiao-Yong Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12461v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12457v1","updated":"2023-11-21T09:12:21Z","published":"2023-11-21T09:12:21Z","title":"LIP-RTVE: An Audiovisual Database for Continuous Spanish in the Wild","summary":"  Speech is considered as a multi-modal process where hearing and vision are\ntwo fundamentals pillars. In fact, several studies have demonstrated that the\nrobustness of Automatic Speech Recognition systems can be improved when audio\nand visual cues are combined to represent the nature of speech. In addition,\nVisual Speech Recognition, an open research problem whose purpose is to\ninterpret speech by reading the lips of the speaker, has been a focus of\ninterest in the last decades. Nevertheless, in order to estimate these systems\nin the currently Deep Learning era, large-scale databases are required. On the\nother hand, while most of these databases are dedicated to English, other\nlanguages lack sufficient resources. Thus, this paper presents a\nsemi-automatically annotated audiovisual database to deal with unconstrained\nnatural Spanish, providing 13 hours of data extracted from Spanish television.\nFurthermore, baseline results for both speaker-dependent and\nspeaker-independent scenarios are reported using Hidden Markov Models, a\ntraditional paradigm that has been widely used in the field of Speech\nTechnologies.\n","authors":["David Gimeno-Gómez","Carlos-D. Martínez-Hinarejos"],"pdf_url":"https://arxiv.org/pdf/2311.12457v1.pdf","comment":"Accepted in Proceedings of LREC 2022 (\n  https://aclanthology.org/2022.lrec-1.294 )"},{"id":"http://arxiv.org/abs/2305.18183v2","updated":"2023-11-21T09:11:38Z","published":"2023-05-29T16:20:23Z","title":"On Counterfactual Data Augmentation Under Confounding","summary":"  Counterfactual data augmentation has recently emerged as a method to mitigate\nconfounding biases in the training data. These biases, such as spurious\ncorrelations, arise due to various observed and unobserved confounding\nvariables in the data generation process. In this paper, we formally analyze\nhow confounding biases impact downstream classifiers and present a causal\nviewpoint to the solutions based on counterfactual data augmentation. We\nexplore how removing confounding biases serves as a means to learn invariant\nfeatures, ultimately aiding in generalization beyond the observed data\ndistribution. Additionally, we present a straightforward yet powerful algorithm\nfor generating counterfactual images, which effectively mitigates the influence\nof confounding effects on downstream classifiers. Through experiments on MNIST\nvariants and the CelebA datasets, we demonstrate how our simple augmentation\nmethod helps existing state-of-the-art methods achieve good results.\n","authors":["Abbavaram Gowtham Reddy","Saketh Bachu","Saloni Dash","Charchit Sharma","Amit Sharma","Vineeth N Balasubramanian"],"pdf_url":"https://arxiv.org/pdf/2305.18183v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.13788v2","updated":"2023-11-21T09:08:50Z","published":"2021-09-28T15:07:43Z","title":"PFENet++: Boosting Few-shot Semantic Segmentation with the\n  Noise-filtered Context-aware Prior Mask","summary":"  In this work, we revisit the prior mask guidance proposed in ``Prior Guided\nFeature Enrichment Network for Few-Shot Segmentation''. The prior mask serves\nas an indicator that highlights the region of interests of unseen categories,\nand it is effective in achieving better performance on different frameworks of\nrecent studies. However, the current method directly takes the maximum\nelement-to-element correspondence between the query and support features to\nindicate the probability of belonging to the target class, thus the broader\ncontextual information is seldom exploited during the prior mask generation. To\naddress this issue, first, we propose the Context-aware Prior Mask (CAPM) that\nleverages additional nearby semantic cues for better locating the objects in\nquery images. Second, since the maximum correlation value is vulnerable to\nnoisy features, we take one step further by incorporating a lightweight Noise\nSuppression Module (NSM) to screen out the unnecessary responses, yielding\nhigh-quality masks for providing the prior knowledge. Both two contributions\nare experimentally shown to have substantial practical merit, and the new model\nnamed PFENet++ significantly outperforms the baseline PFENet as well as all\nother competitors on three challenging benchmarks PASCAL-5$^i$, COCO-20$^i$ and\nFSS-1000. The new state-of-the-art performance is achieved without compromising\nthe efficiency, manifesting the potential for being a new strong baseline in\nfew-shot semantic segmentation. Our code will be available at\nhttps://github.com/luoxiaoliu/PFENet2Plus.\n","authors":["Xiaoliu Luo","Zhuotao Tian","Taiping Zhang","Bei Yu","Yuan Yan Tang","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2109.13788v2.pdf","comment":"The first two authors contribute equally and are listed in\n  alphabetical order"},{"id":"http://arxiv.org/abs/2310.08897v2","updated":"2023-11-21T08:51:03Z","published":"2023-10-13T06:58:52Z","title":"Self supervised convolutional kernel based handcrafted feature\n  harmonization: Enhanced left ventricle hypertension disease phenotyping on\n  echocardiography","summary":"  Radiomics, a medical imaging technique, extracts quantitative handcrafted\nfeatures from images to predict diseases. Harmonization in those features\nensures consistent feature extraction across various imaging devices and\nprotocols. Methods for harmonization include standardized imaging protocols,\nstatistical adjustments, and evaluating feature robustness. Myocardial diseases\nsuch as Left Ventricular Hypertrophy (LVH) and Hypertensive Heart Disease (HHD)\nare diagnosed via echocardiography, but variable imaging settings pose\nchallenges. Harmonization techniques are crucial for applying handcrafted\nfeatures in disease diagnosis in such scenario. Self-supervised learning (SSL)\nenhances data understanding within limited datasets and adapts to diverse data\nsettings. ConvNeXt-V2 integrates convolutional layers into SSL, displaying\nsuperior performance in various tasks. This study focuses on convolutional\nfilters within SSL, using them as preprocessing to convert images into feature\nmaps for handcrafted feature harmonization. Our proposed method excelled in\nharmonization evaluation and exhibited superior LVH classification performance\ncompared to existing methods.\n","authors":["Jina Lee","Youngtaek Hong","Dawun Jeong","Yeonggul Jang","Sihyeon Jeong","Taekgeun Jung","Yeonyee E. Yoon","Inki Moon","Seung-Ah Lee","Hyuk-Jae Chang"],"pdf_url":"https://arxiv.org/pdf/2310.08897v2.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2310.19641v2","updated":"2023-11-21T08:49:00Z","published":"2023-10-30T15:29:48Z","title":"DistNet2D: Leveraging long-range temporal information for efficient\n  segmentation and tracking","summary":"  Extracting long tracks and lineages from videomicroscopy requires an\nextremely low error rate, which is challenging on complex datasets of dense or\ndeforming cells. Leveraging temporal context is key to overcoming this\nchallenge. We propose DistNet2D, a new deep neural network (DNN) architecture\nfor 2D cell segmentation and tracking that leverages both mid- and long-term\ntemporal information. DistNet2D considers seven frames at the input and uses a\npost-processing procedure that exploits information from the entire video to\ncorrect segmentation errors. DistNet2D outperforms two recent methods on two\nexperimental datasets, one containing densely packed bacterial cells and the\nother containing eukaryotic cells. It is integrated into an ImageJ-based\ngraphical user interface for 2D data visualization, curation, and training.\nFinally, we demonstrate the performance of DistNet2D on correlating the size\nand shape of cells with their transport properties over large statistics, for\nboth bacterial and eukaryotic cells.\n","authors":["Jean Ollion","Martin Maliet","Caroline Giuglaris","Elise Vacher","Maxime Deforet"],"pdf_url":"https://arxiv.org/pdf/2310.19641v2.pdf","comment":"40 pages, 5 figures, 18 supp figures"},{"id":"http://arxiv.org/abs/2311.12437v1","updated":"2023-11-21T08:47:08Z","published":"2023-11-21T08:47:08Z","title":"Learning Site-specific Styles for Multi-institutional Unsupervised\n  Cross-modality Domain Adaptation","summary":"  Unsupervised cross-modality domain adaptation is a challenging task in\nmedical image analysis, and it becomes more challenging when source and target\ndomain data are collected from multiple institutions. In this paper, we present\nour solution to tackle the multi-institutional unsupervised domain adaptation\nfor the crossMoDA 2023 challenge. First, we perform unpaired image translation\nto translate the source domain images to the target domain, where we design a\ndynamic network to generate synthetic target domain images with controllable,\nsite-specific styles. Afterwards, we train a segmentation model using the\nsynthetic images and further reduce the domain gap by self-training. Our\nsolution achieved the 1st place during both the validation and testing phases\nof the challenge.\n","authors":["Han Liu","Yubo Fan","Zhoubing Xu","Benoit M. Dawant","Ipek Oguz"],"pdf_url":"https://arxiv.org/pdf/2311.12437v1.pdf","comment":"crossMoDA 2023 challenge 1st place solution"},{"id":"http://arxiv.org/abs/2311.12430v1","updated":"2023-11-21T08:42:44Z","published":"2023-11-21T08:42:44Z","title":"AR Visualization System for Ship Detection and Recognition Based on AI","summary":"  Augmented reality technology has been widely used in industrial design\ninteraction, exhibition guide, information retrieval and other fields. The\ncombination of artificial intelligence and augmented reality technology has\nalso become a future development trend. This project is an AR visualization\nsystem for ship detection and recognition based on AI, which mainly includes\nthree parts: artificial intelligence module, Unity development module and\nHololens2AR module. This project is based on R3Det algorithm to complete the\ndetection and recognition of ships in remote sensing images. The recognition\nrate of model detection trained on RTX 2080Ti can reach 96%. Then, the 3D model\nof the ship is obtained by ship categories and information and generated in the\nvirtual scene. At the same time, voice module and UI interaction module are\nadded. Finally, we completed the deployment of the project on Hololens2 through\nMRTK. The system realizes the fusion of computer vision and augmented reality\ntechnology, which maps the results of object detection to the AR field, and\nmakes a brave step toward the future technological trend and intelligent\napplication.\n","authors":["Ziqi Ye","Limin Huang","Yongji Wu","Min Hu"],"pdf_url":"https://arxiv.org/pdf/2311.12430v1.pdf","comment":"4 pages,7 figures,IEEE International Conference on Virtual Reality\n  and Visualization"},{"id":"http://arxiv.org/abs/2311.07784v2","updated":"2023-11-21T08:23:31Z","published":"2023-11-13T22:21:27Z","title":"A Data-Free Approach to Mitigate Catastrophic Forgetting in Federated\n  Class Incremental Learning for Vision Tasks","summary":"  Deep learning models often suffer from forgetting previously learned\ninformation when trained on new data. This problem is exacerbated in federated\nlearning (FL), where the data is distributed and can change independently for\neach user. Many solutions are proposed to resolve this catastrophic forgetting\nin a centralized setting. However, they do not apply directly to FL because of\nits unique complexities, such as privacy concerns and resource limitations. To\novercome these challenges, this paper presents a framework for\n$\\textbf{federated class incremental learning}$ that utilizes a generative\nmodel to synthesize samples from past distributions. This data can be later\nexploited alongside the training data to mitigate catastrophic forgetting. To\npreserve privacy, the generative model is trained on the server using data-free\nmethods at the end of each task without requesting data from clients. Moreover,\nour solution does not demand the users to store old data or models, which gives\nthem the freedom to join/leave the training at any time. Additionally, we\nintroduce SuperImageNet, a new regrouping of the ImageNet dataset specifically\ntailored for federated continual learning. We demonstrate significant\nimprovements compared to existing baselines through extensive experiments on\nmultiple datasets.\n","authors":["Sara Babakniya","Zalan Fabian","Chaoyang He","Mahdi Soltanolkotabi","Salman Avestimehr"],"pdf_url":"https://arxiv.org/pdf/2311.07784v2.pdf","comment":"Accepted in NeurIPS 2023. arXiv admin note: text overlap with\n  arXiv:2307.00497"},{"id":"http://arxiv.org/abs/2311.12421v1","updated":"2023-11-21T08:21:55Z","published":"2023-11-21T08:21:55Z","title":"Two Views Are Better than One: Monocular 3D Pose Estimation with\n  Multiview Consistency","summary":"  Deducing a 3D human pose from a single 2D image or 2D keypoints is inherently\nchallenging, given the fundamental ambiguity wherein multiple 3D poses can\ncorrespond to the same 2D representation. The acquisition of 3D data, while\ninvaluable for resolving pose ambiguity, is expensive and requires an intricate\nsetup, often restricting its applicability to controlled lab environments. We\nimprove performance of monocular human pose estimation models using multiview\ndata for fine-tuning. We propose a novel loss function, multiview consistency,\nto enable adding additional training data with only 2D supervision. This loss\nenforces that the inferred 3D pose from one view aligns with the inferred 3D\npose from another view under similarity transformations. Our consistency loss\nsubstantially improves performance for fine-tuning with no available 3D data.\nOur experiments demonstrate that two views offset by 90 degrees are enough to\nobtain good performance, with only marginal improvements by adding more views.\nThus, we enable the acquisition of domain-specific data by capturing activities\nwith off-the-shelf cameras, eliminating the need for elaborate calibration\nprocedures. This research introduces new possibilities for domain adaptation in\n3D pose estimation, providing a practical and cost-effective solution to\ncustomize models for specific applications. The used dataset, featuring\nadditional views, will be made publicly available.\n","authors":["Christian Keilstrup Ingwersen","Anders Bjorholm Dahl","Janus Nørtoft Jensen","Morten Rieger Hannemose"],"pdf_url":"https://arxiv.org/pdf/2311.12421v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12419v1","updated":"2023-11-21T08:16:01Z","published":"2023-11-21T08:16:01Z","title":"Board-to-Board: Evaluating Moonboard Grade Prediction Generalization","summary":"  Bouldering is a sport where athletes aim to climb up an obstacle using a set\nof defined holds called a route. Typically routes are assigned a grade to\ninform climbers of its difficulty and allow them to more easily track their\nprogression. However, the variation in individual climbers technical and\nphysical attributes and many nuances of an individual route make grading a\ndifficult and often biased task. In this work, we apply classical and\ndeep-learning modelling techniques to the 2016, 2017 and 2019 Moonboard\ndatasets, achieving state of the art grade prediction performance with 0.87 MAE\nand 1.12 RMSE. We achieve this performance on a feature-set that does not\nrequire decomposing routes into individual moves, which is a method common in\nliterature and introduces bias. We also demonstrate the generalization\ncapability of this model between editions and introduce a novel vision-based\nmethod of grade prediction. While the generalization performance of these\ntechniques is below human level performance currently, we propose these methods\nas a basis for future work. Such a tool could be implemented in pre-existing\nmobile applications and would allow climbers to better track their progress and\nassess new routes with reduced bias.\n","authors":["Daniel Petashvili","Matthew Rodda"],"pdf_url":"https://arxiv.org/pdf/2311.12419v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12407v1","updated":"2023-11-21T07:54:40Z","published":"2023-11-21T07:54:40Z","title":"Learning Part Motion of Articulated Objects Using Spatially Continuous\n  Neural Implicit Representations","summary":"  Articulated objects (e.g., doors and drawers) exist everywhere in our life.\nDifferent from rigid objects, articulated objects have higher degrees of\nfreedom and are rich in geometries, semantics, and part functions. Modeling\ndifferent kinds of parts and articulations with nerual networks plays an\nessential role in articulated object understanding and manipulation, and will\nfurther benefit 3D vision and robotics communities. To model articulated\nobjects, most previous works directly encode articulated objects into feature\nrepresentations, without specific designs for parts, articulations and part\nmotions. In this paper, we introduce a novel framework that explicitly\ndisentangles the part motion of articulated objects by predicting the\ntransformation matrix of points on the part surface, using spatially continuous\nneural implicit representations to model the part motion smoothly in the space.\nMore importantly, while many methods could only model a certain kind of joint\nmotion (such as the revolution in the clockwise order), our proposed framework\nis generic to different kinds of joint motions in that transformation matrix\ncan model diverse kinds of joint motions in the space. Quantitative and\nqualitative results of experiments over diverse categories of articulated\nobjects demonstrate the effectiveness of our proposed framework.\n","authors":["Yushi Du","Ruihai Wu","Yan Shen","Hao Dong"],"pdf_url":"https://arxiv.org/pdf/2311.12407v1.pdf","comment":"10 pages, 6 figures. Accepted by BMVC 2023"},{"id":"http://arxiv.org/abs/2311.12401v1","updated":"2023-11-21T07:28:51Z","published":"2023-11-21T07:28:51Z","title":"CASR: Refining Action Segmentation via Magrinalizing Frame-levle Causal\n  Relationships","summary":"  Integrating deep learning and causal discovery has increased the\ninterpretability of Temporal Action Segmentation (TAS) tasks. However,\nframe-level causal relationships exist many complicated noises outside the\nsegment-level, making it infeasible to directly express macro action semantics.\nThus, we propose \\textit{\\textbf{Causal Abstraction Segmentation Refiner\n(CASR)}}, which can refine TAS results from various models by enhancing video\ncausality in marginalizing frame-level casual relationships. Specifically, we\ndefine the equivalent frame-level casual model and segment-level causal model,\nso that the causal adjacency matrix constructed from marginalized frame-level\ncausal relationships has the ability to represent the segmnet-level causal\nrelationships. CASR works out by reducing the difference in the causal\nadjacency matrix between we constructed and pre-segmentation results of\nbackbone models. In addition, we propose a novel evaluation metric Causal Edit\nDistance (CED) to evaluate the causal interpretability. Extensive experimental\nresults on mainstream datasets indicate that CASR significantly surpasses\nexisting various methods in action segmentation performance, as well as in\ncausal explainability and generalization. Our code will be available soon.\n","authors":["Keqing Du","Xinyu Yang","Hang Chen"],"pdf_url":"https://arxiv.org/pdf/2311.12401v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.09112v2","updated":"2023-11-21T07:27:08Z","published":"2023-07-18T10:02:09Z","title":"NU-MCC: Multiview Compressive Coding with Neighborhood Decoder and\n  Repulsive UDF","summary":"  Remarkable progress has been made in 3D reconstruction from single-view RGB-D\ninputs. MCC is the current state-of-the-art method in this field, which\nachieves unprecedented success by combining vision Transformers with\nlarge-scale training. However, we identified two key limitations of MCC: 1) The\nTransformer decoder is inefficient in handling large number of query points; 2)\nThe 3D representation struggles to recover high-fidelity details. In this\npaper, we propose a new approach called NU-MCC that addresses these\nlimitations. NU-MCC includes two key innovations: a Neighborhood decoder and a\nRepulsive Unsigned Distance Function (Repulsive UDF). First, our Neighborhood\ndecoder introduces center points as an efficient proxy of input visual\nfeatures, allowing each query point to only attend to a small neighborhood.\nThis design not only results in much faster inference speed but also enables\nthe exploitation of finer-scale visual features for improved recovery of 3D\ntextures. Second, our Repulsive UDF is a novel alternative to the occupancy\nfield used in MCC, significantly improving the quality of 3D object\nreconstruction. Compared to standard UDFs that suffer from holes in results,\nour proposed Repulsive UDF can achieve more complete surface reconstruction.\nExperimental results demonstrate that NU-MCC is able to learn a strong 3D\nrepresentation, significantly advancing the state of the art in single-view 3D\nreconstruction. Particularly, it outperforms MCC by 9.7% in terms of the\nF1-score on the CO3D-v2 dataset with more than 5x faster running speed.\n","authors":["Stefan Lionar","Xiangyu Xu","Min Lin","Gim Hee Lee"],"pdf_url":"https://arxiv.org/pdf/2307.09112v2.pdf","comment":"NeurIPS 2023. Project page: https://numcc.github.io/ Code:\n  https://github.com/sail-sg/numcc"},{"id":"http://arxiv.org/abs/2311.11700v2","updated":"2023-11-21T07:26:16Z","published":"2023-11-20T12:08:23Z","title":"GS-SLAM: Dense Visual SLAM with 3D Gaussian Splatting","summary":"  In this paper, we introduce $\\textbf{GS-SLAM}$ that first utilizes 3D\nGaussian representation in the Simultaneous Localization and Mapping (SLAM)\nsystem. It facilitates a better balance between efficiency and accuracy.\nCompared to recent SLAM methods employing neural implicit representations, our\nmethod utilizes a real-time differentiable splatting rendering pipeline that\noffers significant speedup to map optimization and RGB-D re-rendering.\nSpecifically, we propose an adaptive expansion strategy that adds new or\ndeletes noisy 3D Gaussian in order to efficiently reconstruct new observed\nscene geometry and improve the mapping of previously observed areas. This\nstrategy is essential to extend 3D Gaussian representation to reconstruct the\nwhole scene rather than synthesize a static object in existing methods.\nMoreover, in the pose tracking process, an effective coarse-to-fine technique\nis designed to select reliable 3D Gaussian representations to optimize camera\npose, resulting in runtime reduction and robust estimation. Our method achieves\ncompetitive performance compared with existing state-of-the-art real-time\nmethods on the Replica, TUM-RGBD datasets. The source code will be released\nsoon.\n","authors":["Chi Yan","Delin Qu","Dong Wang","Dan Xu","Zhigang Wang","Bin Zhao","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2311.11700v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.14372v2","updated":"2023-11-21T07:22:04Z","published":"2022-06-29T02:36:53Z","title":"Formalizing and Evaluating Requirements of Perception Systems for\n  Automated Vehicles using Spatio-Temporal Perception Logic","summary":"  Automated vehicles (AV) heavily depend on robust perception systems. Current\nmethods for evaluating vision systems focus mainly on frame-by-frame\nperformance. Such evaluation methods appear to be inadequate in assessing the\nperformance of a perception subsystem when used within an AV. In this paper, we\npresent a logic -- referred to as Spatio-Temporal Perception Logic (STPL) --\nwhich utilizes both spatial and temporal modalities. STPL enables reasoning\nover perception data using spatial and temporal operators. One major advantage\nof STPL is that it facilitates basic sanity checks on the functional\nperformance of the perception system, even without ground-truth data in some\ncases. We identify a fragment of STPL which is efficiently monitorable offline\nin polynomial time. Finally, we present a range of specifications for AV\nperception systems to highlight the types of requirements that can be expressed\nand analyzed through offline monitoring with STPL.\n","authors":["Mohammad Hekmatnejad","Bardh Hoxha","Jyotirmoy V. Deshmukh","Yezhou Yang","Georgios Fainekos"],"pdf_url":"https://arxiv.org/pdf/2206.14372v2.pdf","comment":"32 pages, 11 figures, 6 tables, 4 algorithms, 2 appendixes"},{"id":"http://arxiv.org/abs/2304.07647v2","updated":"2023-11-21T07:21:50Z","published":"2023-04-15T22:24:05Z","title":"LASER: A Neuro-Symbolic Framework for Learning Spatial-Temporal Scene\n  Graphs with Weak Supervision","summary":"  We propose LASER, a neuro-symbolic approach to learn semantic video\nrepresentations that capture rich spatial and temporal properties in video data\nby leveraging high-level logic specifications. In particular, we formulate the\nproblem in terms of alignment between raw videos and spatio-temporal logic\nspecifications. The alignment algorithm leverages a differentiable symbolic\nreasoner and a combination of contrastive, temporal, and semantics losses. It\neffectively and efficiently trains low-level perception models to extract\nfine-grained video representation in the form of a spatio-temporal scene graph\nthat conforms to the desired high-level specification. In doing so, we explore\na novel methodology that weakly supervises the learning of video semantic\nrepresentations through logic specifications. We evaluate our method on two\ndatasets with rich spatial and temporal specifications:\n20BN-Something-Something and MUGEN. We demonstrate that our method learns\nbetter fine-grained video semantics than existing baselines.\n","authors":["Jiani Huang","Ziyang Li","Mayur Naik","Ser-Nam Lim"],"pdf_url":"https://arxiv.org/pdf/2304.07647v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.09688v3","updated":"2023-11-21T07:20:50Z","published":"2022-08-20T14:15:35Z","title":"Learning Sub-Pixel Disparity Distribution for Light Field Depth\n  Estimation","summary":"  Light field (LF) depth estimation plays a crucial role in many LF-based\napplications. Existing LF depth estimation methods consider depth estimation as\na regression problem, where a pixel-wise L1 loss is employed to supervise the\ntraining process. However, the disparity map is only a sub-space projection\n(i.e., an expectation) of the disparity distribution, which is essential for\nmodels to learn. In this paper, we propose a simple yet effective method to\nlearn the sub-pixel disparity distribution by fully utilizing the power of deep\nnetworks, especially for LF of narrow baselines. We construct the cost volume\nat the sub-pixel level to produce a finer disparity distribution and design an\nuncertainty-aware focal loss to supervise the predicted disparity distribution\ntoward the ground truth. Extensive experimental results demonstrate the\neffectiveness of our method.Our method significantly outperforms recent\nstate-of-the-art LF depth algorithms on the HCI 4D LF Benchmark in terms of all\nfour accuracy metrics (i.e., BadPix 0.01, BadPix 0.03, BadPix 0.07, and MSE\n$\\times$100). The code and model of the proposed method are available at\n\\url{https://github.com/chaowentao/SubFocal}.\n","authors":["Wentao Chao","Xuechun Wang","Yingqian Wang","Guanghui Wang","Fuqing Duan"],"pdf_url":"https://arxiv.org/pdf/2208.09688v3.pdf","comment":"Accepted by IEEE Transactions on Computational Imaging"},{"id":"http://arxiv.org/abs/2311.12398v1","updated":"2023-11-21T07:19:47Z","published":"2023-11-21T07:19:47Z","title":"RFTrans: Leveraging Refractive Flow of Transparent Objects for Surface\n  Normal Estimation and Manipulation","summary":"  Transparent objects are widely used in our daily lives, making it important\nto teach robots to interact with them. However, it's not easy because the\nreflective and refractive effects can make RGB-D cameras fail to give accurate\ngeometry measurements. To solve this problem, this paper introduces RFTrans, an\nRGB-D-based method for surface normal estimation and manipulation of\ntransparent objects. By leveraging refractive flow as an intermediate\nrepresentation, RFTrans circumvents the drawbacks of directly predicting the\ngeometry (e.g. surface normal) from RGB images and helps bridge the sim-to-real\ngap. RFTrans integrates the RFNet, which predicts refractive flow, object mask,\nand boundaries, followed by the F2Net, which estimates surface normal from the\nrefractive flow. To make manipulation possible, a global optimization module\nwill take in the predictions, refine the raw depth, and construct the point\ncloud with normal. An analytical grasp planning algorithm, ISF, is followed to\ngenerate the grasp poses. We build a synthetic dataset with physically\nplausible ray-tracing rendering techniques to train the networks. Results show\nthat the RFTrans trained on the synthetic dataset can consistently outperform\nthe baseline ClearGrasp in both synthetic and real-world benchmarks by a large\nmargin. Finally, a real-world robot grasping task witnesses an 83% success\nrate, proving that refractive flow can help enable direct sim-to-real transfer.\nThe code, data, and supplementary materials are available at\nhttps://rftrans.robotflow.ai.\n","authors":["Tutian Tang","Jiyu Liu","Jieyi Zhang","Haoyuan Fu","Wenqiang Xu","Cewu Lu"],"pdf_url":"https://arxiv.org/pdf/2311.12398v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.09815v3","updated":"2023-11-21T07:19:03Z","published":"2023-07-19T08:03:53Z","title":"LDP: Language-driven Dual-Pixel Image Defocus Deblurring Network","summary":"  Recovering sharp images from dual-pixel (DP) pairs with disparity-dependent\nblur is a challenging task.~Existing blur map-based deblurring methods have\ndemonstrated promising results. In this paper, we propose, to the best of our\nknowledge, the first framework that introduces the contrastive language-image\npre-training framework (CLIP) to accurately estimate the blur map from a DP\npair unsupervisedly. To achieve this, we first carefully design text prompts to\nenable CLIP to understand blur-related geometric prior knowledge from the DP\npair. Then, we propose a format to input a stereo DP pair to CLIP without any\nfine-tuning, despite the fact that CLIP is pre-trained on monocular images.\nGiven the estimated blur map, we introduce a blur-prior attention block, a\nblur-weighting loss, and a blur-aware loss to recover the all-in-focus image.\nOur method achieves state-of-the-art performance in extensive experiments (see\nFig.~\\ref{fig:teaser}).\n","authors":["Hao Yang","Liyuan Pan","Yan Yang","Richard Hartley","Miaomiao Liu"],"pdf_url":"https://arxiv.org/pdf/2307.09815v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12397v1","updated":"2023-11-21T07:12:40Z","published":"2023-11-21T07:12:40Z","title":"Rich and Poor Texture Contrast: A Simple yet Effective Approach for\n  AI-generated Image Detection","summary":"  Recent generative models show impressive performance in generating\nphotographic images. Humans can hardly distinguish such incredibly\nrealistic-looking AI-generated images from real ones. AI-generated images may\nlead to ubiquitous disinformation dissemination. Therefore, it is of utmost\nurgency to develop a detector to identify AI-generated images. Most existing\ndetectors suffer from sharp performance drops over unseen generative models. In\nthis paper, we propose a novel AI-generated image detector capable of\nidentifying fake images created by a wide range of generative models. Our\napproach leverages the inter-pixel correlation contrast between rich and poor\ntexture regions within an image. Pixels in rich texture regions exhibit more\nsignificant fluctuations than those in poor texture regions. This discrepancy\nreflects that the entropy of rich texture regions is larger than that of poor\nones. Consequently, synthesizing realistic rich texture regions proves to be\nmore challenging for existing generative models. Based on this principle, we\ndivide an image into multiple patches and reconstruct them into two images,\ncomprising rich-texture and poor-texture patches respectively. Subsequently, we\nextract the inter-pixel correlation discrepancy feature between rich and poor\ntexture regions. This feature serves as a universal fingerprint used for\nAI-generated image forensics across different generative models. In addition,\nwe build a comprehensive AI-generated image detection benchmark, which includes\n16 kinds of prevalent generative models, to evaluate the effectiveness of\nexisting baselines and our approach. Our benchmark provides a leaderboard for\nfollow-up studies. Extensive experimental results show that our approach\noutperforms state-of-the-art baselines by a significant margin. Our project:\nhttps://fdmas.github.io/AIGCDetect/\n","authors":["Nan Zhong","Yiran Xu","Zhenxing Qian","Xinpeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12397v1.pdf","comment":"Our project: https://fdmas.github.io/AIGCDetect/"},{"id":"http://arxiv.org/abs/2311.11439v2","updated":"2023-11-21T07:12:22Z","published":"2023-11-19T22:24:19Z","title":"Improved Defect Detection and Classification Method for Advanced IC\n  Nodes by Using Slicing Aided Hyper Inference with Refinement Strategy","summary":"  In semiconductor manufacturing, lithography has often been the manufacturing\nstep defining the smallest possible pattern dimensions. In recent years,\nprogress has been made towards high-NA (Numerical Aperture) EUVL\n(Extreme-Ultraviolet-Lithography) paradigm, which promises to advance pattern\nshrinking (2 nm node and beyond). However, a significant increase in stochastic\ndefects and the complexity of defect detection becomes more pronounced with\nhigh-NA. Present defect inspection techniques (both non-machine learning and\nmachine learning based), fail to achieve satisfactory performance at high-NA\ndimensions. In this work, we investigate the use of the Slicing Aided Hyper\nInference (SAHI) framework for improving upon current techniques. Using SAHI,\ninference is performed on size-increased slices of the SEM images. This leads\nto the object detector's receptive field being more effective in capturing\nsmall defect instances. First, the performance on previously investigated\nsemiconductor datasets is benchmarked across various configurations, and the\nSAHI approach is demonstrated to substantially enhance the detection of small\ndefects, by approx. 2x. Afterwards, we also demonstrated application of SAHI\nleads to flawless detection rates on a new test dataset, with scenarios not\nencountered during training, whereas previous trained models failed. Finally,\nwe formulate an extension of SAHI that does not significantly reduce\ntrue-positive predictions while eliminating false-positive predictions.\n","authors":["Vic De Ridder","Bappaditya Dey","Victor Blanco","Sandip Halder","Bartel Van Waeyenberge"],"pdf_url":"https://arxiv.org/pdf/2311.11439v2.pdf","comment":"12 pages, 9 figures, to be presented at International Conference on\n  Machine Intelligence with Applications (ICMIA), and to be published in\n  conference proceedings by AIP"},{"id":"http://arxiv.org/abs/2311.12391v1","updated":"2023-11-21T07:02:32Z","published":"2023-11-21T07:02:32Z","title":"From Wrong To Right: A Recursive Approach Towards Vision-Language\n  Explanation","summary":"  Addressing the challenge of adapting pre-trained vision-language models for\ngenerating insightful explanations for visual reasoning tasks with limited\nannotations, we present ReVisE: a $\\textbf{Re}$cursive $\\textbf{Vis}$ual\n$\\textbf{E}$xplanation algorithm. Our method iteratively computes visual\nfeatures (conditioned on the text input), an answer, and an explanation, to\nimprove the explanation quality step by step until the answer converges. We\nfind that this multi-step approach guides the model to correct its own answers\nand outperforms single-step explanation generation. Furthermore, explanations\ngenerated by ReVisE also serve as valuable annotations for few-shot\nself-training. Our approach outperforms previous methods while utilizing merely\n5% of the human-annotated explanations across 10 metrics, demonstrating up to a\n4.2 and 1.3 increase in BLEU-1 score on the VCR and VQA-X datasets,\nunderscoring the efficacy and data-efficiency of our method.\n","authors":["Jiaxin Ge","Sanjay Subramanian","Trevor Darrell","Boyi Li"],"pdf_url":"https://arxiv.org/pdf/2311.12391v1.pdf","comment":"EMNLP 2023 Main"},{"id":"http://arxiv.org/abs/2311.12386v1","updated":"2023-11-21T06:55:21Z","published":"2023-11-21T06:55:21Z","title":"Point, Segment and Count: A Generalized Framework for Object Counting","summary":"  Class-agnostic object counting aims to count all objects in an image with\nrespect to example boxes or class names, \\emph{a.k.a} few-shot and zero-shot\ncounting. Current state-of-the-art methods highly rely on density maps to\npredict object counts, which lacks model interpretability. In this paper, we\npropose a generalized framework for both few-shot and zero-shot object counting\nbased on detection. Our framework combines the superior advantages of two\nfoundation models without compromising their zero-shot capability: (\\textbf{i})\nSAM to segment all possible objects as mask proposals, and (\\textbf{ii}) CLIP\nto classify proposals to obtain accurate object counts. However, this strategy\nmeets the obstacles of efficiency overhead and the small crowded objects that\ncannot be localized and distinguished. To address these issues, our framework,\ntermed PseCo, follows three steps: point, segment, and count. Specifically, we\nfirst propose a class-agnostic object localization to provide accurate but\nleast point prompts for SAM, which consequently not only reduces computation\ncosts but also avoids missing small objects. Furthermore, we propose a\ngeneralized object classification that leverages CLIP image/text embeddings as\nthe classifier, following a hierarchical knowledge distillation to obtain\ndiscriminative classifications among hierarchical mask proposals. Extensive\nexperimental results on FSC-147 dataset demonstrate that PseCo achieves\nstate-of-the-art performance in both few-shot/zero-shot object\ncounting/detection, with additional results on large-scale COCO and LVIS\ndatasets. The source code is available at\n\\url{https://github.com/Hzzone/PseCo}.\n","authors":["Huang Zhizhong","Dai Mingliang","Zhang Yi","Zhang Junping","Shan Hongming"],"pdf_url":"https://arxiv.org/pdf/2311.12386v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11013v2","updated":"2023-11-21T06:18:25Z","published":"2023-11-18T08:48:58Z","title":"Implicit Event-RGBD Neural SLAM","summary":"  Implicit neural SLAM has achieved remarkable progress recently. Nevertheless,\nexisting methods face significant challenges in non-ideal scenarios, such as\nmotion blur or lighting variation, which often leads to issues like convergence\nfailures, localization drifts, and distorted mapping. To address these\nchallenges, we propose $\\textbf{EN-SLAM}$, the first event-RGBD implicit neural\nSLAM framework, which effectively leverages the high rate and high dynamic\nrange advantages of event data for tracking and mapping. Specifically, EN-SLAM\nproposes a differentiable CRF (Camera Response Function) rendering technique to\ngenerate distinct RGB and event camera data via a shared radiance field, which\nis optimized by learning a unified implicit representation with the captured\nevent and RGBD supervision. Moreover, based on the temporal difference property\nof events, we propose a temporal aggregating optimization strategy for the\nevent joint tracking and global bundle adjustment, capitalizing on the\nconsecutive difference constraints of events, significantly enhancing tracking\naccuracy and robustness. Finally, we construct the simulated dataset\n$\\textbf{DEV-Indoors}$ and real captured dataset $\\textbf{DEV-Reals}$\ncontaining 6 scenes, 17 sequences with practical motion blur and lighting\nchanges for evaluations. Experimental results show that our method outperforms\nthe SOTA methods in both tracking ATE and mapping ACC with a real-time $17$ FPS\nin various challenging environments. The code and dataset will be released\nsoon.\n","authors":["Delin Qu","Chi Yan","Dong Wang","Jie Yin","Dan Xu","Bin Zhao","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2311.11013v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12364v1","updated":"2023-11-21T05:55:39Z","published":"2023-11-21T05:55:39Z","title":"Semi-supervised Medical Image Segmentation via Query Distribution\n  Consistency","summary":"  Semi-supervised learning is increasingly popular in medical image\nsegmentation due to its ability to leverage large amounts of unlabeled data to\nextract additional information. However, most existing semi-supervised\nsegmentation methods focus only on extracting information from unlabeled data.\nIn this paper, we propose a novel Dual KMax UX-Net framework that leverages\nlabeled data to guide the extraction of information from unlabeled data. Our\napproach is based on a mutual learning strategy that incorporates two modules:\n3D UX-Net as our backbone meta-architecture and KMax decoder to enhance the\nsegmentation performance. Extensive experiments on the Atrial Segmentation\nChallenge dataset have shown that our method can significantly improve\nperformance by merging unlabeled data. Meanwhile, our framework outperforms\nstate-of-the-art semi-supervised learning methods on 10\\% and 20\\% labeled\nsettings. Code located at: https://github.com/Rows21/DK-UXNet.\n","authors":["Rong Wu","Dehua Li","Cong Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12364v1.pdf","comment":"Submitted to IEEE ISBI 2024"},{"id":"http://arxiv.org/abs/2310.17949v2","updated":"2023-11-21T05:55:10Z","published":"2023-10-27T07:44:25Z","title":"Instance Segmentation under Occlusions via Location-aware Copy-Paste\n  Data Augmentation","summary":"  Occlusion is a long-standing problem in computer vision, particularly in\ninstance segmentation. ACM MMSports 2023 DeepSportRadar has introduced a\ndataset that focuses on segmenting human subjects within a basketball context\nand a specialized evaluation metric for occlusion scenarios. Given the modest\nsize of the dataset and the highly deformable nature of the objects to be\nsegmented, this challenge demands the application of robust data augmentation\ntechniques and wisely-chosen deep learning architectures. Our work (ranked 1st\nin the competition) first proposes a novel data augmentation technique, capable\nof generating more training samples with wider distribution. Then, we adopt a\nnew architecture - Hybrid Task Cascade (HTC) framework with CBNetV2 as backbone\nand MaskIoU head to improve segmentation performance. Furthermore, we employ a\nStochastic Weight Averaging (SWA) training strategy to improve the model's\ngeneralization. As a result, we achieve a remarkable occlusion score (OM) of\n0.533 on the challenge dataset, securing the top-1 position on the leaderboard.\nSource code is available at this\nhttps://github.com/nguyendinhson-kaist/MMSports23-Seg-AutoID.\n","authors":["Son Nguyen","Mikel Lainsa","Hung Dao","Daeyoung Kim","Giang Nguyen"],"pdf_url":"https://arxiv.org/pdf/2310.17949v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12359v1","updated":"2023-11-21T05:27:16Z","published":"2023-11-21T05:27:16Z","title":"Post-Training Quantization with Low-precision Minifloats and Integers on\n  FPGAs","summary":"  Post-Training Quantization (PTQ) is a powerful technique for model\ncompression, reducing the precision of neural networks without additional\ntraining overhead. Recent works have investigated adopting 8-bit floating-point\nquantization (FP8) in the context of PTQ for model inference. However, the\nexploration of floating-point formats smaller than 8 bits and their comparison\nwith integer quantization remains relatively limited. In this work, we present\nminifloats, which are reduced-precision floating-point formats capable of\nfurther reducing the memory footprint, latency, and energy cost of a model\nwhile approaching full-precision model accuracy. Our work presents a novel PTQ\ndesign-space exploration, comparing minifloat and integer quantization schemes\nacross a range of 3 to 8 bits for both weights and activations. We examine the\napplicability of various PTQ techniques to minifloats, including weight\nequalization, bias correction, SmoothQuant, gradient-based learned rounding,\nand the GPTQ method. Our experiments validate the effectiveness of\nlow-precision minifloats when compared to their integer counterparts across a\nspectrum of accuracy-precision trade-offs on a set of reference deep learning\nvision workloads. Finally, we evaluate our results against an FPGA-based\nhardware cost model, showing that integer quantization often remains the\nPareto-optimal option, given its relatively smaller hardware resource\nfootprint.\n","authors":["Shivam Aggarwal","Alessandro Pappalardo","Hans Jakob Damsgaard","Giuseppe Franco","Thomas B. Preußer","Michaela Blott","Tulika Mitra"],"pdf_url":"https://arxiv.org/pdf/2311.12359v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12345v1","updated":"2023-11-21T04:38:21Z","published":"2023-11-21T04:38:21Z","title":"Stable Diffusion For Aerial Object Detection","summary":"  Aerial object detection is a challenging task, in which one major obstacle\nlies in the limitations of large-scale data collection and the long-tail\ndistribution of certain classes. Synthetic data offers a promising solution,\nespecially with recent advances in diffusion-based methods like stable\ndiffusion (SD). However, the direct application of diffusion methods to aerial\ndomains poses unique challenges: stable diffusion's optimization for rich\nground-level semantics doesn't align with the sparse nature of aerial objects,\nand the extraction of post-synthesis object coordinates remains problematic. To\naddress these challenges, we introduce a synthetic data augmentation framework\ntailored for aerial images. It encompasses sparse-to-dense region of interest\n(ROI) extraction to bridge the semantic gap, fine-tuning the diffusion model\nwith low-rank adaptation (LORA) to circumvent exhaustive retraining, and\nfinally, a Copy-Paste method to compose synthesized objects with backgrounds,\nproviding a nuanced approach to aerial object detection through synthetic data.\n","authors":["Yanan Jian","Fuxun Yu","Simranjit Singh","Dimitrios Stamoulis"],"pdf_url":"https://arxiv.org/pdf/2311.12345v1.pdf","comment":"Accepted at NeurIPS 2023 Synthetic Data Generation with Generative AI\n  workshop"},{"id":"http://arxiv.org/abs/2311.12344v1","updated":"2023-11-21T04:32:28Z","published":"2023-11-21T04:32:28Z","title":"Modality Mixer Exploiting Complementary Information for Multi-modal\n  Action Recognition","summary":"  Due to the distinctive characteristics of sensors, each modality exhibits\nunique physical properties. For this reason, in the context of multi-modal\naction recognition, it is important to consider not only the overall action\ncontent but also the complementary nature of different modalities. In this\npaper, we propose a novel network, named Modality Mixer (M-Mixer) network,\nwhich effectively leverages and incorporates the complementary information\nacross modalities with the temporal context of actions for action recognition.\nA key component of our proposed M-Mixer is the Multi-modal Contextualization\nUnit (MCU), a simple yet effective recurrent unit. Our MCU is responsible for\ntemporally encoding a sequence of one modality (e.g., RGB) with action content\nfeatures of other modalities (e.g., depth and infrared modalities). This\nprocess encourages M-Mixer network to exploit global action content and also to\nsupplement complementary information of other modalities. Furthermore, to\nextract appropriate complementary information regarding to the given modality\nsettings, we introduce a new module, named Complementary Feature Extraction\nModule (CFEM). CFEM incorporates sepearte learnable query embeddings for each\nmodality, which guide CFEM to extract complementary information and global\naction content from the other modalities. As a result, our proposed method\noutperforms state-of-the-art methods on NTU RGB+D 60, NTU RGB+D 120, and\nNW-UCLA datasets. Moreover, through comprehensive ablation studies, we further\nvalidate the effectiveness of our proposed method.\n","authors":["Sumin Lee","Sangmin Woo","Muhammad Adi Nugroho","Changick Kim"],"pdf_url":"https://arxiv.org/pdf/2311.12344v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2208.11314"},{"id":"http://arxiv.org/abs/2311.12342v1","updated":"2023-11-21T04:28:12Z","published":"2023-11-21T04:28:12Z","title":"LoCo: Locally Constrained Training-Free Layout-to-Image Synthesis","summary":"  Recent text-to-image diffusion models have reached an unprecedented level in\ngenerating high-quality images. However, their exclusive reliance on textual\nprompts often falls short in accurately conveying fine-grained spatial\ncompositions. In this paper, we propose LoCo, a training-free approach for\nlayout-to-image synthesis that excels in producing high-quality images aligned\nwith both textual prompts and spatial layouts. Our method introduces a\nLocalized Attention Constraint to refine cross-attention for individual\nobjects, ensuring their precise placement in designated regions. We further\npropose a Padding Token Constraint to leverage the semantic information\nembedded in previously neglected padding tokens, thereby preventing the\nundesired fusion of synthesized objects. LoCo seamlessly integrates into\nexisting text-to-image and layout-to-image models, significantly amplifying\ntheir performance and effectively addressing semantic failures observed in\nprior methods. Through extensive experiments, we showcase the superiority of\nour approach, surpassing existing state-of-the-art training-free\nlayout-to-image methods both qualitatively and quantitatively across multiple\nbenchmarks.\n","authors":["Peiang Zhao","Han Li","Ruiyang Jin","S. Kevin Zhou"],"pdf_url":"https://arxiv.org/pdf/2311.12342v1.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2206.10996v4","updated":"2023-11-21T04:18:38Z","published":"2022-06-22T11:55:53Z","title":"ProtoCLIP: Prototypical Contrastive Language Image Pretraining","summary":"  Contrastive Language Image Pretraining (CLIP) has received widespread\nattention, since its learned representations can be transferred well to various\ndownstream tasks. During the training process of the CLIP model, the InfoNCE\nobjective aligns positive image-text pairs and separates negative ones. We show\nan underlying representation grouping effect during this process: the InfoNCE\nobjective indirectly groups semantically similar representations together via\nrandomly emerged within-modal anchors. Based on this understanding, in this\npaper, Prototypical Contrastive Language Image Pretraining (ProtoCLIP) is\nintroduced to enhance such grouping by boosting its efficiency and increasing\nits robustness against the modality gap. Specifically, ProtoCLIP sets up\nprototype-level discrimination between image and text spaces, which efficiently\ntransfers higher-level structural knowledge. Further, Prototypical Back\nTranslation (PBT) is proposed to decouple representation grouping from\nrepresentation alignment, resulting in effective learning of meaningful\nrepresentations under large modality gap. The PBT also enables us to introduce\nadditional external teachers with richer prior language knowledge. ProtoCLIP is\ntrained with an online episodic training strategy, which makes it can be scaled\nup to unlimited amounts of data. We train our ProtoCLIP on Conceptual Captions\nand achieved an +5.81% ImageNet linear probing improvement and an +2.01%\nImageNet zero-shot classification improvement. On the larger YFCC-15M dataset,\nProtoCLIP matches the performance of CLIP with 33% of training time. Codes are\navailable at https://github.com/megvii-research/protoclip.\n","authors":["Delong Chen","Zhao Wu","Fan Liu","Zaiquan Yang","Huaxi Huang","Ying Tan","Erjin Zhou"],"pdf_url":"https://arxiv.org/pdf/2206.10996v4.pdf","comment":"Accepted by IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS)"},{"id":"http://arxiv.org/abs/2309.04342v3","updated":"2023-11-21T04:10:20Z","published":"2023-09-08T14:12:03Z","title":"Revealing the preference for correcting separated aberrations in joint\n  optic-image design","summary":"  The joint design of the optical system and the downstream algorithm is a\nchallenging and promising task. Due to the demand for balancing the global\noptimal of imaging systems and the computational cost of physical simulation,\nexisting methods cannot achieve efficient joint design of complex systems such\nas smartphones and drones. In this work, starting from the perspective of the\noptical design, we characterize the optics with separated aberrations.\nAdditionally, to bridge the hardware and software without gradients, an image\nsimulation system is presented to reproduce the genuine imaging procedure of\nlenses with large field-of-views. As for aberration correction, we propose a\nnetwork to perceive and correct the spatially varying aberrations and validate\nits superiority over state-of-the-art methods. Comprehensive experiments reveal\nthat the preference for correcting separated aberrations in joint design is as\nfollows: longitudinal chromatic aberration, lateral chromatic aberration,\nspherical aberration, field curvature, and coma, with astigmatism coming last.\nDrawing from the preference, a 10% reduction in the total track length of the\nconsumer-level mobile phone lens module is accomplished. Moreover, this\nprocedure spares more space for manufacturing deviations, realizing\nextreme-quality enhancement of computational photography. The optimization\nparadigm provides innovative insight into the practical joint design of\nsophisticated optical systems and post-processing algorithms.\n","authors":["Jingwen Zhou","Shiqi Chen","Zheng Ren","Wenguan Zhang","Jiapu Yan","Huajun Feng","Qi Li","Yueting Chen"],"pdf_url":"https://arxiv.org/pdf/2309.04342v3.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2311.11354v2","updated":"2023-11-21T03:45:32Z","published":"2023-11-19T15:35:15Z","title":"Scale-aware competition network for palmprint recognition","summary":"  Palmprint biometrics garner heightened attention in palm-scanning payment and\nsocial security due to their distinctive attributes. However, prevailing\nmethodologies singularly prioritize texture orientation, neglecting the\nsignificant texture scale dimension. We design an innovative network for\nconcurrently extracting intra-scale and inter-scale features to redress this\nlimitation. This paper proposes a scale-aware competitive network (SAC-Net),\nwhich includes the Inner-Scale Competition Module (ISCM) and the Across-Scale\nCompetition Module (ASCM) to capture texture characteristics related to\norientation and scale. ISCM efficiently integrates learnable Gabor filters and\na self-attention mechanism to extract rich orientation data and discern\ntextures with long-range discriminative properties. Subsequently, ASCM\nleverages a competitive strategy across various scales to effectively\nencapsulate the competitive texture scale elements. By synergizing ISCM and\nASCM, our method adeptly characterizes palmprint features. Rigorous\nexperimentation across three benchmark datasets unequivocally demonstrates our\nproposed approach's exceptional recognition performance and resilience relative\nto state-of-the-art alternatives.\n","authors":["Chengrui Gao","Ziyuan Yang","Min Zhu","Andrew Beng Jin Teoh"],"pdf_url":"https://arxiv.org/pdf/2311.11354v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12327v1","updated":"2023-11-21T03:40:09Z","published":"2023-11-21T03:40:09Z","title":"ViLaM: A Vision-Language Model with Enhanced Visual Grounding and\n  Generalization Capability","summary":"  Vision-language models have revolutionized human-computer interaction and\nshown significant progress in multi-modal tasks. However, applying these models\nto complex visual tasks like medical image analysis remains challenging. In\nthis study, we propose ViLaM, a unified Vision-Language transformer model that\nintegrates instruction tuning predicated on a large language model. This\napproach enables us to optimally utilize the knowledge and reasoning capacities\nof large pre-trained language models for an array of tasks encompassing both\nlanguage and vision. We employ frozen pre-trained encoders to encode and align\nboth image and text features, enabling ViLaM to handle a variety of visual\ntasks following textual instructions. Besides, we've designed cycle training\nfor referring expressions to address the need for high-quality, paired\nreferring expression datasets for training large models in terms of both\nquantity and quality. We evaluated ViLaM's exceptional performance on public\ngeneral datasets and further confirmed its generalizability on medical\ndatasets. Importantly, we've observed the model's impressive zero-shot learning\nability, indicating the potential future application of ViLaM in the medical\nfield.\n","authors":["Xiaoyu Yang","Lijian Xu","Hongsheng Li","Shaoting Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12327v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12316v1","updated":"2023-11-21T03:25:51Z","published":"2023-11-21T03:25:51Z","title":"Overcoming Pathology Image Data Deficiency: Generating Images from\n  Pathological Transformation Process","summary":"  Histopathology serves as the gold standard for medical diagnosis but faces\napplication limitations due to the shortage of medical resources. Leveraging\ndeep learning, computer-aided diagnosis has the potential to alleviate the\npathologist scarcity and provide timely clinical analysis. However, developing\na reliable model generally necessitates substantial data for training, which is\nchallenging in pathological field. In response, we propose an adaptive\ndepth-controlled bidirectional diffusion (ADBD) network for image data\ngeneration. The domain migration approach can work with small trainset and\novercome the diffusion overfitting by source information guidance.\nSpecifically, we developed a hybrid attention strategy to blend global and\nlocal attention priorities, which guides the bidirectional diffusion and\nensures the migration success. In addition, we developed the adaptive\ndepth-controlled strategy to simulate physiological transformations, capable of\nyielding unlimited cross-domain intermediate images with corresponding soft\nlabels. ADBD is effective for overcoming pathological image data deficiency and\nsupportable for further pathology-related research.\n","authors":["Zeyu Liu","Yufang He","Yu Zhao","Yunlu Feng","Guanglei Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12316v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.18639v2","updated":"2023-11-21T03:23:39Z","published":"2023-10-28T08:48:44Z","title":"Towards Plastic and Stable Exemplar-Free Incremental Learning: A\n  Dual-Learner Framework with Cumulative Parameter Averaging","summary":"  The dilemma between plasticity and stability presents a significant challenge\nin Incremental Learning (IL), especially in the exemplar-free scenario where\naccessing old-task samples is strictly prohibited during the learning of a new\ntask. A straightforward solution to this issue is learning and storing an\nindependent model for each task, known as Single Task Learning (STL). Despite\nthe linear growth in model storage with the number of tasks in STL, we\nempirically discover that averaging these model parameters can potentially\npreserve knowledge across all tasks. Inspired by this observation, we propose a\nDual-Learner framework with Cumulative Parameter Averaging (DLCPA). DLCPA\nemploys a dual-learner design: a plastic learner focused on acquiring new-task\nknowledge and a stable learner responsible for accumulating all learned\nknowledge. The knowledge from the plastic learner is transferred to the stable\nlearner via cumulative parameter averaging. Additionally, several task-specific\nclassifiers work in cooperation with the stable learner to yield the final\nprediction. Specifically, when learning a new task, these modules are updated\nin a cyclic manner: i) the plastic learner is initially optimized using a\nself-supervised loss besides the supervised loss to enhance the feature\nextraction robustness; ii) the stable learner is then updated with respect to\nthe plastic learner in a cumulative parameter averaging manner to maintain its\ntask-wise generalization; iii) the task-specific classifier is accordingly\noptimized to align with the stable learner. Experimental results on CIFAR-100\nand Tiny-ImageNet show that DLCPA outperforms several state-of-the-art\nexemplar-free baselines in both Task-IL and Class-IL settings.\n","authors":["Wenju Sun","Qingyong Li","Wen Wang","Yangli-ao Geng"],"pdf_url":"https://arxiv.org/pdf/2310.18639v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12311v1","updated":"2023-11-21T03:03:22Z","published":"2023-11-21T03:03:22Z","title":"ABFL: Angular Boundary Discontinuity Free Loss for Arbitrary Oriented\n  Object Detection in Aerial Images","summary":"  Arbitrary oriented object detection (AOOD) in aerial images is a widely\nconcerned and highly challenging task, and plays an important role in many\nscenarios. The core of AOOD involves the representation, encoding, and feature\naugmentation of oriented bounding-boxes (Bboxes). Existing methods lack\nintuitive modeling of angle difference measurement in oriented Bbox\nrepresentations. Oriented Bboxes under different representations exhibit\nrotational symmetry with varying periods due to angle periodicity. The angular\nboundary discontinuity (ABD) problem at periodic boundary positions is caused\nby rotational symmetry in measuring angular differences. In addition, existing\nmethods also use additional encoding-decoding structures for oriented Bboxes.\nIn this paper, we design an angular boundary free loss (ABFL) based on the von\nMises distribution. The ABFL aims to solve the ABD problem when detecting\noriented objects. Specifically, ABFL proposes to treat angles as circular data\nrather than linear data when measuring angle differences, aiming to introduce\nangle periodicity to alleviate the ABD problem and improve the accuracy of\nangle difference measurement. In addition, ABFL provides a simple and effective\nsolution for various periodic boundary discontinuities caused by rotational\nsymmetry in AOOD tasks, as it does not require additional encoding-decoding\nstructures for oriented Bboxes. Extensive experiments on the DOTA and HRSC2016\ndatasets show that the proposed ABFL loss outperforms some state-of-the-art\nmethods focused on addressing the ABD problem.\n","authors":["Zifei Zhao","Shengyang Li"],"pdf_url":"https://arxiv.org/pdf/2311.12311v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12685v3","updated":"2023-11-21T02:57:09Z","published":"2023-06-22T06:12:23Z","title":"Rethinking the Backward Propagation for Adversarial Transferability","summary":"  Transfer-based attacks generate adversarial examples on the surrogate model,\nwhich can mislead other black-box models without access, making it promising to\nattack real-world applications. Recently, several works have been proposed to\nboost adversarial transferability, in which the surrogate model is usually\noverlooked. In this work, we identify that non-linear layers (e.g., ReLU,\nmax-pooling, etc.) truncate the gradient during backward propagation, making\nthe gradient w.r.t. input image imprecise to the loss function. We hypothesize\nand empirically validate that such truncation undermines the transferability of\nadversarial examples. Based on these findings, we propose a novel method called\nBackward Propagation Attack (BPA) to increase the relevance between the\ngradient w.r.t. input image and loss function so as to generate adversarial\nexamples with higher transferability. Specifically, BPA adopts a non-monotonic\nfunction as the derivative of ReLU and incorporates softmax with temperature to\nsmooth the derivative of max-pooling, thereby mitigating the information loss\nduring the backward propagation of gradients. Empirical results on the ImageNet\ndataset demonstrate that not only does our method substantially boost the\nadversarial transferability, but it is also general to existing transfer-based\nattacks. Code is available at https://github.com/Trustworthy-AI-Group/RPA.\n","authors":["Xiaosen Wang","Kangheng Tong","Kun He"],"pdf_url":"https://arxiv.org/pdf/2306.12685v3.pdf","comment":"Accepted by NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.12300v1","updated":"2023-11-21T02:36:47Z","published":"2023-11-21T02:36:47Z","title":"Challenges in Video-Based Infant Action Recognition: A Critical\n  Examination of the State of the Art","summary":"  Automated human action recognition, a burgeoning field within computer\nvision, boasts diverse applications spanning surveillance, security,\nhuman-computer interaction, tele-health, and sports analysis. Precise action\nrecognition in infants serves a multitude of pivotal purposes, encompassing\nsafety monitoring, developmental milestone tracking, early intervention for\ndevelopmental delays, fostering parent-infant bonds, advancing computer-aided\ndiagnostics, and contributing to the scientific comprehension of child\ndevelopment. This paper delves into the intricacies of infant action\nrecognition, a domain that has remained relatively uncharted despite the\naccomplishments in adult action recognition. In this study, we introduce a\ngroundbreaking dataset called ``InfActPrimitive'', encompassing five\nsignificant infant milestone action categories, and we incorporate specialized\npreprocessing for infant data. We conducted an extensive comparative analysis\nemploying cutting-edge skeleton-based action recognition models using this\ndataset. Our findings reveal that, although the PoseC3D model achieves the\nhighest accuracy at approximately 71%, the remaining models struggle to\naccurately capture the dynamics of infant actions. This highlights a\nsubstantial knowledge gap between infant and adult action recognition domains\nand the urgent need for data-efficient pipeline models.\n","authors":["Elaheh Hatamimajoumerd","Pooria Daneshvar Kakhaki","Xiaofei Huang","Lingfei Luan","Somaieh Amraee","Sarah Ostadabbas"],"pdf_url":"https://arxiv.org/pdf/2311.12300v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10899v2","updated":"2023-11-21T02:16:27Z","published":"2023-11-17T22:44:05Z","title":"Extraction and Summarization of Explicit Video Content using Multi-Modal\n  Deep Learning","summary":"  With the increase in video-sharing platforms across the internet, it is\ndifficult for humans to moderate the data for explicit content. Hence, an\nautomated pipeline to scan through video data for explicit content has become\nthe need of the hour. We propose a novel pipeline that uses multi-modal deep\nlearning to first extract the explicit segments of input videos and then\nsummarize their content using text to determine its age appropriateness and age\nrating. We also evaluate our pipeline's effectiveness in the end using standard\nmetrics.\n","authors":["Shaunak Joshi","Raghav Gaggar"],"pdf_url":"https://arxiv.org/pdf/2311.10899v2.pdf","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.12291v1","updated":"2023-11-21T02:14:16Z","published":"2023-11-21T02:14:16Z","title":"Instance-aware 3D Semantic Segmentation powered by Shape Generators and\n  Classifiers","summary":"  Existing 3D semantic segmentation methods rely on point-wise or voxel-wise\nfeature descriptors to output segmentation predictions. However, these\ndescriptors are often supervised at point or voxel level, leading to\nsegmentation models that can behave poorly at instance-level. In this paper, we\nproposed a novel instance-aware approach for 3D semantic segmentation. Our\nmethod combines several geometry processing tasks supervised at instance-level\nto promote the consistency of the learned feature representation. Specifically,\nour methods use shape generators and shape classifiers to perform shape\nreconstruction and classification tasks for each shape instance. This enforces\nthe feature representation to faithfully encode both structural and local shape\ninformation, with an awareness of shape instances. In the experiments, our\nmethod significantly outperform existing approaches in 3D semantic segmentation\non several public benchmarks, such as Waymo Open Dataset, SemanticKITTI and\nScanNetV2.\n","authors":["Bo Sun","Qixing Huang","Xiangru Huang"],"pdf_url":"https://arxiv.org/pdf/2311.12291v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12272v1","updated":"2023-11-21T01:25:24Z","published":"2023-11-21T01:25:24Z","title":"Procedural Generation of Grain Orientations using the Wave Function\n  Collapse Algorithm","summary":"  Statistics of grain sizes and orientations in metals correlate to the\nmaterial's mechanical properties. Reproducing representative volume elements\nfor further analysis of deformation and failure in metals, like 316L stainless\nsteel, is particularly important due to their wide use in manufacturing goods\ntoday. Two approaches, initially created for video games, were considered for\nthe procedural generation of representative grain microstructures. The first is\nthe Wave Function Collapse (WFC) algorithm, and the second is constraint\npropagation and probabilistic inference through Markov Junior, a free and\nopen-source software. This study aimed to investigate these two algorithms'\neffectiveness in using reference electron backscatter diffraction (EBSD) maps\nand recreating a statistically similar one that could be used in further\nresearch. It utilized two stainless steel EBSD maps as references to test both\nalgorithms. First, the WFC algorithm was too constricting and, thus, incapable\nof producing images that resembled EBSDs. The second, MarkovJunior, was much\nmore effective in creating a Voronoi tessellation that could be used to create\nan EBSD map in Python. When comparing the results between the reference and the\ngenerated EBSD, we discovered that the orientation and volume fractions were\nextremely similar. With the study, it was concluded that MarkovJunior is an\neffective machine learning tool that can reproduce representative grain\nmicrostructures.\n","authors":["G. Magny-Fokam","D. Madisetti","J. El-Awady"],"pdf_url":"https://arxiv.org/pdf/2311.12272v1.pdf","comment":"6 pages, 18 figures"},{"id":"http://arxiv.org/abs/2311.12268v1","updated":"2023-11-21T01:18:23Z","published":"2023-11-21T01:18:23Z","title":"Boosting Audio-visual Zero-shot Learning with Large Language Models","summary":"  Audio-visual zero-shot learning aims to recognize unseen categories based on\npaired audio-visual sequences. Recent methods mainly focus on learning aligned\nand discriminative multi-modal features to boost generalization towards unseen\ncategories. However, these approaches ignore the obscure action concepts in\ncategory names and may inevitably introduce complex network structures with\ndifficult training objectives. In this paper, we propose a simple yet effective\nframework named Knowledge-aware Distribution Adaptation (KDA) to help the model\nbetter grasp the novel action contents with an external knowledge base.\nSpecifically, we first propose using large language models to generate rich\ndescriptions from category names, which leads to a better understanding of\nunseen categories. Additionally, we propose a distribution alignment loss as\nwell as a knowledge-aware adaptive margin loss to further improve the\ngeneralization ability towards unseen categories. Extensive experimental\nresults demonstrate that our proposed KDA can outperform state-of-the-art\nmethods on three popular audio-visual zero-shot learning datasets. Our code\nwill be avaliable at \\url{https://github.com/chenhaoxing/KDA}.\n","authors":["Haoxing Chen","Yaohui Li","Yan Hong","Zizheng Huang","Zhuoer Xu","Zhangxuan Gu","Jun Lan","Huijia Zhu","Weiqiang Wang"],"pdf_url":"https://arxiv.org/pdf/2311.12268v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12265v1","updated":"2023-11-21T01:01:08Z","published":"2023-11-21T01:01:08Z","title":"Virtual Home Staging: Inverse Rendering and Editing an Indoor Panorama\n  under Natural Illumination","summary":"  We propose a novel inverse rendering method that enables the transformation\nof existing indoor panoramas with new indoor furniture layouts under natural\nillumination. To achieve this, we captured indoor HDR panoramas along with\nreal-time outdoor hemispherical HDR photographs. Indoor and outdoor HDR images\nwere linearly calibrated with measured absolute luminance values for accurate\nscene relighting. Our method consists of three key components: (1) panoramic\nfurniture detection and removal, (2) automatic floor layout design, and (3)\nglobal rendering with scene geometry, new furniture objects, and a real-time\noutdoor photograph. We demonstrate the effectiveness of our workflow in\nrendering indoor scenes under different outdoor illumination conditions.\nAdditionally, we contribute a new calibrated HDR (Cali-HDR) dataset that\nconsists of 137 calibrated indoor panoramas and their associated outdoor\nphotographs. The source code and dataset are available:\nhttps://github.com/Gzhji/Cali-HDR-Dataset.\n","authors":["Guanzhou Ji","Azadeh O. Sawyer","Srinivasa G. Narasimhan"],"pdf_url":"https://arxiv.org/pdf/2311.12265v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.08420v2","updated":"2023-11-21T23:40:09Z","published":"2023-10-12T15:39:54Z","title":"Visual Attention-Prompted Prediction and Learning","summary":"  Explanation(attention)-guided learning is a method that enhances a model's\npredictive power by incorporating human understanding during the training\nphase. While attention-guided learning has shown promising results, it often\ninvolves time-consuming and computationally expensive model retraining. To\naddress this issue, we introduce the attention-prompted prediction technique,\nwhich enables direct prediction guided by the attention prompt without the need\nfor model retraining. However, this approach presents several challenges,\nincluding: 1) How to incorporate the visual attention prompt into the model's\ndecision-making process and leverage it for future predictions even in the\nabsence of a prompt? and 2) How to handle the incomplete information from the\nvisual attention prompt? To tackle these challenges, we propose a novel\nframework called Visual Attention-Prompted Prediction and Learning, which\nseamlessly integrates visual attention prompts into the model's decision-making\nprocess and adapts to images both with and without attention prompts for\nprediction. To address the incomplete information of the visual attention\nprompt, we introduce a perturbation-based attention map modification method.\nAdditionally, we propose an optimization-based mask aggregation method with a\nnew weight learning function for adaptive perturbed annotation aggregation in\nthe attention map modification process. Our overall framework is designed to\nlearn in an attention-prompt guided multi-task manner to enhance future\npredictions even for samples without attention prompts and trained in an\nalternating manner for better convergence. Extensive experiments conducted on\ntwo datasets demonstrate the effectiveness of our proposed framework in\nenhancing predictions for samples, both with and without provided prompts.\n","authors":["Yifei Zhang","Siyi Gu","Bo Pan","Guangji Bai","Xiaofeng Yang","Liang Zhao"],"pdf_url":"https://arxiv.org/pdf/2310.08420v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13052v1","updated":"2023-11-21T23:25:04Z","published":"2023-11-21T23:25:04Z","title":"Novel OCT mosaicking pipeline with Feature- and Pixel-based registration","summary":"  High-resolution Optical Coherence Tomography (OCT) images are crucial for\nophthalmology studies but are limited by their relatively narrow field of view\n(FoV). Image mosaicking is a technique for aligning multiple overlapping images\nto obtain a larger FoV. Current mosaicking pipelines often struggle with\nsubstantial noise and considerable displacement between the input sub-fields.\nIn this paper, we propose a versatile pipeline for stitching multi-view\nOCT/OCTA \\textit{en face} projection images. Our method combines the strengths\nof learning-based feature matching and robust pixel-based registration to align\nmultiple images effectively. Furthermore, we advance the application of a\ntrained foundational model, Segment Anything Model (SAM), to validate\nmosaicking results in an unsupervised manner. The efficacy of our pipeline is\nvalidated using an in-house dataset and a large public dataset, where our\nmethod shows superior performance in terms of both accuracy and computational\nefficiency. We also made our evaluation tool for image mosaicking and the\ncorresponding pipeline publicly available at\n\\url{https://github.com/MedICL-VU/OCT-mosaicking}.\n","authors":["Jiacheng Wang","Hao Li","Dewei Hu","Yuankai K. Tao","Ipek Oguz"],"pdf_url":"https://arxiv.org/pdf/2311.13052v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.16020v2","updated":"2023-11-21T23:23:08Z","published":"2023-09-27T20:54:56Z","title":"GeoCLIP: Clip-Inspired Alignment between Locations and Images for\n  Effective Worldwide Geo-localization","summary":"  Worldwide Geo-localization aims to pinpoint the precise location of images\ntaken anywhere on Earth. This task has considerable challenges due to immense\nvariation in geographic landscapes. The image-to-image retrieval-based\napproaches fail to solve this problem on a global scale as it is not feasible\nto construct a large gallery of images covering the entire world. Instead,\nexisting approaches divide the globe into discrete geographic cells,\ntransforming the problem into a classification task. However, their performance\nis limited by the predefined classes and often results in inaccurate\nlocalizations when an image's location significantly deviates from its class\ncenter. To overcome these limitations, we propose GeoCLIP, a novel\nCLIP-inspired Image-to-GPS retrieval approach that enforces alignment between\nthe image and its corresponding GPS locations. GeoCLIP's location encoder\nmodels the Earth as a continuous function by employing positional encoding\nthrough random Fourier features and constructing a hierarchical representation\nthat captures information at varying resolutions to yield a semantically rich\nhigh-dimensional feature suitable to use even beyond geo-localization. To the\nbest of our knowledge, this is the first work employing GPS encoding for\ngeo-localization. We demonstrate the efficacy of our method via extensive\nexperiments and ablations on benchmark datasets. We achieve competitive\nperformance with just 20% of training data, highlighting its effectiveness even\nin limited-data settings. Furthermore, we qualitatively demonstrate\ngeo-localization using a text query by leveraging CLIP backbone of our image\nencoder. The project webpage is available at:\nhttps://vicentevivan.github.io/GeoCLIP\n","authors":["Vicente Vivanco Cepeda","Gaurav Kumar Nayak","Mubarak Shah"],"pdf_url":"https://arxiv.org/pdf/2309.16020v2.pdf","comment":"Accepted at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.13045v1","updated":"2023-11-21T23:14:42Z","published":"2023-11-21T23:14:42Z","title":"Camera-Independent Single Image Depth Estimation from Defocus Blur","summary":"  Monocular depth estimation is an important step in many downstream tasks in\nmachine vision. We address the topic of estimating monocular depth from defocus\nblur which can yield more accurate results than the semantic based depth\nestimation methods. The existing monocular depth from defocus techniques are\nsensitive to the particular camera that the images are taken from. We show how\nseveral camera-related parameters affect the defocus blur using optical physics\nequations and how they make the defocus blur depend on these parameters. The\nsimple correction procedure we propose can alleviate this problem which does\nnot require any retraining of the original model. We created a synthetic\ndataset which can be used to test the camera independent performance of depth\nfrom defocus blur models. We evaluate our model on both synthetic and real\ndatasets (DDFF12 and NYU depth V2) obtained with different cameras and show\nthat our methods are significantly more robust to the changes of cameras. Code:\nhttps://github.com/sleekEagle/defocus_camind.git\n","authors":["Lahiru Wijayasingha","Homa Alemzadeh","John A. Stankovic"],"pdf_url":"https://arxiv.org/pdf/2311.13045v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13022v1","updated":"2023-11-21T22:05:00Z","published":"2023-11-21T22:05:00Z","title":"Unsupervised Multimodal Surface Registration with Geometric Deep\n  Learning","summary":"  This paper introduces GeoMorph, a novel geometric deep-learning framework\ndesigned for image registration of cortical surfaces. The registration process\nconsists of two main steps. First, independent feature extraction is performed\non each input surface using graph convolutions, generating low-dimensional\nfeature representations that capture important cortical surface\ncharacteristics. Subsequently, features are registered in a deep-discrete\nmanner to optimize the overlap of common structures across surfaces by learning\ndisplacements of a set of control points. To ensure smooth and biologically\nplausible deformations, we implement regularization through a deep conditional\nrandom field implemented with a recurrent neural network. Experimental results\ndemonstrate that GeoMorph surpasses existing deep-learning methods by achieving\nimproved alignment with smoother deformations. Furthermore, GeoMorph exhibits\ncompetitive performance compared to classical frameworks. Such versatility and\nrobustness suggest strong potential for various neuroscience applications.\n","authors":["Mohamed A. Suliman","Logan Z. J. Williams","Abdulah Fawaz","Emma C. Robinson"],"pdf_url":"https://arxiv.org/pdf/2311.13022v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13018v1","updated":"2023-11-21T21:48:51Z","published":"2023-11-21T21:48:51Z","title":"Attention: Large Multimodal Model is Watching your Geo-privacy","summary":"  Geographic privacy, a crucial aspect of personal security, often goes\nunnoticed in daily activities. This paper addresses the underestimation of this\nprivacy in the context of increasing online data sharing and the advancements\nin information gathering technologies. With the surge in the use of Large\nMultimodal Models, such as GPT-4, for Open Source Intelligence (OSINT), the\npotential risks associated with geographic privacy breaches have intensified.\nThis study highlights the criticality of these developments, focusing on their\nimplications for individual privacy. The primary objective is to demonstrate\nthe capabilities of advanced AI tools, specifically a GPT-4 based model named\n\"Dr. Watson,\" in identifying and potentially compromising geographic privacy\nthrough online shared content. We developed \"Dr. Watson\" to analyze and extract\ngeographic information from publicly available data sources. The study involved\nfive experimental cases, each offering different perspectives on the tool's\napplication in extracting precise location data from partial images and social\nmedia content. The experiments revealed that \"Dr. Watson\" could successfully\nidentify specific geographic details, thereby exposing the vulnerabilities in\ncurrent geo-privacy measures. These findings underscore the ease with which\ngeographic information can be unintentionally disclosed. The paper concludes\nwith a discussion on the broader implications of these findings for individuals\nand the community at large. It emphasizes the urgency for enhanced awareness\nand protective measures against geo-privacy leakage in the era of advanced AI\nand widespread social media usage.\n","authors":["Yifan Yang","Yixian Zhang","Daoyang Li","Shuju Sun","Junhong Duan","Junzhou He","Qingyang Wu","Hao Liu"],"pdf_url":"https://arxiv.org/pdf/2311.13018v1.pdf","comment":"14 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.13016v1","updated":"2023-11-21T21:44:45Z","published":"2023-11-21T21:44:45Z","title":"Image-Based Soil Organic Carbon Remote Sensing from Satellite Images\n  with Fourier Neural Operator and Structural Similarity","summary":"  Soil organic carbon (SOC) sequestration is the transfer and storage of\natmospheric carbon dioxide in soils, which plays an important role in climate\nchange mitigation. SOC concentration can be improved by proper land use, thus\nit is beneficial if SOC can be estimated at a regional or global scale. As\nmultispectral satellite data can provide SOC-related information such as\nvegetation and soil properties at a global scale, estimation of SOC through\nsatellite data has been explored as an alternative to manual soil sampling.\nAlthough existing studies show promising results, they are mainly based on\npixel-based approaches with traditional machine learning methods, and\nconvolutional neural networks (CNNs) are uncommon. To study the use of CNNs on\nSOC remote sensing, here we propose the FNO-DenseNet based on the Fourier\nneural operator (FNO). By combining the advantages of the FNO and DenseNet, the\nFNO-DenseNet outperformed the FNO in our experiments with hundreds of times\nfewer parameters. The FNO-DenseNet also outperformed a pixel-based random\nforest by 18% in the mean absolute percentage error.\n","authors":["Ken C. L. Wong","Levente Klein","Ademir Ferreira da Silva","Hongzhi Wang","Jitendra Singh","Tanveer Syeda-Mahmood"],"pdf_url":"https://arxiv.org/pdf/2311.13016v1.pdf","comment":"This paper was accepted by the 2023 IEEE International Geoscience and\n  Remote Sensing Symposium (IGARSS 2023)"},{"id":"http://arxiv.org/abs/2311.13009v1","updated":"2023-11-21T21:36:09Z","published":"2023-11-21T21:36:09Z","title":"3D Compression Using Neural Fields","summary":"  Neural Fields (NFs) have gained momentum as a tool for compressing various\ndata modalities - e.g. images and videos. This work leverages previous advances\nand proposes a novel NF-based compression algorithm for 3D data. We derive two\nversions of our approach - one tailored to watertight shapes based on Signed\nDistance Fields (SDFs) and, more generally, one for arbitrary non-watertight\nshapes using Unsigned Distance Fields (UDFs). We demonstrate that our method\nexcels at geometry compression on 3D point clouds as well as meshes. Moreover,\nwe show that, due to the NF formulation, it is straightforward to extend our\ncompression algorithm to compress both geometry and attribute (e.g. color) of\n3D data.\n","authors":["Janis Postels","Yannick Strümpler","Klara Reichard","Luc Van Gool","Federico Tombari"],"pdf_url":"https://arxiv.org/pdf/2311.13009v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.01121v2","updated":"2023-11-21T21:04:24Z","published":"2023-07-03T15:51:39Z","title":"Artifacts Mapping: Multi-Modal Semantic Mapping for Object Detection and\n  3D Localization","summary":"  Geometric navigation is nowadays a well-established field of robotics and the\nresearch focus is shifting towards higher-level scene understanding, such as\nSemantic Mapping. When a robot needs to interact with its environment, it must\nbe able to comprehend the contextual information of its surroundings. This work\nfocuses on classifying and localising objects within a map, which is under\nconstruction (SLAM) or already built. To further explore this direction, we\npropose a framework that can autonomously detect and localize predefined\nobjects in a known environment using a multi-modal sensor fusion approach\n(combining RGB and depth data from an RGB-D camera and a lidar). The framework\nconsists of three key elements: understanding the environment through RGB data,\nestimating depth through multi-modal sensor fusion, and managing artifacts\n(i.e., filtering and stabilizing measurements). The experiments show that the\nproposed framework can accurately detect 98% of the objects in the real sample\nenvironment, without post-processing, while 85% and 80% of the objects were\nmapped using the single RGBD camera or RGB + lidar setup respectively. The\ncomparison with single-sensor (camera or lidar) experiments is performed to\nshow that sensor fusion allows the robot to accurately detect near and far\nobstacles, which would have been noisy or imprecise in a purely visual or\nlaser-based approach.\n","authors":["Federico Rollo","Gennaro Raiola","Andrea Zunino","Nikolaos Tsagarakis","Arash Ajoudani"],"pdf_url":"https://arxiv.org/pdf/2307.01121v2.pdf","comment":"Accepted to the 11th European Conference on Mobile Robots (ECMR) 2023"},{"id":"http://arxiv.org/abs/2311.12993v1","updated":"2023-11-21T21:00:42Z","published":"2023-11-21T21:00:42Z","title":"AI for Agriculture: the Comparison of Semantic Segmentation Methods for\n  Crop Mapping with Sentinel-2 Imagery","summary":"  Crop mapping is one of the most common tasks in artificial intelligence for\nagriculture due to higher food demands from a growing population and increased\nawareness of climate change. In case of vineyards, the texture is very\nimportant for crop segmentation: with higher resolution satellite imagery the\ntexture is easily detected by majority of state-of-the-art algorithms. However,\nthis task becomes increasingly more difficult as the resolution of satellite\nimagery decreases and the information about the texture becomes unavailable. In\nthis paper we aim to explore the main machine learning methods that can be used\nwith freely available satellite imagery and discuss how and when they can be\napplied for vineyard segmentation problem. We assess the effectiveness of\nvarious widely-used machine learning techniques and offer guidance on selecting\nthe most suitable model for specific scenarios.\n","authors":["Irina Korotkova","Natalia Efremova"],"pdf_url":"https://arxiv.org/pdf/2311.12993v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12992v1","updated":"2023-11-21T20:59:27Z","published":"2023-11-21T20:59:27Z","title":"FollowMe: a Robust Person Following Framework Based on Re-Identification\n  and Gestures","summary":"  Human-robot interaction (HRI) has become a crucial enabler in houses and\nindustries for facilitating operational flexibility. When it comes to mobile\ncollaborative robots, this flexibility can be further increased due to the\nautonomous mobility and navigation capacity of the robotic agents, expanding\ntheir workspace and consequently, the personalizable assistance they can\nprovide to the human operators. This however requires that the robot is capable\nof detecting and identifying the human counterpart in all stages of the\ncollaborative task, and in particular while following a human in crowded\nworkplaces. To respond to this need, we developed a unified perception and\nnavigation framework, which enables the robot to identify and follow a target\nperson using a combination of visual Re-Identification (Re-ID), hand gestures\ndetection, and collision-free navigation. The Re-ID module can autonomously\nlearn the features of a target person and use the acquired knowledge to\nvisually re-identify the target. The navigation stack is used to follow the\ntarget avoiding obstacles and other individuals in the environment. Experiments\nare conducted with few subjects in a laboratory setting where some unknown\ndynamic obstacles are introduced.\n","authors":["Federico Rollo","Andrea Zunino","Gennaro Raiola","Fabio Amadio","Arash Ajoudani","Nikolaos Tsagarakis"],"pdf_url":"https://arxiv.org/pdf/2311.12992v1.pdf","comment":"published in \"2023 IEEE International Conference on Advanced Robotics\n  and Its Social Impacts (ARSO)\""},{"id":"http://arxiv.org/abs/2311.11819v2","updated":"2023-11-21T20:45:51Z","published":"2023-11-20T14:55:40Z","title":"Generalized super-resolution 4D Flow MRI $\\unicode{x2013}$ using\n  ensemble learning to extend across the cardiovascular system","summary":"  4D Flow Magnetic Resonance Imaging (4D Flow MRI) is a non-invasive\nmeasurement technique capable of quantifying blood flow across the\ncardiovascular system. While practical use is limited by spatial resolution and\nimage noise, incorporation of trained super-resolution (SR) networks has\npotential to enhance image quality post-scan. However, these efforts have\npredominantly been restricted to narrowly defined cardiovascular domains, with\nlimited exploration of how SR performance extends across the cardiovascular\nsystem; a task aggravated by contrasting hemodynamic conditions apparent across\nthe cardiovasculature. The aim of our study was to explore the generalizability\nof SR 4D Flow MRI using a combination of heterogeneous training sets and\ndedicated ensemble learning. With synthetic training data generated across\nthree disparate domains (cardiac, aortic, cerebrovascular), varying\nconvolutional base and ensemble learners were evaluated as a function of domain\nand architecture, quantifying performance on both in-silico and acquired\nin-vivo data from the same three domains. Results show that both bagging and\nstacking ensembling enhance SR performance across domains, accurately\npredicting high-resolution velocities from low-resolution input data in-silico.\nLikewise, optimized networks successfully recover native resolution velocities\nfrom downsampled in-vivo data, as well as show qualitative potential in\ngenerating denoised SR-images from clinical level input data. In conclusion,\nour work presents a viable approach for generalized SR 4D Flow MRI, with\nensemble learning extending utility across various clinical areas of interest.\n","authors":["Leon Ericsson","Adam Hjalmarsson","Muhammad Usman Akbar","Edward Ferdian","Mia Bonini","Brandon Hardy","Jonas Schollenberger","Maria Aristova","Patrick Winter","Nicholas Burris","Alexander Fyrdahl","Andreas Sigfridsson","Susanne Schnell","C. Alberto Figueroa","David Nordsletten","Alistair A. Young","David Marlevi"],"pdf_url":"https://arxiv.org/pdf/2311.11819v2.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.12981v1","updated":"2023-11-21T20:33:17Z","published":"2023-11-21T20:33:17Z","title":"SD-NAE: Generating Natural Adversarial Examples with Stable Diffusion","summary":"  Robustly evaluating deep learning image classifiers is challenging due to\nsome limitations of standard datasets. Natural Adversarial Examples (NAEs),\narising naturally from the environment and capable of deceiving classifiers,\nare instrumental in identifying vulnerabilities in trained models. Existing\nworks collect such NAEs by filtering from a huge set of real images, a process\nthat is passive and lacks control. In this work, we propose to actively\nsynthesize NAEs with the state-of-the-art Stable Diffusion. Specifically, our\nmethod formulates a controlled optimization process, where we perturb the token\nembedding that corresponds to a specified class to synthesize NAEs. The\ngeneration is guided by the gradient of loss from the target classifier so that\nthe created image closely mimics the ground-truth class yet fools the\nclassifier. Named SD-NAE (Stable Diffusion for Natural Adversarial Examples),\nour innovative method is effective in producing valid and useful NAEs, which is\ndemonstrated through a meticulously designed experiment. Our work thereby\nprovides a valuable method for obtaining challenging evaluation data, which in\nturn can potentially advance the development of more robust deep learning\nmodels. Code is available at https://github.com/linyueqian/SD-NAE.\n","authors":["Yueqian Lin","Jingyang Zhang","Yiran Chen","Hai Li"],"pdf_url":"https://arxiv.org/pdf/2311.12981v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12967v1","updated":"2023-11-21T20:12:29Z","published":"2023-11-21T20:12:29Z","title":"Robustifying Generalizable Implicit Shape Networks with a Tunable\n  Non-Parametric Model","summary":"  Feedforward generalizable models for implicit shape reconstruction from\nunoriented point cloud present multiple advantages, including high performance\nand inference speed. However, they still suffer from generalization issues,\nranging from underfitting the input point cloud, to misrepresenting samples\noutside of the training data distribution, or with toplogies unseen at\ntraining. We propose here an efficient mechanism to remedy some of these\nlimitations at test time. We combine the inter-shape data prior of the network\nwith an intra-shape regularization prior of a Nystr\\\"om Kernel Ridge\nRegression, that we further adapt by fitting its hyperprameters to the current\nshape. The resulting shape function defined in a shape specific Reproducing\nKernel Hilbert Space benefits from desirable stability and efficiency\nproperties and grants a shape adaptive expressiveness-robustness trade-off. We\ndemonstrate the improvement obtained through our method with respect to\nbaselines and the state-of-the-art using synthetic and real data.\n","authors":["Amine Ouasfi","Adnane Boukhayma"],"pdf_url":"https://arxiv.org/pdf/2311.12967v1.pdf","comment":"NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.12956v1","updated":"2023-11-21T19:49:13Z","published":"2023-11-21T19:49:13Z","title":"Innovative Horizons in Aerial Imagery: LSKNet Meets DiffusionDet for\n  Advanced Object Detection","summary":"  In the realm of aerial image analysis, object detection plays a pivotal role,\nwith significant implications for areas such as remote sensing, urban planning,\nand disaster management. This study addresses the inherent challenges in this\ndomain, notably the detection of small objects, managing densely packed\nelements, and accounting for diverse orientations. We present an in-depth\nevaluation of an object detection model that integrates the Large Selective\nKernel Network (LSKNet)as its backbone with the DiffusionDet head, utilizing\nthe iSAID dataset for empirical analysis. Our approach encompasses the\nintroduction of novel methodologies and extensive ablation studies. These\nstudies critically assess various aspects such as loss functions, box\nregression techniques, and classification strategies to refine the model's\nprecision in object detection. The paper details the experimental application\nof the LSKNet backbone in synergy with the DiffusionDet heads, a combination\ntailored to meet the specific challenges in aerial image object detection. The\nfindings of this research indicate a substantial enhancement in the model's\nperformance, especially in the accuracy-time tradeoff. The proposed model\nachieves a mean average precision (MAP) of approximately 45.7%, which is a\nsignificant improvement, outperforming the RCNN model by 4.7% on the same\ndataset. This advancement underscores the effectiveness of the proposed\nmodifications and sets a new benchmark in aerial image analysis, paving the way\nfor more accurate and efficient object detection methodologies. The code is\npublicly available at https://github.com/SashaMatsun/LSKDiffDet\n","authors":["Ahmed Sharshar","Aleksandr Matsun"],"pdf_url":"https://arxiv.org/pdf/2311.12956v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05705v2","updated":"2023-11-21T19:24:43Z","published":"2023-06-09T06:54:58Z","title":"On the Challenges and Perspectives of Foundation Models for Medical\n  Image Analysis","summary":"  This article discusses the opportunities, applications and future directions\nof large-scale pre-trained models, i.e., foundation models, for analyzing\nmedical images. Medical foundation models have immense potential in solving a\nwide range of downstream tasks, as they can help to accelerate the development\nof accurate and robust models, reduce the large amounts of required labeled\ndata, preserve the privacy and confidentiality of patient data. Specifically,\nwe illustrate the \"spectrum\" of medical foundation models, ranging from general\nvision models, modality-specific models, to organ/task-specific models,\nhighlighting their challenges, opportunities and applications. We also discuss\nhow foundation models can be leveraged in downstream medical tasks to enhance\nthe accuracy and efficiency of medical image analysis, leading to more precise\ndiagnosis and treatment decisions.\n","authors":["Shaoting Zhang","Dimitris Metaxas"],"pdf_url":"https://arxiv.org/pdf/2306.05705v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12919v1","updated":"2023-11-21T18:43:07Z","published":"2023-11-21T18:43:07Z","title":"SPOT! Revisiting Video-Language Models for Event Understanding","summary":"  Understanding videos is an important research topic for multimodal learning.\nLeveraging large-scale datasets of web-crawled video-text pairs as weak\nsupervision has become a pre-training paradigm for learning joint\nrepresentations and showcased remarkable potential in video understanding\ntasks. However, videos can be multi-event and multi-grained, while these\nvideo-text pairs usually contain only broad-level video captions. This raises a\nquestion: with such weak supervision, can video representation in\nvideo-language models gain the ability to distinguish even factual\ndiscrepancies in textual description and understand fine-grained events? To\naddress this, we introduce SPOT Prober, to benchmark existing video-language\nmodels's capacities of distinguishing event-level discrepancies as an indicator\nof models' event understanding ability. Our approach involves extracting events\nas tuples (<Subject, Predicate, Object, Attribute, Timestamps>) from videos and\ngenerating false event tuples by manipulating tuple components systematically.\nWe reevaluate the existing video-language models with these positive and\nnegative captions and find they fail to distinguish most of the manipulated\nevents. Based on our findings, we propose to plug in these manipulated event\ncaptions as hard negative samples and find them effective in enhancing models\nfor event understanding.\n","authors":["Gengyuan Zhang","Jinhe Bi","Jindong Gu","Volker Tresp"],"pdf_url":"https://arxiv.org/pdf/2311.12919v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2311.12914v1","updated":"2023-11-21T17:55:46Z","published":"2023-11-21T17:55:46Z","title":"Attention Deficit is Ordered! Fooling Deformable Vision Transformers\n  with Collaborative Adversarial Patches","summary":"  The latest generation of transformer-based vision models have proven to be\nsuperior to Convolutional Neural Network (CNN)-based models across several\nvision tasks, largely attributed to their remarkable prowess in relation\nmodeling. Deformable vision transformers significantly reduce the quadratic\ncomplexity of modeling attention by using sparse attention structures, enabling\nthem to be used in larger scale applications such as multi-view vision systems.\nRecent work demonstrated adversarial attacks against transformers; we show that\nthese attacks do not transfer to deformable transformers due to their sparse\nattention structure. Specifically, attention in deformable transformers is\nmodeled using pointers to the most relevant other tokens. In this work, we\ncontribute for the first time adversarial attacks that manipulate the attention\nof deformable transformers, distracting them to focus on irrelevant parts of\nthe image. We also develop new collaborative attacks where a source patch\nmanipulates attention to point to a target patch that adversarially attacks the\nsystem. In our experiments, we find that only 1% patched area of the input\nfield can lead to 0% AP. We also show that the attacks provide substantial\nversatility to support different attacker scenarios because of their ability to\nredirect attention under the attacker control.\n","authors":["Quazi Mishkatul Alam","Bilel Tarchoun","Ihsen Alouani","Nael Abu-Ghazaleh"],"pdf_url":"https://arxiv.org/pdf/2311.12914v1.pdf","comment":"9 pages, 10 figures"},{"id":"http://arxiv.org/abs/2311.12912v1","updated":"2023-11-21T17:27:20Z","published":"2023-11-21T17:27:20Z","title":"Q-Seg: Quantum Annealing-based Unsupervised Image Segmentation","summary":"  In this study, we present Q-Seg, a novel unsupervised image segmentation\nmethod based on quantum annealing, tailored for existing quantum hardware. We\nformulate the pixel-wise segmentation problem, which assimilates spectral and\nspatial information of the image, as a graph-cut optimization task. Our method\nefficiently leverages the interconnected qubit topology of the D-Wave Advantage\ndevice, offering superior scalability over existing quantum approaches and\noutperforming state-of-the-art classical methods. Our empirical evaluations on\nsynthetic datasets reveal that Q-Seg offers better runtime performance against\nthe classical optimizer Gurobi. Furthermore, we evaluate our method on\nsegmentation of Earth Observation images, an area of application where the\namount of labeled data is usually very limited. In this case, Q-Seg\ndemonstrates near-optimal results in flood mapping detection with respect to\nclassical supervised state-of-the-art machine learning methods. Also, Q-Seg\nprovides enhanced segmentation for forest coverage compared to existing\nannotated masks. Thus, Q-Seg emerges as a viable alternative for real-world\napplications using available quantum hardware, particularly in scenarios where\nthe lack of labeled data and computational runtime are critical.\n","authors":["Supreeth Mysore Venkatesh","Antonio Macaluso","Marlon Nuske","Matthias Klusch","Andreas Dengel"],"pdf_url":"https://arxiv.org/pdf/2311.12912v1.pdf","comment":"12 pages, 9 figures, 1 table"},{"id":"http://arxiv.org/abs/2311.12908v1","updated":"2023-11-21T15:24:05Z","published":"2023-11-21T15:24:05Z","title":"Diffusion Model Alignment Using Direct Preference Optimization","summary":"  Large language models (LLMs) are fine-tuned using human comparison data with\nReinforcement Learning from Human Feedback (RLHF) methods to make them better\naligned with users' preferences. In contrast to LLMs, human preference learning\nhas not been widely explored in text-to-image diffusion models; the best\nexisting approach is to fine-tune a pretrained model using carefully curated\nhigh quality images and captions to improve visual appeal and text alignment.\nWe propose Diffusion-DPO, a method to align diffusion models to human\npreferences by directly optimizing on human comparison data. Diffusion-DPO is\nadapted from the recently developed Direct Preference Optimization (DPO), a\nsimpler alternative to RLHF which directly optimizes a policy that best\nsatisfies human preferences under a classification objective. We re-formulate\nDPO to account for a diffusion model notion of likelihood, utilizing the\nevidence lower bound to derive a differentiable objective. Using the Pick-a-Pic\ndataset of 851K crowdsourced pairwise preferences, we fine-tune the base model\nof the state-of-the-art Stable Diffusion XL (SDXL)-1.0 model with\nDiffusion-DPO. Our fine-tuned base model significantly outperforms both base\nSDXL-1.0 and the larger SDXL-1.0 model consisting of an additional refinement\nmodel in human evaluation, improving visual appeal and prompt alignment. We\nalso develop a variant that uses AI feedback and has comparable performance to\ntraining on human preferences, opening the door for scaling of diffusion model\nalignment methods.\n","authors":["Bram Wallace","Meihua Dang","Rafael Rafailov","Linqi Zhou","Aaron Lou","Senthil Purushwalkam","Stefano Ermon","Caiming Xiong","Shafiq Joty","Nikhil Naik"],"pdf_url":"https://arxiv.org/pdf/2311.12908v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2205.10852v6","updated":"2023-11-21T16:36:43Z","published":"2022-05-22T15:30:18Z","title":"Relphormer: Relational Graph Transformer for Knowledge Graph\n  Representations","summary":"  Transformers have achieved remarkable performance in widespread fields,\nincluding natural language processing, computer vision and graph mining.\nHowever, vanilla Transformer architectures have not yielded promising\nimprovements in the Knowledge Graph (KG) representations, where the\ntranslational distance paradigm dominates this area. Note that vanilla\nTransformer architectures struggle to capture the intrinsically heterogeneous\nstructural and semantic information of knowledge graphs. To this end, we\npropose a new variant of Transformer for knowledge graph representations dubbed\nRelphormer. Specifically, we introduce Triple2Seq which can dynamically sample\ncontextualized sub-graph sequences as the input to alleviate the heterogeneity\nissue. We propose a novel structure-enhanced self-attention mechanism to encode\nthe relational information and keep the semantic information within entities\nand relations. Moreover, we utilize masked knowledge modeling for general\nknowledge graph representation learning, which can be applied to various\nKG-based tasks including knowledge graph completion, question answering, and\nrecommendation. Experimental results on six datasets show that Relphormer can\nobtain better performance compared with baselines. Code is available in\nhttps://github.com/zjunlp/Relphormer.\n","authors":["Zhen Bi","Siyuan Cheng","Jing Chen","Xiaozhuan Liang","Feiyu Xiong","Ningyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2205.10852v6.pdf","comment":"Neurocomputing 2023"},{"id":"http://arxiv.org/abs/2311.12474v1","updated":"2023-11-21T09:36:11Z","published":"2023-11-21T09:36:11Z","title":"CSMeD: Bridging the Dataset Gap in Automated Citation Screening for\n  Systematic Literature Reviews","summary":"  Systematic literature reviews (SLRs) play an essential role in summarising,\nsynthesising and validating scientific evidence. In recent years, there has\nbeen a growing interest in using machine learning techniques to automate the\nidentification of relevant studies for SLRs. However, the lack of standardised\nevaluation datasets makes comparing the performance of such automated\nliterature screening systems difficult. In this paper, we analyse the citation\nscreening evaluation datasets, revealing that many of the available datasets\nare either too small, suffer from data leakage or have limited applicability to\nsystems treating automated literature screening as a classification task, as\nopposed to, for example, a retrieval or question-answering task. To address\nthese challenges, we introduce CSMeD, a meta-dataset consolidating nine\npublicly released collections, providing unified access to 325 SLRs from the\nfields of medicine and computer science. CSMeD serves as a comprehensive\nresource for training and evaluating the performance of automated citation\nscreening models. Additionally, we introduce CSMeD-FT, a new dataset designed\nexplicitly for evaluating the full text publication screening task. To\ndemonstrate the utility of CSMeD, we conduct experiments and establish\nbaselines on new datasets.\n","authors":["Wojciech Kusa","Oscar E. Mendoza","Matthias Samwald","Petr Knoth","Allan Hanbury"],"pdf_url":"https://arxiv.org/pdf/2311.12474v1.pdf","comment":"Accepted at NeurIPS 2023 Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2311.12404v1","updated":"2023-11-21T07:43:50Z","published":"2023-11-21T07:43:50Z","title":"InterPrompt: Interpretable Prompting for Interrelated Interpersonal Risk\n  Factors in Reddit Posts","summary":"  Mental health professionals and clinicians have observed the upsurge of\nmental disorders due to Interpersonal Risk Factors (IRFs). To simulate the\nhuman-in-the-loop triaging scenario for early detection of mental health\ndisorders, we recognized textual indications to ascertain these IRFs : Thwarted\nBelongingness (TBe) and Perceived Burdensomeness (PBu) within personal\nnarratives. In light of this, we use N-shot learning with GPT-3 model on the\nIRF dataset, and underscored the importance of fine-tuning GPT-3 model to\nincorporate the context-specific sensitivity and the interconnectedness of\ntextual cues that represent both IRFs.\n  In this paper, we introduce an Interpretable Prompting (InterPrompt)} method\nto boost the attention mechanism by fine-tuning the GPT-3 model. This allows a\nmore sophisticated level of language modification by adjusting the pre-trained\nweights. Our model learns to detect usual patterns and underlying connections\nacross both the IRFs, which leads to better system-level explainability and\ntrustworthiness. The results of our research demonstrate that all four variants\nof GPT-3 model, when fine-tuned with InterPrompt, perform considerably better\nas compared to the baseline methods, both in terms of classification and\nexplanation generation.\n","authors":["MSVPJ Sathvik","Surjodeep Sarkar","Chandni Saxena","Sunghwan Sohn","Muskan Garg"],"pdf_url":"https://arxiv.org/pdf/2311.12404v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2311.12389v1","updated":"2023-11-21T07:01:05Z","published":"2023-11-21T07:01:05Z","title":"Linear-time online visibility graph transformation algorithm: for both\n  natural and horizontal visibility criteria","summary":"  Visibility graph (VG) transformation is a technique used to convert a time\nseries into a graph based on specific visibility criteria. It has attracted\nincreasing interest in the fields of time series analysis, forecasting, and\nclassification. Optimizing the VG transformation algorithm to accelerate the\nprocess is a critical aspect of VG-related research, as it enhances the\napplicability of VG transformation in latency-sensitive areas and conserves\ncomputational resources. In the real world, many time series are presented in\nthe form of data streams. Despite the proposal of the concept of VG's online\nfunctionality, previous studies have not thoroughly explored the acceleration\nof VG transformation by leveraging the characteristics of data streams. In this\npaper, we propose that an efficient online VG algorithm should adhere to two\ncriteria and develop a linear-time method, termed the LOT framework, for both\nnatural and horizontal visibility graph transformations in data stream\nscenarios. Experiments are conducted on two datasets, comparing our approach\nwith five existing methods as baselines. The results demonstrate the validity\nand promising computational efficiency of our framework.\n","authors":["Yusheng Huang","Yong Deng"],"pdf_url":"https://arxiv.org/pdf/2311.12389v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.14884v2","updated":"2023-11-21T05:28:30Z","published":"2023-10-23T12:53:22Z","title":"Budgeted Embedding Table For Recommender Systems","summary":"  At the heart of contemporary recommender systems (RSs) are latent factor\nmodels that provide quality recommendation experience to users. These models\nuse embedding vectors, which are typically of a uniform and fixed size, to\nrepresent users and items. As the number of users and items continues to grow,\nthis design becomes inefficient and hard to scale. Recent lightweight embedding\nmethods have enabled different users and items to have diverse embedding sizes,\nbut are commonly subject to two major drawbacks. Firstly, they limit the\nembedding size search to optimizing a heuristic balancing the recommendation\nquality and the memory complexity, where the trade-off coefficient needs to be\nmanually tuned for every memory budget requested. The implicitly enforced\nmemory complexity term can even fail to cap the parameter usage, making the\nresultant embedding table fail to meet the memory budget strictly. Secondly,\nmost solutions, especially reinforcement learning based ones derive and\noptimize the embedding size for each each user/item on an instance-by-instance\nbasis, which impedes the search efficiency. In this paper, we propose Budgeted\nEmbedding Table (BET), a novel method that generates table-level actions (i.e.,\nembedding sizes for all users and items) that is guaranteed to meet\npre-specified memory budgets. Furthermore, by leveraging a set-based action\nformulation and engaging set representation learning, we present an innovative\naction search strategy powered by an action fitness predictor that efficiently\nevaluates each table-level action. Experiments have shown state-of-the-art\nperformance on two real-world datasets when BET is paired with three popular\nrecommender models under different memory budgets.\n","authors":["Yunke Qu","Tong Chen","Quoc Viet Hung Nguyen","Hongzhi Yin"],"pdf_url":"https://arxiv.org/pdf/2310.14884v2.pdf","comment":"Accepted by WSDM 2024"},{"id":"http://arxiv.org/abs/2311.12355v1","updated":"2023-11-21T05:15:56Z","published":"2023-11-21T05:15:56Z","title":"Utilizing Language Models for Tour Itinerary Recommendation","summary":"  Tour itinerary recommendation involves planning a sequence of relevant\nPoint-of-Interest (POIs), which combines challenges from the fields of both\nOperations Research (OR) and Recommendation Systems (RS). As an OR problem,\nthere is the need to maximize a certain utility (e.g., popularity of POIs in\nthe tour) while adhering to some constraints (e.g., maximum time for the tour).\nAs a RS problem, it is heavily related to problem or filtering or ranking a\nsubset of POIs that are relevant to a user and recommending it as part of an\nitinerary. In this paper, we explore the use of language models for the task of\ntour itinerary recommendation and planning. This task has the unique\nrequirement of recommending personalized POIs relevant to users and planning\nthese POIs as an itinerary that satisfies various constraints. We discuss some\napproaches in this area, such as using word embedding techniques like Word2Vec\nand GloVe for learning POI embeddings and transformer-based techniques like\nBERT for generating\n  itineraries.\n","authors":["Ngai Lam Ho","Kwan Hui Lim"],"pdf_url":"https://arxiv.org/pdf/2311.12355v1.pdf","comment":"PMAI23 @IJCAI 2023 2nd International Workshop on Process Management\n  in the AI era"},{"id":"http://arxiv.org/abs/2304.07763v5","updated":"2023-11-21T05:03:06Z","published":"2023-04-16T12:30:33Z","title":"Meta-optimized Contrastive Learning for Sequential Recommendation","summary":"  Contrastive Learning (CL) performances as a rising approach to address the\nchallenge of sparse and noisy recommendation data. Although having achieved\npromising results, most existing CL methods only perform either hand-crafted\ndata or model augmentation for generating contrastive pairs to find a proper\naugmentation operation for different datasets, which makes the model hard to\ngeneralize. Additionally, since insufficient input data may lead the encoder to\nlearn collapsed embeddings, these CL methods expect a relatively large number\nof training data (e.g., large batch size or memory bank) to contrast. However,\nnot all contrastive pairs are always informative and discriminative enough for\nthe training processing. Therefore, a more general CL-based recommendation\nmodel called Meta-optimized Contrastive Learning for sequential Recommendation\n(MCLRec) is proposed in this work. By applying both data augmentation and\nlearnable model augmentation operations, this work innovates the standard CL\nframework by contrasting data and model augmented views for adaptively\ncapturing the informative features hidden in stochastic data augmentation.\nMoreover, MCLRec utilizes a meta-learning manner to guide the updating of the\nmodel augmenters, which helps to improve the quality of contrastive pairs\nwithout enlarging the amount of input data. Finally, a contrastive\nregularization term is considered to encourage the augmentation model to\ngenerate more informative augmented views and avoid too similar contrastive\npairs within the meta updating. The experimental results on commonly used\ndatasets validate the effectiveness of MCLRec.\n","authors":["Xiuyuan Qin","Huanhuan Yuan","Pengpeng Zhao","Junhua Fang","Fuzhen Zhuang","Guanfeng Liu","Victor Sheng"],"pdf_url":"https://arxiv.org/pdf/2304.07763v5.pdf","comment":"11 Pages,8 figures,SIGIR2023"},{"id":"http://arxiv.org/abs/2311.12338v1","updated":"2023-11-21T04:14:09Z","published":"2023-11-21T04:14:09Z","title":"A Survey on Large Language Models for Personalized and Explainable\n  Recommendations","summary":"  In recent years, Recommender Systems(RS) have witnessed a transformative\nshift with the advent of Large Language Models(LLMs) in the field of Natural\nLanguage Processing(NLP). These models such as OpenAI's GPT-3.5/4, Llama from\nMeta, have demonstrated unprecedented capabilities in understanding and\ngenerating human-like text. This has led to a paradigm shift in the realm of\npersonalized and explainable recommendations, as LLMs offer a versatile toolset\nfor processing vast amounts of textual data to enhance user experiences. To\nprovide a comprehensive understanding of the existing LLM-based recommendation\nsystems, this survey aims to analyze how RS can benefit from LLM-based\nmethodologies. Furthermore, we describe major challenges in Personalized\nExplanation Generating(PEG) tasks, which are cold-start problems, unfairness\nand bias problems in RS.\n","authors":["Junyi Chen"],"pdf_url":"https://arxiv.org/pdf/2311.12338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12329v1","updated":"2023-11-21T03:42:15Z","published":"2023-11-21T03:42:15Z","title":"Graph Neural Ordinary Differential Equations-based method for\n  Collaborative Filtering","summary":"  Graph Convolution Networks (GCNs) are widely considered state-of-the-art for\ncollaborative filtering. Although several GCN-based methods have been proposed\nand achieved state-of-the-art performance in various tasks, they can be\ncomputationally expensive and time-consuming to train if too many layers are\ncreated. However, since the linear GCN model can be interpreted as a\ndifferential equation, it is possible to transfer it to an ODE problem. This\ninspired us to address the computational limitations of GCN-based models by\ndesigning a simple and efficient NODE-based model that can skip some GCN layers\nto reach the final state, thus avoiding the need to create many layers. In this\nwork, we propose a Graph Neural Ordinary Differential Equation-based method for\nCollaborative Filtering (GODE-CF). This method estimates the final embedding by\nutilizing the information captured by one or two GCN layers. To validate our\napproach, we conducted experiments on multiple datasets. The results\ndemonstrate that our model outperforms competitive baselines, including\nGCN-based models and other state-of-the-art CF methods. Notably, our proposed\nGODE-CF model has several advantages over traditional GCN-based models. It is\nsimple, efficient, and has a fast training time, making it a practical choice\nfor real-world situations.\n","authors":["Ke Xu","Yuanjie Zhu","Weizhi Zhang","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2311.12329v1.pdf","comment":"Accepted by ICDM 2023"},{"id":"http://arxiv.org/abs/2311.03488v3","updated":"2023-11-21T03:08:37Z","published":"2023-11-06T19:52:55Z","title":"Multi-Resolution Diffusion for Privacy-Sensitive Recommender Systems","summary":"  While recommender systems have become an integral component of the Web\nexperience, their heavy reliance on user data raises privacy and security\nconcerns. Substituting user data with synthetic data can address these\nconcerns, but accurately replicating these real-world datasets has been a\nnotoriously challenging problem. Recent advancements in generative AI have\ndemonstrated the impressive capabilities of diffusion models in generating\nrealistic data across various domains. In this work we introduce a Score-based\nDiffusion Recommendation Module (SDRM), which captures the intricate patterns\nof real-world datasets required for training highly accurate recommender\nsystems. SDRM allows for the generation of synthetic data that can replace\nexisting datasets to preserve user privacy, or augment existing datasets to\naddress excessive data sparsity. Our method outperforms competing baselines\nsuch as generative adversarial networks, variational autoencoders, and recently\nproposed diffusion models in synthesizing various datasets to replace or\naugment the original data by an average improvement of 4.30% in Recall@$k$ and\n4.65% in NDCG@$k$.\n","authors":["Derek Lilienthal","Paul Mello","Magdalini Eirinaki","Stas Tiomkin"],"pdf_url":"https://arxiv.org/pdf/2311.03488v3.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.12287v1","updated":"2023-11-21T02:01:01Z","published":"2023-11-21T02:01:01Z","title":"Adapting LLMs for Efficient, Personalized Information Retrieval: Methods\n  and Implications","summary":"  The advent of Large Language Models (LLMs) heralds a pivotal shift in online\nuser interactions with information. Traditional Information Retrieval (IR)\nsystems primarily relied on query-document matching, whereas LLMs excel in\ncomprehending and generating human-like text, thereby enriching the IR\nexperience significantly. While LLMs are often associated with chatbot\nfunctionalities, this paper extends the discussion to their explicit\napplication in information retrieval. We explore methodologies to optimize the\nretrieval process, select optimal models, and effectively scale and orchestrate\nLLMs, aiming for cost-efficiency and enhanced result accuracy. A notable\nchallenge, model hallucination-where the model yields inaccurate or\nmisinterpreted data-is addressed alongside other model-specific hurdles. Our\ndiscourse extends to crucial considerations including user privacy, data\noptimization, and the necessity for system clarity and interpretability.\nThrough a comprehensive examination, we unveil not only innovative strategies\nfor integrating Language Models (LLMs) with Information Retrieval (IR) systems,\nbut also the consequential considerations that underline the need for a\nbalanced approach aligned with user-centric principles.\n","authors":["Samira Ghodratnama","Mehrdad Zakershahrak"],"pdf_url":"https://arxiv.org/pdf/2311.12287v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12257v1","updated":"2023-11-21T00:37:47Z","published":"2023-11-21T00:37:47Z","title":"Equipping Pretrained Unconditional Music Transformers with Instrument\n  and Genre Controls","summary":"  The ''pretraining-and-finetuning'' paradigm has become a norm for training\ndomain-specific models in natural language processing and computer vision. In\nthis work, we aim to examine this paradigm for symbolic music generation\nthrough leveraging the largest ever symbolic music dataset sourced from the\nMuseScore forum. We first pretrain a large unconditional transformer model\nusing 1.5 million songs. We then propose a simple technique to equip this\npretrained unconditional music transformer model with instrument and genre\ncontrols by finetuning the model with additional control tokens. Our proposed\nrepresentation offers improved high-level controllability and expressiveness\nagainst two existing representations. The experimental results show that the\nproposed model can successfully generate music with user-specified instruments\nand genre. In a subjective listening test, the proposed model outperforms the\npretrained baseline model in terms of coherence, harmony, arrangement and\noverall quality.\n","authors":["Weihan Xu","Julian McAuley","Shlomo Dubnov","Hao-Wen Dong"],"pdf_url":"https://arxiv.org/pdf/2311.12257v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.08350v2","updated":"2023-11-21T22:09:27Z","published":"2023-11-14T17:48:27Z","title":"ChoralSynth: Synthetic Dataset of Choral Singing","summary":"  Choral singing, a widely practiced form of ensemble singing, lacks\ncomprehensive datasets in the realm of Music Information Retrieval (MIR)\nresearch, due to challenges arising from the requirement to curate multitrack\nrecordings. To address this, we devised a novel methodology, leveraging\nstate-of-the-art synthesizers to create and curate quality renditions. The\nscores were sourced from Choral Public Domain Library(CPDL). This work is done\nin collaboration with a diverse team of musicians, software engineers and\nresearchers. The resulting dataset, complete with its associated metadata, and\nmethodology is released as part of this work, opening up new avenues for\nexploration and advancement in the field of singing voice research.\n","authors":["Jyoti Narang","Viviana De La Vega","Xavier Lizarraga","Oscar Mayor","Hector Parra","Jordi Janer","Xavier Serra"],"pdf_url":"https://arxiv.org/pdf/2311.08350v2.pdf","comment":"Dataset Link: https://doi.org/10.5281/zenodo.10137883"},{"id":"http://arxiv.org/abs/2311.12955v1","updated":"2023-11-21T19:41:46Z","published":"2023-11-21T19:41:46Z","title":"Don't forget private retrieval: distributed private similarity search\n  for large language models","summary":"  While the flexible capabilities of large language models (LLMs) allow them to\nanswer a range of queries based on existing learned knowledge, information\nretrieval to augment generation is an important tool to allow LLMs to answer\nquestions on information not included in pre-training data. Such private\ninformation is increasingly being generated in a wide array of distributed\ncontexts by organizations and individuals. Performing such information\nretrieval using neural embeddings of queries and documents always leaked\ninformation about queries and database content unless both were stored locally.\nWe present Private Retrieval Augmented Generation (PRAG), an approach that uses\nmulti-party computation (MPC) to securely transmit queries to a distributed set\nof servers containing a privately constructed database to return top-k and\napproximate top-k documents. This is a first-of-its-kind approach to dense\ninformation retrieval that ensures no server observes a client's query or can\nsee the database content. The approach introduces a novel MPC friendly protocol\nfor inverted file approximate search (IVF) that allows for fast document search\nover distributed and private data in sublinear communication complexity. This\nwork presents new avenues through which data for use in LLMs can be accessed\nand used without needing to centralize or forgo privacy.\n","authors":["Guy Zyskind","Tobin South","Alex Pentland"],"pdf_url":"https://arxiv.org/pdf/2311.12955v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12894v1","updated":"2023-11-21T08:20:38Z","published":"2023-11-21T08:20:38Z","title":"Attribute-Aware Deep Hashing with Self-Consistency for Large-Scale\n  Fine-Grained Image Retrieval","summary":"  Our work focuses on tackling large-scale fine-grained image retrieval as\nranking the images depicting the concept of interests (i.e., the same\nsub-category labels) highest based on the fine-grained details in the query. It\nis desirable to alleviate the challenges of both fine-grained nature of small\ninter-class variations with large intra-class variations and explosive growth\nof fine-grained data for such a practical task. In this paper, we propose\nattribute-aware hashing networks with self-consistency for generating\nattribute-aware hash codes to not only make the retrieval process efficient,\nbut also establish explicit correspondences between hash codes and visual\nattributes. Specifically, based on the captured visual representations by\nattention, we develop an encoder-decoder structure network of a reconstruction\ntask to unsupervisedly distill high-level attribute-specific vectors from the\nappearance-specific visual representations without attribute annotations. Our\nmodels are also equipped with a feature decorrelation constraint upon these\nattribute vectors to strengthen their representative abilities. Then, driven by\npreserving original entities' similarity, the required hash codes can be\ngenerated from these attribute-specific vectors and thus become\nattribute-aware. Furthermore, to combat simplicity bias in deep hashing, we\nconsider the model design from the perspective of the self-consistency\nprinciple and propose to further enhance models' self-consistency by equipping\nan additional image reconstruction path. Comprehensive quantitative experiments\nunder diverse empirical settings on six fine-grained retrieval datasets and two\ngeneric retrieval datasets show the superiority of our models over competing\nmethods.\n","authors":["Xiu-Shen Wei","Yang Shen","Xuhao Sun","Peng Wang","Yuxin Peng"],"pdf_url":"https://arxiv.org/pdf/2311.12894v1.pdf","comment":"Accepted by IEEE TPAMI"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2311.12796v1","updated":"2023-11-21T18:59:58Z","published":"2023-11-21T18:59:58Z","title":"Physics-guided Shape-from-Template: Monocular Video Perception through\n  Neural Surrogate Models","summary":"  3D reconstruction of dynamic scenes is a long-standing problem in computer\ngraphics and increasingly difficult the less information is available.\nShape-from-Template (SfT) methods aim to reconstruct a template-based geometry\nfrom RGB images or video sequences, often leveraging just a single monocular\ncamera without depth information, such as regular smartphone recordings.\nUnfortunately, existing reconstruction methods are either unphysical and noisy\nor slow in optimization. To solve this problem, we propose a novel SfT\nreconstruction algorithm for cloth using a pre-trained neural surrogate model\nthat is fast to evaluate, stable, and produces smooth reconstructions due to a\nregularizing physics simulation. Differentiable rendering of the simulated mesh\nenables pixel-wise comparisons between the reconstruction and a target video\nsequence that can be used for a gradient-based optimization procedure to\nextract not only shape information but also physical parameters such as\nstretching, shearing, or bending stiffness of the cloth. This allows to retain\na precise, stable, and smooth reconstructed geometry while reducing the runtime\nby a factor of 400-500 compared to $\\phi$-SfT, a state-of-the-art physics-based\nSfT approach.\n","authors":["David Stotko","Nils Wandel","Reinhard Klein"],"pdf_url":"https://arxiv.org/pdf/2311.12796v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.10793v5","updated":"2023-11-21T18:51:56Z","published":"2022-02-22T10:25:59Z","title":"PyTorch Geometric Signed Directed: A Software Package on Graph Neural\n  Networks for Signed and Directed Graphs","summary":"  Networks are ubiquitous in many real-world applications (e.g., social\nnetworks encoding trust/distrust relationships, correlation networks arising\nfrom time series data). While many networks are signed or directed, or both,\nthere is a lack of unified software packages on graph neural networks (GNNs)\nspecially designed for signed and directed networks. In this paper, we present\nPyTorch Geometric Signed Directed (PyGSD), a software package which fills this\ngap. Along the way, we evaluate the implemented methods with experiments with a\nview to providing insights into which method to choose for a given task. The\ndeep learning framework consists of easy-to-use GNN models, synthetic and\nreal-world data, as well as task-specific evaluation metrics and loss functions\nfor signed and directed networks. As an extension library for PyG, our proposed\nsoftware is maintained with open-source releases, detailed documentation,\ncontinuous integration, unit tests and code coverage checks. The GitHub\nrepository of the library is\nhttps://github.com/SherylHYX/pytorch_geometric_signed_directed.\n","authors":["Yixuan He","Xitong Zhang","Junjie Huang","Benedek Rozemberczki","Mihai Cucuringu","Gesine Reinert"],"pdf_url":"https://arxiv.org/pdf/2202.10793v5.pdf","comment":"Accepted by LoG 2023. 27 pages in total"},{"id":"http://arxiv.org/abs/2311.12786v1","updated":"2023-11-21T18:51:04Z","published":"2023-11-21T18:51:04Z","title":"Mechanistically analyzing the effects of fine-tuning on procedurally\n  defined tasks","summary":"  Fine-tuning large pre-trained models has become the de facto strategy for\ndeveloping both task-specific and general-purpose machine learning systems,\nincluding developing models that are safe to deploy. Despite its clear\nimportance, there has been minimal work that explains how fine-tuning alters\nthe underlying capabilities learned by a model during pretraining: does\nfine-tuning yield entirely novel capabilities or does it just modulate existing\nones? We address this question empirically in synthetic, controlled settings\nwhere we can use mechanistic interpretability tools (e.g., network pruning and\nprobing) to understand how the model's underlying capabilities are changing. We\nperform an extensive analysis of the effects of fine-tuning in these settings,\nand show that: (i) fine-tuning rarely alters the underlying model capabilities;\n(ii) a minimal transformation, which we call a 'wrapper', is typically learned\non top of the underlying model capabilities, creating the illusion that they\nhave been modified; and (iii) further fine-tuning on a task where such hidden\ncapabilities are relevant leads to sample-efficient 'revival' of the\ncapability, i.e., the model begins reusing these capability after only a few\ngradient steps. This indicates that practitioners can unintentionally remove a\nmodel's safety wrapper merely by fine-tuning it on a, e.g., superficially\nunrelated, downstream task. We additionally perform analysis on language models\ntrained on the TinyStories dataset to support our claims in a more realistic\nsetup.\n","authors":["Samyak Jain","Robert Kirk","Ekdeep Singh Lubana","Robert P. Dick","Hidenori Tanaka","Edward Grefenstette","Tim Rocktäschel","David Scott Krueger"],"pdf_url":"https://arxiv.org/pdf/2311.12786v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.01331v2","updated":"2023-11-21T18:50:49Z","published":"2023-11-02T15:41:57Z","title":"Offline Imitation from Observation via Primal Wasserstein State\n  Occupancy Matching","summary":"  In real-world scenarios, arbitrary interactions with the environment can\noften be costly, and actions of expert demonstrations are not always available.\nTo reduce the need for both, Offline Learning from Observations (LfO) is\nextensively studied, where the agent learns to solve a task with only expert\nstates and \\textit{task-agnostic} non-expert state-action pairs. The\nstate-of-the-art DIstribution Correction Estimation (DICE) methods minimize the\nstate occupancy divergence between the learner and expert policies. However,\nthey are limited to either $f$-divergences (KL and $\\chi^2$) or Wasserstein\ndistance with Rubinstein duality, the latter of which constrains the underlying\ndistance metric crucial to the performance of Wasserstein-based solutions. To\naddress this problem, we propose Primal Wasserstein DICE (PW-DICE), which\nminimizes the primal Wasserstein distance between the expert and learner state\noccupancies with a pessimistic regularizer and leverages a contrastively\nlearned distance as the underlying metric for the Wasserstein distance.\nTheoretically, we prove that our framework is a generalization of the\nstate-of-the-art, SMODICE, and unifies $f$-divergence and Wasserstein\nminimization. Empirically, we find that PW-DICE improves upon several\nstate-of-the-art methods on multiple testbeds.\n","authors":["Kai Yan","Alexander G. Schwing","Yu-xiong Wang"],"pdf_url":"https://arxiv.org/pdf/2311.01331v2.pdf","comment":"23 pages. Accepted to the Optimal Transport and Machine Learning\n  Workshop at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.12784v1","updated":"2023-11-21T18:50:38Z","published":"2023-11-21T18:50:38Z","title":"Optimality in Mean Estimation: Beyond Worst-Case, Beyond Sub-Gaussian,\n  and Beyond $1+α$ Moments","summary":"  There is growing interest in improving our algorithmic understanding of\nfundamental statistical problems such as mean estimation, driven by the goal of\nunderstanding the limits of what we can extract from valuable data. The state\nof the art results for mean estimation in $\\mathbb{R}$ are 1) the optimal\nsub-Gaussian mean estimator by [LV22], with the tight sub-Gaussian constant for\nall distributions with finite but unknown variance, and 2) the analysis of the\nmedian-of-means algorithm by [BCL13] and a lower bound by [DLLO16],\ncharacterizing the big-O optimal errors for distributions for which only a\n$1+\\alpha$ moment exists for $\\alpha \\in (0,1)$. Both results, however, are\noptimal only in the worst case. We initiate the fine-grained study of the mean\nestimation problem: Can algorithms leverage useful features of the input\ndistribution to beat the sub-Gaussian rate, without explicit knowledge of such\nfeatures?\n  We resolve this question with an unexpectedly nuanced answer: \"Yes in limited\nregimes, but in general no\". For any distribution $p$ with a finite mean, we\nconstruct a distribution $q$ whose mean is well-separated from $p$'s, yet $p$\nand $q$ are not distinguishable with high probability, and $q$ further\npreserves $p$'s moments up to constants. The main consequence is that no\nreasonable estimator can asymptotically achieve better than the sub-Gaussian\nerror rate for any distribution, matching the worst-case result of [LV22]. More\ngenerally, we introduce a new definitional framework to analyze the\nfine-grained optimality of algorithms, which we call \"neighborhood optimality\",\ninterpolating between the unattainably strong \"instance optimality\" and the\ntrivially weak \"admissibility\" definitions. Applying the new framework, we show\nthat median-of-means is neighborhood optimal, up to constant factors. It is\nopen to find a neighborhood-optimal estimator without constant factor\nslackness.\n","authors":["Trung Dang","Jasper C. H. Lee","Maoyuan Song","Paul Valiant"],"pdf_url":"https://arxiv.org/pdf/2311.12784v1.pdf","comment":"27 pages, to appear in NeurIPS 2023. Abstract shortened to fit arXiv\n  limit"},{"id":"http://arxiv.org/abs/2011.04923v5","updated":"2023-11-21T18:49:33Z","published":"2020-11-10T06:06:02Z","title":"Topological properties of basins of attraction and expressiveness of\n  width bounded neural networks","summary":"  In Radhakrishnan et al. [2020], the authors empirically show that\nautoencoders trained with usual SGD methods shape out basins of attraction\naround their training data. We consider network functions of width not\nexceeding the input dimension and prove that in this situation basins of\nattraction are bounded and their complement cannot have bounded components. Our\nconditions in these results are met in several experiments of the latter work\nand we thus address a question posed therein. We also show that under some more\nrestrictive conditions the basins of attraction are path-connected. The\ntightness of the conditions in our results is demonstrated by means of several\nexamples. Finally, the arguments used to prove the above results allow us to\nderive a root cause why scalar-valued neural network functions that fulfill our\nbounded width condition are not dense in spaces of continuous functions.\n","authors":["Hans-Peter Beise","Steve Dias Da Cruz"],"pdf_url":"https://arxiv.org/pdf/2011.04923v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12781v1","updated":"2023-11-21T18:45:52Z","published":"2023-11-21T18:45:52Z","title":"Quantifying Impairment and Disease Severity Using AI Models Trained on\n  Healthy Subjects","summary":"  Automatic assessment of impairment and disease severity is a key challenge in\ndata-driven medicine. We propose a novel framework to address this challenge,\nwhich leverages AI models trained exclusively on healthy individuals. The\nCOnfidence-Based chaRacterization of Anomalies (COBRA) score exploits the\ndecrease in confidence of these models when presented with impaired or diseased\npatients to quantify their deviation from the healthy population. We applied\nthe COBRA score to address a key limitation of current clinical evaluation of\nupper-body impairment in stroke patients. The gold-standard Fugl-Meyer\nAssessment (FMA) requires in-person administration by a trained assessor for\n30-45 minutes, which restricts monitoring frequency and precludes physicians\nfrom adapting rehabilitation protocols to the progress of each patient. The\nCOBRA score, computed automatically in under one minute, is shown to be\nstrongly correlated with the FMA on an independent test cohort for two\ndifferent data modalities: wearable sensors ($\\rho = 0.845$, 95% CI\n[0.743,0.908]) and video ($\\rho = 0.746$, 95% C.I [0.594, 0.847]). To\ndemonstrate the generalizability of the approach to other conditions, the COBRA\nscore was also applied to quantify severity of knee osteoarthritis from\nmagnetic-resonance imaging scans, again achieving significant correlation with\nan independent clinical assessment ($\\rho = 0.644$, 95% C.I [0.585,0.696]).\n","authors":["Boyang Yu","Aakash Kaku","Kangning Liu","Avinash Parnandi","Emily Fokas","Anita Venkatesan","Natasha Pandit","Rajesh Ranganath","Heidi Schambra","Carlos Fernandez-Granda"],"pdf_url":"https://arxiv.org/pdf/2311.12781v1.pdf","comment":"32 pages, 10 figures"},{"id":"http://arxiv.org/abs/2305.12827v3","updated":"2023-11-21T18:43:43Z","published":"2023-05-22T08:39:25Z","title":"Task Arithmetic in the Tangent Space: Improved Editing of Pre-Trained\n  Models","summary":"  Task arithmetic has recently emerged as a cost-effective and scalable\napproach to edit pre-trained models directly in weight space: By adding the\nfine-tuned weights of different tasks, the model's performance can be improved\non these tasks, while negating them leads to task forgetting. Yet, our\nunderstanding of the effectiveness of task arithmetic and its underlying\nprinciples remains limited. We present a comprehensive study of task arithmetic\nin vision-language models and show that weight disentanglement is the crucial\nfactor that makes it effective. This property arises during pre-training and\nmanifests when distinct directions in weight space govern separate, localized\nregions in function space associated with the tasks. Notably, we show that\nfine-tuning models in their tangent space by linearizing them amplifies weight\ndisentanglement. This leads to substantial performance improvements across\nmultiple task arithmetic benchmarks and diverse models. Building on these\nfindings, we provide theoretical and empirical analyses of the neural tangent\nkernel (NTK) of these models and establish a compelling link between task\narithmetic and the spatial localization of the NTK eigenfunctions. Overall, our\nwork uncovers novel insights into the fundamental mechanisms of task arithmetic\nand offers a more reliable and effective approach to edit pre-trained models\nthrough the NTK linearization.\n","authors":["Guillermo Ortiz-Jimenez","Alessandro Favero","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2305.12827v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.09387v2","updated":"2023-11-21T18:31:57Z","published":"2023-11-15T21:30:26Z","title":"Banach-Tarski Embeddings and Transformers","summary":"  We introduce a new construction of embeddings of arbitrary recursive data\nstructures into high dimensional vectors. These embeddings provide an\ninterpretable model for the latent state vectors of transformers. We\ndemonstrate that these embeddings can be decoded to the original data structure\nwhen the embedding dimension is sufficiently large. This decoding algorithm has\na natural implementation as a transformer. We also show that these embedding\nvectors can be manipulated directly to perform computations on the underlying\ndata without decoding. As an example we present an algorithm that constructs\nthe embedded parse tree of an embedded token sequence using only vector\noperations in embedding space.\n","authors":["Joshua Maher"],"pdf_url":"https://arxiv.org/pdf/2311.09387v2.pdf","comment":"22 pages, 7 figures. v2: Fixed order of matrix multiplication in\n  section 2.4"},{"id":"http://arxiv.org/abs/2206.01255v5","updated":"2023-11-21T18:31:13Z","published":"2022-06-02T19:11:27Z","title":"Compressive Fourier collocation methods for high-dimensional diffusion\n  equations with periodic boundary conditions","summary":"  High-dimensional Partial Differential Equations (PDEs) are a popular\nmathematical modelling tool, with applications ranging from finance to\ncomputational chemistry. However, standard numerical techniques for solving\nthese PDEs are typically affected by the curse of dimensionality. In this work,\nwe tackle this challenge while focusing on stationary diffusion equations\ndefined over a high-dimensional domain with periodic boundary conditions.\nInspired by recent progress in sparse function approximation in high\ndimensions, we propose a new method called compressive Fourier collocation.\nCombining ideas from compressive sensing and spectral collocation, our method\nreplaces the use of structured collocation grids with Monte Carlo sampling and\nemploys sparse recovery techniques, such as orthogonal matching pursuit and\n$\\ell^1$ minimization, to approximate the Fourier coefficients of the PDE\nsolution. We conduct a rigorous theoretical analysis showing that the\napproximation error of the proposed method is comparable with the best $s$-term\napproximation (with respect to the Fourier basis) to the solution. Using the\nrecently introduced framework of random sampling in bounded Riesz systems, our\nanalysis shows that the compressive Fourier collocation method mitigates the\ncurse of dimensionality with respect to the number of collocation points under\nsufficient conditions on the regularity of the diffusion coefficient. We also\npresent numerical experiments that illustrate the accuracy and stability of the\nmethod for the approximation of sparse and compressible solutions.\n","authors":["Weiqi Wang","Simone Brugiapaglia"],"pdf_url":"https://arxiv.org/pdf/2206.01255v5.pdf","comment":"34 pages, 10 figures"},{"id":"http://arxiv.org/abs/2310.02168v2","updated":"2023-11-21T18:18:49Z","published":"2023-10-03T16:02:36Z","title":"Editing Personality for LLMs","summary":"  This paper introduces an innovative task focused on editing the personality\ntraits of Large Language Models (LLMs). This task seeks to adjust the models'\nresponses to opinion-related questions on specified topics since an\nindividual's personality often manifests in the form of their expressed\nopinions, thereby showcasing different personality traits. Specifically, we\nconstruct a new benchmark dataset PersonalityEdit to address this task. Drawing\non the theory in Social Psychology, we isolate three representative traits,\nnamely Neuroticism, Extraversion, and Agreeableness, as the foundation for our\nbenchmark. We then gather data using GPT-4, generating responses that not only\nalign with a specified topic but also embody the targeted personality trait. We\nconduct comprehensive experiments involving various baselines and discuss the\nrepresentation of personality behavior in LLMs. Our intriguing findings uncover\npotential challenges of the proposed task, illustrating several remaining\nissues. We anticipate that our work can provide the NLP community with\ninsights. Code and datasets will be released at\nhttps://github.com/zjunlp/EasyEdit.\n","authors":["Shengyu Mao","Ningyu Zhang","Xiaohan Wang","Mengru Wang","Yunzhi Yao","Yong Jiang","Pengjun Xie","Fei Huang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2310.02168v2.pdf","comment":"Work in progress, add more experiments"},{"id":"http://arxiv.org/abs/2311.12760v1","updated":"2023-11-21T18:11:26Z","published":"2023-11-21T18:11:26Z","title":"High-resolution Image-based Malware Classification using Multiple\n  Instance Learning","summary":"  This paper proposes a novel method of classifying malware into families using\nhigh-resolution greyscale images and multiple instance learning to overcome\nadversarial binary enlargement. Current methods of visualisation-based malware\nclassification largely rely on lossy transformations of inputs such as resizing\nto handle the large, variable-sized images. Through empirical analysis and\nexperimentation, it is shown that these approaches cause crucial information\nloss that can be exploited. The proposed solution divides the images into\npatches and uses embedding-based multiple instance learning with a\nconvolutional neural network and an attention aggregation function for\nclassification. The implementation is evaluated on the Microsoft Malware\nClassification dataset and achieves accuracies of up to $96.6\\%$ on\nadversarially enlarged samples compared to the baseline of $22.8\\%$. The Python\ncode is available online at https://github.com/timppeters/MIL-Malware-Images .\n","authors":["Tim Peters","Hikmat Farhat"],"pdf_url":"https://arxiv.org/pdf/2311.12760v1.pdf","comment":"14 pages, 13 figures, 2 tables"},{"id":"http://arxiv.org/abs/2311.12754v1","updated":"2023-11-21T17:59:14Z","published":"2023-11-21T17:59:14Z","title":"SelfOcc: Self-Supervised Vision-Based 3D Occupancy Prediction","summary":"  3D occupancy prediction is an important task for the robustness of\nvision-centric autonomous driving, which aims to predict whether each point is\noccupied in the surrounding 3D space. Existing methods usually require 3D\noccupancy labels to produce meaningful results. However, it is very laborious\nto annotate the occupancy status of each voxel. In this paper, we propose\nSelfOcc to explore a self-supervised way to learn 3D occupancy using only video\nsequences. We first transform the images into the 3D space (e.g., bird's eye\nview) to obtain 3D representation of the scene. We directly impose constraints\non the 3D representations by treating them as signed distance fields. We can\nthen render 2D images of previous and future frames as self-supervision signals\nto learn the 3D representations. We propose an MVS-embedded strategy to\ndirectly optimize the SDF-induced weights with multiple depth proposals. Our\nSelfOcc outperforms the previous best method SceneRF by 58.7% using a single\nframe as input on SemanticKITTI and is the first self-supervised work that\nproduces reasonable 3D occupancy for surround cameras on Occ3D. SelfOcc\nproduces high-quality depth and achieves state-of-the-art results on novel\ndepth synthesis, monocular depth estimation, and surround-view depth estimation\non the SemanticKITTI, KITTI-2015, and nuScenes, respectively. Code:\nhttps://github.com/huang-yh/SelfOcc.\n","authors":["Yuanhui Huang","Wenzhao Zheng","Borui Zhang","Jie Zhou","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2311.12754v1.pdf","comment":"Code is available at: https://github.com/huang-yh/SelfOcc"},{"id":"http://arxiv.org/abs/2310.02129v2","updated":"2023-11-21T17:59:04Z","published":"2023-10-03T15:10:46Z","title":"Unveiling the Pitfalls of Knowledge Editing for Large Language Models","summary":"  As the cost associated with fine-tuning Large Language Models (LLMs)\ncontinues to rise, recent research efforts have pivoted towards developing\nmethodologies to edit implicit knowledge embedded within LLMs. Yet, there's\nstill a dark cloud lingering overhead -- will knowledge editing trigger\nbutterfly effect? since it is still unclear whether knowledge editing might\nintroduce side effects that pose potential risks or not. This paper pioneers\nthe investigation into the potential pitfalls associated with knowledge editing\nfor LLMs. To achieve this, we introduce new benchmark datasets and propose\ninnovative evaluation metrics. Our results underline two pivotal concerns: (1)\nKnowledge Conflict: Editing groups of facts that logically clash can magnify\nthe inherent inconsistencies in LLMs-a facet neglected by previous methods. (2)\nKnowledge Distortion: Altering parameters with the aim of editing factual\nknowledge can irrevocably warp the innate knowledge structure of LLMs.\nExperimental results vividly demonstrate that knowledge editing might\ninadvertently cast a shadow of unintended consequences on LLMs, which warrant\nattention and efforts for future works. Code is available at\nhttps://github.com/zjunlp/PitfallsKnowledgeEditing.\n","authors":["Zhoubo Li","Ningyu Zhang","Yunzhi Yao","Mengru Wang","Xi Chen","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2310.02129v2.pdf","comment":"Work in progress, add more experiments"},{"id":"http://arxiv.org/abs/2311.12750v1","updated":"2023-11-21T17:51:30Z","published":"2023-11-21T17:51:30Z","title":"Learning to Optimise Wind Farms with Graph Transformers","summary":"  This work proposes a novel data-driven model capable of providing accurate\npredictions for the power generation of all wind turbines in wind farms of\narbitrary layout, yaw angle configurations and wind conditions. The proposed\nmodel functions by encoding a wind farm into a fully-connected graph and\nprocessing the graph representation through a graph transformer. The graph\ntransformer surrogate is shown to generalise well and is able to uncover latent\nstructural patterns within the graph representation of wind farms. It is\ndemonstrated how the resulting surrogate model can be used to optimise yaw\nangle configurations using genetic algorithms, achieving similar levels of\naccuracy to industrially-standard wind farm simulation tools while only taking\na fraction of the computational cost.\n","authors":["Siyi Li","Arnaud Robert","A. Aldo Faisal","Matthew D. Piggott"],"pdf_url":"https://arxiv.org/pdf/2311.12750v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.06185v2","updated":"2023-11-21T17:42:42Z","published":"2023-11-10T17:06:28Z","title":"An Automated Pipeline for Tumour-Infiltrating Lymphocyte Scoring in\n  Breast Cancer","summary":"  Tumour-infiltrating lymphocytes (TILs) are considered as a valuable\nprognostic markers in both triple-negative and human epidermal growth factor\nreceptor 2 (HER2) positive breast cancer. In this study, we introduce an\ninnovative deep learning pipeline based on the Efficient-UNet architecture to\npredict the TILs score for breast cancer whole-slide images (WSIs). We first\nsegment tumour and stromal regions in order to compute a tumour bulk mask. We\nthen detect TILs within the tumour-associated stroma, generating a TILs score\nby closely mirroring the pathologist's workflow. Our method exhibits\nstate-of-the-art performance in segmenting tumour/stroma areas and TILs\ndetection, as demonstrated by internal cross-validation on the TiGER Challenge\ntraining dataset and evaluation on the final leaderboards. Additionally, our\nTILs score proves competitive in predicting survival outcomes within the same\nchallenge, underscoring the clinical relevance and potential of our automated\nTILs scoring pipeline as a breast cancer prognostic tool.\n","authors":["Adam J Shephard","Mostafa Jahanifar","Ruoyu Wang","Muhammad Dawood","Simon Graham","Kastytis Sidlauskas","Syed Ali Khurram","Nasir M Rajpoot","Shan E Ahmed Raza"],"pdf_url":"https://arxiv.org/pdf/2311.06185v2.pdf","comment":"5 pages, 1 figure, 2 tables"},{"id":"http://arxiv.org/abs/2307.16189v6","updated":"2023-11-21T17:35:03Z","published":"2023-07-30T10:03:36Z","title":"Stable Adam Optimization for 16-bit Neural Networks Training","summary":"  In this research, we address critical concerns related to the numerical\ninstability observed in 16-bit computations of machine learning models. Such\ninstability, particularly when employing popular optimization algorithms like\nAdam, often leads to unstable training of deep neural networks. This not only\ndisrupts the learning process but also poses significant challenges in\ndeploying dependable models in real-world applications. Our investigation\nidentifies the epsilon hyperparameter as the primary source of this\ninstability. A nuanced exploration reveals that subtle adjustments to epsilon\nwithin 16-bit computations can enhance the numerical stability of Adam,\nenabling more stable training of 16-bit neural networks. We propose a novel,\ndependable approach that leverages updates from the Adam optimizer to bolster\nthe stability of the learning process. Our contributions provide deeper\ninsights into optimization challenges in low-precision computations and offer\nsolutions to ensure the stability of deep neural network training, paving the\nway for their dependable use in various applications.\n","authors":["Juyoung Yun"],"pdf_url":"https://arxiv.org/pdf/2307.16189v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12742v1","updated":"2023-11-21T17:31:10Z","published":"2023-11-21T17:31:10Z","title":"Image Transformation for IoT Time-Series Data: A Review","summary":"  In the era of the Internet of Things (IoT), where smartphones, built-in\nsystems, wireless sensors, and nearly every smart device connect through local\nnetworks or the internet, billions of smart things communicate with each other\nand generate vast amounts of time-series data. As IoT time-series data is\nhigh-dimensional and high-frequency, time-series classification or regression\nhas been a challenging issue in IoT. Recently, deep learning algorithms have\ndemonstrated superior performance results in time-series data classification in\nmany smart and intelligent IoT applications. However, it is hard to explore the\nhidden dynamic patterns and trends in time-series. Recent studies show that\ntransforming IoT data into images improves the performance of the learning\nmodel. In this paper, we present a review of these studies which use image\ntransformation/encoding techniques in IoT domain. We examine the studies\naccording to their encoding techniques, data types, and application areas.\nLastly, we emphasize the challenges and future dimensions of image\ntransformation.\n","authors":["Duygu Altunkaya","Feyza Yildirim Okay","Suat Ozdemir"],"pdf_url":"https://arxiv.org/pdf/2311.12742v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2311.12741v1","updated":"2023-11-21T17:30:57Z","published":"2023-11-21T17:30:57Z","title":"Content Augmented Graph Neural Networks","summary":"  In recent years, graph neural networks (GNNs) have become a popular tool for\nsolving various problems over graphs. In these models, the link structure of\nthe graph is typically exploited and nodes' embeddings are iteratively updated\nbased on adjacent nodes. Nodes' contents are used solely in the form of feature\nvectors, served as nodes' first-layer embeddings. However, the filters or\nconvolutions, applied during iterations/layers to these initial embeddings lead\nto their impact diminish and contribute insignificantly to the final\nembeddings. In order to address this issue, in this paper we propose augmenting\nnodes' embeddings by embeddings generating from their content, at higher GNN\nlayers. More precisely, we propose models wherein a structural embedding using\na GNN and a content embedding are computed for each node. These two are\ncombined using a combination layer to form the embedding of a node at a given\nlayer. We suggest methods such as using an auto-encoder or building a content\ngraph, to generate content embeddings. In the end, by conducting experiments\nover several real-world datasets, we demonstrate the high accuracy and\nperformance of our models.\n","authors":["Fatemeh Gholamzadeh Nasrabadi","AmirHossein Kashani","Pegah Zahedi","Mostafa Haghir Chehreghani"],"pdf_url":"https://arxiv.org/pdf/2311.12741v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11995v2","updated":"2023-11-21T17:29:59Z","published":"2023-11-20T18:26:01Z","title":"BrainWash: A Poisoning Attack to Forget in Continual Learning","summary":"  Continual learning has gained substantial attention within the deep learning\ncommunity, offering promising solutions to the challenging problem of\nsequential learning. Yet, a largely unexplored facet of this paradigm is its\nsusceptibility to adversarial attacks, especially with the aim of inducing\nforgetting. In this paper, we introduce \"BrainWash,\" a novel data poisoning\nmethod tailored to impose forgetting on a continual learner. By adding the\nBrainWash noise to a variety of baselines, we demonstrate how a trained\ncontinual learner can be induced to forget its previously learned tasks\ncatastrophically, even when using these continual learning baselines. An\nimportant feature of our approach is that the attacker requires no access to\nprevious tasks' data and is armed merely with the model's current parameters\nand the data belonging to the most recent task. Our extensive experiments\nhighlight the efficacy of BrainWash, showcasing degradation in performance\nacross various regularization-based continual learning methods.\n","authors":["Ali Abbasi","Parsa Nooralinejad","Hamed Pirsiavash","Soheil Kolouri"],"pdf_url":"https://arxiv.org/pdf/2311.11995v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.03489v2","updated":"2023-11-21T17:28:17Z","published":"2023-11-06T19:58:26Z","title":"Leveraging High-Level Synthesis and Large Language Models to Generate,\n  Simulate, and Deploy a Uniform Random Number Generator Hardware Design","summary":"  We present a new high-level synthesis methodology for using large language\nmodel tools to generate hardware designs. The methodology uses exclusively\nopen-source tools excluding the large language model. As a case study, we use\nour methodology to generate a permuted congruential random number generator\ndesign with a wishbone interface. We verify the functionality and quality of\nthe random number generator design using large language model-generated\nsimulations and the Dieharder randomness test suite. We document all the large\nlanguage model chat logs, Python scripts, Verilog scripts, and simulation\nresults used in the case study. We believe that our method of hardware design\ngeneration coupled with the open source silicon 130 nm design tools will\nrevolutionize application-specific integrated circuit design. Our methodology\nsignificantly lowers the bar to entry when building domain-specific computing\naccelerators for the Internet of Things and proof of concept prototypes for\nlater fabrication in more modern process nodes.\n","authors":["James T. Meech"],"pdf_url":"https://arxiv.org/pdf/2311.03489v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12737v1","updated":"2023-11-21T17:23:05Z","published":"2023-11-21T17:23:05Z","title":"Exploring Graph Classification Techniques Under Low Data Constraints: A\n  Comprehensive Study","summary":"  This survey paper presents a brief overview of recent research on graph data\naugmentation and few-shot learning. It covers various techniques for graph data\naugmentation, including node and edge perturbation, graph coarsening, and graph\ngeneration, as well as the latest developments in few-shot learning, such as\nmeta-learning and model-agnostic meta-learning. The paper explores these areas\nin depth and delves into further sub classifications. Rule based approaches and\nlearning based approaches are surveyed under graph augmentation techniques.\nFew-Shot Learning on graphs is also studied in terms of metric learning\ntechniques and optimization-based techniques. In all, this paper provides an\nextensive array of techniques that can be employed in solving graph processing\nproblems faced in low-data scenarios.\n","authors":["Kush Kothari","Bhavya Mehta","Reshmika Nambiar","Seema Shrawne"],"pdf_url":"https://arxiv.org/pdf/2311.12737v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.11774v2","updated":"2023-11-21T17:16:02Z","published":"2023-05-19T16:01:35Z","title":"Multi-Objective Optimization Using the R2 Utility","summary":"  The goal of multi-objective optimization is to identify a collection of\npoints which describe the best possible trade-offs between the multiple\nobjectives. In order to solve this vector-valued optimization problem,\npractitioners often appeal to the use of scalarization functions in order to\ntransform the multi-objective problem into a collection of single-objective\nproblems. This set of scalarized problems can then be solved using traditional\nsingle-objective optimization techniques. In this work, we formalise this\nconvention into a general mathematical framework. We show how this strategy\neffectively recasts the original multi-objective optimization problem into a\nsingle-objective optimization problem defined over sets. An appropriate class\nof objective functions for this new problem is the R2 utility function, which\nis defined as a weighted integral over the scalarized optimization problems. We\nshow that this utility function is a monotone and submodular set function,\nwhich can be optimised effectively using greedy optimization algorithms. We\nanalyse the performance of these greedy algorithms both theoretically and\nempirically. Our analysis largely focusses on Bayesian optimization, which is a\npopular probabilistic framework for black-box optimization.\n","authors":["Ben Tu","Nikolas Kantas","Robert M. Lee","Behrang Shafei"],"pdf_url":"https://arxiv.org/pdf/2305.11774v2.pdf","comment":"The code is available at: https://github.com/benmltu/scalarize"},{"id":"http://arxiv.org/abs/2311.10801v2","updated":"2023-11-21T17:11:55Z","published":"2023-11-17T09:16:59Z","title":"Reinforcement Learning with Maskable Stock Representation for Portfolio\n  Management in Customizable Stock Pools","summary":"  Portfolio management (PM) is a fundamental financial trading task, which\nexplores the optimal periodical reallocation of capitals into different stocks\nto pursue long-term profits. Reinforcement learning (RL) has recently shown its\npotential to train profitable agents for PM through interacting with financial\nmarkets. However, existing work mostly focuses on fixed stock pools, which is\ninconsistent with investors' practical demand. Specifically, the target stock\npool of different investors varies dramatically due to their discrepancy on\nmarket states and individual investors may temporally adjust stocks they desire\nto trade (e.g., adding one popular stocks), which lead to customizable stock\npools (CSPs). Existing RL methods require to retrain RL agents even with a tiny\nchange of the stock pool, which leads to high computational cost and unstable\nperformance. To tackle this challenge, we propose EarnMore, a rEinforcement\nleARNing framework with Maskable stOck REpresentation to handle PM with CSPs\nthrough one-shot training in a global stock pool (GSP). Specifically, we first\nintroduce a mechanism to mask out the representation of the stocks outside the\ntarget pool. Second, we learn meaningful stock representations through a\nself-supervised masking and reconstruction process. Third, a re-weighting\nmechanism is designed to make the portfolio concentrate on favorable stocks and\nneglect the stocks outside the target pool. Through extensive experiments on 8\nsubset stock pools of the US stock market, we demonstrate that EarnMore\nsignificantly outperforms 14 state-of-the-art baselines in terms of 6 popular\nfinancial metrics with over 40% improvement on profit.\n","authors":["Wentao Zhang","Yilei Zhao","Shuo Sun","Jie Ying","Yonggang Xie","Zitao Song","Xinrun Wang","Bo An"],"pdf_url":"https://arxiv.org/pdf/2311.10801v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.17844v2","updated":"2023-11-21T17:08:34Z","published":"2023-06-30T17:59:13Z","title":"The Clock and the Pizza: Two Stories in Mechanistic Explanation of\n  Neural Networks","summary":"  Do neural networks, trained on well-understood algorithmic tasks, reliably\nrediscover known algorithms for solving those tasks? Several recent studies, on\ntasks ranging from group arithmetic to in-context linear regression, have\nsuggested that the answer is yes. Using modular addition as a prototypical\nproblem, we show that algorithm discovery in neural networks is sometimes more\ncomplex. Small changes to model hyperparameters and initializations can induce\nthe discovery of qualitatively different algorithms from a fixed training set,\nand even parallel implementations of multiple such algorithms. Some networks\ntrained to perform modular addition implement a familiar Clock algorithm;\nothers implement a previously undescribed, less intuitive, but comprehensible\nprocedure which we term the Pizza algorithm, or a variety of even more complex\nprocedures. Our results show that even simple learning problems can admit a\nsurprising diversity of solutions, motivating the development of new tools for\ncharacterizing the behavior of neural networks across their algorithmic phase\nspace.\n","authors":["Ziqian Zhong","Ziming Liu","Max Tegmark","Jacob Andreas"],"pdf_url":"https://arxiv.org/pdf/2306.17844v2.pdf","comment":"Accepted by NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.12727v1","updated":"2023-11-21T17:03:21Z","published":"2023-11-21T17:03:21Z","title":"Soft Random Sampling: A Theoretical and Empirical Analysis","summary":"  Soft random sampling (SRS) is a simple yet effective approach for efficient\ntraining of large-scale deep neural networks when dealing with massive data.\nSRS selects a subset uniformly at random with replacement from the full data\nset in each epoch. In this paper, we conduct a theoretical and empirical\nanalysis of SRS. First, we analyze its sampling dynamics including data\ncoverage and occupancy. Next, we investigate its convergence with non-convex\nobjective functions and give the convergence rate. Finally, we provide its\ngeneralization performance. We empirically evaluate SRS for image recognition\non CIFAR10 and automatic speech recognition on Librispeech and an in-house\npayload dataset to demonstrate its effectiveness. Compared to existing\ncoreset-based data selection methods, SRS offers a better accuracy-efficiency\ntrade-off. Especially on real-world industrial scale data sets, it is shown to\nbe a powerful training strategy with significant speedup and competitive\nperformance with almost no additional computing cost.\n","authors":["Xiaodong Cui","Ashish Mittal","Songtao Lu","Wei Zhang","George Saon","Brian Kingsbury"],"pdf_url":"https://arxiv.org/pdf/2311.12727v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12722v1","updated":"2023-11-21T16:51:33Z","published":"2023-11-21T16:51:33Z","title":"Attacking Motion Planners Using Adversarial Perception Errors","summary":"  Autonomous driving (AD) systems are often built and tested in a modular\nfashion, where the performance of different modules is measured using\ntask-specific metrics. These metrics should be chosen so as to capture the\ndownstream impact of each module and the performance of the system as a whole.\nFor example, high perception quality should enable prediction and planning to\nbe performed safely. Even though this is true in general, we show here that it\nis possible to construct planner inputs that score very highly on various\nperception quality metrics but still lead to planning failures. In an analogy\nto adversarial attacks on image classifiers, we call such inputs\n\\textbf{adversarial perception errors} and show they can be systematically\nconstructed using a simple boundary-attack algorithm. We demonstrate the\neffectiveness of this algorithm by finding attacks for two different black-box\nplanners in several urban and highway driving scenarios using the CARLA\nsimulator. Finally, we analyse the properties of these attacks and show that\nthey are isolated in the input space of the planner, and discuss their\nimplications for AD system deployment and testing.\n","authors":["Jonathan Sadeghi","Nicholas A. Lord","John Redford","Romain Mueller"],"pdf_url":"https://arxiv.org/pdf/2311.12722v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12716v1","updated":"2023-11-21T16:43:13Z","published":"2023-11-21T16:43:13Z","title":"minimax: Efficient Baselines for Autocurricula in JAX","summary":"  Unsupervised environment design (UED) is a form of automatic curriculum\nlearning for training robust decision-making agents to zero-shot transfer into\nunseen environments. Such autocurricula have received much interest from the RL\ncommunity. However, UED experiments, based on CPU rollouts and GPU model\nupdates, have often required several weeks of training. This compute\nrequirement is a major obstacle to rapid innovation for the field. This work\nintroduces the minimax library for UED training on accelerated hardware. Using\nJAX to implement fully-tensorized environments and autocurriculum algorithms,\nminimax allows the entire training loop to be compiled for hardware\nacceleration. To provide a petri dish for rapid experimentation, minimax\nincludes a tensorized grid-world based on MiniGrid, in addition to reusable\nabstractions for conducting autocurricula in procedurally-generated\nenvironments. With these components, minimax provides strong UED baselines,\nincluding new parallelized variants, which achieve over 120$\\times$ speedups in\nwall time compared to previous implementations when training with equal batch\nsizes. The minimax library is available under the Apache 2.0 license at\nhttps://github.com/facebookresearch/minimax.\n","authors":["Minqi Jiang","Michael Dennis","Edward Grefenstette","Tim Rocktäschel"],"pdf_url":"https://arxiv.org/pdf/2311.12716v1.pdf","comment":"Presented at ALOE 2023"},{"id":"http://arxiv.org/abs/2311.12715v1","updated":"2023-11-21T16:42:03Z","published":"2023-11-21T16:42:03Z","title":"Attacks of fairness in Federated Learning","summary":"  Federated Learning is an important emerging distributed training paradigm\nthat keeps data private on clients. It is now well understood that by\ncontrolling only a small subset of FL clients, it is possible to introduce a\nbackdoor to a federated learning model, in the presence of certain attributes.\nIn this paper, we present a new type of attack that compromises the fairness of\nthe trained model. Fairness is understood to be the attribute-level performance\ndistribution of a trained model. It is particularly salient in domains where,\nfor example, skewed accuracy discrimination between subpopulations could have\ndisastrous consequences. We find that by employing a threat model similar to\nthat of a backdoor attack, an attacker is able to influence the aggregated\nmodel to have an unfair performance distribution between any given set of\nattributes. Furthermore, we find that this attack is possible by controlling\nonly a single client. While combating naturally induced unfairness in FL has\npreviously been discussed in depth, its artificially induced kind has been\nneglected. We show that defending against attacks on fairness should be a\ncritical consideration in any situation where unfairness in a trained model\ncould benefit a user who participated in its training.\n","authors":["Joseph Rance","Filip Svoboda"],"pdf_url":"https://arxiv.org/pdf/2311.12715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.10852v6","updated":"2023-11-21T16:36:43Z","published":"2022-05-22T15:30:18Z","title":"Relphormer: Relational Graph Transformer for Knowledge Graph\n  Representations","summary":"  Transformers have achieved remarkable performance in widespread fields,\nincluding natural language processing, computer vision and graph mining.\nHowever, vanilla Transformer architectures have not yielded promising\nimprovements in the Knowledge Graph (KG) representations, where the\ntranslational distance paradigm dominates this area. Note that vanilla\nTransformer architectures struggle to capture the intrinsically heterogeneous\nstructural and semantic information of knowledge graphs. To this end, we\npropose a new variant of Transformer for knowledge graph representations dubbed\nRelphormer. Specifically, we introduce Triple2Seq which can dynamically sample\ncontextualized sub-graph sequences as the input to alleviate the heterogeneity\nissue. We propose a novel structure-enhanced self-attention mechanism to encode\nthe relational information and keep the semantic information within entities\nand relations. Moreover, we utilize masked knowledge modeling for general\nknowledge graph representation learning, which can be applied to various\nKG-based tasks including knowledge graph completion, question answering, and\nrecommendation. Experimental results on six datasets show that Relphormer can\nobtain better performance compared with baselines. Code is available in\nhttps://github.com/zjunlp/Relphormer.\n","authors":["Zhen Bi","Siyuan Cheng","Jing Chen","Xiaozhuan Liang","Feiyu Xiong","Ningyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2205.10852v6.pdf","comment":"Neurocomputing 2023"},{"id":"http://arxiv.org/abs/2311.12711v1","updated":"2023-11-21T16:31:27Z","published":"2023-11-21T16:31:27Z","title":"Regression-Based Analysis of Multimodal Single-Cell Data Integration\n  Strategies","summary":"  Multimodal single-cell technologies enable the simultaneous collection of\ndiverse data types from individual cells, enhancing our understanding of\ncellular states. However, the integration of these datatypes and modeling the\ninterrelationships between modalities presents substantial computational and\nanalytical challenges in disease biomarker detection and drug discovery.\nEstablished practices rely on isolated methodologies to investigate individual\nmolecular aspects separately, often resulting in inaccurate analyses. To\naddress these obstacles, distinct Machine Learning Techniques are leveraged,\neach of its own kind to model the co-variation of DNA to RNA, and finally to\nsurface proteins in single cells during hematopoietic stem cell development,\nwhich simplifies understanding of underlying cellular mechanisms and immune\nresponses. Experiments conducted on a curated subset of a 300,000-cell time\ncourse dataset, highlights the exceptional performance of Echo State Networks,\nboasting a remarkable state-of-the-art correlation score of 0.94 and 0.895 on\nMulti-omic and CiteSeq datasets. Beyond the confines of this study, these\nfindings hold promise for advancing comprehension of cellular differentiation\nand function, leveraging the potential of Machine Learning.\n","authors":["Bhavya Mehta","Nirmit Deliwala","Madhav Chandane"],"pdf_url":"https://arxiv.org/pdf/2311.12711v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.07251v2","updated":"2023-11-21T16:26:36Z","published":"2023-05-12T04:53:59Z","title":"Machine-learning-accelerated simulations to enable automatic surface\n  reconstruction","summary":"  Understanding material surfaces and interfaces is vital in applications like\ncatalysis or electronics. By combining energies from electronic structure with\nstatistical mechanics, ab initio simulations can in principle predict the\nstructure of material surfaces as a function of thermodynamic variables.\nHowever, accurate energy simulations are prohibitive when coupled to the vast\nphase space that must be statistically sampled. Here, we present a bi-faceted\ncomputational loop to predict surface phase diagrams of multi-component\nmaterials that accelerates both the energy scoring and statistical sampling\nmethods. Fast, scalable, and data-efficient machine learning interatomic\npotentials are trained on high-throughput density-functional theory\ncalculations through closed-loop active learning. Markov-chain Monte Carlo\nsampling in the semi-grand canonical ensemble is enabled by using virtual\nsurface sites. The predicted surfaces for GaN(0001), Si(111), and SrTiO3(001)\nare in agreement with past work and suggest that the proposed strategy can\nmodel complex material surfaces and discover previously unreported surface\nterminations.\n","authors":["Xiaochen Du","James K. Damewood","Jaclyn R. Lunger","Reisel Millan","Bilge Yildiz","Lin Li","Rafael Gómez-Bombarelli"],"pdf_url":"https://arxiv.org/pdf/2305.07251v2.pdf","comment":"30 pages main, 15 figures/tables, 5 pages supplementary"},{"id":"http://arxiv.org/abs/2211.08942v2","updated":"2023-11-21T16:14:54Z","published":"2022-11-16T14:44:27Z","title":"Differentially Private Optimizers Can Learn Adversarially Robust Models","summary":"  Machine learning models have shone in a variety of domains and attracted\nincreasing attention from both the security and the privacy communities. One\nimportant yet worrying question is: Will training models under the differential\nprivacy (DP) constraint have an unfavorable impact on their adversarial\nrobustness? While previous works have postulated that privacy comes at the cost\nof worse robustness, we give the first theoretical analysis to show that DP\nmodels can indeed be robust and accurate, even sometimes more robust than their\nnaturally-trained non-private counterparts. We observe three key factors that\ninfluence the privacy-robustness-accuracy tradeoff: (1) hyper-parameters for DP\noptimizers are critical; (2) pre-training on public data significantly\nmitigates the accuracy and robustness drop; (3) choice of DP optimizers makes a\ndifference. With these factors set properly, we achieve 90\\% natural accuracy,\n72\\% robust accuracy ($+9\\%$ than the non-private model) under $l_2(0.5)$\nattack, and 69\\% robust accuracy ($+16\\%$ than the non-private model) with\npre-trained SimCLRv2 model under $l_\\infty(4/255)$ attack on CIFAR10 with\n$\\epsilon=2$. In fact, we show both theoretically and empirically that DP\nmodels are Pareto optimal on the accuracy-robustness tradeoff. Empirically, the\nrobustness of DP models is consistently observed across various datasets and\nmodels. We believe our encouraging results are a significant step towards\ntraining models that are private as well as robust.\n","authors":["Yuan Zhang","Zhiqi Bu"],"pdf_url":"https://arxiv.org/pdf/2211.08942v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.02956v3","updated":"2023-11-21T15:57:17Z","published":"2022-05-05T22:56:19Z","title":"Low Dimensional Invariant Embeddings for Universal Geometric Learning","summary":"  This paper studies separating invariants: mappings on $D$ dimensional domains\nwhich are invariant to an appropriate group action, and which separate orbits.\nThe motivation for this study comes from the usefulness of separating\ninvariants in proving universality of equivariant neural network architectures.\n  We observe that in several cases the cardinality of separating invariants\nproposed in the machine learning literature is much larger than the dimension\n$D$. As a result, the theoretical universal constructions based on these\nseparating invariants is unrealistically large. Our goal in this paper is to\nresolve this issue.\n  We show that when a continuous family of semi-algebraic separating invariants\nis available, separation can be obtained by randomly selecting $2D+1 $ of these\ninvariants. We apply this methodology to obtain an efficient scheme for\ncomputing separating invariants for several classical group actions which have\nbeen studied in the invariant learning literature. Examples include matrix\nmultiplication actions on point clouds by permutations, rotations, and various\nother linear groups.\n  Often the requirement of invariant separation is relaxed and only generic\nseparation is required. In this case, we show that only $D+1$ invariants are\nrequired. More importantly, generic invariants are often significantly easier\nto compute, as we illustrate by discussing generic and full separation for\nweighted graphs. Finally we outline an approach for proving that separating\ninvariants can be constructed also when the random parameters have finite\nprecision.\n","authors":["Nadav Dym","Steven J. Gortler"],"pdf_url":"https://arxiv.org/pdf/2205.02956v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02143v2","updated":"2023-11-21T15:54:28Z","published":"2023-11-03T17:12:29Z","title":"Pairing-based graph neural network for simulating quantum materials","summary":"  We develop a pairing-based graph neural network for simulating quantum\nmany-body systems. Our architecture augments a BCS-type geminal wavefunction\nwith a generalized pair amplitude parameterized by a graph neural network.\nVariational Monte Carlo with our neural network simultaneously provides an\naccurate, flexible, and scalable method for simulating many-electron systems.\nWe apply this method to two-dimensional semiconductor electron-hole bilayers\nand obtain accurate results on a variety of interaction-induced phases,\nincluding the exciton Bose-Einstein condensate, electron-hole superconductor,\nand bilayer Wigner crystal. Our study demonstrates the potential of\nphysically-motivated neural network wavefunctions for quantum materials\nsimulations.\n","authors":["Di Luo","David D. Dai","Liang Fu"],"pdf_url":"https://arxiv.org/pdf/2311.02143v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12689v1","updated":"2023-11-21T15:51:06Z","published":"2023-11-21T15:51:06Z","title":"Fair Text Classification with Wasserstein Independence","summary":"  Group fairness is a central research topic in text classification, where\nreaching fair treatment between sensitive groups (e.g. women vs. men) remains\nan open challenge. This paper presents a novel method for mitigating biases in\nneural text classification, agnostic to the model architecture. Considering the\ndifficulty to distinguish fair from unfair information in a text encoder, we\ntake inspiration from adversarial training to induce Wasserstein independence\nbetween representations learned to predict our target label and the ones\nlearned to predict some sensitive attribute. Our approach provides two\nsignificant advantages. Firstly, it does not require annotations of sensitive\nattributes in both testing and training data. This is more suitable for\nreal-life scenarios compared to existing methods that require annotations of\nsensitive attributes at train time. Second, our approach exhibits a comparable\nor better fairness-accuracy trade-off compared to existing methods.\n","authors":["Thibaud Leteno","Antoine Gourru","Charlotte Laclau","Rémi Emonet","Christophe Gravier"],"pdf_url":"https://arxiv.org/pdf/2311.12689v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12688v1","updated":"2023-11-21T15:50:37Z","published":"2023-11-21T15:50:37Z","title":"On the Out-of-Distribution Coverage of Combining Split Conformal\n  Prediction and Bayesian Deep Learning","summary":"  Bayesian deep learning and conformal prediction are two methods that have\nbeen used to convey uncertainty and increase safety in machine learning\nsystems. We focus on combining Bayesian deep learning with split conformal\nprediction and how this combination effects out-of-distribution coverage;\nparticularly in the case of multiclass image classification. We suggest that if\nthe model is generally underconfident on the calibration set, then the\nresultant conformal sets may exhibit worse out-of-distribution coverage\ncompared to simple predictive credible sets. Conversely, if the model is\noverconfident on the calibration set, the use of conformal prediction may\nimprove out-of-distribution coverage. We evaluate prediction sets as a result\nof combining split conformal methods and neural networks trained with (i)\nstochastic gradient descent, (ii) deep ensembles, and (iii) mean-field\nvariational inference. Our results suggest that combining Bayesian deep\nlearning models with split conformal prediction can, in some cases, cause\nunintended consequences such as reducing out-of-distribution coverage.\n","authors":["Paul Scemama","Ariel Kapusta"],"pdf_url":"https://arxiv.org/pdf/2311.12688v1.pdf","comment":"26 pages, 18 figures"},{"id":"http://arxiv.org/abs/2308.16113v2","updated":"2023-11-21T15:50:05Z","published":"2023-08-30T16:14:20Z","title":"survex: an R package for explaining machine learning survival models","summary":"  Due to their flexibility and superior performance, machine learning models\nfrequently complement and outperform traditional statistical survival models.\nHowever, their widespread adoption is hindered by a lack of user-friendly tools\nto explain their internal operations and prediction rationales. To tackle this\nissue, we introduce the survex R package, which provides a cohesive framework\nfor explaining any survival model by applying explainable artificial\nintelligence techniques. The capabilities of the proposed software encompass\nunderstanding and diagnosing survival models, which can lead to their\nimprovement. By revealing insights into the decision-making process, such as\nvariable effects and importances, survex enables the assessment of model\nreliability and the detection of biases. Thus, transparency and responsibility\nmay be promoted in sensitive areas, such as biomedical research and healthcare\napplications.\n","authors":["Mikołaj Spytek","Mateusz Krzyziński","Sophie Hanna Langbein","Hubert Baniecki","Marvin N. Wright","Przemysław Biecek"],"pdf_url":"https://arxiv.org/pdf/2308.16113v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12686v1","updated":"2023-11-21T15:47:06Z","published":"2023-11-21T15:47:06Z","title":"Managing ML-Based Application Non-Functional Behavior: A Multi-Model\n  Approach","summary":"  Modern applications are increasingly driven by Machine Learning (ML) models\nwhose non-deterministic behavior is affecting the entire application life cycle\nfrom design to operation. The pervasive adoption of ML is urgently calling for\napproaches that guarantee a stable non-functional behavior of ML-based\napplications over time and across model changes. To this aim, non-functional\nproperties of ML models, such as privacy, confidentiality, fairness, and\nexplainability, must be monitored, verified, and maintained. This need is even\nmore pressing when modern applications operate in the edge-cloud continuum,\nincreasing their complexity and dynamicity. Existing approaches mostly focus on\ni) implementing classifier selection solutions according to the functional\nbehavior of ML models, ii) finding new algorithmic solutions to this need, such\nas continuous re-training. In this paper, we propose a multi-model approach\nbuilt on dynamic classifier selection, where multiple ML models showing similar\nnon-functional properties are made available to the application and one model\nis selected over time according to (dynamic and unpredictable) contextual\nchanges. Our solution goes beyond the state of the art by providing an\narchitectural and methodological approach that continuously guarantees a stable\nnon-functional behavior of ML-based applications, is applicable to different ML\nmodels, and is driven by non-functional properties assessed on the models\nthemselves. It consists of a two-step process working during application\noperation, where model assessment verifies non-functional properties of ML\nmodels trained and selected at development time, and model substitution\nguarantees a continuous and stable support of non-functional properties. We\nexperimentally evaluate our solution in a real-world scenario focusing on\nnon-functional property fairness.\n","authors":["Marco Anisetti","Claudio A. Ardagna","Nicola Bena","Ernesto Damiani","Paolo G. Panero"],"pdf_url":"https://arxiv.org/pdf/2311.12686v1.pdf","comment":"13 pages, 12 figures"},{"id":"http://arxiv.org/abs/2311.12684v1","updated":"2023-11-21T15:46:11Z","published":"2023-11-21T15:46:11Z","title":"Adversarial Reweighting Guided by Wasserstein Distance for Bias\n  Mitigation","summary":"  The unequal representation of different groups in a sample population can\nlead to discrimination of minority groups when machine learning models make\nautomated decisions. To address these issues, fairness-aware machine learning\njointly optimizes two (or more) metrics aiming at predictive effectiveness and\nlow unfairness. However, the inherent under-representation of minorities in the\ndata makes the disparate treatment of subpopulations less noticeable and\ndifficult to deal with during learning. In this paper, we propose a novel\nadversarial reweighting method to address such \\emph{representation bias}. To\nbalance the data distribution between the majority and the minority groups, our\napproach deemphasizes samples from the majority group. To minimize empirical\nrisk, our method prefers samples from the majority group that are close to the\nminority group as evaluated by the Wasserstein distance. Our theoretical\nanalysis shows the effectiveness of our adversarial reweighting approach.\nExperiments demonstrate that our approach mitigates bias without sacrificing\nclassification accuracy, outperforming related state-of-the-art methods on\nimage and tabular benchmark datasets.\n","authors":["Xuan Zhao","Simone Fabbrizzi","Paula Reyero Lobo","Siamak Ghodsi","Klaus Broelemann","Steffen Staab","Gjergji Kasneci"],"pdf_url":"https://arxiv.org/pdf/2311.12684v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.12311v3","updated":"2023-11-21T15:40:54Z","published":"2020-12-22T19:32:52Z","title":"Influencer Videos: Unboxing the Mystique","summary":"  Influencer marketing has become a very popular tool to reach customers.\nDespite the rapid growth in influencer videos, there has been little research\non the effectiveness of their constituent features in explaining video\nengagement. We study YouTube influencers and analyze their unstructured video\ndata across text, audio and images using an \"interpretable deep learning\"\nframework that accomplishes both goals of prediction and interpretation. Our\nprediction-based approach analyzes unstructured data and finds that \"what is\nsaid\" in words (text) is more influential than \"how it is said\" in imagery\n(images) or acoustics (audio). Our novel interpretation-based approach is\nimplemented after completion of model prediction by analyzing the same source\nof unstructured data to measure importance attributed to the video features. We\neliminate several spurious relationships in two steps, identifying a subset of\nrelationships which are confirmed using theory. We uncover novel findings that\nestablish distinct associations for measures of shallow and deep engagement\nbased on the dual-system framework of human thinking. Our approach is validated\nusing simulated data, and we discuss the learnings from our findings for\ninfluencers and brands.\n","authors":["Prashant Rajaram","Puneet Manchanda"],"pdf_url":"https://arxiv.org/pdf/2012.12311v3.pdf","comment":"45 pages, Online Appendix"},{"id":"http://arxiv.org/abs/2311.12679v1","updated":"2023-11-21T15:37:19Z","published":"2023-11-21T15:37:19Z","title":"BundleMoCap: Efficient, Robust and Smooth Motion Capture from Sparse\n  Multiview Videos","summary":"  Capturing smooth motions from videos using markerless techniques typically\ninvolves complex processes such as temporal constraints, multiple stages with\ndata-driven regression and optimization, and bundle solving over temporal\nwindows. These processes can be inefficient and require tuning multiple\nobjectives across stages. In contrast, BundleMoCap introduces a novel and\nefficient approach to this problem. It solves the motion capture task in a\nsingle stage, eliminating the need for temporal smoothness objectives while\nstill delivering smooth motions. BundleMoCap outperforms the state-of-the-art\nwithout increasing complexity. The key concept behind BundleMoCap is manifold\ninterpolation between latent keyframes. By relying on a local manifold\nsmoothness assumption, we can efficiently solve a bundle of frames using a\nsingle code. Additionally, the method can be implemented as a sliding window\noptimization and requires only the first frame to be properly initialized,\nreducing the overall computational burden. BundleMoCap's strength lies in its\nability to achieve high-quality motion capture results with simplicity and\nefficiency. More details can be found at https://moverseai.github.io/bundle/.\n","authors":["Georgios Albanis","Nikolaos Zioulis","Kostas Kolomvatsos"],"pdf_url":"https://arxiv.org/pdf/2311.12679v1.pdf","comment":"Published in European Conference on Visual Media Production (CVMP\n  '23)"},{"id":"http://arxiv.org/abs/2311.12678v1","updated":"2023-11-21T15:36:20Z","published":"2023-11-21T15:36:20Z","title":"Interpretation of the Transformer and Improvement of the Extractor","summary":"  It has been over six years since the Transformer architecture was put\nforward. Surprisingly, the vanilla Transformer architecture is still widely\nused today. One reason is that the lack of deep understanding and comprehensive\ninterpretation of the Transformer architecture makes it more challenging to\nimprove the Transformer architecture. In this paper, we first interpret the\nTransformer architecture comprehensively in plain words based on our\nunderstanding and experiences. The interpretations are further proved and\nverified. These interpretations also cover the Extractor, a family of drop-in\nreplacements for the multi-head self-attention in the Transformer architecture.\nThen, we propose an improvement on a type of the Extractor that outperforms the\nself-attention, without introducing additional trainable parameters.\nExperimental results demonstrate that the improved Extractor performs even\nbetter, showing a way to improve the Transformer architecture.\n","authors":["Zhe Chen"],"pdf_url":"https://arxiv.org/pdf/2311.12678v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12674v1","updated":"2023-11-21T15:31:16Z","published":"2023-11-21T15:31:16Z","title":"Contrastive Left-Right Wearable Sensors (IMUs) Consistency Matching for\n  HAR","summary":"  Machine learning algorithms are improving rapidly, but annotating training\ndata remains a bottleneck for many applications. In this paper, we show how\nreal data can be used for self-supervised learning without any transformations\nby taking advantage of the symmetry present in the activities. Our approach\ninvolves contrastive matching of two different sensors (left and right wrist or\nleg-worn IMUs) to make representations of co-occurring sensor data more similar\nand those of non-co-occurring sensor data more different. We test our approach\non the Opportunity and MM-Fit datasets. In MM-Fit we show significant\nimprovement over the baseline supervised and self-supervised method SimCLR,\nwhile for Opportunity there is significant improvement over the supervised\nbaseline and slight improvement when compared to SimCLR. Moreover, our method\nimproves supervised baselines even when using only a small amount of the data\nfor training. Future work should explore under which conditions our method is\nbeneficial for human activity recognition systems and other related\napplications.\n","authors":["Dominique Nshimyimana","Vitor Fortes Rey","Paul Lukowic"],"pdf_url":"https://arxiv.org/pdf/2311.12674v1.pdf","comment":"Accepted at ABC 2023. The 5th International Conference on Activity\n  and Behavior Computing September 7th - 9th, 2023 in Kaiserslautern, Germany\n  (Hybrid)"},{"id":"http://arxiv.org/abs/2311.12670v1","updated":"2023-11-21T15:28:44Z","published":"2023-11-21T15:28:44Z","title":"Towards a more inductive world for drug repurposing approaches","summary":"  Drug-target interaction (DTI) prediction is a challenging, albeit essential\ntask in drug repurposing. Learning on graph models have drawn special attention\nas they can significantly reduce drug repurposing costs and time commitment.\nHowever, many current approaches require high-demanding additional information\nbesides DTIs that complicates their evaluation process and usability.\nAdditionally, structural differences in the learning architecture of current\nmodels hinder their fair benchmarking. In this work, we first perform an\nin-depth evaluation of current DTI datasets and prediction models through a\nrobust benchmarking process, and show that DTI prediction methods based on\ntransductive models lack generalization and lead to inflated performance when\nevaluated as previously done in the literature, hence not being suited for drug\nrepurposing approaches. We then propose a novel biologically-driven strategy\nfor negative edge subsampling and show through in vitro validation that newly\ndiscovered interactions are indeed true. We envision this work as the\nunderpinning for future fair benchmarking and robust model design. All\ngenerated resources and tools are publicly available as a python package.\n","authors":["Jesus de la Fuente","Guillermo Serrano","Uxía Veleiro","Mikel Casals","Laura Vera","Marija Pizurica","Antonio Pineda-Lucena","Idoia Ochoa","Silve Vicent","Olivier Gevaert","Mikel Hernaez"],"pdf_url":"https://arxiv.org/pdf/2311.12670v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2004.07780v5","updated":"2023-11-21T15:22:43Z","published":"2020-04-16T17:18:49Z","title":"Shortcut Learning in Deep Neural Networks","summary":"  Deep learning has triggered the current rise of artificial intelligence and\nis the workhorse of today's machine intelligence. Numerous success stories have\nrapidly spread all over science, industry and society, but its limitations have\nonly recently come into focus. In this perspective we seek to distill how many\nof deep learning's problems can be seen as different symptoms of the same\nunderlying problem: shortcut learning. Shortcuts are decision rules that\nperform well on standard benchmarks but fail to transfer to more challenging\ntesting conditions, such as real-world scenarios. Related issues are known in\nComparative Psychology, Education and Linguistics, suggesting that shortcut\nlearning may be a common characteristic of learning systems, biological and\nartificial alike. Based on these observations, we develop a set of\nrecommendations for model interpretation and benchmarking, highlighting recent\nadvances in machine learning to improve robustness and transferability from the\nlab to real-world applications.\n","authors":["Robert Geirhos","Jörn-Henrik Jacobsen","Claudio Michaelis","Richard Zemel","Wieland Brendel","Matthias Bethge","Felix A. Wichmann"],"pdf_url":"https://arxiv.org/pdf/2004.07780v5.pdf","comment":"perspective article published at Nature Machine Intelligence\n  (https://doi.org/10.1038/s42256-020-00257-z)"},{"id":"http://arxiv.org/abs/2311.12666v1","updated":"2023-11-21T15:18:29Z","published":"2023-11-21T15:18:29Z","title":"SSVEP-DAN: A Data Alignment Network for SSVEP-based Brain Computer\n  Interfaces","summary":"  Steady-state visual-evoked potential (SSVEP)-based brain-computer interfaces\n(BCIs) offer a non-invasive means of communication through high-speed speller\nsystems. However, their efficiency heavily relies on individual training data\nobtained during time-consuming calibration sessions. To address the challenge\nof data insufficiency in SSVEP-based BCIs, we present SSVEP-DAN, the first\ndedicated neural network model designed for aligning SSVEP data across\ndifferent domains, which can encompass various sessions, subjects, or devices.\nOur experimental results across multiple cross-domain scenarios demonstrate\nSSVEP-DAN's capability to transform existing source SSVEP data into\nsupplementary calibration data, significantly enhancing SSVEP decoding accuracy\nin scenarios with limited calibration data. We envision SSVEP-DAN as a catalyst\nfor practical SSVEP-based BCI applications with minimal calibration. The source\ncodes in this work are available at: https://github.com/CECNL/SSVEP-DAN.\n","authors":["Sung-Yu Chen","Chi-Min Chang","Kuan-Jung Chiang","Chun-Shu Wei"],"pdf_url":"https://arxiv.org/pdf/2311.12666v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11908v2","updated":"2023-11-21T15:17:00Z","published":"2023-11-20T16:40:29Z","title":"Continual Learning: Applications and the Road Forward","summary":"  Continual learning is a sub-field of machine learning, which aims to allow\nmachine learning models to continuously learn on new data, by accumulating\nknowledge without forgetting what was learned in the past. In this work, we\ntake a step back, and ask: \"Why should one care about continual learning in the\nfirst place?\". We set the stage by surveying recent continual learning papers\npublished at three major machine learning conferences, and show that\nmemory-constrained settings dominate the field. Then, we discuss five open\nproblems in machine learning, and even though they seem unrelated to continual\nlearning at first sight, we show that continual learning will inevitably be\npart of their solution. These problems are model-editing, personalization,\non-device learning, faster (re-)training and reinforcement learning. Finally,\nby comparing the desiderata from these unsolved problems and the current\nassumptions in continual learning, we highlight and discuss four future\ndirections for continual learning research. We hope that this work offers an\ninteresting perspective on the future of continual learning, while displaying\nits potential value and the paths we have to pursue in order to make it\nsuccessful. This work is the result of the many discussions the authors had at\nthe Dagstuhl seminar on Deep Continual Learning, in March 2023.\n","authors":["Eli Verwimp","Rahaf Aljundi","Shai Ben-David","Matthias Bethge","Andrea Cossu","Alexander Gepperth","Tyler L. Hayes","Eyke Hüllermeier","Christopher Kanan","Dhireesha Kudithipudi","Christoph H. Lampert","Martin Mundt","Razvan Pascanu","Adrian Popescu","Andreas S. Tolias","Joost van de Weijer","Bing Liu","Vincenzo Lomonaco","Tinne Tuytelaars","Gido M. van de Ven"],"pdf_url":"https://arxiv.org/pdf/2311.11908v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12657v1","updated":"2023-11-21T15:01:14Z","published":"2023-11-21T15:01:14Z","title":"Carbohydrate NMR chemical shift predictions using E(3) equivariant graph\n  neural networks","summary":"  Carbohydrates, vital components of biological systems, are well-known for\ntheir structural diversity. Nuclear Magnetic Resonance (NMR) spectroscopy plays\na crucial role in understanding their intricate molecular arrangements and is\nessential in assessing and verifying the molecular structure of organic\nmolecules. An important part of this process is to predict the NMR chemical\nshift from the molecular structure. This work introduces a novel approach that\nleverages E(3) equivariant graph neural networks to predict carbohydrate NMR\nspectra. Notably, our model achieves a substantial reduction in mean absolute\nerror, up to threefold, compared to traditional models that rely solely on\ntwo-dimensional molecular structure. Even with limited data, the model excels,\nhighlighting its robustness and generalization capabilities. The implications\nare far-reaching and go beyond an advanced understanding of carbohydrate\nstructures and spectral interpretation. For example, it could accelerate\nresearch in pharmaceutical applications, biochemistry, and structural biology,\noffering a faster and more reliable analysis of molecular structures.\nFurthermore, our approach is a key step towards a new data-driven era in\nspectroscopy, potentially influencing spectroscopic techniques beyond NMR.\n","authors":["Maria Bånkestad","Keven M. Dorst","Göran Widmalm","Jerk Rönnols"],"pdf_url":"https://arxiv.org/pdf/2311.12657v1.pdf","comment":"13 pages, 9 figures, 2 tables"},{"id":"http://arxiv.org/abs/2304.12023v2","updated":"2023-11-21T14:59:37Z","published":"2023-04-24T11:44:00Z","title":"Multi-channel Speech Separation Using Spatially Selective Deep\n  Non-linear Filters","summary":"  In a multi-channel separation task with multiple speakers, we aim to recover\nall individual speech signals from the mixture. In contrast to single-channel\napproaches, which rely on the different spectro-temporal characteristics of the\nspeech signals, multi-channel approaches should additionally utilize the\ndifferent spatial locations of the sources for a more powerful separation\nespecially when the number of sources increases. To enhance the spatial\nprocessing in a multi-channel source separation scenario, in this work, we\npropose a deep neural network (DNN) based spatially selective filter (SSF) that\ncan be spatially steered to extract the speaker of interest by initializing a\nrecurrent neural network layer with the target direction. We compare the\nproposed SSF with a common end-to-end direct separation (DS) approach trained\nusing utterance-wise permutation invariant training (PIT), which only\nimplicitly learns to perform spatial filtering. We show that the SSF has a\nclear advantage over a DS approach with the same underlying network\narchitecture when there are more than two speakers in the mixture, which can be\nattributed to a better use of the spatial information. Furthermore, we find\nthat the SSF generalizes much better to additional noise sources that were not\nseen during training and to scenarios with speakers positioned at a similar\nangle.\n","authors":["Kristina Tesch","Timo Gerkmann"],"pdf_url":"https://arxiv.org/pdf/2304.12023v2.pdf","comment":"Accepted version"},{"id":"http://arxiv.org/abs/2302.04181v2","updated":"2023-11-21T14:56:21Z","published":"2023-02-08T16:40:11Z","title":"Attending to Graph Transformers","summary":"  Recently, transformer architectures for graphs emerged as an alternative to\nestablished techniques for machine learning with graphs, such as\n(message-passing) graph neural networks. So far, they have shown promising\nempirical results, e.g., on molecular prediction datasets, often attributed to\ntheir ability to circumvent graph neural networks' shortcomings, such as\nover-smoothing and over-squashing. Here, we derive a taxonomy of graph\ntransformer architectures, bringing some order to this emerging field. We\noverview their theoretical properties, survey structural and positional\nencodings, and discuss extensions for important graph classes, e.g., 3D\nmolecular graphs. Empirically, we probe how well graph transformers can recover\nvarious graph properties, how well they can deal with heterophilic graphs, and\nto what extent they prevent over-squashing. Further, we outline open challenges\nand research direction to stimulate future work. Our code is available at\nhttps://github.com/luis-mueller/probing-graph-transformers.\n","authors":["Luis Müller","Mikhail Galkin","Christopher Morris","Ladislav Rampášek"],"pdf_url":"https://arxiv.org/pdf/2302.04181v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.04158v2","updated":"2023-11-21T14:55:52Z","published":"2023-11-07T17:34:56Z","title":"Computing Approximate $\\ell_p$ Sensitivities","summary":"  Recent works in dimensionality reduction for regression tasks have introduced\nthe notion of sensitivity, an estimate of the importance of a specific\ndatapoint in a dataset, offering provable guarantees on the quality of the\napproximation after removing low-sensitivity datapoints via subsampling.\nHowever, fast algorithms for approximating $\\ell_p$ sensitivities, which we\nshow is equivalent to approximate $\\ell_p$ regression, are known for only the\n$\\ell_2$ setting, in which they are termed leverage scores.\n  In this work, we provide efficient algorithms for approximating $\\ell_p$\nsensitivities and related summary statistics of a given matrix. In particular,\nfor a given $n \\times d$ matrix, we compute $\\alpha$-approximation to its\n$\\ell_1$ sensitivities at the cost of $O(n/\\alpha)$ sensitivity computations.\nFor estimating the total $\\ell_p$ sensitivity (i.e. the sum of $\\ell_p$\nsensitivities), we provide an algorithm based on importance sampling of\n$\\ell_p$ Lewis weights, which computes a constant factor approximation to the\ntotal sensitivity at the cost of roughly $O(\\sqrt{d})$ sensitivity\ncomputations. Furthermore, we estimate the maximum $\\ell_1$ sensitivity, up to\na $\\sqrt{d}$ factor, using $O(d)$ sensitivity computations. We generalize all\nthese results to $\\ell_p$ norms for $p > 1$. Lastly, we experimentally show\nthat for a wide class of matrices in real-world datasets, the total sensitivity\ncan be quickly approximated and is significantly smaller than the theoretical\nprediction, demonstrating that real-world datasets have low intrinsic effective\ndimensionality.\n","authors":["Swati Padmanabhan","David P. Woodruff","Qiuyi Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.04158v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12652v1","updated":"2023-11-21T14:53:39Z","published":"2023-11-21T14:53:39Z","title":"FedDRO: Federated Compositional Optimization for Distributionally Robust\n  Learning","summary":"  Recently, compositional optimization (CO) has gained popularity because of\nits applications in distributionally robust optimization (DRO) and many other\nmachine learning problems. Large-scale and distributed availability of data\ndemands the development of efficient federated learning (FL) algorithms for\nsolving CO problems. Developing FL algorithms for CO is particularly\nchallenging because of the compositional nature of the objective. Moreover,\ncurrent state-of-the-art methods to solve such problems rely on large batch\ngradients (depending on the solution accuracy) not feasible for most practical\nsettings. To address these challenges, in this work, we propose efficient\nFedAvg-type algorithms for solving non-convex CO in the FL setting. We first\nestablish that vanilla FedAvg is not suitable to solve distributed CO problems\nbecause of the data heterogeneity in the compositional objective at each client\nwhich leads to the amplification of bias in the local compositional gradient\nestimates. To this end, we propose a novel FL framework FedDRO that utilizes\nthe DRO problem structure to design a communication strategy that allows FedAvg\nto control the bias in the estimation of the compositional gradient. A key\nnovelty of our work is to develop solution accuracy-independent algorithms that\ndo not require large batch gradients (and function evaluations) for solving\nfederated CO problems. We establish $\\mathcal{O}(\\epsilon^{-2})$ sample and\n$\\mathcal{O}(\\epsilon^{-3/2})$ communication complexity in the FL setting while\nachieving linear speedup with the number of clients. We corroborate our\ntheoretical findings with empirical studies on large-scale DRO problems.\n","authors":["Prashant Khanduri","Chengyin Li","Rafi Ibn Sultan","Yao Qiang","Joerg Kliewer","Dongxiao Zhu"],"pdf_url":"https://arxiv.org/pdf/2311.12652v1.pdf","comment":"38 Pages, 6 Figures"},{"id":"http://arxiv.org/abs/2310.19805v3","updated":"2023-11-21T14:50:12Z","published":"2023-10-07T00:02:05Z","title":"Sample Efficient Reward Augmentation in offline-to-online Reinforcement\n  Learning","summary":"  Offline-to-online RL can make full use of pre-collected offline datasets to\ninitialize policies, resulting in higher sample efficiency and better\nperformance compared to only using online algorithms alone for policy training.\nHowever, direct fine-tuning of the pre-trained policy tends to result in\nsub-optimal performance. A primary reason is that conservative offline RL\nmethods diminish the agent's capability of exploration, thereby impacting\nonline fine-tuning performance. To encourage agent's exploration during online\nfine-tuning and enhance the overall online fine-tuning performance, we propose\na generalized reward augmentation method called Sample Efficient Reward\nAugmentation (SERA). Specifically, SERA encourages agent to explore by\ncomputing Q conditioned entropy as intrinsic reward. The advantage of SERA is\nthat it can extensively utilize offline pre-trained Q to encourage agent\nuniformly coverage of state space while considering the imbalance between the\ndistributions of high-value and low-value states. Additionally, SERA can be\neffortlessly plugged into various RL algorithms to improve online fine-tuning\nand ensure sustained asymptotic improvement. Moreover, extensive experimental\nresults demonstrate that when conducting offline-to-online problems, SERA\nconsistently and effectively enhances the performance of various offline\nalgorithms.\n","authors":["Ziqi Zhang","Xiao Xiong","Zifeng Zhuang","Jinxin Liu","Donglin Wang"],"pdf_url":"https://arxiv.org/pdf/2310.19805v3.pdf","comment":"23 pages, 11 Figures, and 6 Tables"},{"id":"http://arxiv.org/abs/2311.12644v1","updated":"2023-11-21T14:44:51Z","published":"2023-11-21T14:44:51Z","title":"Careful Selection and Thoughtful Discarding: Graph Explicit Pooling\n  Utilizing Discarded Nodes","summary":"  Graph pooling has been increasingly recognized as crucial for Graph Neural\nNetworks (GNNs) to facilitate hierarchical graph representation learning.\nExisting graph pooling methods commonly consist of two stages: selecting\ntop-ranked nodes and discarding the remaining to construct coarsened graph\nrepresentations. However, this paper highlights two key issues with these\nmethods: 1) The process of selecting nodes to discard frequently employs\nadditional Graph Convolutional Networks or Multilayer Perceptrons, lacking a\nthorough evaluation of each node's impact on the final graph representation and\nsubsequent prediction tasks. 2) Current graph pooling methods tend to directly\ndiscard the noise segment (dropped) of the graph without accounting for the\nlatent information contained within these elements. To address the first issue,\nwe introduce a novel Graph Explicit Pooling (GrePool) method, which selects\nnodes by explicitly leveraging the relationships between the nodes and final\nrepresentation vectors crucial for classification. The second issue is\naddressed using an extended version of GrePool (i.e., GrePool+), which applies\na uniform loss on the discarded nodes. This addition is designed to augment the\ntraining process and improve classification accuracy. Furthermore, we conduct\ncomprehensive experiments across 12 widely used datasets to validate our\nproposed method's effectiveness, including the Open Graph Benchmark datasets.\nOur experimental results uniformly demonstrate that GrePool outperforms 14\nbaseline methods for most datasets. Likewise, implementing GrePool+ enhances\nGrePool's performance without incurring additional computational costs.\n","authors":["Chuang Liu","Wenhang Yu","Kuang Gao","Xueqi Ma","Yibing Zhan","Jia Wu","Bo Du","Wenbin Hu"],"pdf_url":"https://arxiv.org/pdf/2311.12644v1.pdf","comment":"14 pages, 7 figures, 4 tables. Submitting to Science China\n  Information Sciences"},{"id":"http://arxiv.org/abs/2311.12630v1","updated":"2023-11-21T14:24:21Z","published":"2023-11-21T14:24:21Z","title":"Hierarchical Joint Graph Learning and Multivariate Time Series\n  Forecasting","summary":"  Multivariate time series is prevalent in many scientific and industrial\ndomains. Modeling multivariate signals is challenging due to their long-range\ntemporal dependencies and intricate interactions--both direct and indirect. To\nconfront these complexities, we introduce a method of representing multivariate\nsignals as nodes in a graph with edges indicating interdependency between them.\nSpecifically, we leverage graph neural networks (GNN) and attention mechanisms\nto efficiently learn the underlying relationships within the time series data.\nMoreover, we suggest employing hierarchical signal decompositions running over\nthe graphs to capture multiple spatial dependencies. The effectiveness of our\nproposed model is evaluated across various real-world benchmark datasets\ndesigned for long-term forecasting tasks. The results consistently showcase the\nsuperiority of our model, achieving an average 23\\% reduction in mean squared\nerror (MSE) compared to existing models.\n","authors":["Juhyeon Kim","Hyungeun Lee","Seungwon Yu","Ung Hwang","Wooyul Jung","Miseon Park","Kijung Yoon"],"pdf_url":"https://arxiv.org/pdf/2311.12630v1.pdf","comment":"Temporal Graph Learning Workshop @ NeurIPS 2023, New Orleans, United\n  States"},{"id":"http://arxiv.org/abs/2311.12624v1","updated":"2023-11-21T14:18:28Z","published":"2023-11-21T14:18:28Z","title":"Bridging Algorithmic Information Theory and Machine Learning: A New\n  Approach to Kernel Learning","summary":"  Machine Learning (ML) and Algorithmic Information Theory (AIT) look at\nComplexity from different points of view. We explore the interface between AIT\nand Kernel Methods (that are prevalent in ML) by adopting an AIT perspective on\nthe problem of learning kernels from data, in kernel ridge regression, through\nthe method of Sparse Kernel Flows. In particular, by looking at the differences\nand commonalities between Minimal Description Length (MDL) and Regularization\nin Machine Learning (RML), we prove that the method of Sparse Kernel Flows is\nthe natural approach to adopt to learn kernels from data. This paper shows that\nit is not necessary to use the statistical route to derive Sparse Kernel Flows\nand that one can directly work with code-lengths and complexities that are\nconcepts that show up in AIT.\n","authors":["Boumediene Hamzi","Marcus Hutter","Houman Owhadi"],"pdf_url":"https://arxiv.org/pdf/2311.12624v1.pdf","comment":"An earlier version of this paper appeared at\n  https://www.researchgate.net/publication/371875631_A_note_on_learning_kernels_from_data_from_an_Algorithmic_Information_Theoretic_point_of_view.\n  arXiv admin note: text overlap with arXiv:2111.13037, arXiv:2007.05074"},{"id":"http://arxiv.org/abs/2306.03163v2","updated":"2023-11-21T14:10:03Z","published":"2023-06-05T18:17:37Z","title":"How Can We Train Deep Learning Models Across Clouds and Continents? An\n  Experimental Study","summary":"  Training deep learning models in the cloud or on dedicated hardware is\nexpensive. A more cost-efficient option are hyperscale clouds offering spot\ninstances, a cheap but ephemeral alternative to on-demand resources. As spot\ninstance availability can change depending on the time of day, continent, and\ncloud provider, it could be more cost-efficient to distribute resources over\nthe world. Still, it has not been investigated whether geo-distributed,\ndata-parallel spot deep learning training could be a more cost-efficient\nalternative to centralized training.\n  This paper aims to answer the question: Can deep learning models be\ncost-efficiently trained on a global market of spot VMs spanning different data\ncenters and cloud providers? To provide guidance, we extensively evaluate the\ncost and throughput implications of training in different zones, continents,\nand clouds for representative CV, NLP and ASR models. To expand the current\ntraining options further, we compare the scalability potential for hybrid-cloud\nscenarios by adding cloud resources to on-premise hardware to improve training\nthroughput. Finally, we show how leveraging spot instance pricing enables a new\ncost-efficient way to train models with multiple cheap VMs, trumping both more\ncentralized and powerful hardware and even on-demand cloud offerings at\ncompetitive prices.\n","authors":["Alexander Isenko","Ruben Mayer","Hans-Arno Jacobsen"],"pdf_url":"https://arxiv.org/pdf/2306.03163v2.pdf","comment":"Currently in review. Artifacts and Code:\n  https://github.com/cirquit/hivemind-multi-cloud"},{"id":"http://arxiv.org/abs/2211.07931v3","updated":"2023-11-21T13:59:55Z","published":"2022-11-15T06:30:57Z","title":"Personalized Federated Learning with Multi-branch Architecture","summary":"  Federated learning (FL) is a decentralized machine learning technique that\nenables multiple clients to collaboratively train models without requiring\nclients to reveal their raw data to each other. Although traditional FL trains\na single global model with average performance among clients, statistical data\nheterogeneity across clients has resulted in the development of personalized FL\n(PFL), which trains personalized models with good performance on each client's\ndata. A key challenge with PFL is how to facilitate clients with similar data\nto collaborate more in a situation where each client has data from complex\ndistribution and cannot determine one another's distribution. In this paper, we\npropose a new PFL method (pFedMB) using multi-branch architecture, which\nachieves personalization by splitting each layer of a neural network into\nmultiple branches and assigning client-specific weights to each branch. We also\ndesign an aggregation method to improve the communication efficiency and the\nmodel performance, with which each branch is globally updated with weighted\naveraging by client-specific weights assigned to the branch. pFedMB is simple\nbut effective in facilitating each client to share knowledge with similar\nclients by adjusting the weights assigned to each branch. We experimentally\nshow that pFedMB performs better than the state-of-the-art PFL methods using\nthe CIFAR10 and CIFAR100 datasets.\n","authors":["Junki Mori","Tomoyuki Yoshiyama","Furukawa Ryo","Isamu Teranishi"],"pdf_url":"https://arxiv.org/pdf/2211.07931v3.pdf","comment":"Published at IJCNN 2023"},{"id":"http://arxiv.org/abs/2311.12615v1","updated":"2023-11-21T13:59:00Z","published":"2023-11-21T13:59:00Z","title":"Koopman Learning with Episodic Memory","summary":"  Koopman operator theory, a data-driven dynamical systems framework, has found\nsignificant success in learning models from complex, real-world data sets,\nenabling state-of-the-art prediction and control. The greater interpretability\nand lower computational costs of these models, compared to traditional machine\nlearning methodologies, make Koopman learning an especially appealing approach.\nDespite this, little work has been performed on endowing Koopman learning with\nthe ability to learn from its own mistakes. To address this, we equip Koopman\nmethods - developed for predicting non-stationary time-series - with an\nepisodic memory mechanism, enabling global recall of (or attention to) periods\nin time where similar dynamics previously occurred. We find that a basic\nimplementation of Koopman learning with episodic memory leads to significant\nimprovements in prediction on synthetic and real-world data. Our framework has\nconsiderable potential for expansion, allowing for future advances, and opens\nexciting new directions for Koopman learning.\n","authors":["William T. Redman","Dean Huang","Maria Fonoberova","Igor Mezić"],"pdf_url":"https://arxiv.org/pdf/2311.12615v1.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2310.10837v3","updated":"2023-11-21T13:58:00Z","published":"2023-10-16T21:23:16Z","title":"Approximating Two-Layer Feedforward Networks for Efficient Transformers","summary":"  How to reduce compute and memory requirements of neural networks (NNs)\nwithout sacrificing performance? Many recent works use sparse Mixtures of\nExperts (MoEs) to build resource-efficient large language models (LMs). Here we\nintroduce several novel perspectives on MoEs, presenting a general framework\nthat unifies various methods to approximate two-layer NNs (e.g., feedforward\nblocks of Transformers), including product-key memories (PKMs). Leveraging\ninsights from this framework, we propose methods to improve both MoEs and PKMs.\nUnlike prior work that compares MoEs with dense baselines under the\ncompute-equal condition, our evaluation condition is parameter-equal, which is\ncrucial to properly evaluate LMs. We show that our MoEs are competitive with\nthe dense Transformer-XL on both the WikiText-103 and enwiki8 datasets at two\ndifferent scales, while being much more resource efficient. This demonstrates\nthat MoEs are relevant not only to extremely large LMs but also to any-scale\nresource-efficient LMs. Our code is public.\n","authors":["Róbert Csordás","Kazuki Irie","Jürgen Schmidhuber"],"pdf_url":"https://arxiv.org/pdf/2310.10837v3.pdf","comment":"Accepted to EMNLP 2023 Findings"},{"id":"http://arxiv.org/abs/2311.12613v1","updated":"2023-11-21T13:56:44Z","published":"2023-11-21T13:56:44Z","title":"Decentralised Q-Learning for Multi-Agent Markov Decision Processes with\n  a Satisfiability Criterion","summary":"  In this paper, we propose a reinforcement learning algorithm to solve a\nmulti-agent Markov decision process (MMDP). The goal, inspired by Blackwell's\nApproachability Theorem, is to lower the time average cost of each agent to\nbelow a pre-specified agent-specific bound. For the MMDP, we assume the state\ndynamics to be controlled by the joint actions of agents, but the per-stage\ncosts to only depend on the individual agent's actions. We combine the\nQ-learning algorithm for a weighted combination of the costs of each agent,\nobtained by a gossip algorithm with the Metropolis-Hastings or Multiplicative\nWeights formalisms to modulate the averaging matrix of the gossip. We use\nmultiple timescales in our algorithm and prove that under mild conditions, it\napproximately achieves the desired bounds for each of the agents. We also\ndemonstrate the empirical performance of this algorithm in the more general\nsetting of MMDPs having jointly controlled per-stage costs.\n","authors":["Keshav P. Keval","Vivek S. Borkar"],"pdf_url":"https://arxiv.org/pdf/2311.12613v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.05858v2","updated":"2023-11-21T13:55:33Z","published":"2023-11-10T03:54:40Z","title":"Layer-wise Auto-Weighting for Non-Stationary Test-Time Adaptation","summary":"  Given the inevitability of domain shifts during inference in real-world\napplications, test-time adaptation (TTA) is essential for model adaptation\nafter deployment. However, the real-world scenario of continuously changing\ntarget distributions presents challenges including catastrophic forgetting and\nerror accumulation. Existing TTA methods for non-stationary domain shifts,\nwhile effective, incur excessive computational load, making them impractical\nfor on-device settings. In this paper, we introduce a layer-wise auto-weighting\nalgorithm for continual and gradual TTA that autonomously identifies layers for\npreservation or concentrated adaptation. By leveraging the Fisher Information\nMatrix (FIM), we first design the learning weight to selectively focus on\nlayers associated with log-likelihood changes while preserving unrelated ones.\nThen, we further propose an exponential min-max scaler to make certain layers\nnearly frozen while mitigating outliers. This minimizes forgetting and error\naccumulation, leading to efficient adaptation to non-stationary target\ndistribution. Experiments on CIFAR-10C, CIFAR-100C, and ImageNet-C show our\nmethod outperforms conventional continual and gradual TTA approaches while\nsignificantly reducing computational load, highlighting the importance of\nFIM-based learning weight in adapting to continuously or gradually shifting\ntarget domains.\n","authors":["Junyoung Park","Jin Kim","Hyeongjun Kwon","Ilhoon Yoon","Kwanghoon Sohn"],"pdf_url":"https://arxiv.org/pdf/2311.05858v2.pdf","comment":"Accepted to WACV 2024"},{"id":"http://arxiv.org/abs/2308.07121v2","updated":"2023-11-21T13:55:04Z","published":"2023-08-14T13:06:10Z","title":"Active Bird2Vec: Towards End-to-End Bird Sound Monitoring with\n  Transformers","summary":"  We propose a shift towards end-to-end learning in bird sound monitoring by\ncombining self-supervised (SSL) and deep active learning (DAL). Leveraging\ntransformer models, we aim to bypass traditional spectrogram conversions,\nenabling direct raw audio processing. ActiveBird2Vec is set to generate\nhigh-quality bird sound representations through SSL, potentially accelerating\nthe assessment of environmental changes and decision-making processes for wind\nfarms. Additionally, we seek to utilize the wide variety of bird vocalizations\nthrough DAL, reducing the reliance on extensively labeled datasets by human\nexperts. We plan to curate a comprehensive set of tasks through Huggingface\nDatasets, enhancing future comparability and reproducibility of bioacoustic\nresearch. A comparative analysis between various transformer models will be\nconducted to evaluate their proficiency in bird sound recognition tasks. We aim\nto accelerate the progression of avian bioacoustic research and contribute to\nmore effective conservation strategies.\n","authors":["Lukas Rauch","Raphael Schwinger","Moritz Wirth","Bernhard Sick","Sven Tomforde","Christoph Scholz"],"pdf_url":"https://arxiv.org/pdf/2308.07121v2.pdf","comment":"Accepted @AI4S ECAI2023. This is the author's version of the work"},{"id":"http://arxiv.org/abs/2311.12612v1","updated":"2023-11-21T13:54:08Z","published":"2023-11-21T13:54:08Z","title":"A New Type Of Upper And Lower Bounds On Right-Tail Probabilities Of\n  Continuous Random Variables","summary":"  In this paper, I present a completely new type of upper and lower bounds on\nthe right-tail probabilities of continuous random variables with unbounded\nsupport and with semi-bounded support from the left. The presented upper and\nlower right-tail bounds depend only on the probability density function (PDF),\nits first derivative, and two parameters that are used for tightening the\nbounds. These tail bounds hold under certain conditions that depend on the PDF,\nits first and second derivatives, and the two parameters. The new tail bounds\nare shown to be tight for a wide range of continuous random variables via\nnumerical examples.\n","authors":["Nikola Zlatanov"],"pdf_url":"https://arxiv.org/pdf/2311.12612v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.07955v2","updated":"2023-11-21T13:53:36Z","published":"2023-04-17T02:50:18Z","title":"Heterogeneous Domain Adaptation with Positive and Unlabeled Data","summary":"  Heterogeneous unsupervised domain adaptation (HUDA) is the most challenging\ndomain adaptation setting where the feature spaces of source and target domains\nare heterogeneous, and the target domain has only unlabeled data. Existing HUDA\nmethods assume that both positive and negative examples are available in the\nsource domain, which may not be satisfied in some real applications. This paper\naddresses a new challenging setting called positive and unlabeled heterogeneous\nunsupervised domain adaptation (PU-HUDA), a HUDA setting where the source\ndomain only has positives. PU-HUDA can also be viewed as an extension of PU\nlearning where the positive and unlabeled examples are sampled from different\ndomains. A naive combination of existing HUDA and PU learning methods is\nineffective in PU-HUDA due to the gap in label distribution between the source\nand target domains. To overcome this issue, we propose a novel method,\npredictive adversarial domain adaptation (PADA), which can predict likely\npositive examples from the unlabeled target data and simultaneously align the\nfeature spaces to reduce the distribution divergence between the whole source\ndata and the likely positive target data. PADA achieves this by a unified\nadversarial training framework for learning a classifier to predict positive\nexamples and a feature transformer to transform the target feature space to\nthat of the source. Specifically, they are both trained to fool a common\ndiscriminator that determines whether the likely positive examples are from the\ntarget or source domain. We experimentally show that PADA outperforms several\nbaseline methods, such as the naive combination of HUDA and PU learning.\n","authors":["Junki Mori","Ryo Furukawa","Isamu Teranishi","Jun Sakuma"],"pdf_url":"https://arxiv.org/pdf/2304.07955v2.pdf","comment":"Accepted by IEEE Big Data 2023 as a regular paper"},{"id":"http://arxiv.org/abs/2311.12602v1","updated":"2023-11-21T13:43:06Z","published":"2023-11-21T13:43:06Z","title":"TouchSDF: A DeepSDF Approach for 3D Shape Reconstruction using\n  Vision-Based Tactile Sensing","summary":"  Humans rely on their visual and tactile senses to develop a comprehensive 3D\nunderstanding of their physical environment. Recently, there has been a growing\ninterest in exploring and manipulating objects using data-driven approaches\nthat utilise high-resolution vision-based tactile sensors. However, 3D shape\nreconstruction using tactile sensing has lagged behind visual shape\nreconstruction because of limitations in existing techniques, including the\ninability to generalise over unseen shapes, the absence of real-world testing,\nand limited expressive capacity imposed by discrete representations. To address\nthese challenges, we propose TouchSDF, a Deep Learning approach for tactile 3D\nshape reconstruction that leverages the rich information provided by a\nvision-based tactile sensor and the expressivity of the implicit neural\nrepresentation DeepSDF. Our technique consists of two components: (1) a\nConvolutional Neural Network that maps tactile images into local meshes\nrepresenting the surface at the touch location, and (2) an implicit neural\nfunction that predicts a signed distance function to extract the desired 3D\nshape. This combination allows TouchSDF to reconstruct smooth and continuous 3D\nshapes from tactile inputs in simulation and real-world settings, opening up\nresearch avenues for robust 3D-aware representations and improved multimodal\nperception in robotics. Code and supplementary material are available at:\nhttps://touchsdf.github.io/\n","authors":["Mauro Comi","Yijiong Lin","Alex Church","Alessio Tonioni","Laurence Aitchison","Nathan F. Lepora"],"pdf_url":"https://arxiv.org/pdf/2311.12602v1.pdf","comment":"10 pages, 8 figures"},{"id":"http://arxiv.org/abs/2311.12601v1","updated":"2023-11-21T13:42:40Z","published":"2023-11-21T13:42:40Z","title":"Deep learning-based detection of morphological features associated with\n  hypoxia in H&E breast cancer whole slide images","summary":"  Hypoxia occurs when tumour cells outgrow their blood supply, leading to\nregions of low oxygen levels within the tumour. Calculating hypoxia levels can\nbe an important step in understanding the biology of tumours, their clinical\nprogression and response to treatment. This study demonstrates a novel\napplication of deep learning to evaluate hypoxia in the context of breast\ncancer histomorphology. More precisely, we show that Weakly Supervised Deep\nLearning (WSDL) models can accurately detect hypoxia associated features in\nroutine Hematoxylin and Eosin (H&E) whole slide images (WSI). We trained and\nevaluated a deep Multiple Instance Learning model on tiles from WSI H&E tissue\nfrom breast cancer primary sites (n=240) obtaining on average an AUC of 0.87 on\na left-out test set. We also showed significant differences between features of\nhypoxic and normoxic tissue regions as distinguished by the WSDL models. Such\nDL hypoxia H&E WSI detection models could potentially be extended to other\ntumour types and easily integrated into the pathology workflow without\nrequiring additional costly assays.\n","authors":["Petru Manescu","Joseph Geradts","Delmiro Fernandez-Reyes"],"pdf_url":"https://arxiv.org/pdf/2311.12601v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2310.17355v2","updated":"2023-11-21T13:27:01Z","published":"2023-10-26T12:44:33Z","title":"Exploring the Trie of Rules: a fast data structure for the\n  representation of association rules","summary":"  Association rule mining techniques can generate a large volume of sequential\ndata when implemented on transactional databases. Extracting insights from a\nlarge set of association rules has been found to be a challenging process. When\nexamining a ruleset, the fundamental question is how to summarise and represent\nmeaningful mined knowledge efficiently. Many algorithms and strategies have\nbeen developed to address issue of knowledge extraction; however, the\neffectiveness of this process can be limited by the data structures. A better\ndata structure can sufficiently affect the speed of the knowledge extraction\nprocess. This paper proposes a novel data structure, called the Trie of rules,\nfor storing a ruleset that is generated by association rule mining. The\nresulting data structure is a prefix-tree graph structure made of pre-mined\nrules. This graph stores the rules as paths within the prefix-tree in a way\nthat similar rules overlay each other. Each node in the tree represents a rule\nwhere a consequent is this node, and an antecedent is a path from this node to\nthe root of the tree. The evaluation showed that the proposed representation\ntechnique is promising. It compresses a ruleset with almost no data loss and\nbenefits in terms of time for basic operations such as searching for a specific\nrule and sorting, which is the base for many knowledge discovery methods.\nMoreover, our method demonstrated a significant improvement in traversing time,\nachieving an 8-fold increase compared to traditional data structures.\n","authors":["Mikhail Kudriavtsev","Marija Bezbradica","Andrew McCarren"],"pdf_url":"https://arxiv.org/pdf/2310.17355v2.pdf","comment":"12 pages, 13 figures, preprint of journal article"},{"id":"http://arxiv.org/abs/2311.12590v1","updated":"2023-11-21T13:26:33Z","published":"2023-11-21T13:26:33Z","title":"ChronoPscychosis: Temporal Segmentation and Its Impact on Schizophrenia\n  Classification Using Motor Activity Data","summary":"  Schizophrenia is a complicated mental illness characterized by a broad\nspectrum of symptoms affecting cognition, behavior, and emotion. The task of\nidentifying reliable biomarkers to classify Schizophrenia accurately continues\nto be a challenge in the field of psychiatry. We investigate the temporal\npatterns within the motor activity data as a potential key to enhancing the\ncategorization of individuals with Schizophrenia, using the dataset having\nmotor activity recordings of 22 Schizophrenia patients and 32 control subjects.\nThe dataset contains per-minute motor activity measurements collected for an\naverage of 12.7 days in a row for each participant. We dissect each day into\nsegments (Twelve, Eight, six, four, three, and two parts) and evaluate their\nimpact on classification. We employ sixteen statistical features within these\ntemporal segments and train them on Seven machine learning models to get deeper\ninsights. LightGBM model outperforms the other six models. Our results indicate\nthat the temporal segmentation significantly improves the classification, with\nAUC-ROC = 0.93, F1 score = 0.84( LightGBM- without any segmentation) and\nAUC-ROC = 0.98, F1 score = 0.93( LightGBM- with segmentation). Distinguishing\nbetween diurnal and nocturnal segments amplifies the differences between\nSchizophrenia patients and controls. However, further subdivisions into smaller\ntime segments do not affect the AUC- ROC significantly. Morning, afternoon,\nevening, and night partitioning gives similar classification performance to\nday-night partitioning. These findings are valuable as they indicate that\nextensive temporal classification beyond distinguishing between day and night\ndoes not yield substantial results, offering an efficient approach for further\nclassification, early diagnosis, and monitoring of Schizophrenia.\n","authors":["Pradnya Rajendra Jadhav","Raviprasad Aduri"],"pdf_url":"https://arxiv.org/pdf/2311.12590v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12589v1","updated":"2023-11-21T13:26:13Z","published":"2023-11-21T13:26:13Z","title":"Improving Source-Free Target Adaptation with Vision Transformers\n  Leveraging Domain Representation Images","summary":"  Unsupervised Domain Adaptation (UDA) methods facilitate knowledge transfer\nfrom a labeled source domain to an unlabeled target domain, navigating the\nobstacle of domain shift. While Convolutional Neural Networks (CNNs) are a\nstaple in UDA, the rise of Vision Transformers (ViTs) provides new avenues for\ndomain generalization. This paper presents an innovative method to bolster ViT\nperformance in source-free target adaptation, beginning with an evaluation of\nhow key, query, and value elements affect ViT outcomes. Experiments indicate\nthat altering the key component has negligible effects on Transformer\nperformance. Leveraging this discovery, we introduce Domain Representation\nImages (DRIs), feeding embeddings through the key element. DRIs act as\ndomain-specific markers, effortlessly merging with the training regimen. To\nassess our method, we perform target adaptation tests on the Cross Instance DRI\nsource-only (SO) control. We measure the efficacy of target adaptation with and\nwithout DRIs, against existing benchmarks like SHOT-B* and adaptations via\nCDTrans. Findings demonstrate that excluding DRIs offers limited gains over\nSHOT-B*, while their inclusion in the key segment boosts average precision\npromoting superior domain generalization. This research underscores the vital\nrole of DRIs in enhancing ViT efficiency in UDA scenarios, setting a precedent\nfor further domain adaptation explorations.\n","authors":["Gauransh Sawhney","Daksh Dave","Adeel Ahmed","Jiechao Gao","Khalid Saleem"],"pdf_url":"https://arxiv.org/pdf/2311.12589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.09355v5","updated":"2023-11-21T13:12:21Z","published":"2023-04-19T00:33:59Z","title":"To Compress or Not to Compress- Self-Supervised Learning and Information\n  Theory: A Review","summary":"  Deep neural networks excel in supervised learning tasks but are constrained\nby the need for extensive labeled data. Self-supervised learning emerges as a\npromising alternative, allowing models to learn without explicit labels.\nInformation theory, and notably the information bottleneck principle, has been\npivotal in shaping deep neural networks. This principle focuses on optimizing\nthe trade-off between compression and preserving relevant information,\nproviding a foundation for efficient network design in supervised contexts.\nHowever, its precise role and adaptation in self-supervised learning remain\nunclear. In this work, we scrutinize various self-supervised learning\napproaches from an information-theoretic perspective, introducing a unified\nframework that encapsulates the \\textit{self-supervised information-theoretic\nlearning problem}. We weave together existing research into a cohesive\nnarrative, delve into contemporary self-supervised methodologies, and spotlight\npotential research avenues and inherent challenges. Additionally, we discuss\nthe empirical evaluation of information-theoretic quantities and their\nestimation methods. Overall, this paper furnishes an exhaustive review of the\nintersection of information theory, self-supervised learning, and deep neural\nnetworks.\n","authors":["Ravid Shwartz-Ziv","Yann LeCun"],"pdf_url":"https://arxiv.org/pdf/2304.09355v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.11494v2","updated":"2023-11-21T13:11:36Z","published":"2023-07-21T10:56:36Z","title":"Predict, Refine, Synthesize: Self-Guiding Diffusion Models for\n  Probabilistic Time Series Forecasting","summary":"  Diffusion models have achieved state-of-the-art performance in generative\nmodeling tasks across various domains. Prior works on time series diffusion\nmodels have primarily focused on developing conditional models tailored to\nspecific forecasting or imputation tasks. In this work, we explore the\npotential of task-agnostic, unconditional diffusion models for several time\nseries applications. We propose TSDiff, an unconditionally-trained diffusion\nmodel for time series. Our proposed self-guidance mechanism enables\nconditioning TSDiff for downstream tasks during inference, without requiring\nauxiliary networks or altering the training procedure. We demonstrate the\neffectiveness of our method on three different time series tasks: forecasting,\nrefinement, and synthetic data generation. First, we show that TSDiff is\ncompetitive with several task-specific conditional forecasting methods\n(predict). Second, we leverage the learned implicit probability density of\nTSDiff to iteratively refine the predictions of base forecasters with reduced\ncomputational overhead over reverse diffusion (refine). Notably, the generative\nperformance of the model remains intact -- downstream forecasters trained on\nsynthetic samples from TSDiff outperform forecasters that are trained on\nsamples from other state-of-the-art generative time series models, occasionally\neven outperforming models trained on real data (synthesize).\n","authors":["Marcel Kollovieh","Abdul Fatir Ansari","Michael Bohlke-Schneider","Jasper Zschiegner","Hao Wang","Yuyang Wang"],"pdf_url":"https://arxiv.org/pdf/2307.11494v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12579v1","updated":"2023-11-21T12:50:24Z","published":"2023-11-21T12:50:24Z","title":"Machine-Guided Discovery of a Real-World Rogue Wave Model","summary":"  Big data and large-scale machine learning have had a profound impact on\nscience and engineering, particularly in fields focused on forecasting and\nprediction. Yet, it is still not clear how we can use the superior pattern\nmatching abilities of machine learning models for scientific discovery. This is\nbecause the goals of machine learning and science are generally not aligned. In\naddition to being accurate, scientific theories must also be causally\nconsistent with the underlying physical process and allow for human analysis,\nreasoning, and manipulation to advance the field. In this paper, we present a\ncase study on discovering a new symbolic model for oceanic rogue waves from\ndata using causal analysis, deep learning, parsimony-guided model selection,\nand symbolic regression. We train an artificial neural network on causal\nfeatures from an extensive dataset of observations from wave buoys, while\nselecting for predictive performance and causal invariance. We apply symbolic\nregression to distill this black-box model into a mathematical equation that\nretains the neural network's predictive capabilities, while allowing for\ninterpretation in the context of existing wave theory. The resulting model\nreproduces known behavior, generates well-calibrated probabilities, and\nachieves better predictive scores on unseen data than current theory. This\nshowcases how machine learning can facilitate inductive scientific discovery,\nand paves the way for more accurate rogue wave forecasting.\n","authors":["Dion Häfner","Johannes Gemmrich","Markus Jochum"],"pdf_url":"https://arxiv.org/pdf/2311.12579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02081v2","updated":"2023-11-21T12:43:30Z","published":"2022-12-05T07:52:08Z","title":"YolOOD: Utilizing Object Detection Concepts for Multi-Label\n  Out-of-Distribution Detection","summary":"  Out-of-distribution (OOD) detection has attracted a large amount of attention\nfrom the machine learning research community in recent years due to its\nimportance in deployed systems. Most of the previous studies focused on the\ndetection of OOD samples in the multi-class classification task. However, OOD\ndetection in the multi-label classification task, a more common real-world use\ncase, remains an underexplored domain. In this research, we propose YolOOD - a\nmethod that utilizes concepts from the object detection domain to perform OOD\ndetection in the multi-label classification task. Object detection models have\nan inherent ability to distinguish between objects of interest\n(in-distribution) and irrelevant objects (e.g., OOD objects) in images that\ncontain multiple objects belonging to different class categories. These\nabilities allow us to convert a regular object detection model into an image\nclassifier with inherent OOD detection capabilities with just minor changes. We\ncompare our approach to state-of-the-art OOD detection methods and demonstrate\nYolOOD's ability to outperform these methods on a comprehensive suite of\nin-distribution and OOD benchmark datasets.\n","authors":["Alon Zolfi","Guy Amit","Amit Baras","Satoru Koda","Ikuya Morikawa","Yuval Elovici","Asaf Shabtai"],"pdf_url":"https://arxiv.org/pdf/2212.02081v2.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.12573v1","updated":"2023-11-21T12:38:05Z","published":"2023-11-21T12:38:05Z","title":"Moderating Model Marketplaces: Platform Governance Puzzles for AI\n  Intermediaries","summary":"  The AI development community is increasingly making use of hosting\nintermediaries such as Hugging Face provide easy access to user-uploaded models\nand training data. These model marketplaces lower technical deployment barriers\nfor hundreds of thousands of users, yet can be used in numerous potentially\nharmful and illegal ways. In this article, we explain ways in which AI systems,\nwhich can both `contain' content and be open-ended tools, present one of the\ntrickiest platform governance challenges seen to date. We provide case studies\nof several incidents across three illustrative platforms -- Hugging Face,\nGitHub and Civitai -- to examine how model marketplaces moderate models.\nBuilding on this analysis, we outline important (and yet nevertheless limited)\npractices that industry has been developing to respond to moderation demands:\nlicensing, access and use restrictions, automated content moderation, and open\npolicy development. While the policy challenge at hand is a considerable one,\nwe conclude with some ideas as to how platforms could better mobilize resources\nto act as a careful, fair, and proportionate regulatory access point.\n","authors":["Robert Gorwa","Michael Veale"],"pdf_url":"https://arxiv.org/pdf/2311.12573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.08051v3","updated":"2023-11-21T12:36:49Z","published":"2023-10-12T05:52:54Z","title":"LGL-BCI: A Lightweight Geometric Learning Framework for Motor\n  Imagery-Based Brain-Computer Interfaces","summary":"  Brain-Computer Interfaces (BCIs) are a groundbreaking technology for\ninteracting with external devices using brain signals. Despite advancements,\nelectroencephalogram (EEG)-based Motor Imagery (MI) tasks face challenges like\namplitude and phase variability, and complex spatial correlations, with a need\nfor smaller model size and faster inference. This study introduces the LGL-BCI\nframework, employing a Geometric Deep Learning Framework for EEG processing in\nnon-Euclidean metric spaces, particularly the Symmetric Positive Definite (SPD)\nManifold space. LGL-BCI offers robust EEG data representation and captures\nspatial correlations. We propose an EEG channel selection solution via a\nfeature decomposition algorithm to reduce SPD matrix dimensionality, with a\nlossless transformation boosting inference speed. Extensive experiments show\nLGL-BCI's superior accuracy and efficiency compared to current solutions,\nhighlighting geometric deep learning's potential in MI-BCI applications. The\nefficiency, assessed on two public EEG datasets and two real-world EEG devices,\nsignificantly outperforms the state-of-the-art solution in accuracy ($82.54\\%$\nversus $62.22\\%$) with fewer parameters (64.9M compared to 183.7M).\n","authors":["Jianchao Lu","Yuzhe Tian","Yang Zhang","Jiaqi Ge","Quan Z. Sheng","Xi Zheng"],"pdf_url":"https://arxiv.org/pdf/2310.08051v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12570v1","updated":"2023-11-21T12:34:00Z","published":"2023-11-21T12:34:00Z","title":"BEND: Benchmarking DNA Language Models on biologically meaningful tasks","summary":"  The genome sequence contains the blueprint for governing cellular processes.\nWhile the availability of genomes has vastly increased over the last decades,\nexperimental annotation of the various functional, non-coding and regulatory\nelements encoded in the DNA sequence remains both expensive and challenging.\nThis has sparked interest in unsupervised language modeling of genomic DNA, a\nparadigm that has seen great success for protein sequence data. Although\nvarious DNA language models have been proposed, evaluation tasks often differ\nbetween individual works, and might not fully recapitulate the fundamental\nchallenges of genome annotation, including the length, scale and sparsity of\nthe data. In this study, we introduce BEND, a Benchmark for DNA language\nmodels, featuring a collection of realistic and biologically meaningful\ndownstream tasks defined on the human genome. We find that embeddings from\ncurrent DNA LMs can approach performance of expert methods on some tasks, but\nonly capture limited information about long-range features. BEND is available\nat https://github.com/frederikkemarin/BEND.\n","authors":["Frederikke Isa Marin","Felix Teufel","Marc Horrender","Dennis Madsen","Dennis Pultz","Ole Winther","Wouter Boomsma"],"pdf_url":"https://arxiv.org/pdf/2311.12570v1.pdf","comment":"10 pages, 1 figure, 3 tables, code available at\n  https://github.com/frederikkemarin/BEND"},{"id":"http://arxiv.org/abs/2311.12569v1","updated":"2023-11-21T12:32:38Z","published":"2023-11-21T12:32:38Z","title":"Differentiable Sampling of Categorical Distributions Using the\n  CatLog-Derivative Trick","summary":"  Categorical random variables can faithfully represent the discrete and\nuncertain aspects of data as part of a discrete latent variable model. Learning\nin such models necessitates taking gradients with respect to the parameters of\nthe categorical probability distributions, which is often intractable due to\ntheir combinatorial nature. A popular technique to estimate these otherwise\nintractable gradients is the Log-Derivative trick. This trick forms the basis\nof the well-known REINFORCE gradient estimator and its many extensions. While\nthe Log-Derivative trick allows us to differentiate through samples drawn from\ncategorical distributions, it does not take into account the discrete nature of\nthe distribution itself. Our first contribution addresses this shortcoming by\nintroducing the CatLog-Derivative trick - a variation of the Log-Derivative\ntrick tailored towards categorical distributions. Secondly, we use the\nCatLog-Derivative trick to introduce IndeCateR, a novel and unbiased gradient\nestimator for the important case of products of independent categorical\ndistributions with provably lower variance than REINFORCE. Thirdly, we\nempirically show that IndeCateR can be efficiently implemented and that its\ngradient estimates have significantly lower bias and variance for the same\nnumber of samples compared to the state of the art.\n","authors":["Lennert De Smet","Emanuele Sansone","Pedro Zuidberg Dos Martires"],"pdf_url":"https://arxiv.org/pdf/2311.12569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12566v1","updated":"2023-11-21T12:26:14Z","published":"2023-11-21T12:26:14Z","title":"Variational Elliptical Processes","summary":"  We present elliptical processes, a family of non-parametric probabilistic\nmodels that subsume Gaussian processes and Student's t processes. This\ngeneralization includes a range of new heavy-tailed behaviors while retaining\ncomputational tractability. Elliptical processes are based on a representation\nof elliptical distributions as a continuous mixture of Gaussian distributions.\nWe parameterize this mixture distribution as a spline normalizing flow, which\nwe train using variational inference. The proposed form of the variational\nposterior enables a sparse variational elliptical process applicable to\nlarge-scale problems. We highlight advantages compared to Gaussian processes\nthrough regression and classification experiments. Elliptical processes can\nsupersede Gaussian processes in several settings, including cases where the\nlikelihood is non-Gaussian or when accurate tail modeling is essential.\n","authors":["Maria Bånkestad","Jens Sjölund","Jalil Taghia","Thomas B. Schöon"],"pdf_url":"https://arxiv.org/pdf/2311.12566v1.pdf","comment":"14 pages, 15 figures, appendix 9 pages"},{"id":"http://arxiv.org/abs/2311.12564v1","updated":"2023-11-21T12:23:58Z","published":"2023-11-21T12:23:58Z","title":"Summary of the DISPLACE Challenge 2023 -- DIarization of SPeaker and\n  LAnguage in Conversational Environments","summary":"  In multi-lingual societies, where multiple languages are spoken in a small\ngeographic vicinity, informal conversations often involve mix of languages.\nExisting speech technologies may be inefficient in extracting information from\nsuch conversations, where the speech data is rich in diversity with multiple\nlanguages and speakers. The DISPLACE (DIarization of SPeaker and LAnguage in\nConversational Environments) challenge constitutes an open-call for evaluating\nand bench-marking the speaker and language diarization technologies on this\nchallenging condition. The challenge entailed two tracks: Track-1 focused on\nspeaker diarization (SD) in multilingual situations while, Track-2 addressed\nthe language diarization (LD) in a multi-speaker scenario. Both the tracks were\nevaluated using the same underlying audio data. To facilitate this evaluation,\na real-world dataset featuring multilingual, multi-speaker conversational\nfar-field speech was recorded and distributed. Furthermore, a baseline system\nwas made available for both SD and LD task which mimicked the state-of-art in\nthese tasks. The challenge garnered a total of $42$ world-wide registrations\nand received a total of $19$ combined submissions for Track-1 and Track-2. This\npaper describes the challenge, details of the datasets, tasks, and the baseline\nsystem. Additionally, the paper provides a concise overview of the submitted\nsystems in both tracks, with an emphasis given to the top performing systems.\nThe paper also presents insights and future perspectives for SD and LD tasks,\nfocusing on the key challenges that the systems need to overcome before\nwide-spread commercial deployment on such conversations.\n","authors":["Shikha Baghel","Shreyas Ramoji","Somil Jain","Pratik Roy Chowdhuri","Prachi Singh","Deepu Vijayasenan","Sriram Ganapathy"],"pdf_url":"https://arxiv.org/pdf/2311.12564v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.09076v2","updated":"2023-11-21T12:23:27Z","published":"2021-10-18T07:55:39Z","title":"An actor-critic algorithm with policy gradients to solve the job shop\n  scheduling problem using deep double recurrent agents","summary":"  There is a growing interest in integrating machine learning techniques and\noptimization to solve challenging optimization problems. In this work, we\npropose a deep reinforcement learning methodology for the job shop scheduling\nproblem (JSSP). The aim is to build up a greedy-like heuristic able to learn on\nsome distribution of JSSP instances, different in the number of jobs and\nmachines. The need for fast scheduling methods is well known, and it arises in\nmany areas, from transportation to healthcare. We model the JSSP as a Markov\nDecision Process and then we exploit the efficacy of reinforcement learning to\nsolve the problem. We adopt an actor-critic scheme, where the action taken by\nthe agent is influenced by policy considerations on the state-value function.\nThe procedures are adapted to take into account the challenging nature of JSSP,\nwhere the state and the action space change not only for every instance but\nalso after each decision. To tackle the variability in the number of jobs and\noperations in the input, we modeled the agent using two incident LSTM models, a\nspecial type of deep neural network. Experiments show the algorithm reaches\ngood solutions in a short time, proving that is possible to generate new greedy\nheuristics just from learning-based methodologies. Benchmarks have been\ngenerated in comparison with the commercial solver CPLEX. As expected, the\nmodel can generalize, to some extent, to larger problems or instances\noriginated by a different distribution from the one used in training.\n","authors":["Marta Monaci","Valerio Agasucci","Giorgio Grani"],"pdf_url":"https://arxiv.org/pdf/2110.09076v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.13193v2","updated":"2023-11-21T12:17:40Z","published":"2022-10-24T13:10:06Z","title":"Langevin dynamics based algorithm e-TH$\\varepsilon$O POULA for\n  stochastic optimization problems with discontinuous stochastic gradient","summary":"  We introduce a new Langevin dynamics based algorithm, called\ne-TH$\\varepsilon$O POULA, to solve optimization problems with discontinuous\nstochastic gradients which naturally appear in real-world applications such as\nquantile estimation, vector quantization, CVaR minimization, and regularized\noptimization problems involving ReLU neural networks. We demonstrate both\ntheoretically and numerically the applicability of the e-TH$\\varepsilon$O POULA\nalgorithm. More precisely, under the conditions that the stochastic gradient is\nlocally Lipschitz in average and satisfies a certain convexity at infinity\ncondition, we establish non-asymptotic error bounds for e-TH$\\varepsilon$O\nPOULA in Wasserstein distances and provide a non-asymptotic estimate for the\nexpected excess risk, which can be controlled to be arbitrarily small. Three\nkey applications in finance and insurance are provided, namely, multi-period\nportfolio optimization, transfer learning in multi-period portfolio\noptimization, and insurance claim prediction, which involve neural networks\nwith (Leaky)-ReLU activation functions. Numerical experiments conducted using\nreal-world datasets illustrate the superior empirical performance of\ne-TH$\\varepsilon$O POULA compared to SGLD, TUSLA, ADAM, and AMSGrad in terms of\nmodel accuracy.\n","authors":["Dong-Young Lim","Ariel Neufeld","Sotirios Sabanis","Ying Zhang"],"pdf_url":"https://arxiv.org/pdf/2210.13193v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12561v1","updated":"2023-11-21T12:15:28Z","published":"2023-11-21T12:15:28Z","title":"Convolutional Neural Networks for Neuroimaging in Parkinson's Disease:\n  Is Preprocessing Needed?","summary":"  Spatial and intensity normalization are nowadays a prerequisite for\nneuroimaging analysis. Influenced by voxel-wise and other univariate\ncomparisons, where these corrections are key, they are commonly applied to any\ntype of analysis and imaging modalities. Nuclear imaging modalities such as\nPET-FDG or FP-CIT SPECT, a common modality used in Parkinson's Disease\ndiagnosis, are especially dependent on intensity normalization. However, these\nsteps are computationally expensive and furthermore, they may introduce\ndeformations in the images, altering the information contained in them.\nConvolutional Neural Networks (CNNs), for their part, introduce position\ninvariance to pattern recognition, and have been proven to classify objects\nregardless of their orientation, size, angle, etc. Therefore, a question\narises: how well can CNNs account for spatial and intensity differences when\nanalysing nuclear brain imaging? Are spatial and intensity normalization still\nneeded? To answer this question, we have trained four different CNN models\nbased on well-established architectures, using or not different spatial and\nintensity normalization preprocessing. The results show that a sufficiently\ncomplex model such as our three-dimensional version of the ALEXNET can\neffectively account for spatial differences, achieving a diagnosis accuracy of\n94.1% with an area under the ROC curve of 0.984. The visualization of the\ndifferences via saliency maps shows that these models are correctly finding\npatterns that match those found in the literature, without the need of applying\nany complex spatial normalization procedure. However, the intensity\nnormalization -- and its type -- is revealed as very influential in the results\nand accuracy of the trained model, and therefore must be well accounted.\n","authors":["Francisco J. Martinez-Murcia","Juan M. Górriz","Javier Ramírez","Andrés Ortiz"],"pdf_url":"https://arxiv.org/pdf/2311.12561v1.pdf","comment":"19 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.12550v1","updated":"2023-11-21T11:59:16Z","published":"2023-11-21T11:59:16Z","title":"Explainable Anomaly Detection using Masked Latent Generative Modeling","summary":"  We present a novel time series anomaly detection method that achieves\nexcellent detection accuracy while offering a superior level of explainability.\nOur proposed method, TimeVQVAE-AD, leverages masked generative modeling adapted\nfrom the cutting-edge time series generation method known as TimeVQVAE. The\nprior model is trained on the discrete latent space of a time-frequency domain.\nNotably, the dimensional semantics of the time-frequency domain are preserved\nin the latent space, enabling us to compute anomaly scores across different\nfrequency bands, which provides a better insight into the detected anomalies.\nAdditionally, the generative nature of the prior model allows for sampling\nlikely normal states for detected anomalies, enhancing the explainability of\nthe detected anomalies through counterfactuals. Our experimental evaluation on\nthe UCR Time Series Anomaly archive demonstrates that TimeVQVAE-AD\nsignificantly surpasses the existing methods in terms of detection accuracy and\nexplainability.\n","authors":["Daesoo Lee","Sara Malacarne","Erlend Aune"],"pdf_url":"https://arxiv.org/pdf/2311.12550v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12538v1","updated":"2023-11-21T11:33:03Z","published":"2023-11-21T11:33:03Z","title":"In-Context Learning Functions with Varying Number of Minima","summary":"  Large Language Models (LLMs) have proven effective at In-Context Learning\n(ICL), an ability that allows them to create predictors from labeled examples.\nFew studies have explored the interplay between ICL and specific properties of\nfunctions it attempts to approximate. In our study, we use a formal framework\nto explore ICL and propose a new task of approximating functions with varying\nnumber of minima. We implement a method that allows for producing functions\nwith given inputs as minima. We find that increasing the number of minima\ndegrades ICL performance. At the same time, our evaluation shows that ICL\noutperforms 2-layer Neural Network (2NN) model. Furthermore, ICL learns faster\nthan 2NN in all settings. We validate the findings through a set of few-shot\nexperiments across various hyperparameter configurations.\n","authors":["David Oniani","Yanshan Wang"],"pdf_url":"https://arxiv.org/pdf/2311.12538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11899v3","updated":"2023-11-21T11:24:29Z","published":"2023-01-27T18:23:10Z","title":"Is TinyML Sustainable? Assessing the Environmental Impacts of Machine\n  Learning on Microcontrollers","summary":"  The sustained growth of carbon emissions and global waste elicits significant\nsustainability concerns for our environment's future. The growing Internet of\nThings (IoT) has the potential to exacerbate this issue. However, an emerging\narea known as Tiny Machine Learning (TinyML) has the opportunity to help\naddress these environmental challenges through sustainable computing practices.\nTinyML, the deployment of machine learning (ML) algorithms onto low-cost,\nlow-power microcontroller systems, enables on-device sensor analytics that\nunlocks numerous always-on ML applications. This article discusses both the\npotential of these TinyML applications to address critical sustainability\nchallenges, as well as the environmental footprint of this emerging technology.\nThrough a complete life cycle analysis (LCA), we find that TinyML systems\npresent opportunities to offset their carbon emissions by enabling applications\nthat reduce the emissions of other sectors. Nevertheless, when globally scaled,\nthe carbon footprint of TinyML systems is not negligible, necessitating that\ndesigners factor in environmental impact when formulating new devices. Finally,\nwe outline research directions to enable further sustainable contributions of\nTinyML.\n","authors":["Shvetank Prakash","Matthew Stewart","Colby Banbury","Mark Mazumder","Pete Warden","Brian Plancher","Vijay Janapa Reddi"],"pdf_url":"https://arxiv.org/pdf/2301.11899v3.pdf","comment":"Communications of the ACM (CACM) November 2023 Issue"},{"id":"http://arxiv.org/abs/2311.12530v1","updated":"2023-11-21T11:21:53Z","published":"2023-11-21T11:21:53Z","title":"An efficient likelihood-free Bayesian inference method based on\n  sequential neural posterior estimation","summary":"  Sequential neural posterior estimation (SNPE) techniques have been recently\nproposed for dealing with simulation-based models with intractable likelihoods.\nUnlike approximate Bayesian computation, SNPE techniques learn the posterior\nfrom sequential simulation using neural network-based conditional density\nestimators. This paper reclaims SNPE-B proposed by Lueckmann et al. (2017),\nwhich suffers from inefficiency and slow inference due to inefficient\nutilization of simulated data and high variance of parameter updates. To\naddress these issues, we firstly introduce a concentrated loss function based\non an adaptive calibration kernel that reweights the simulated data\nappropriately to improve the data efficiency. Moreover, we provide a\ntheoretical analysis of the variance of associated Monte Carlo estimators.\nBased on this analysis, we then propose several variance reduction techniques\nto further accelerate the process of learning. Numerical experiments\ndemonstrate that our method outperforms the original method together with other\nexisting competitors on certain tasks.\n","authors":["Yifei Xiong","Xiliang Yang","Sanguo Zhang","Zhijian He"],"pdf_url":"https://arxiv.org/pdf/2311.12530v1.pdf","comment":"29 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.12528v1","updated":"2023-11-21T11:15:14Z","published":"2023-11-21T11:15:14Z","title":"Inverse Problems with Learned Forward Operators","summary":"  Solving inverse problems requires knowledge of the forward operator, but\naccurate models can be computationally expensive and hence cheaper variants are\ndesired that do not compromise reconstruction quality. This chapter reviews\nreconstruction methods in inverse problems with learned forward operators that\nfollow two different paradigms. The first one is completely agnostic to the\nforward operator and learns its restriction to the subspace spanned by the\ntraining data. The framework of regularisation by projection is then used to\nfind a reconstruction. The second one uses a simplified model of the physics of\nthe measurement process and only relies on the training data to learn a model\ncorrection. We present the theory of these two approaches and compare them\nnumerically. A common theme emerges: both methods require, or at least benefit\nfrom, training data not only for the forward operator, but also for its\nadjoint.\n","authors":["Simon Arridge","Andreas Hauptmann","Yury Korolev"],"pdf_url":"https://arxiv.org/pdf/2311.12528v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12526v1","updated":"2023-11-21T11:12:03Z","published":"2023-11-21T11:12:03Z","title":"Neural Network Pruning by Gradient Descent","summary":"  The rapid increase in the parameters of deep learning models has led to\nsignificant costs, challenging computational efficiency and model\ninterpretability. In this paper, we introduce a novel and straightforward\nneural network pruning framework that incorporates the Gumbel-Softmax\ntechnique. This framework enables the simultaneous optimization of a network's\nweights and topology in an end-to-end process using stochastic gradient\ndescent. Empirical results demonstrate its exceptional compression capability,\nmaintaining high accuracy on the MNIST dataset with only 0.15\\% of the original\nnetwork parameters. Moreover, our framework enhances neural network\ninterpretability, not only by allowing easy extraction of feature importance\ndirectly from the pruned network but also by enabling visualization of feature\nsymmetry and the pathways of information propagation from features to outcomes.\nAlthough the pruning strategy is learned through deep learning, it is\nsurprisingly intuitive and understandable, focusing on selecting key\nrepresentative features and exploiting data patterns to achieve extreme sparse\npruning. We believe our method opens a promising new avenue for deep learning\npruning and the creation of interpretable machine learning systems.\n","authors":["Zhang Zhang","Ruyi Tao","Jiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12526v1.pdf","comment":"21 pages, 5 figures"},{"id":"http://arxiv.org/abs/2309.06255v2","updated":"2023-11-21T11:11:57Z","published":"2023-09-12T14:16:34Z","title":"Enhancing Multi-modal Cooperation via Fine-grained Modality Valuation","summary":"  One primary topic of multi-modal learning is to jointly incorporate\nheterogeneous information from different modalities. However, most models often\nsuffer from unsatisfactory multi-modal cooperation, which could not jointly\nutilize all modalities well. Some methods are proposed to identify and enhance\nthe worse learnt modality, but are often hard to provide the fine-grained\nobservation of multi-modal cooperation at sample-level with theoretical\nsupport. Hence, it is essential to reasonably observe and improve the\nfine-grained cooperation between modalities, especially when facing realistic\nscenarios where the modality discrepancy could vary across different samples.\nTo this end, we introduce a fine-grained modality valuation metric to evaluate\nthe contribution of each modality at sample-level. Via modality valuation, we\nregretfully observe that the multi-modal model tends to rely on one specific\nmodality, resulting in other modalities being low-contributing. We further\nanalyze this issue and improve cooperation between modalities by enhancing the\ndiscriminative ability of low-contributing modalities in a targeted manner.\nOverall, our methods reasonably observe the fine-grained uni-modal contribution\nat sample-level and achieve considerable improvement on different multi-modal\nmodels.\n","authors":["Yake Wei","Ruoxuan Feng","Zihe Wang","Di Hu"],"pdf_url":"https://arxiv.org/pdf/2309.06255v2.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2311.12524v1","updated":"2023-11-21T11:09:57Z","published":"2023-11-21T11:09:57Z","title":"ALPHA: AnomaLous Physiological Health Assessment Using Large Language\n  Models","summary":"  This study concentrates on evaluating the efficacy of Large Language Models\n(LLMs) in healthcare, with a specific focus on their application in personal\nanomalous health monitoring. Our research primarily investigates the\ncapabilities of LLMs in interpreting and analyzing physiological data obtained\nfrom FDA-approved devices. We conducted an extensive analysis using anomalous\nphysiological data gathered in a simulated low-air-pressure plateau\nenvironment. This allowed us to assess the precision and reliability of LLMs in\nunderstanding and evaluating users' health status with notable specificity. Our\nfindings reveal that LLMs exhibit exceptional performance in determining\nmedical indicators, including a Mean Absolute Error (MAE) of less than 1 beat\nper minute for heart rate and less than 1% for oxygen saturation (SpO2).\nFurthermore, the Mean Absolute Percentage Error (MAPE) for these evaluations\nremained below 1%, with the overall accuracy of health assessments surpassing\n85%. In image analysis tasks, such as interpreting photoplethysmography (PPG)\ndata, our specially adapted GPT models demonstrated remarkable proficiency,\nachieving less than 1 bpm error in cycle count and 7.28 MAE for heart rate\nestimation. This study highlights LLMs' dual role as health data analysis tools\nand pivotal elements in advanced AI health assistants, offering personalized\nhealth insights and recommendations within the future health assistant\nframework.\n","authors":["Jiankai Tang","Kegang Wang","Hongming Hu","Xiyuxing Zhang","Peiyu Wang","Xin Liu","Yuntao Wang"],"pdf_url":"https://arxiv.org/pdf/2311.12524v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.05587v2","updated":"2023-11-21T10:38:16Z","published":"2023-11-09T18:47:33Z","title":"Bayesian Methods for Media Mix Modelling with shape and funnel effects","summary":"  In recent years, significant progress in generative AI has highlighted the\nimportant role of physics-inspired models that utilize advanced mathematical\nconcepts based on fundamental physics principles to enhance artificial\nintelligence capabilities. Among these models, those based on diffusion\nequations have greatly improved image quality. This study aims to explore the\npotential uses of Maxwell-Boltzmann equation, which forms the basis of the\nkinetic theory of gases, and the Michaelis-Menten model in Marketing Mix\nModelling (MMM) applications. We propose incorporating these equations into\nHierarchical Bayesian models to analyse consumer behaviour in the context of\nadvertising. These equation sets excel in accurately describing the random\ndynamics in complex systems like social interactions and consumer-advertising\ninteractions.\n","authors":["Javier Marin"],"pdf_url":"https://arxiv.org/pdf/2311.05587v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12501v1","updated":"2023-11-21T10:20:34Z","published":"2023-11-21T10:20:34Z","title":"Fair Polylog-Approximate Low-Cost Hierarchical Clustering","summary":"  Research in fair machine learning, and particularly clustering, has been\ncrucial in recent years given the many ethical controversies that modern\nintelligent systems have posed. Ahmadian et al. [2020] established the study of\nfairness in \\textit{hierarchical} clustering, a stronger, more structured\nvariant of its well-known flat counterpart, though their proposed algorithm\nthat optimizes for Dasgupta's [2016] famous cost function was highly\ntheoretical. Knittel et al. [2023] then proposed the first practical fair\napproximation for cost, however they were unable to break the\npolynomial-approximate barrier they posed as a hurdle of interest. We break\nthis barrier, proposing the first truly polylogarithmic-approximate low-cost\nfair hierarchical clustering, thus greatly bridging the gap between the best\nfair and vanilla hierarchical clustering approximations.\n","authors":["Marina Knittel","Max Springer","John Dickerson","MohammadTaghi Hajiaghayi"],"pdf_url":"https://arxiv.org/pdf/2311.12501v1.pdf","comment":"Accepted to NeurIPS '23 (16 pages, 5 figures)"},{"id":"http://arxiv.org/abs/2311.12495v1","updated":"2023-11-21T10:11:19Z","published":"2023-11-21T10:11:19Z","title":"Multi-Objective Reinforcement Learning based on Decomposition: A\n  taxonomy and framework","summary":"  Multi-objective reinforcement learning (MORL) extends traditional RL by\nseeking policies making different compromises among conflicting objectives. The\nrecent surge of interest in MORL has led to diverse studies and solving\nmethods, often drawing from existing knowledge in multi-objective optimization\nbased on decomposition (MOO/D). Yet, a clear categorization based on both RL\nand MOO/D is lacking in the existing literature. Consequently, MORL researchers\nface difficulties when trying to classify contributions within a broader\ncontext due to the absence of a standardized taxonomy. To tackle such an issue,\nthis paper introduces Multi-Objective Reinforcement Learning based on\nDecomposition (MORL/D), a novel methodology bridging RL and MOO literature. A\ncomprehensive taxonomy for MORL/D is presented, providing a structured\nfoundation for categorizing existing and potential MORL works. The introduced\ntaxonomy is then used to scrutinize MORL research, enhancing clarity and\nconciseness through well-defined categorization. Moreover, a flexible framework\nderived from the taxonomy is introduced. This framework accommodates diverse\ninstantiations using tools from both RL and MOO/D. Implementation across\nvarious configurations demonstrates its versatility, assessed against benchmark\nproblems. Results indicate MORL/D instantiations achieve comparable performance\nwith significantly greater versatility than current state-of-the-art\napproaches. By presenting the taxonomy and framework, this paper offers a\ncomprehensive perspective and a unified vocabulary for MORL. This not only\nfacilitates the identification of algorithmic contributions but also lays the\ngroundwork for novel research avenues in MORL, contributing to the continued\nadvancement of this field.\n","authors":["Florian Felten","El-Ghazali Talbi","Grégoire Danoy"],"pdf_url":"https://arxiv.org/pdf/2311.12495v1.pdf","comment":"Under review at JAIR"},{"id":"http://arxiv.org/abs/2311.12491v1","updated":"2023-11-21T10:05:32Z","published":"2023-11-21T10:05:32Z","title":"Heuristics for Detecting CoinJoin Transactions on the Bitcoin Blockchain","summary":"  This research delves into the intricacies of Bitcoin, a decentralized\npeer-to-peer network, and its associated blockchain, which records all\ntransactions since its inception. While this ensures integrity and\ntransparency, the transparent nature of Bitcoin potentially compromises users'\nprivacy rights. To address this concern, users have adopted CoinJoin, a method\nthat amalgamates multiple transaction intents into a single, larger transaction\nto bolster transactional privacy. This process complicates individual\ntransaction tracing and disrupts many established blockchain analysis\nheuristics. Despite its significance, limited research has been conducted on\nidentifying CoinJoin transactions. Particularly noteworthy are varied CoinJoin\nimplementations such as JoinMarket, Wasabi, and Whirlpool, each presenting\ndistinct challenges due to their unique transaction structures. This study\ndelves deeply into the open-source implementations of these protocols, aiming\nto develop refined heuristics for identifying their transactions on the\nblockchain. Our exhaustive analysis covers transactions up to block 760,000,\noffering a comprehensive insight into CoinJoin transactions and their\nimplications for Bitcoin blockchain analysis.\n","authors":["Hugo Schnoering","Michalis Vazirgiannis"],"pdf_url":"https://arxiv.org/pdf/2311.12491v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2108.05879v2","updated":"2023-11-21T10:04:37Z","published":"2021-08-12T17:53:47Z","title":"Feature Engineering with Regularity Structures","summary":"  We investigate the use of models from the theory of regularity structures as\nfeatures in machine learning tasks. A model is a polynomial function of a\nspace-time signal designed to well-approximate solutions to partial\ndifferential equations (PDEs), even in low regularity regimes. Models can be\nseen as natural multi-dimensional generalisations of signatures of paths; our\nwork therefore aims to extend the recent use of signatures in data science\nbeyond the context of time-ordered data. We provide a flexible definition of a\nmodel feature vector associated to a space-time signal, along with two\nalgorithms which illustrate ways in which these features can be combined with\nlinear regression. We apply these algorithms in several numerical experiments\ndesigned to learn solutions to PDEs with a given forcing and boundary data. Our\nexperiments include semi-linear parabolic and wave equations with forcing, and\nBurgers' equation with no forcing. We find an advantage in favour of our\nalgorithms when compared to several alternative methods. Additionally, in the\nexperiment with Burgers' equation, we find non-trivial predictive power when\nnoise is added to the observations.\n","authors":["Ilya Chevyrev","Andris Gerasimovics","Hendrik Weber"],"pdf_url":"https://arxiv.org/pdf/2108.05879v2.pdf","comment":"33 pages, 7 figures, 7 tables. Improved presentation of model feature\n  vector (Section 2) and experiments (Section 3). Added new experiment in 2D\n  spatial domain (Section 3.1.2). To appear in Journal of Scientific Computing"},{"id":"http://arxiv.org/abs/2311.12490v1","updated":"2023-11-21T10:01:08Z","published":"2023-11-21T10:01:08Z","title":"Hyb-NeRF: A Multiresolution Hybrid Encoding for Neural Radiance Fields","summary":"  Recent advances in Neural radiance fields (NeRF) have enabled high-fidelity\nscene reconstruction for novel view synthesis. However, NeRF requires hundreds\nof network evaluations per pixel to approximate a volume rendering integral,\nmaking it slow to train. Caching NeRFs into explicit data structures can\neffectively enhance rendering speed but at the cost of higher memory usage. To\naddress these issues, we present Hyb-NeRF, a novel neural radiance field with a\nmulti-resolution hybrid encoding that achieves efficient neural modeling and\nfast rendering, which also allows for high-quality novel view synthesis. The\nkey idea of Hyb-NeRF is to represent the scene using different encoding\nstrategies from coarse-to-fine resolution levels. Hyb-NeRF exploits\nmemory-efficiency learnable positional features at coarse resolutions and the\nfast optimization speed and local details of hash-based feature grids at fine\nresolutions. In addition, to further boost performance, we embed cone\ntracing-based features in our learnable positional encoding that eliminates\nencoding ambiguity and reduces aliasing artifacts. Extensive experiments on\nboth synthetic and real-world datasets show that Hyb-NeRF achieves faster\nrendering speed with better rending quality and even a lower memory footprint\nin comparison to previous state-of-the-art methods.\n","authors":["Yifan Wang","Yi Gong","Yuan Zeng"],"pdf_url":"https://arxiv.org/pdf/2311.12490v1.pdf","comment":"WACV2024"},{"id":"http://arxiv.org/abs/2205.02645v3","updated":"2023-11-21T09:48:28Z","published":"2022-05-05T13:44:24Z","title":"PyDaddy: A Python package for discovering stochastic dynamical equations\n  from timeseries data","summary":"  Stochastic differential equations (SDEs) are an important framework to model\ndynamics with randomness, as is common in most biological systems. The inverse\nproblem of integrating these models with empirical data remains a major\nchallenge. Here, we present a software package, PyDaDDy (Python Library for\nData Driven Dynamics) that takes time series data as an input and outputs an\ninterpretable SDE. We achieve this by combining traditional approaches from\nstochastic calculus literature with state-of-the-art equation discovery\ntechniques. We validate our approach on synthetic datasets, and demonstrate the\ngenerality and applicability of the method on two real-world datasets of vastly\ndifferent spatiotemporal scales: (i) collective movement of fish school where\nstochasticity plays a crucial role, and (ii) confined migration of a single\ncell, primarily following a relaxed oscillation. We make the method available\nas an easy-to-use, open-source Python package, PyDaddy (Python Library for Data\nDriven Dynamics).\n","authors":["Arshed Nabeel","Ashwin Karichannavar","Shuaib Palathingal","Jitesh Jhawar","David B. Brückner","Danny Raj M.","Vishwesha Guttal"],"pdf_url":"https://arxiv.org/pdf/2205.02645v3.pdf","comment":"15 pages (+ 9 page appendix), 6 figures (+ 8 appendix figures)"},{"id":"http://arxiv.org/abs/2211.15513v2","updated":"2023-11-21T09:42:12Z","published":"2022-11-25T09:41:07Z","title":"Composite Score for Anomaly Detection in Imbalanced Real-World\n  Industrial Dataset","summary":"  In recent years, the industrial sector has evolved towards its fourth\nrevolution. The quality control domain is particularly interested in advanced\nmachine learning for computer vision anomaly detection. Nevertheless, several\nchallenges have to be faced, including imbalanced datasets, the image\ncomplexity, and the zero-false-negative (ZFN) constraint to guarantee the\nhigh-quality requirement. This paper illustrates a use case for an industrial\npartner, where Printed Circuit Board Assembly (PCBA) images are first\nreconstructed with a Vector Quantized Generative Adversarial Network (VQGAN)\ntrained on normal products. Then, several multi-level metrics are extracted on\na few normal and abnormal images, highlighting anomalies through reconstruction\ndifferences. Finally, a classifer is trained to build a composite anomaly score\nthanks to the metrics extracted. This three-step approach is performed on the\npublic MVTec-AD datasets and on the partner PCBA dataset, where it achieves a\nregular accuracy of 95.69% and 87.93% under the ZFN constraint.\n","authors":["Arnaud Bougaham","Mohammed El Adoui","Isabelle Linden","Benoît Frénay"],"pdf_url":"https://arxiv.org/pdf/2211.15513v2.pdf","comment":"This version of the article has been accepted for publication, after\n  peer review and is subject to Springer Nature AM terms of use, but is not the\n  Version of Record and does not reflect post-acceptance improvements, or any\n  corrections. The Version of Record is available online at:\n  https://doi.org/10.1007/s10994-023-06415-9"},{"id":"http://arxiv.org/abs/2311.12476v1","updated":"2023-11-21T09:37:49Z","published":"2023-11-21T09:37:49Z","title":"MaskFlow: Object-Aware Motion Estimation","summary":"  We introduce a novel motion estimation method, MaskFlow, that is capable of\nestimating accurate motion fields, even in very challenging cases with small\nobjects, large displacements and drastic appearance changes. In addition to\nlower-level features, that are used in other Deep Neural Network (DNN)-based\nmotion estimation methods, MaskFlow draws from object-level features and\nsegmentations. These features and segmentations are used to approximate the\nobjects' translation motion field. We propose a novel and effective way of\nincorporating the incomplete translation motion field into a subsequent motion\nestimation network for refinement and completion. We also produced a new\nchallenging synthetic dataset with motion field ground truth, and also provide\nextra ground truth for the object-instance matchings and corresponding\nsegmentation masks. We demonstrate that MaskFlow outperforms state of the art\nmethods when evaluated on our new challenging dataset, whilst still producing\ncomparable results on the popular FlyingThings3D benchmark dataset.\n","authors":["Aria Ahmadi","David R. Walton","Tim Atherton","Cagatay Dikici"],"pdf_url":"https://arxiv.org/pdf/2311.12476v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.00018v2","updated":"2023-11-21T09:22:28Z","published":"2023-08-31T07:53:02Z","title":"Unsupervised discovery of Interpretable Visual Concepts","summary":"  Providing interpretability of deep-learning models to non-experts, while\nfundamental for a responsible real-world usage, is challenging. Attribution\nmaps from xAI techniques, such as Integrated Gradients, are a typical example\nof a visualization technique containing a high level of information, but with\ndifficult interpretation. In this paper, we propose two methods, Maximum\nActivation Groups Extraction (MAGE) and Multiscale Interpretable Visualization\n(Ms-IV), to explain the model's decision, enhancing global interpretability.\nMAGE finds, for a given CNN, combinations of features which, globally, form a\nsemantic meaning, that we call concepts. We group these similar feature\npatterns by clustering in ``concepts'', that we visualize through Ms-IV. This\nlast method is inspired by Occlusion and Sensitivity analysis (incorporating\ncausality), and uses a novel metric, called Class-aware Order Correlation\n(CaOC), to globally evaluate the most important image regions according to the\nmodel's decision space. We compare our approach to xAI methods such as LIME and\nIntegrated Gradients. Experimental results evince the Ms-IV higher localization\nand faithfulness values. Finally, qualitative evaluation of combined MAGE and\nMs-IV demonstrates humans' ability to agree, based on the visualization, with\nthe decision of clusters' concepts; and, to detect, among a given set of\nnetworks, the existence of bias.\n","authors":["Caroline Mazini Rodrigues","Nicolas Boutry","Laurent Najman"],"pdf_url":"https://arxiv.org/pdf/2309.00018v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.06617v3","updated":"2023-11-21T09:20:33Z","published":"2022-11-12T09:41:02Z","title":"Empirical Risk Minimization with Relative Entropy Regularization","summary":"  The empirical risk minimization (ERM) problem with relative entropy\nregularization (ERM-RER) is investigated under the assumption that the\nreference measure is a {\\sigma}-finite measure, and not necessarily a\nprobability measure. Under this assumption, which leads to a generalization of\nthe ERM-RER problem allowing a larger degree of flexibility for incorporating\nprior knowledge, numerous relevant properties are stated. Among these\nproperties, the solution to this problem, if it exists, is shown to be a unique\nprobability measure, often mutually absolutely continuous with the reference\nmeasure. Such a solution exhibits a probably-approximately-correct guarantee\nfor the ERM problem independently of whether the latter possesses a solution.\nFor a fixed dataset, the empirical risk is shown to be a sub-Gaussian random\nvariable when the models are sampled from the solution to the ERM-RER problem.\nThe generalization capabilities of the solution to the ERM-RER problem (the\nGibbs algorithm) are studied via the sensitivity of the expected empirical risk\nto deviations from such a solution towards alternative probability measures.\nFinally, an interesting connection between sensitivity, generalization error,\nand lautum information is established\n","authors":["Samir M. Perlaza","Gaetan Bisson","Iñaki Esnaola","Alain Jean-Marie","Stefano Rini"],"pdf_url":"https://arxiv.org/pdf/2211.06617v3.pdf","comment":"Submitted to the the Transactions on Information Theory on June 12,\n  2023. Also available as: Research Report, INRIA, No. RR-9454, Centre Inria\n  d'Universit\\'e C\\^ote d'Azur, Sophia Antipolis, France, Feb., 2022 This\n  version contains the revision for Transactions on Information Theory on\n  November 21, 2023"},{"id":"http://arxiv.org/abs/2310.20567v2","updated":"2023-11-21T09:19:06Z","published":"2023-10-31T15:56:17Z","title":"One-shot backpropagation for multi-step prediction in physics-based\n  system identification -- EXTENDED VERSION","summary":"  The aim of this paper is to present a novel physics-based framework for the\nidentification of dynamical systems, in which the physical and structural\ninsights are reflected directly into a backpropagation-based learning\nalgorithm. The main result is a method to compute in closed form the gradient\nof a multi-step loss function, while enforcing physical properties and\nconstraints. The derived algorithm has been exploited to identify the unknown\ninertia matrix of a space debris, and the results show the reliability of the\nmethod in capturing the physical adherence of the estimated parameters.\n","authors":["Cesare Donati","Martina Mammarella","Fabrizio Dabbene","Carlo Novara","Constantino Lagoa"],"pdf_url":"https://arxiv.org/pdf/2310.20567v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.18168v3","updated":"2023-11-21T09:19:03Z","published":"2023-10-27T14:27:43Z","title":"Personas as a Way to Model Truthfulness in Language Models","summary":"  Large Language Models (LLMs) are trained on vast amounts of text from the\ninternet, which contains both factual and misleading information about the\nworld. Can language models discern truth from falsehood in this contradicting\ndata? Expanding on the view that LLMs can model different communicative agents,\nwe present the persona hypothesis: LLMs can cluster agents into personas using\ncommon features of their generations. For instance, a truthful persona is a\ngroup of agents that are likely to produce truthful text and that share similar\nfeatures like formal writing styles and scientific references. By modeling this\npersona, LLMs can generalize truthfulness beyond the specific contexts in which\neach agent generated the training text. For example, the model can infer that\nthe agent ``Wikipedia'' will behave truthfully on topics that were only\ngenerated by ``Science'' because they both belong to the truthful persona. We\nshow evidence for the persona hypothesis via two observations: (1) we can probe\nwhether a model's answer will be truthful before it is generated; (2)\nfinetuning a model on a set of facts improves its truthfulness on unseen\ntopics. Next, using arithmetics as a synthetic environment, we show that\nlanguage models can separate true and false statements, and generalize\ntruthfulness across agents; but only if agents in the training data share a\ntruthful generative process that enables the creation of a truthful persona.\nOverall, our findings suggest that models can exploit hierarchical structures\nin the data to learn abstract concepts like truthfulness.\n","authors":["Nitish Joshi","Javier Rando","Abulhair Saparov","Najoung Kim","He He"],"pdf_url":"https://arxiv.org/pdf/2310.18168v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.18183v2","updated":"2023-11-21T09:11:38Z","published":"2023-05-29T16:20:23Z","title":"On Counterfactual Data Augmentation Under Confounding","summary":"  Counterfactual data augmentation has recently emerged as a method to mitigate\nconfounding biases in the training data. These biases, such as spurious\ncorrelations, arise due to various observed and unobserved confounding\nvariables in the data generation process. In this paper, we formally analyze\nhow confounding biases impact downstream classifiers and present a causal\nviewpoint to the solutions based on counterfactual data augmentation. We\nexplore how removing confounding biases serves as a means to learn invariant\nfeatures, ultimately aiding in generalization beyond the observed data\ndistribution. Additionally, we present a straightforward yet powerful algorithm\nfor generating counterfactual images, which effectively mitigates the influence\nof confounding effects on downstream classifiers. Through experiments on MNIST\nvariants and the CelebA datasets, we demonstrate how our simple augmentation\nmethod helps existing state-of-the-art methods achieve good results.\n","authors":["Abbavaram Gowtham Reddy","Saketh Bachu","Saloni Dash","Charchit Sharma","Amit Sharma","Vineeth N Balasubramanian"],"pdf_url":"https://arxiv.org/pdf/2305.18183v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.01959v2","updated":"2023-11-21T09:01:17Z","published":"2023-10-03T11:10:21Z","title":"Beyond Labeling Oracles: What does it mean to steal ML models?","summary":"  Model extraction attacks are designed to steal trained models with only query\naccess, as is often provided through APIs that ML-as-a-Service providers offer.\nML models are expensive to train, in part because data is hard to obtain, and a\nprimary incentive for model extraction is to acquire a model while incurring\nless cost than training from scratch. Literature on model extraction commonly\nclaims or presumes that the attacker is able to save on both data acquisition\nand labeling costs. We show that the attacker often does not. This is because\ncurrent attacks implicitly rely on the adversary being able to sample from the\nvictim model's data distribution. We thoroughly evaluate factors influencing\nthe success of model extraction. We discover that prior knowledge of the\nattacker, i.e. access to in-distribution data, dominates other factors like the\nattack policy the adversary follows to choose which queries to make to the\nvictim model API. Thus, an adversary looking to develop an equally capable\nmodel with a fixed budget has little practical incentive to perform model\nextraction, since for the attack to work they need to collect in-distribution\ndata, saving only on the cost of labeling. With low labeling costs in the\ncurrent market, the usefulness of such attacks is questionable. Ultimately, we\ndemonstrate that the effect of prior knowledge needs to be explicitly decoupled\nfrom the attack policy. To this end, we propose a benchmark to evaluate attack\npolicy directly.\n","authors":["Avital Shafran","Ilia Shumailov","Murat A. Erdogdu","Nicolas Papernot"],"pdf_url":"https://arxiv.org/pdf/2310.01959v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12439v1","updated":"2023-11-21T08:51:58Z","published":"2023-11-21T08:51:58Z","title":"Harnessing FPGA Technology for Enhanced Biomedical Computation","summary":"  This research delves into sophisticated neural network frameworks like\nConvolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Long\nShort-Term Memory Networks (LSTMs), and Deep Belief Networks (DBNs) for\nimproved analysis of ECG signals via Field Programmable Gate Arrays (FPGAs).\nThe MIT-BIH Arrhythmia Database serves as the foundation for training and\nevaluating our models, with added Gaussian noise to heighten the algorithms'\nresilience. The developed architectures incorporate various layers for specific\nprocessing and categorization functions, employing strategies such as the\nEarlyStopping callback and Dropout layer to prevent overfitting. Additionally,\nthis paper details the creation of a tailored Tensor Compute Unit (TCU)\naccelerator for the PYNQ Z1 platform. It provides a thorough methodology for\nimplementing FPGA-based machine learning, encompassing the configuration of the\nTensil toolchain in Docker, selection of architectures, PS-PL configuration,\nand the compilation and deployment of models. By evaluating performance\nindicators like latency and throughput, we showcase the efficacy of FPGAs in\nadvanced biomedical computing. This study ultimately serves as a comprehensive\nguide to optimizing neural network operations on FPGAs across various fields.\n","authors":["Nisanur Alici","Kayode Inadagbo","Murat Isik"],"pdf_url":"https://arxiv.org/pdf/2311.12439v1.pdf","comment":"Submitted to IEEE Transactions on Biomedical Circuits and Systems.\n  arXiv admin note: substantial text overlap with arXiv:2307.07914"},{"id":"http://arxiv.org/abs/2310.08897v2","updated":"2023-11-21T08:51:03Z","published":"2023-10-13T06:58:52Z","title":"Self supervised convolutional kernel based handcrafted feature\n  harmonization: Enhanced left ventricle hypertension disease phenotyping on\n  echocardiography","summary":"  Radiomics, a medical imaging technique, extracts quantitative handcrafted\nfeatures from images to predict diseases. Harmonization in those features\nensures consistent feature extraction across various imaging devices and\nprotocols. Methods for harmonization include standardized imaging protocols,\nstatistical adjustments, and evaluating feature robustness. Myocardial diseases\nsuch as Left Ventricular Hypertrophy (LVH) and Hypertensive Heart Disease (HHD)\nare diagnosed via echocardiography, but variable imaging settings pose\nchallenges. Harmonization techniques are crucial for applying handcrafted\nfeatures in disease diagnosis in such scenario. Self-supervised learning (SSL)\nenhances data understanding within limited datasets and adapts to diverse data\nsettings. ConvNeXt-V2 integrates convolutional layers into SSL, displaying\nsuperior performance in various tasks. This study focuses on convolutional\nfilters within SSL, using them as preprocessing to convert images into feature\nmaps for handcrafted feature harmonization. Our proposed method excelled in\nharmonization evaluation and exhibited superior LVH classification performance\ncompared to existing methods.\n","authors":["Jina Lee","Youngtaek Hong","Dawun Jeong","Yeonggul Jang","Sihyeon Jeong","Taekgeun Jung","Yeonyee E. Yoon","Inki Moon","Seung-Ah Lee","Hyuk-Jae Chang"],"pdf_url":"https://arxiv.org/pdf/2310.08897v2.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.12436v1","updated":"2023-11-21T08:45:09Z","published":"2023-11-21T08:45:09Z","title":"Classifier Calibration with ROC-Regularized Isotonic Regression","summary":"  Calibration of machine learning classifiers is necessary to obtain reliable\nand interpretable predictions, bridging the gap between model confidence and\nactual probabilities. One prominent technique, isotonic regression (IR), aims\nat calibrating binary classifiers by minimizing the cross entropy on a\ncalibration set via monotone transformations. IR acts as an adaptive binning\nprocedure, which allows achieving a calibration error of zero, but leaves open\nthe issue of the effect on performance. In this paper, we first prove that IR\npreserves the convex hull of the ROC curve -- an essential performance metric\nfor binary classifiers. This ensures that a classifier is calibrated while\ncontrolling for overfitting of the calibration set. We then present a novel\ngeneralization of isotonic regression to accommodate classifiers with K\nclasses. Our method constructs a multidimensional adaptive binning scheme on\nthe probability simplex, again achieving a multi-class calibration error equal\nto zero. We regularize this algorithm by imposing a form of monotony that\npreserves the K-dimensional ROC surface of the classifier. We show empirically\nthat this general monotony criterion is effective in striking a balance between\nreducing cross entropy loss and avoiding overfitting of the calibration set.\n","authors":["Eugene Berta","Francis Bach","Michael Jordan"],"pdf_url":"https://arxiv.org/pdf/2311.12436v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12435v1","updated":"2023-11-21T08:44:38Z","published":"2023-11-21T08:44:38Z","title":"Fair Enough? A map of the current limitations of the requirements to\n  have \"fair'' algorithms","summary":"  In the recent years, the raise in the usage and efficiency of Artificial\nIntelligence and, more in general, of Automated Decision-Making systems has\nbrought with it an increasing and welcome awareness of the risks associated\nwith such systems. One of such risks is that of perpetuating or even amplifying\nbias and unjust disparities present in the data from which many of these\nsystems learn to adjust and optimise their decisions. This awareness has on one\nside encouraged several scientific communities to come up with more and more\nappropriate ways and methods to assess, quantify, and possibly mitigate such\nbiases and disparities. On the other hand, it has prompted more and more layers\nof society, including policy makers, to call for ``fair'' algorithms. We\nbelieve that while a lot of excellent and multidisciplinary research is\ncurrently being conducted, what is still fundamentally missing is the awareness\nthat having ``fair'' algorithms is per s\\'e a nearly meaningless requirement,\nthat needs to be complemented with a lot of additional societal choices to\nbecome actionable. Namely, there is a hiatus between what the society is\ndemanding from Automated Decision-Making systems, and what this demand actually\nmeans in real-world scenarios. In this work, we outline the key features of\nsuch a hiatus, and pinpoint a list of fundamental ambiguities and attention\npoints that we as a society must address in order to give a concrete meaning to\nthe increasing demand of fairness in Automated Decision-Making systems.\n","authors":["Alessandro Castelnovo","Nicole Inverardi","Gabriele Nanino","Ilaria Giuseppina Penco","Daniele Regoli"],"pdf_url":"https://arxiv.org/pdf/2311.12435v1.pdf","comment":"20 pages, 2 figures, 2 tables"},{"id":"http://arxiv.org/abs/2208.13405v4","updated":"2023-11-21T08:41:31Z","published":"2022-08-29T07:36:17Z","title":"Interpreting Black-box Machine Learning Models for High Dimensional\n  Datasets","summary":"  Deep neural networks (DNNs) have been shown to outperform traditional machine\nlearning algorithms in a broad variety of application domains due to their\neffectiveness in modeling complex problems and handling high-dimensional\ndatasets. Many real-life datasets, however, are of increasingly high\ndimensionality, where a large number of features may be irrelevant for both\nsupervised and unsupervised learning tasks. The inclusion of such features\nwould not only introduce unwanted noise but also increase computational\ncomplexity. Furthermore, due to high non-linearity and dependency among a large\nnumber of features, DNN models tend to be unavoidably opaque and perceived as\nblack-box methods because of their not well-understood internal functioning.\nTheir algorithmic complexity is often simply beyond the capacities of humans to\nunderstand the interplay among myriads of hyperparameters. A well-interpretable\nmodel can identify statistically significant features and explain the way they\naffect the model's outcome. In this paper, we propose an efficient method to\nimprove the interpretability of black-box models for classification tasks in\nthe case of high-dimensional datasets. First, we train a black-box model on a\nhigh-dimensional dataset to learn the embeddings on which the classification is\nperformed. To decompose the inner working principles of the black-box model and\nto identify top-k important features, we employ different probing and\nperturbing techniques. We then approximate the behavior of the black-box model\nby means of an interpretable surrogate model on the top-k feature space.\nFinally, we derive decision rules and local explanations from the surrogate\nmodel to explain individual decisions. Our approach outperforms\nstate-of-the-art methods like TabNet and XGboost when tested on different\ndatasets with varying dimensionality between 50 and 20,000 w.r.t metrics and\nexplainability.\n","authors":["Md. Rezaul Karim","Md. Shajalal","Alex Graß","Till Döhmen","Sisay Adugna Chala","Alexander Boden","Christian Beecks","Stefan Decker"],"pdf_url":"https://arxiv.org/pdf/2208.13405v4.pdf","comment":"This paper is currently under review in a journal"},{"id":"http://arxiv.org/abs/2311.12424v1","updated":"2023-11-21T08:32:38Z","published":"2023-11-21T08:32:38Z","title":"Looped Transformers are Better at Learning Learning Algorithms","summary":"  Transformers have demonstrated effectiveness in \\emph{in-context solving}\ndata-fitting problems from various (latent) models, as reported by Garg et al.\nHowever, the absence of an inherent iterative structure in the transformer\narchitecture presents a challenge in emulating the iterative algorithms, which\nare commonly employed in traditional machine learning methods. To address this,\nwe propose the utilization of \\emph{looped} transformer architecture and its\nassociated training methodology, with the aim of incorporating iterative\ncharacteristics into the transformer architectures. Experimental results\nsuggest that the looped transformer achieves performance comparable to the\nstandard transformer in solving various data-fitting problems, while utilizing\nless than 10\\% of the parameter count.\n","authors":["Liu Yang","Kangwook Lee","Robert Nowak","Dimitris Papailiopoulos"],"pdf_url":"https://arxiv.org/pdf/2311.12424v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.05077v4","updated":"2023-11-21T08:29:16Z","published":"2022-06-10T13:18:26Z","title":"Tensor Train for Global Optimization Problems in Robotics","summary":"  The convergence of many numerical optimization techniques is highly dependent\non the initial guess given to the solver. To address this issue, we propose a\nnovel approach that utilizes tensor methods to initialize existing optimization\nsolvers near global optima. Our method does not require access to a database of\ngood solutions. We first transform the cost function, which depends on both\ntask parameters and optimization variables, into a probability density\nfunction. Unlike existing approaches, the joint probability distribution of the\ntask parameters and optimization variables is approximated using the Tensor\nTrain model, which enables efficient conditioning and sampling. We treat the\ntask parameters as random variables, and for a given task, we generate samples\nfor decision variables from the conditional distribution to initialize the\noptimization solver. Our method can produce multiple solutions (when they\nexist) faster than existing methods. We first evaluate the approach on\nbenchmark functions for numerical optimization that are hard to solve using\ngradient-based optimization solvers with a naive initialization. The results\nshow that the proposed method can generate samples close to global optima and\nfrom multiple modes. We then demonstrate the generality and relevance of our\nframework to robotics by applying it to inverse kinematics with obstacles and\nmotion planning problems with a 7-DoF manipulator.\n","authors":["Suhan Shetty","Teguh Lembono","Tobias Loew","Sylvain Calinon"],"pdf_url":"https://arxiv.org/pdf/2206.05077v4.pdf","comment":"25 pages, 21 figures"},{"id":"http://arxiv.org/abs/2311.07784v2","updated":"2023-11-21T08:23:31Z","published":"2023-11-13T22:21:27Z","title":"A Data-Free Approach to Mitigate Catastrophic Forgetting in Federated\n  Class Incremental Learning for Vision Tasks","summary":"  Deep learning models often suffer from forgetting previously learned\ninformation when trained on new data. This problem is exacerbated in federated\nlearning (FL), where the data is distributed and can change independently for\neach user. Many solutions are proposed to resolve this catastrophic forgetting\nin a centralized setting. However, they do not apply directly to FL because of\nits unique complexities, such as privacy concerns and resource limitations. To\novercome these challenges, this paper presents a framework for\n$\\textbf{federated class incremental learning}$ that utilizes a generative\nmodel to synthesize samples from past distributions. This data can be later\nexploited alongside the training data to mitigate catastrophic forgetting. To\npreserve privacy, the generative model is trained on the server using data-free\nmethods at the end of each task without requesting data from clients. Moreover,\nour solution does not demand the users to store old data or models, which gives\nthem the freedom to join/leave the training at any time. Additionally, we\nintroduce SuperImageNet, a new regrouping of the ImageNet dataset specifically\ntailored for federated continual learning. We demonstrate significant\nimprovements compared to existing baselines through extensive experiments on\nmultiple datasets.\n","authors":["Sara Babakniya","Zalan Fabian","Chaoyang He","Mahdi Soltanolkotabi","Salman Avestimehr"],"pdf_url":"https://arxiv.org/pdf/2311.07784v2.pdf","comment":"Accepted in NeurIPS 2023. arXiv admin note: text overlap with\n  arXiv:2307.00497"},{"id":"http://arxiv.org/abs/2008.12690v2","updated":"2023-11-21T08:18:01Z","published":"2020-08-28T14:46:56Z","title":"ROOT-SGD: Sharp Nonasymptotics and Asymptotic Efficiency in a Single\n  Algorithm","summary":"  We study the problem of solving strongly convex and smooth unconstrained\noptimization problems using stochastic first-order algorithms. We devise a\nnovel algorithm, referred to as \\emph{Recursive One-Over-T SGD} (\\ROOTSGD),\nbased on an easily implementable, recursive averaging of past stochastic\ngradients. We prove that it simultaneously achieves state-of-the-art\nperformance in both a finite-sample, nonasymptotic sense and an asymptotic\nsense. On the nonasymptotic side, we prove risk bounds on the last iterate of\n\\ROOTSGD with leading-order terms that match the optimal statistical risk with\na unity pre-factor, along with a higher-order term that scales at the sharp\nrate of $O(n^{-3/2})$ under the Lipschitz condition on the Hessian matrix. On\nthe asymptotic side, we show that when a mild, one-point Hessian continuity\ncondition is imposed, the rescaled last iterate of (multi-epoch) \\ROOTSGD\nconverges asymptotically to a Gaussian limit with the Cram\\'{e}r-Rao optimal\nasymptotic covariance, for a broad range of step-size choices.\n","authors":["Chris Junchi Li","Wenlong Mou","Martin J. Wainwright","Michael I. Jordan"],"pdf_url":"https://arxiv.org/pdf/2008.12690v2.pdf","comment":"Camera Ready, COLT 2022"},{"id":"http://arxiv.org/abs/2311.12419v1","updated":"2023-11-21T08:16:01Z","published":"2023-11-21T08:16:01Z","title":"Board-to-Board: Evaluating Moonboard Grade Prediction Generalization","summary":"  Bouldering is a sport where athletes aim to climb up an obstacle using a set\nof defined holds called a route. Typically routes are assigned a grade to\ninform climbers of its difficulty and allow them to more easily track their\nprogression. However, the variation in individual climbers technical and\nphysical attributes and many nuances of an individual route make grading a\ndifficult and often biased task. In this work, we apply classical and\ndeep-learning modelling techniques to the 2016, 2017 and 2019 Moonboard\ndatasets, achieving state of the art grade prediction performance with 0.87 MAE\nand 1.12 RMSE. We achieve this performance on a feature-set that does not\nrequire decomposing routes into individual moves, which is a method common in\nliterature and introduces bias. We also demonstrate the generalization\ncapability of this model between editions and introduce a novel vision-based\nmethod of grade prediction. While the generalization performance of these\ntechniques is below human level performance currently, we propose these methods\nas a basis for future work. Such a tool could be implemented in pre-existing\nmobile applications and would allow climbers to better track their progress and\nassess new routes with reduced bias.\n","authors":["Daniel Petashvili","Matthew Rodda"],"pdf_url":"https://arxiv.org/pdf/2311.12419v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12410v1","updated":"2023-11-21T07:56:30Z","published":"2023-11-21T07:56:30Z","title":"nach0: Multimodal Natural and Chemical Languages Foundation Model","summary":"  Large Language Models (LLMs) have substantially driven scientific progress in\nvarious domains, and many papers have demonstrated their ability to tackle\ncomplex problems with creative solutions. Our paper introduces a new foundation\nmodel, nach0, capable of solving various chemical and biological tasks:\nbiomedical question answering, named entity recognition, molecular generation,\nmolecular synthesis, attributes prediction, and others. nach0 is a multi-domain\nand multi-task encoder-decoder LLM pre-trained on unlabeled text from\nscientific literature, patents, and molecule strings to incorporate a range of\nchemical and linguistic knowledge. We employed instruction tuning, where\nspecific task-related instructions are utilized to fine-tune nach0 for the\nfinal set of tasks. To train nach0 effectively, we leverage the NeMo framework,\nenabling efficient parallel optimization of both base and large model versions.\nExtensive experiments demonstrate that our model outperforms state-of-the-art\nbaselines on single-domain and cross-domain tasks. Furthermore, it can generate\nhigh-quality outputs in molecular and textual formats, showcasing its\neffectiveness in multi-domain setups.\n","authors":["Micha Livne","Zulfat Miftahutdinov","Elena Tutubalina","Maksim Kuznetsov","Daniil Polykovskiy","Annika Brundyn","Aastha Jhunjhunwala","Anthony Costa","Alex Aliper","Alex Zhavoronkov"],"pdf_url":"https://arxiv.org/pdf/2311.12410v1.pdf","comment":"Submitted to Nature Communications"},{"id":"http://arxiv.org/abs/2202.06054v4","updated":"2023-11-21T07:47:04Z","published":"2022-02-12T12:42:36Z","title":"Towards Data-Algorithm Dependent Generalization: a Case Study on\n  Overparameterized Linear Regression","summary":"  One of the major open problems in machine learning is to characterize\ngeneralization in the overparameterized regime, where most traditional\ngeneralization bounds become inconsistent even for overparameterized linear\nregression. In many scenarios, this failure can be attributed to obscuring the\ncrucial interplay between the training algorithm and the underlying data\ndistribution. This paper demonstrate that the generalization behavior of\noverparameterized model should be analyzed in a both data-relevant and\nalgorithm-relevant manner. To make a formal characterization, We introduce a\nnotion called data-algorithm compatibility, which considers the generalization\nbehavior of the entire data-dependent training trajectory, instead of\ntraditional last-iterate analysis. We validate our claim by studying the\nsetting of solving overparameterized linear regression with gradient descent.\nSpecifically, we perform a data-dependent trajectory analysis and derive a\nsufficient condition for compatibility in such a setting. Our theoretical\nresults demonstrate that if we take early stopping iterates into consideration,\ngeneralization can hold with significantly weaker restrictions on the problem\ninstance than the previous last-iterate analysis.\n","authors":["Jing Xu","Jiaye Teng","Yang Yuan","Andrew Chi-Chih Yao"],"pdf_url":"https://arxiv.org/pdf/2202.06054v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.09299v3","updated":"2023-11-21T07:34:26Z","published":"2023-10-07T09:09:19Z","title":"Digital Twin Assisted Deep Reinforcement Learning for Online Admission\n  Control in Sliced Network","summary":"  The proliferation of diverse wireless services in 5G and beyond has led to\nthe emergence of network slicing technologies. Among these, admission control\nplays a crucial role in achieving service-oriented optimization goals through\nthe selective acceptance of service requests. Although deep reinforcement\nlearning (DRL) forms the foundation in many admission control approaches thanks\nto its effectiveness and flexibility, initial instability with excessive\nconvergence delay of DRL models hinders their deployment in real-world\nnetworks. We propose a digital twin (DT) accelerated DRL solution to address\nthis issue. Specifically, we first formulate the admission decision-making\nprocess as a semi-Markov decision process, which is subsequently simplified\ninto an equivalent discrete-time Markov decision process to facilitate the\nimplementation of DRL methods. A neural network-based DT is established with a\ncustomized output layer for queuing systems, trained through supervised\nlearning, and then employed to assist the training phase of the DRL model.\nExtensive simulations show that the DT-accelerated DRL improves resource\nutilization by over 40% compared to the directly trained state-of-the-art\ndueling deep Q-learning model. This improvement is achieved while preserving\nthe model's capability to optimize the long-term rewards of the admission\nprocess.\n","authors":["Zhenyu Tao","Wei Xu","Xiaohu You"],"pdf_url":"https://arxiv.org/pdf/2310.09299v3.pdf","comment":"13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2311.12399v1","updated":"2023-11-21T07:22:48Z","published":"2023-11-21T07:22:48Z","title":"A Survey of Graph Meets Large Language Model: Progress and Future\n  Directions","summary":"  Graph plays a significant role in representing and analyzing complex\nrelationships in real-world applications such as citation networks, social\nnetworks, and biological data. Recently, Large Language Models (LLMs), which\nhave achieved tremendous success in various domains, have also been leveraged\nin graph-related tasks to surpass traditional Graph Neural Networks (GNNs)\nbased methods and yield state-of-the-art performance. In this survey, we first\npresent a comprehensive review and analysis of existing methods that integrate\nLLMs with graphs. First of all, we propose a new taxonomy, which organizes\nexisting methods into three categories based on the role (i.e., enhancer,\npredictor, and alignment component) played by LLMs in graph-related tasks. Then\nwe systematically survey the representative methods along the three categories\nof the taxonomy. Finally, we discuss the remaining limitations of existing\nstudies and highlight promising avenues for future research. The relevant\npapers are summarized and will be consistently updated at:\nhttps://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks.\n","authors":["Yuhan Li","Zhixun Li","Peisong Wang","Jia Li","Xiangguo Sun","Hong Cheng","Jeffrey Xu Yu"],"pdf_url":"https://arxiv.org/pdf/2311.12399v1.pdf","comment":"Work in progress; 13 pages, 5 figures"},{"id":"http://arxiv.org/abs/2304.07647v2","updated":"2023-11-21T07:21:50Z","published":"2023-04-15T22:24:05Z","title":"LASER: A Neuro-Symbolic Framework for Learning Spatial-Temporal Scene\n  Graphs with Weak Supervision","summary":"  We propose LASER, a neuro-symbolic approach to learn semantic video\nrepresentations that capture rich spatial and temporal properties in video data\nby leveraging high-level logic specifications. In particular, we formulate the\nproblem in terms of alignment between raw videos and spatio-temporal logic\nspecifications. The alignment algorithm leverages a differentiable symbolic\nreasoner and a combination of contrastive, temporal, and semantics losses. It\neffectively and efficiently trains low-level perception models to extract\nfine-grained video representation in the form of a spatio-temporal scene graph\nthat conforms to the desired high-level specification. In doing so, we explore\na novel methodology that weakly supervises the learning of video semantic\nrepresentations through logic specifications. We evaluate our method on two\ndatasets with rich spatial and temporal specifications:\n20BN-Something-Something and MUGEN. We demonstrate that our method learns\nbetter fine-grained video semantics than existing baselines.\n","authors":["Jiani Huang","Ziyang Li","Mayur Naik","Ser-Nam Lim"],"pdf_url":"https://arxiv.org/pdf/2304.07647v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.04589v3","updated":"2023-11-21T07:16:51Z","published":"2022-08-09T08:07:21Z","title":"Long-term Causal Effects Estimation via Latent Surrogates Representation\n  Learning","summary":"  Estimating long-term causal effects based on short-term surrogates is a\nsignificant but challenging problem in many real-world applications, e.g.,\nmarketing and medicine. Despite its success in certain domains, most existing\nmethods estimate causal effects in an idealistic and simplistic way - ignoring\nthe causal structure among short-term outcomes and treating all of them as\nsurrogates. However, such methods cannot be well applied to real-world\nscenarios, in which the partially observed surrogates are mixed with their\nproxies among short-term outcomes. To this end, we develop our flexible method,\nLaser, to estimate long-term causal effects in the more realistic situation\nthat the surrogates are observed or have observed proxies.Given the\nindistinguishability between the surrogates and proxies, we utilize\nidentifiable variational auto-encoder (iVAE) to recover the whole valid\nsurrogates on all the surrogates candidates without the need of distinguishing\nthe observed surrogates or the proxies of latent surrogates. With the help of\nthe recovered surrogates, we further devise an unbiased estimation of long-term\ncausal effects. Extensive experimental results on the real-world and\nsemi-synthetic datasets demonstrate the effectiveness of our proposed method.\n","authors":["Ruichu Cai","Weilin Chen","Zeqin Yang","Shu Wan","Chen Zheng","Xiaoqing Yang","Jiecheng Guo"],"pdf_url":"https://arxiv.org/pdf/2208.04589v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10777v2","updated":"2023-11-21T07:15:57Z","published":"2023-11-16T06:01:47Z","title":"A Systematic Review of Aspect-based Sentiment Analysis (ABSA): Domains,\n  Methods, and Trends","summary":"  Aspect-based Sentiment Analysis (ABSA) is a type of fine-grained sentiment\nanalysis (SA) that identifies aspects and the associated opinions from a given\ntext. In the digital era, ABSA gained increasing popularity and applications in\nmining opinionated text data to obtain insights and support decisions. ABSA\nresearch employs linguistic, statistical, and machine-learning approaches and\nutilises resources such as labelled datasets, aspect and sentiment lexicons and\nontology. By its nature, ABSA is domain-dependent and can be sensitive to the\nimpact of misalignment between the resource and application domains. However,\nto our knowledge, this topic has not been explored by the existing ABSA\nliterature reviews. In this paper, we present a Systematic Literature Review\n(SLR) of ABSA studies with a focus on the research application domain, dataset\ndomain, and the research methods to examine their relationships and identify\ntrends over time. Our results suggest a number of potential systemic issues in\nthe ABSA research literature, including the predominance of the\n``product/service review'' dataset domain among the majority of studies that\ndid not have a specific research application domain, coupled with the\nprevalence of dataset-reliant methods such as supervised machine learning. This\nreview makes a number of unique contributions to the ABSA research field: 1) To\nour knowledge, it is the first SLR that links the research domain, dataset\ndomain, and research method through a systematic perspective; 2) it is one of\nthe largest scoped SLR on ABSA, with 519 eligible studies filtered from 4191\nsearch results without time constraint; and 3) our review methodology adopted\nan innovative automatic filtering process based on PDF-mining, which enhanced\nscreening quality and reliability. Suggestions and our review limitations are\nalso discussed.\n","authors":["Yan Cathy Hua","Paul Denny","Katerina Taskova","Jörg Wicker"],"pdf_url":"https://arxiv.org/pdf/2311.10777v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10770v2","updated":"2023-11-21T06:59:59Z","published":"2023-11-15T18:42:50Z","title":"Exponentially Faster Language Modelling","summary":"  Language models only really need to use an exponential fraction of their\nneurons for individual inferences. As proof, we present UltraFastBERT, a BERT\nvariant that uses 0.3% of its neurons during inference while performing on par\nwith similar BERT models. UltraFastBERT selectively engages just 12 out of 4095\nneurons for each layer inference. This is achieved by replacing feedforward\nnetworks with fast feedforward networks (FFFs). While no truly efficient\nimplementation currently exists to unlock the full acceleration potential of\nconditional neural execution, we provide high-level CPU code achieving 78x\nspeedup over the optimized baseline feedforward implementation, and a PyTorch\nimplementation delivering 40x speedup over the equivalent batched feedforward\ninference. We publish our training code, benchmarking setup, and model weights.\n","authors":["Peter Belcak","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2311.10770v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12379v1","updated":"2023-11-21T06:41:41Z","published":"2023-11-21T06:41:41Z","title":"Infinite forecast combinations based on Dirichlet process","summary":"  Forecast combination integrates information from various sources by\nconsolidating multiple forecast results from the target time series. Instead of\nthe need to select a single optimal forecasting model, this paper introduces a\ndeep learning ensemble forecasting model based on the Dirichlet process.\nInitially, the learning rate is sampled with three basis distributions as\nhyperparameters to convert the infinite mixture into a finite one. All\ncheckpoints are collected to establish a deep learning sub-model pool, and\nweight adjustment and diversity strategies are developed during the combination\nprocess. The main advantage of this method is its ability to generate the\nrequired base learners through a single training process, utilizing the\ndecaying strategy to tackle the challenge posed by the stochastic nature of\ngradient descent in determining the optimal learning rate. To ensure the\nmethod's generalizability and competitiveness, this paper conducts an empirical\nanalysis using the weekly dataset from the M4 competition and explores\nsensitivity to the number of models to be combined. The results demonstrate\nthat the ensemble model proposed offers substantial improvements in prediction\naccuracy and stability compared to a single benchmark model.\n","authors":["Yinuo Ren","Feng Li","Yanfei Kang"],"pdf_url":"https://arxiv.org/pdf/2311.12379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10863v2","updated":"2023-11-21T06:15:56Z","published":"2023-11-17T20:51:24Z","title":"Verified Compositional Neuro-Symbolic Control for Stochastic Systems\n  with Temporal Logic Tasks","summary":"  Several methods have been proposed recently to learn neural network (NN)\ncontrollers for autonomous agents, with unknown and stochastic dynamics, tasked\nwith complex missions captured by Linear Temporal Logic (LTL). Due to the\nsample-inefficiency of the majority of these works, compositional learning\nmethods have been proposed decomposing the LTL specification into smaller\nsub-tasks. Then, separate controllers are learned and composed to satisfy the\noriginal task. A key challenge within these approaches is that they often lack\nsafety guarantees or the provided guarantees are impractical. This paper aims\nto address this challenge. Particularly, we consider autonomous systems with\nunknown and stochastic dynamics and LTL-encoded tasks. We assume that the\nsystem is equipped with a finite set of base skills modeled by trained NN\nfeedback controllers. Our goal is to check if there exists a temporal\ncomposition of the trained NN controllers - and if so, to compute it - that\nwill yield a composite system behavior that satisfies the assigned LTL task\nwith probability one. We propose a new approach that relies on a novel\nintegration of automata theory and data-driven reachability analysis tools for\nNN-controlled stochastic systems. The resulting neuro-symbolic controller\nallows the agent to generate safe behaviors for unseen complex temporal logic\ntasks in a zero-shot fashion by leveraging its base skills. We show correctness\nof the proposed method and we provide conditions under which it is complete. To\nthe best of our knowledge, this is the first work that designs verified\ntemporal compositions of NN controllers for unknown and stochastic systems.\nFinally, we provide extensive numerical simulations and hardware experiments on\nrobot navigation tasks to demonstrate the proposed method.\n","authors":["Jun Wang","Kaiyuan Tan","Zihe Sun","Yiannis Kantaros"],"pdf_url":"https://arxiv.org/pdf/2311.10863v2.pdf","comment":"The paper was withdrawn as it did not include the correct author\n  list, credit was given to the wrong author"},{"id":"http://arxiv.org/abs/2311.01038v2","updated":"2023-11-21T05:48:06Z","published":"2023-11-02T07:09:59Z","title":"Better with Less: A Data-Active Perspective on Pre-Training Graph Neural\n  Networks","summary":"  Pre-training on graph neural networks (GNNs) aims to learn transferable\nknowledge for downstream tasks with unlabeled data, and it has recently become\nan active research area. The success of graph pre-training models is often\nattributed to the massive amount of input data. In this paper, however, we\nidentify the curse of big data phenomenon in graph pre-training: more training\ndata do not necessarily lead to better downstream performance. Motivated by\nthis observation, we propose a better-with-less framework for graph\npre-training: fewer, but carefully chosen data are fed into a GNN model to\nenhance pre-training. The proposed pre-training pipeline is called the\ndata-active graph pre-training (APT) framework, and is composed of a graph\nselector and a pre-training model. The graph selector chooses the most\nrepresentative and instructive data points based on the inherent properties of\ngraphs as well as predictive uncertainty. The proposed predictive uncertainty,\nas feedback from the pre-training model, measures the confidence level of the\nmodel in the data. When fed with the chosen data, on the other hand, the\npre-training model grasps an initial understanding of the new, unseen data, and\nat the same time attempts to remember the knowledge learned from previous data.\nTherefore, the integration and interaction between these two components form a\nunified framework (APT), in which graph pre-training is performed in a\nprogressive and iterative way. Experiment results show that the proposed APT is\nable to obtain an efficient pre-training model with fewer training data and\nbetter downstream performance.\n","authors":["Jiarong Xu","Renhong Huang","Xin Jiang","Yuxuan Cao","Carl Yang","Chunping Wang","Yang Yang"],"pdf_url":"https://arxiv.org/pdf/2311.01038v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12359v1","updated":"2023-11-21T05:27:16Z","published":"2023-11-21T05:27:16Z","title":"Post-Training Quantization with Low-precision Minifloats and Integers on\n  FPGAs","summary":"  Post-Training Quantization (PTQ) is a powerful technique for model\ncompression, reducing the precision of neural networks without additional\ntraining overhead. Recent works have investigated adopting 8-bit floating-point\nquantization (FP8) in the context of PTQ for model inference. However, the\nexploration of floating-point formats smaller than 8 bits and their comparison\nwith integer quantization remains relatively limited. In this work, we present\nminifloats, which are reduced-precision floating-point formats capable of\nfurther reducing the memory footprint, latency, and energy cost of a model\nwhile approaching full-precision model accuracy. Our work presents a novel PTQ\ndesign-space exploration, comparing minifloat and integer quantization schemes\nacross a range of 3 to 8 bits for both weights and activations. We examine the\napplicability of various PTQ techniques to minifloats, including weight\nequalization, bias correction, SmoothQuant, gradient-based learned rounding,\nand the GPTQ method. Our experiments validate the effectiveness of\nlow-precision minifloats when compared to their integer counterparts across a\nspectrum of accuracy-precision trade-offs on a set of reference deep learning\nvision workloads. Finally, we evaluate our results against an FPGA-based\nhardware cost model, showing that integer quantization often remains the\nPareto-optimal option, given its relatively smaller hardware resource\nfootprint.\n","authors":["Shivam Aggarwal","Alessandro Pappalardo","Hans Jakob Damsgaard","Giuseppe Franco","Thomas B. Preußer","Michaela Blott","Tulika Mitra"],"pdf_url":"https://arxiv.org/pdf/2311.12359v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12358v1","updated":"2023-11-21T05:26:33Z","published":"2023-11-21T05:26:33Z","title":"Federated Learning via Consensus Mechanism on Heterogeneous Data: A New\n  Perspective on Convergence","summary":"  Federated learning (FL) on heterogeneous data (non-IID data) has recently\nreceived great attention. Most existing methods focus on studying the\nconvergence guarantees for the global objective. While these methods can\nguarantee the decrease of the global objective in each communication round,\nthey fail to ensure risk decrease for each client. In this paper, to address\nthe problem,we propose FedCOME, which introduces a consensus mechanism to\nenforce decreased risk for each client after each training round. In\nparticular, we allow a slight adjustment to a client's gradient on the server\nside, which generates an acute angle between the corrected gradient and the\noriginal ones of other clients. We theoretically show that the consensus\nmechanism can guarantee the convergence of the global objective. To generalize\nthe consensus mechanism to the partial participation FL scenario, we devise a\nnovel client sampling strategy to select the most representative clients for\nthe global data distribution. Training on these selected clients with the\nconsensus mechanism could empirically lead to risk decrease for clients that\nare not selected. Finally, we conduct extensive experiments on four benchmark\ndatasets to show the superiority of FedCOME against other state-of-the-art\nmethods in terms of effectiveness, efficiency and fairness. For\nreproducibility, we make our source code publicly available at:\n\\url{https://github.com/fedcome/fedcome}.\n","authors":["Shu Zheng","Tiandi Ye","Xiang Li","Ming Gao"],"pdf_url":"https://arxiv.org/pdf/2311.12358v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12356v1","updated":"2023-11-21T05:22:39Z","published":"2023-11-21T05:22:39Z","title":"Random Linear Projections Loss for Hyperplane-Based Optimization in\n  Regression Neural Networks","summary":"  Despite their popularity across a wide range of domains, regression neural\nnetworks are prone to overfitting complex datasets. In this work, we propose a\nloss function termed Random Linear Projections (RLP) loss, which is empirically\nshown to mitigate overfitting. With RLP loss, the distance between sets of\nhyperplanes connecting fixed-size subsets of the neural network's\nfeature-prediction pairs and feature-label pairs is minimized. The intuition\nbehind this loss derives from the notion that if two functions share the same\nhyperplanes connecting all subsets of feature-label pairs, then these functions\nmust necessarily be equivalent. Our empirical studies, conducted across\nbenchmark datasets and representative synthetic examples, demonstrate the\nimprovements of the proposed RLP loss over mean squared error (MSE).\nSpecifically, neural networks trained with the RLP loss achieve better\nperformance while requiring fewer data samples and are more robust to additive\nnoise. We provide theoretical analysis supporting our empirical findings.\n","authors":["Shyam Venkatasubramanian","Ahmed Aloui","Vahid Tarokh"],"pdf_url":"https://arxiv.org/pdf/2311.12356v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12355v1","updated":"2023-11-21T05:15:56Z","published":"2023-11-21T05:15:56Z","title":"Utilizing Language Models for Tour Itinerary Recommendation","summary":"  Tour itinerary recommendation involves planning a sequence of relevant\nPoint-of-Interest (POIs), which combines challenges from the fields of both\nOperations Research (OR) and Recommendation Systems (RS). As an OR problem,\nthere is the need to maximize a certain utility (e.g., popularity of POIs in\nthe tour) while adhering to some constraints (e.g., maximum time for the tour).\nAs a RS problem, it is heavily related to problem or filtering or ranking a\nsubset of POIs that are relevant to a user and recommending it as part of an\nitinerary. In this paper, we explore the use of language models for the task of\ntour itinerary recommendation and planning. This task has the unique\nrequirement of recommending personalized POIs relevant to users and planning\nthese POIs as an itinerary that satisfies various constraints. We discuss some\napproaches in this area, such as using word embedding techniques like Word2Vec\nand GloVe for learning POI embeddings and transformer-based techniques like\nBERT for generating\n  itineraries.\n","authors":["Ngai Lam Ho","Kwan Hui Lim"],"pdf_url":"https://arxiv.org/pdf/2311.12355v1.pdf","comment":"PMAI23 @IJCAI 2023 2nd International Workshop on Process Management\n  in the AI era"},{"id":"http://arxiv.org/abs/2204.09157v2","updated":"2023-11-21T05:06:33Z","published":"2022-04-19T23:19:05Z","title":"Multifidelity Deep Operator Networks For Data-Driven and\n  Physics-Informed Problems","summary":"  Operator learning for complex nonlinear systems is increasingly common in\nmodeling multi-physics and multi-scale systems. However, training such\nhigh-dimensional operators requires a large amount of expensive, high-fidelity\ndata, either from experiments or simulations. In this work, we present a\ncomposite Deep Operator Network (DeepONet) for learning using two datasets with\ndifferent levels of fidelity to accurately learn complex operators when\nsufficient high-fidelity data is not available. Additionally, we demonstrate\nthat the presence of low-fidelity data can improve the predictions of\nphysics-informed learning with DeepONets. We demonstrate the new multi-fidelity\ntraining in diverse examples, including modeling of the ice-sheet dynamics of\nthe Humboldt glacier, Greenland, using two different fidelity models and also\nusing the same physical model at two different resolutions.\n","authors":["Amanda A. Howard","Mauro Perego","George E. Karniadakis","Panos Stinis"],"pdf_url":"https://arxiv.org/pdf/2204.09157v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12351v1","updated":"2023-11-21T04:59:17Z","published":"2023-11-21T04:59:17Z","title":"Advancing Transformer Architecture in Long-Context Large Language\n  Models: A Comprehensive Survey","summary":"  With the bomb ignited by ChatGPT, Transformer-based Large Language Models\n(LLMs) have paved a revolutionary path toward Artificial General Intelligence\n(AGI) and have been applied in diverse areas as knowledge bases, human\ninterfaces, and dynamic agents. However, a prevailing limitation exists: many\ncurrent LLMs, constrained by resources, are primarily pre-trained on shorter\ntexts, rendering them less effective for longer-context prompts, commonly\nencountered in real-world settings. In this paper, we present a comprehensive\nsurvey focusing on the advancement of model architecture in Transformer-based\nLLMs to optimize long-context capabilities across all stages from pre-training\nto inference. We firstly delineate and analyze the problems of handling\nlong-context input and output with the current Transformer-based models. Then,\nwe mainly offer a holistic taxonomy to navigate the landscape of Transformer\nupgrades on architecture to solve these problems. Afterward, we provide the\ninvestigation on wildly used evaluation necessities tailored for long-context\nLLMs, including datasets, metrics, and baseline models, as well as some amazing\noptimization toolkits like libraries, systems, and compilers to augment LLMs'\nefficiency and efficacy across different stages. Finally, we further discuss\nthe predominant challenges and potential avenues for future research in this\ndomain. Additionally, we have established a repository where we curate relevant\nliterature with real-time updates at\nhttps://github.com/Strivin0311/long-llms-learning.\n","authors":["Yunpeng Huang","Jingwei Xu","Zixu Jiang","Junyu Lai","Zenan Li","Yuan Yao","Taolue Chen","Lijuan Yang","Zhou Xin","Xiaoxing Ma"],"pdf_url":"https://arxiv.org/pdf/2311.12351v1.pdf","comment":"35 pages, 3 figures, 4 tables"},{"id":"http://arxiv.org/abs/2311.06483v2","updated":"2023-11-21T04:53:27Z","published":"2023-11-11T05:43:54Z","title":"Stacked networks improve physics-informed training: applications to\n  neural networks and deep operator networks","summary":"  Physics-informed neural networks and operator networks have shown promise for\neffectively solving equations modeling physical systems. However, these\nnetworks can be difficult or impossible to train accurately for some systems of\nequations. We present a novel multifidelity framework for stacking\nphysics-informed neural networks and operator networks that facilitates\ntraining. We successively build a chain of networks, where the output at one\nstep can act as a low-fidelity input for training the next step, gradually\nincreasing the expressivity of the learned model. The equations imposed at each\nstep of the iterative process can be the same or different (akin to simulated\nannealing). The iterative (stacking) nature of the proposed method allows us to\nprogressively learn features of a solution that are hard to learn directly.\nThrough benchmark problems including a nonlinear pendulum, the wave equation,\nand the viscous Burgers equation, we show how stacking can be used to improve\nthe accuracy and reduce the required size of physics-informed neural networks\nand operator networks.\n","authors":["Amanda A Howard","Sarah H Murphy","Shady E Ahmed","Panos Stinis"],"pdf_url":"https://arxiv.org/pdf/2311.06483v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12345v1","updated":"2023-11-21T04:38:21Z","published":"2023-11-21T04:38:21Z","title":"Stable Diffusion For Aerial Object Detection","summary":"  Aerial object detection is a challenging task, in which one major obstacle\nlies in the limitations of large-scale data collection and the long-tail\ndistribution of certain classes. Synthetic data offers a promising solution,\nespecially with recent advances in diffusion-based methods like stable\ndiffusion (SD). However, the direct application of diffusion methods to aerial\ndomains poses unique challenges: stable diffusion's optimization for rich\nground-level semantics doesn't align with the sparse nature of aerial objects,\nand the extraction of post-synthesis object coordinates remains problematic. To\naddress these challenges, we introduce a synthetic data augmentation framework\ntailored for aerial images. It encompasses sparse-to-dense region of interest\n(ROI) extraction to bridge the semantic gap, fine-tuning the diffusion model\nwith low-rank adaptation (LORA) to circumvent exhaustive retraining, and\nfinally, a Copy-Paste method to compose synthesized objects with backgrounds,\nproviding a nuanced approach to aerial object detection through synthetic data.\n","authors":["Yanan Jian","Fuxun Yu","Simranjit Singh","Dimitrios Stamoulis"],"pdf_url":"https://arxiv.org/pdf/2311.12345v1.pdf","comment":"Accepted at NeurIPS 2023 Synthetic Data Generation with Generative AI\n  workshop"},{"id":"http://arxiv.org/abs/2304.14922v2","updated":"2023-11-21T04:25:31Z","published":"2023-04-24T05:21:10Z","title":"Supervised and Unsupervised Deep Learning Approaches for EEG Seizure\n  Prediction","summary":"  Epilepsy affects more than 50 million people worldwide, making it one of the\nworld's most prevalent neurological diseases. The main symptom of epilepsy is\nseizures, which occur abruptly and can cause serious injury or death. The\nability to predict the occurrence of an epileptic seizure could alleviate many\nrisks and stresses people with epilepsy face. We formulate the problem of\ndetecting preictal (or pre-seizure) with reference to normal EEG as a precursor\nto incoming seizure. To this end, we developed several supervised deep learning\napproaches model to identify preictal EEG from normal EEG. We further develop\nnovel unsupervised deep learning approaches to train the models on only normal\nEEG, and detecting pre-seizure EEG as an anomalous event. These deep learning\nmodels were trained and evaluated on two large EEG seizure datasets in a\nperson-specific manner. We found that both supervised and unsupervised\napproaches are feasible; however, their performance varies depending on the\npatient, approach and architecture. This new line of research has the potential\nto develop therapeutic interventions and save human lives.\n","authors":["Zakary Georgis-Yap","Milos R. Popovic","Shehroz S. Khan"],"pdf_url":"https://arxiv.org/pdf/2304.14922v2.pdf","comment":"16 figures, 9 tables"},{"id":"http://arxiv.org/abs/2307.01452v2","updated":"2023-11-21T03:43:15Z","published":"2023-07-04T03:00:43Z","title":"Causal Reinforcement Learning: A Survey","summary":"  Reinforcement learning is an essential paradigm for solving sequential\ndecision problems under uncertainty. Despite many remarkable achievements in\nrecent decades, applying reinforcement learning methods in the real world\nremains challenging. One of the main obstacles is that reinforcement learning\nagents lack a fundamental understanding of the world and must therefore learn\nfrom scratch through numerous trial-and-error interactions. They may also face\nchallenges in providing explanations for their decisions and generalizing the\nacquired knowledge. Causality, however, offers a notable advantage as it can\nformalize knowledge in a systematic manner and leverage invariance for\neffective knowledge transfer. This has led to the emergence of causal\nreinforcement learning, a subfield of reinforcement learning that seeks to\nenhance existing algorithms by incorporating causal relationships into the\nlearning process. In this survey, we comprehensively review the literature on\ncausal reinforcement learning. We first introduce the basic concepts of\ncausality and reinforcement learning, and then explain how causality can\naddress core challenges in non-causal reinforcement learning. We categorize and\nsystematically review existing causal reinforcement learning approaches based\non their target problems and methodologies. Finally, we outline open issues and\nfuture directions in this emerging field.\n","authors":["Zhihong Deng","Jing Jiang","Guodong Long","Chengqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2307.01452v2.pdf","comment":"52 pages, 10 figures"},{"id":"http://arxiv.org/abs/2311.12329v1","updated":"2023-11-21T03:42:15Z","published":"2023-11-21T03:42:15Z","title":"Graph Neural Ordinary Differential Equations-based method for\n  Collaborative Filtering","summary":"  Graph Convolution Networks (GCNs) are widely considered state-of-the-art for\ncollaborative filtering. Although several GCN-based methods have been proposed\nand achieved state-of-the-art performance in various tasks, they can be\ncomputationally expensive and time-consuming to train if too many layers are\ncreated. However, since the linear GCN model can be interpreted as a\ndifferential equation, it is possible to transfer it to an ODE problem. This\ninspired us to address the computational limitations of GCN-based models by\ndesigning a simple and efficient NODE-based model that can skip some GCN layers\nto reach the final state, thus avoiding the need to create many layers. In this\nwork, we propose a Graph Neural Ordinary Differential Equation-based method for\nCollaborative Filtering (GODE-CF). This method estimates the final embedding by\nutilizing the information captured by one or two GCN layers. To validate our\napproach, we conducted experiments on multiple datasets. The results\ndemonstrate that our model outperforms competitive baselines, including\nGCN-based models and other state-of-the-art CF methods. Notably, our proposed\nGODE-CF model has several advantages over traditional GCN-based models. It is\nsimple, efficient, and has a fast training time, making it a practical choice\nfor real-world situations.\n","authors":["Ke Xu","Yuanjie Zhu","Weizhi Zhang","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2311.12329v1.pdf","comment":"Accepted by ICDM 2023"},{"id":"http://arxiv.org/abs/2311.12323v1","updated":"2023-11-21T03:34:20Z","published":"2023-11-21T03:34:20Z","title":"Modeling Political Orientation of Social Media Posts: An Extended\n  Analysis","summary":"  Developing machine learning models to characterize political polarization on\nonline social media presents significant challenges. These challenges mainly\nstem from various factors such as the lack of annotated data, presence of noise\nin social media datasets, and the sheer volume of data. The common research\npractice typically examines the biased structure of online user communities for\na given topic or qualitatively measuring the impacts of polarized topics on\nsocial media. However, there is limited work focusing on analyzing polarization\nat the ground-level, specifically in the social media posts themselves. Such\nexisting analysis heavily relies on annotated data, which often requires\nlaborious human labeling, offers labels only to specific problems, and lacks\nthe ability to determine the near-future bias state of a social media\nconversations. Understanding the degree of political orientation conveyed in\nsocial media posts is crucial for quantifying the bias of online user\ncommunities and investigating the spread of polarized content. In this work, we\nfirst introduce two heuristic methods that leverage on news media bias and post\ncontent to label social media posts. Next, we compare the efficacy and quality\nof heuristically labeled dataset with a randomly sampled human-annotated\ndataset. Additionally, we demonstrate that current machine learning models can\nexhibit improved performance in predicting political orientation of social\nmedia posts, employing both traditional supervised learning and few-shot\nlearning setups. We conduct experiments using the proposed heuristic methods\nand machine learning approaches to predict the political orientation of posts\ncollected from two social media forums with diverse political ideologies: Gab\nand Twitter.\n","authors":["Sadia Kamal","Brenner Little","Jade Gullic","Trevor Harms","Kristin Olofsson","Arunkumar Bagavathi"],"pdf_url":"https://arxiv.org/pdf/2311.12323v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.13108v2","updated":"2023-11-21T03:25:56Z","published":"2023-09-22T18:00:01Z","title":"Data is often loadable in short depth: Quantum circuits from tensor\n  networks for finance, images, fluids, and proteins","summary":"  Though there has been substantial progress in developing quantum algorithms\nto study classical datasets, the cost of simply loading classical data is an\nobstacle to quantum advantage. When the amplitude encoding is used, loading an\narbitrary classical vector requires up to exponential circuit depths with\nrespect to the number of qubits. Here, we address this \"input problem\" with two\ncontributions. First, we introduce a circuit compilation method based on tensor\nnetwork (TN) theory. Our method -- AMLET (Automatic Multi-layer Loader\nExploiting TNs) -- proceeds via careful construction of a specific TN topology\nand can be tailored to arbitrary circuit depths. Second, we perform numerical\nexperiments on real-world classical data from four distinct areas: finance,\nimages, fluid mechanics, and proteins. To the best of our knowledge, this is\nthe broadest numerical analysis to date of loading classical data into a\nquantum computer. Consistent with other recent work in this area, the required\ncircuit depths are often several orders of magnitude lower than the\nexponentially-scaling general loading algorithm would require. Besides\nintroducing a more efficient loading algorithm, this work demonstrates that\nmany classical datasets are loadable in depths that are much shorter than\npreviously expected, which has positive implications for speeding up classical\nworkloads on quantum computers.\n","authors":["Raghav Jumade","Nicolas PD Sawaya"],"pdf_url":"https://arxiv.org/pdf/2309.13108v2.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.03488v3","updated":"2023-11-21T03:08:37Z","published":"2023-11-06T19:52:55Z","title":"Multi-Resolution Diffusion for Privacy-Sensitive Recommender Systems","summary":"  While recommender systems have become an integral component of the Web\nexperience, their heavy reliance on user data raises privacy and security\nconcerns. Substituting user data with synthetic data can address these\nconcerns, but accurately replicating these real-world datasets has been a\nnotoriously challenging problem. Recent advancements in generative AI have\ndemonstrated the impressive capabilities of diffusion models in generating\nrealistic data across various domains. In this work we introduce a Score-based\nDiffusion Recommendation Module (SDRM), which captures the intricate patterns\nof real-world datasets required for training highly accurate recommender\nsystems. SDRM allows for the generation of synthetic data that can replace\nexisting datasets to preserve user privacy, or augment existing datasets to\naddress excessive data sparsity. Our method outperforms competing baselines\nsuch as generative adversarial networks, variational autoencoders, and recently\nproposed diffusion models in synthesizing various datasets to replace or\naugment the original data by an average improvement of 4.30% in Recall@$k$ and\n4.65% in NDCG@$k$.\n","authors":["Derek Lilienthal","Paul Mello","Magdalini Eirinaki","Stas Tiomkin"],"pdf_url":"https://arxiv.org/pdf/2311.03488v3.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.12310v1","updated":"2023-11-21T03:02:33Z","published":"2023-11-21T03:02:33Z","title":"IEKM: A Model Incorporating External Keyword Matrices","summary":"  A customer service platform system with a core text semantic similarity (STS)\ntask faces two urgent challenges: Firstly, one platform system needs to adapt\nto different domains of customers, i.e., different domains adaptation (DDA).\nSecondly, it is difficult for the model of the platform system to distinguish\nsentence pairs that are literally close but semantically different, i.e., hard\nnegative samples. In this paper, we propose an incorporation external keywords\nmatrices model (IEKM) to address these challenges. The model uses external\ntools or dictionaries to construct external matrices and fuses them to the\nself-attention layers of the Transformer structure through gating units, thus\nenabling flexible corrections to the model results. We evaluate the method on\nmultiple datasets and the results show that our method has improved performance\non all datasets. To demonstrate that our method can effectively solve all the\nabove challenges, we conduct a flexible correction experiment, which results in\nan increase in the F1 value from 56.61 to 73.53. Our code will be publicly\navailable.\n","authors":["Cheng Luo","Qin Li","Zhao Yan","Mengliang Rao","Yunbo Cao"],"pdf_url":"https://arxiv.org/pdf/2311.12310v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12309v1","updated":"2023-11-21T03:02:30Z","published":"2023-11-21T03:02:30Z","title":"Power grid operational risk assessment using graph neural network\n  surrogates","summary":"  We investigate the utility of graph neural networks (GNNs) as proxies of\npower grid operational decision-making algorithms (optimal power flow (OPF) and\nsecurity-constrained unit commitment (SCUC)) to enable rigorous quantification\nof the operational risk. To conduct principled risk analysis, numerous Monte\nCarlo (MC) samples are drawn from the (foretasted) probability distributions of\nspatio-temporally correlated stochastic grid variables. The corresponding OPF\nand SCUC solutions, which are needed to quantify the risk, are generated using\ntraditional OPF and SCUC solvers to generate data for training GNN model(s).\nThe GNN model performance is evaluated in terms of the accuracy of predicting\nquantities of interests (QoIs) derived from the decision variables in OPF and\nSCUC. Specifically, we focus on thermal power generation and load shedding at\nsystem and individual zone level. We also perform reliability and risk\nquantification based on GNN predictions and compare with that obtained from\nOPF/SCUC solutions. Our results demonstrate that GNNs are capable of providing\nfast and accurate prediction of QoIs and thus can be good surrogate models for\nOPF and SCUC. The excellent accuracy of GNN-based reliability and risk\nassessment further suggests that GNN surrogate has the potential to be applied\nin real-time and hours-ahead risk quantification.\n","authors":["Yadong Zhang","Pranav M Karve","Sankaran Mahadevan"],"pdf_url":"https://arxiv.org/pdf/2311.12309v1.pdf","comment":"Manuscript submitted to IEEE PES GM 2024"},{"id":"http://arxiv.org/abs/2311.12304v1","updated":"2023-11-21T02:46:14Z","published":"2023-11-21T02:46:14Z","title":"Discovering Effective Policies for Land-Use Planning","summary":"  How areas of land are allocated for different uses, such as forests, urban,\nand agriculture, has a large effect on carbon balance, and therefore climate\nchange. Based on available historical data on changes in land use and a\nsimulation of carbon emissions/absorption, a surrogate model can be learned\nthat makes it possible to evaluate the different options available to\ndecision-makers efficiently. An evolutionary search process can then be used to\ndiscover effective land-use policies for specific locations. Such a system was\nbuilt on the Project Resilience platform and evaluated with the Land-Use\nHarmonization dataset and the BLUE simulator. It generates Pareto fronts that\ntrade off carbon impact and amount of change customized to different locations,\nthus providing a potentially useful tool for land-use planning.\n","authors":["Risto Miikkulainen","Olivier Francon","Daniel Young","Elliot Meyerson","Babak Hodjat"],"pdf_url":"https://arxiv.org/pdf/2311.12304v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12303v1","updated":"2023-11-21T02:45:53Z","published":"2023-11-21T02:45:53Z","title":"Detecting subtle macroscopic changes in a finite temperature classical\n  scalar field with machine learning","summary":"  The ability to detect macroscopic changes is important for probing the\nbehaviors of experimental many-body systems from the classical to the quantum\nrealm. Although abrupt changes near phase boundaries can easily be detected,\nsubtle macroscopic changes are much more difficult to detect as the changes can\nbe obscured by noise. In this study, as a toy model for detecting subtle\nmacroscopic changes in many-body systems, we try to differentiate scalar field\nsamples at varying temperatures. We compare different methods for making such\ndifferentiations, from physics method, statistics method, to AI method. Our\nfinding suggests that the AI method outperforms both the statistical method and\nthe physics method in its sensitivity. Our result provides a proof-of-concept\nthat AI can potentially detect macroscopic changes in many-body systems that\nelude physical measures.\n","authors":["Jiming Yang","Yutong Zheng","Jiahong Zhou","Huiyu Li","Jun Yin"],"pdf_url":"https://arxiv.org/pdf/2311.12303v1.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2310.13230v2","updated":"2023-11-21T02:28:21Z","published":"2023-10-20T02:40:05Z","title":"Absolute Policy Optimization","summary":"  In recent years, trust region on-policy reinforcement learning has achieved\nimpressive results in addressing complex control tasks and gaming scenarios.\nHowever, contemporary state-of-the-art algorithms within this category\nprimarily emphasize improvement in expected performance, lacking the ability to\ncontrol over the worst-case performance outcomes. To address this limitation,\nwe introduce a novel objective function; by optimizing which, it will lead to\nguaranteed monotonic improvement in the lower bound of near-total performance\nsamples (absolute performance). Considering this groundbreaking theoretical\nadvancement, we then refine this theoretically grounded algorithm through a\nseries of approximations, resulting in a practical solution called Absolute\nPolicy Optimization (APO). Our experiments demonstrate the effectiveness of our\napproach across challenging continuous control benchmark tasks and extend its\napplicability to mastering Atari games. Our findings reveal that APO\nsignificantly outperforms state-of-the-art policy gradient algorithms,\nresulting in substantial improvements in both expected performance and\nworst-case performance.\n","authors":["Weiye Zhao","Feihan Li","Yifan Sun","Rui Chen","Tianhao Wei","Changliu Liu"],"pdf_url":"https://arxiv.org/pdf/2310.13230v2.pdf","comment":"I submitted this article to Journal of Machine Learning Research. The\n  manuscript will go under a major revision and I don't want the reviewer know\n  who I am. I will re-upload after JMLR review released"},{"id":"http://arxiv.org/abs/2311.12292v1","updated":"2023-11-21T02:24:52Z","published":"2023-11-21T02:24:52Z","title":"Mapping \"Brain Coral\" Regions on Mars using Deep Learning","summary":"  One of the main objectives of the Mars Exploration Program is to search for\nevidence of past or current life on the planet. To achieve this, Mars\nexploration has been focusing on regions that may have liquid or frozen water.\nA set of critical areas may have seen cycles of ice thawing in the relatively\nrecent past in response to periodic changes in the obliquity of Mars. In this\nwork, we use convolutional neural networks to detect surface regions containing\n\"Brain Coral\" terrain, a landform on Mars whose similarity in morphology and\nscale to sorted stone circles on Earth suggests that it may have formed as a\nconsequence of freeze/thaw cycles. We use large images (~100-1000 megapixels)\nfrom the Mars Reconnaissance Orbiter to search for these landforms at\nresolutions close to a few tens of centimeters per pixel (~25--50 cm). Over\n52,000 images (~28 TB) were searched (~5% of the Martian surface) where we\nfound detections in over 200 images. To expedite the processing we leverage a\nclassifier network (prior to segmentation) in the Fourier domain that can take\nadvantage of JPEG compression by leveraging blocks of coefficients from a\ndiscrete cosine transform in lieu of decoding the entire image at the full\nspatial resolution. The hybrid pipeline approach maintains ~93% accuracy while\ncutting down on ~95% of the total processing time compared to running the\nsegmentation network at the full resolution on every image. The timely\nprocessing of big data sets helps inform mission operations, geologic surveys\nto prioritize candidate landing sites, avoid hazardous areas, or map the\nspatial extent of certain terrain. The segmentation masks and source code are\navailable on Github for the community to explore and build upon.\n","authors":["Kyle A. Pearson","Eldar Noe","Daniel Zhao","Alphan Altinok","Alex Morgan"],"pdf_url":"https://arxiv.org/pdf/2311.12292v1.pdf","comment":"Submitted for publication, seeking comments from the community. Code\n  available: https://github.com/pearsonkyle/Mars-Brain-Coral-Network"},{"id":"http://arxiv.org/abs/2311.10899v2","updated":"2023-11-21T02:16:27Z","published":"2023-11-17T22:44:05Z","title":"Extraction and Summarization of Explicit Video Content using Multi-Modal\n  Deep Learning","summary":"  With the increase in video-sharing platforms across the internet, it is\ndifficult for humans to moderate the data for explicit content. Hence, an\nautomated pipeline to scan through video data for explicit content has become\nthe need of the hour. We propose a novel pipeline that uses multi-modal deep\nlearning to first extract the explicit segments of input videos and then\nsummarize their content using text to determine its age appropriateness and age\nrating. We also evaluate our pipeline's effectiveness in the end using standard\nmetrics.\n","authors":["Shaunak Joshi","Raghav Gaggar"],"pdf_url":"https://arxiv.org/pdf/2311.10899v2.pdf","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2304.07927v2","updated":"2023-11-21T02:15:33Z","published":"2023-04-17T00:38:01Z","title":"A Randomized Approach for Tight Privacy Accounting","summary":"  Bounding privacy leakage over compositions, i.e., privacy accounting, is a\nkey challenge in differential privacy (DP). The privacy parameter ($\\eps$ or\n$\\delta$) is often easy to estimate but hard to bound. In this paper, we\npropose a new differential privacy paradigm called estimate-verify-release\n(EVR), which addresses the challenges of providing a strict upper bound for\nprivacy parameter in DP compositions by converting an estimate of privacy\nparameter into a formal guarantee. The EVR paradigm first estimates the privacy\nparameter of a mechanism, then verifies whether it meets this guarantee, and\nfinally releases the query output based on the verification result. The core\ncomponent of the EVR is privacy verification. We develop a randomized privacy\nverifier using Monte Carlo (MC) technique. Furthermore, we propose an MC-based\nDP accountant that outperforms existing DP accounting techniques in terms of\naccuracy and efficiency. Our empirical evaluation shows the newly proposed EVR\nparadigm improves the utility-privacy tradeoff for privacy-preserving machine\nlearning.\n","authors":["Jiachen T. Wang","Saeed Mahloujifar","Tong Wu","Ruoxi Jia","Prateek Mittal"],"pdf_url":"https://arxiv.org/pdf/2304.07927v2.pdf","comment":"NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.13059v1","updated":"2023-11-21T23:46:44Z","published":"2023-11-21T23:46:44Z","title":"A note on estimating the dimension from a random geometric graph","summary":"  Let $G_n$ be a random geometric graph with vertex set $[n]$ based on $n$\ni.i.d.\\ random vectors $X_1,\\ldots,X_n$ drawn from an unknown density $f$ on\n$\\R^d$. An edge $(i,j)$ is present when $\\|X_i -X_j\\| \\le r_n$, for a given\nthreshold $r_n$ possibly depending upon $n$, where $\\| \\cdot \\|$ denotes\nEuclidean distance. We study the problem of estimating the dimension $d$ of the\nunderlying space when we have access to the adjacency matrix of the graph but\ndo not know $r_n$ or the vectors $X_i$. The main result of the paper is that\nthere exists an estimator of $d$ that converges to $d$ in probability as $n \\to\n\\infty$ for all densities with $\\int f^5 < \\infty$ whenever $n^{3/2} r_n^d \\to\n\\infty$ and $r_n = o(1)$. The conditions allow very sparse graphs since when\n$n^{3/2} r_n^d \\to 0$, the graph contains isolated edges only, with high\nprobability. We also show that, without any condition on the density, a\nconsistent estimator of $d$ exists when $n r_n^d \\to \\infty$ and $r_n = o(1)$.\n","authors":["Caelan Atamanchuk","Luc Devroye","Gabor Lugosi"],"pdf_url":"https://arxiv.org/pdf/2311.13059v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.17301v2","updated":"2023-11-21T23:42:55Z","published":"2023-06-29T20:58:48Z","title":"Why Shallow Networks Struggle with Approximating and Learning High\n  Frequency: A Numerical Study","summary":"  In this work, a comprehensive numerical study involving analysis and\nexperiments shows why a two-layer neural network has difficulties handling high\nfrequencies in approximation and learning when machine precision and\ncomputation cost are important factors in real practice. In particular, the\nfollowing basic computational issues are investigated: (1) the minimal\nnumerical error one can achieve given a finite machine precision, (2) the\ncomputation cost to achieve a given accuracy, and (3) stability with respect to\nperturbations. The key to the study is the conditioning of the representation\nand its learning dynamics. Explicit answers to the above questions with\nnumerical verifications are presented.\n","authors":["Shijun Zhang","Hongkai Zhao","Yimin Zhong","Haomin Zhou"],"pdf_url":"https://arxiv.org/pdf/2306.17301v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13052v1","updated":"2023-11-21T23:25:04Z","published":"2023-11-21T23:25:04Z","title":"Novel OCT mosaicking pipeline with Feature- and Pixel-based registration","summary":"  High-resolution Optical Coherence Tomography (OCT) images are crucial for\nophthalmology studies but are limited by their relatively narrow field of view\n(FoV). Image mosaicking is a technique for aligning multiple overlapping images\nto obtain a larger FoV. Current mosaicking pipelines often struggle with\nsubstantial noise and considerable displacement between the input sub-fields.\nIn this paper, we propose a versatile pipeline for stitching multi-view\nOCT/OCTA \\textit{en face} projection images. Our method combines the strengths\nof learning-based feature matching and robust pixel-based registration to align\nmultiple images effectively. Furthermore, we advance the application of a\ntrained foundational model, Segment Anything Model (SAM), to validate\nmosaicking results in an unsupervised manner. The efficacy of our pipeline is\nvalidated using an in-house dataset and a large public dataset, where our\nmethod shows superior performance in terms of both accuracy and computational\nefficiency. We also made our evaluation tool for image mosaicking and the\ncorresponding pipeline publicly available at\n\\url{https://github.com/MedICL-VU/OCT-mosaicking}.\n","authors":["Jiacheng Wang","Hao Li","Dewei Hu","Yuankai K. Tao","Ipek Oguz"],"pdf_url":"https://arxiv.org/pdf/2311.13052v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.16020v2","updated":"2023-11-21T23:23:08Z","published":"2023-09-27T20:54:56Z","title":"GeoCLIP: Clip-Inspired Alignment between Locations and Images for\n  Effective Worldwide Geo-localization","summary":"  Worldwide Geo-localization aims to pinpoint the precise location of images\ntaken anywhere on Earth. This task has considerable challenges due to immense\nvariation in geographic landscapes. The image-to-image retrieval-based\napproaches fail to solve this problem on a global scale as it is not feasible\nto construct a large gallery of images covering the entire world. Instead,\nexisting approaches divide the globe into discrete geographic cells,\ntransforming the problem into a classification task. However, their performance\nis limited by the predefined classes and often results in inaccurate\nlocalizations when an image's location significantly deviates from its class\ncenter. To overcome these limitations, we propose GeoCLIP, a novel\nCLIP-inspired Image-to-GPS retrieval approach that enforces alignment between\nthe image and its corresponding GPS locations. GeoCLIP's location encoder\nmodels the Earth as a continuous function by employing positional encoding\nthrough random Fourier features and constructing a hierarchical representation\nthat captures information at varying resolutions to yield a semantically rich\nhigh-dimensional feature suitable to use even beyond geo-localization. To the\nbest of our knowledge, this is the first work employing GPS encoding for\ngeo-localization. We demonstrate the efficacy of our method via extensive\nexperiments and ablations on benchmark datasets. We achieve competitive\nperformance with just 20% of training data, highlighting its effectiveness even\nin limited-data settings. Furthermore, we qualitatively demonstrate\ngeo-localization using a text query by leveraging CLIP backbone of our image\nencoder. The project webpage is available at:\nhttps://vicentevivan.github.io/GeoCLIP\n","authors":["Vicente Vivanco Cepeda","Gaurav Kumar Nayak","Mubarak Shah"],"pdf_url":"https://arxiv.org/pdf/2309.16020v2.pdf","comment":"Accepted at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.13050v1","updated":"2023-11-21T23:22:11Z","published":"2023-11-21T23:22:11Z","title":"Multi-fidelity Bayesian Optimization in Engineering Design","summary":"  Resided at the intersection of multi-fidelity optimization (MFO) and Bayesian\noptimization (BO), MF BO has found a niche in solving expensive engineering\ndesign optimization problems, thanks to its advantages in incorporating\nphysical and mathematical understandings of the problems, saving resources,\naddressing exploitation-exploration trade-off, considering uncertainty, and\nprocessing parallel computing. The increasing number of works dedicated to MF\nBO suggests the need for a comprehensive review of this advanced optimization\ntechnique. In this paper, we survey recent developments of two essential\ningredients of MF BO: Gaussian process (GP) based MF surrogates and acquisition\nfunctions. We first categorize the existing MF modeling methods and MFO\nstrategies to locate MF BO in a large family of surrogate-based optimization\nand MFO algorithms. We then exploit the common properties shared between the\nmethods from each ingredient of MF BO to describe important GP-based MF\nsurrogate models and review various acquisition functions. By doing so, we\nexpect to provide a structured understanding of MF BO. Finally, we attempt to\nreveal important aspects that require further research for applications of MF\nBO in solving intricate yet important design optimization problems, including\nconstrained optimization, high-dimensional optimization, optimization under\nuncertainty, and multi-objective optimization.\n","authors":["Bach Do","Ruda Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.13050v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13046v1","updated":"2023-11-21T23:14:47Z","published":"2023-11-21T23:14:47Z","title":"Do we listen to what we are told? An empirical study on human behaviour\n  during the COVID-19 pandemic: neural networks vs. regression analysis","summary":"  In this work, we contribute the first visual open-source empirical study on\nhuman behaviour during the COVID-19 pandemic, in order to investigate how\ncompliant a general population is to mask-wearing-related public-health policy.\nObject-detection-based convolutional neural networks, regression analysis and\nmultilayer perceptrons are combined to analyse visual data of the Viennese\npublic during 2020. We find that mask-wearing-related government regulations\nand public-transport announcements encouraged correct mask-wearing-behaviours\nduring the COVID-19 pandemic. Importantly, changes in announcement and\nregulation contents led to heterogeneous effects on people's behaviour.\nComparing the predictive power of regression analysis and neural networks, we\ndemonstrate that the latter produces more accurate predictions of population\nreactions during the COVID-19 pandemic. Our use of regression modelling also\nallows us to unearth possible causal pathways underlying societal behaviour.\nSince our findings highlight the importance of appropriate communication\ncontents, our results will facilitate more effective non-pharmaceutical\ninterventions to be developed in future. Adding to the literature, we\ndemonstrate that regression modelling and neural networks are not mutually\nexclusive but instead complement each other.\n","authors":["Yuxi Heluo","Kexin Wang","Charles W. Robson"],"pdf_url":"https://arxiv.org/pdf/2311.13046v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.13933v2","updated":"2023-11-21T23:06:51Z","published":"2022-08-30T00:08:37Z","title":"Using Taylor-Approximated Gradients to Improve the Frank-Wolfe Method\n  for Empirical Risk Minimization","summary":"  The Frank-Wolfe method has become increasingly useful in statistical and\nmachine learning applications, due to the structure-inducing properties of the\niterates, and especially in settings where linear minimization over the\nfeasible set is more computationally efficient than projection. In the setting\nof Empirical Risk Minimization -- one of the fundamental optimization problems\nin statistical and machine learning -- the computational effectiveness of\nFrank-Wolfe methods typically grows linearly in the number of data observations\n$n$. This is in stark contrast to the case for typical stochastic projection\nmethods. In order to reduce this dependence on $n$, we look to second-order\nsmoothness of typical smooth loss functions (least squares loss and logistic\nloss, for example) and we propose amending the Frank-Wolfe method with Taylor\nseries-approximated gradients, including variants for both deterministic and\nstochastic settings. Compared with current state-of-the-art methods in the\nregime where the optimality tolerance $\\varepsilon$ is sufficiently small, our\nmethods are able to simultaneously reduce the dependence on large $n$ while\nobtaining optimal convergence rates of Frank-Wolfe methods, in both the convex\nand non-convex settings. We also propose a novel adaptive step-size approach\nfor which we have computational guarantees. Last of all, we present\ncomputational experiments which show that our methods exhibit very significant\nspeed-ups over existing methods on real-world datasets for both convex and\nnon-convex binary classification problems.\n","authors":["Zikai Xiong","Robert M. Freund"],"pdf_url":"https://arxiv.org/pdf/2208.13933v2.pdf","comment":"30 pages, 2 figures"},{"id":"http://arxiv.org/abs/2311.10242v2","updated":"2023-11-21T23:01:29Z","published":"2023-11-17T00:08:19Z","title":"Advancements in Generative AI: A Comprehensive Review of GANs, GPT,\n  Autoencoders, Diffusion Model, and Transformers","summary":"  The launch of ChatGPT has garnered global attention, marking a significant\nmilestone in the field of Generative Artificial Intelligence. While Generative\nAI has been in effect for the past decade, the introduction of ChatGPT has\nignited a new wave of research and innovation in the AI domain. This surge in\ninterest has led to the development and release of numerous cutting-edge tools,\nsuch as Bard, Stable Diffusion, DALL-E, Make-A-Video, Runway ML, and Jukebox,\namong others. These tools exhibit remarkable capabilities, encompassing tasks\nranging from text generation and music composition, image creation, video\nproduction, code generation, and even scientific work. They are built upon\nvarious state-of-the-art models, including Stable Diffusion, transformer models\nlike GPT-3 (recent GPT-4), variational autoencoders, and generative adversarial\nnetworks. This advancement in Generative AI presents a wealth of exciting\nopportunities and, simultaneously, unprecedented challenges. Throughout this\npaper, we have explored these state-of-the-art models, the diverse array of\ntasks they can accomplish, the challenges they pose, and the promising future\nof Generative Artificial Intelligence.\n","authors":["Staphord Bengesi","Hoda El-Sayed","Md Kamruzzaman Sarker","Yao Houkpati","John Irungu","Timothy Oladunni"],"pdf_url":"https://arxiv.org/pdf/2311.10242v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13038v1","updated":"2023-11-21T22:56:13Z","published":"2023-11-21T22:56:13Z","title":"Synaptic Sampling of Neural Networks","summary":"  Probabilistic artificial neural networks offer intriguing prospects for\nenabling the uncertainty of artificial intelligence methods to be described\nexplicitly in their function; however, the development of techniques that\nquantify uncertainty by well-understood methods such as Monte Carlo sampling\nhas been limited by the high costs of stochastic sampling on deterministic\ncomputing hardware. Emerging computing systems that are amenable to\nhardware-level probabilistic computing, such as those that leverage stochastic\ndevices, may make probabilistic neural networks more feasible in the\nnot-too-distant future. This paper describes the scANN technique --\n\\textit{sampling (by coinflips) artificial neural networks} -- which enables\nneural networks to be sampled directly by treating the weights as Bernoulli\ncoin flips. This method is natively well suited for probabilistic computing\ntechniques that focus on tunable stochastic devices, nearly matches fully\ndeterministic performance while also describing the uncertainty of correct and\nincorrect neural network outputs.\n","authors":["James B. Aimone","William Severa","J. Darby Smith"],"pdf_url":"https://arxiv.org/pdf/2311.13038v1.pdf","comment":"9 pages, accepted to 2023 IEEE International Conference on Rebooting\n  Computing"},{"id":"http://arxiv.org/abs/2311.13036v1","updated":"2023-11-21T22:53:20Z","published":"2023-11-21T22:53:20Z","title":"Favour: FAst Variance Operator for Uncertainty Rating","summary":"  Bayesian Neural Networks (BNN) have emerged as a crucial approach for\ninterpreting ML predictions. By sampling from the posterior distribution, data\nscientists may estimate the uncertainty of an inference. Unfortunately many\ninference samples are often needed, the overhead of which greatly hinder BNN's\nwide adoption. To mitigate this, previous work proposed propagating the first\nand second moments of the posterior directly through the network. However, on\nits own this method is even slower than sampling, so the propagated variance\nneeds to be approximated such as assuming independence between neural nodes.\nThe resulting trade-off between quality and inference time did not match even\nplain Monte Carlo sampling.\n  Our contribution is a more principled variance propagation framework based on\n\"spiked covariance matrices\", which smoothly interpolates between quality and\ninference time. This is made possible by a new fast algorithm for updating a\ndiagonal-plus-low-rank matrix approximation under various operations. We tested\nour algorithm against sampling based MC Dropout and Variational Inference on a\nnumber of downstream uncertainty themed tasks, such as calibration and\nout-of-distribution testing. We find that Favour is as fast as performing 2-3\ninference samples, while matching the performance of 10-100 samples.\n  In summary, this work enables the use of BNN in the realm of performance\ncritical tasks where they have previously been out of reach.\n","authors":["Thomas D. Ahle","Sahar Karimi","Peter Tak Peter Tang"],"pdf_url":"https://arxiv.org/pdf/2311.13036v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.08549v3","updated":"2023-11-21T22:49:27Z","published":"2023-09-15T17:12:19Z","title":"HINT: Healthy Influential-Noise based Training to Defend against Data\n  Poisoning Attacks","summary":"  While numerous defense methods have been proposed to prohibit potential\npoisoning attacks from untrusted data sources, most research works only defend\nagainst specific attacks, which leaves many avenues for an adversary to\nexploit. In this work, we propose an efficient and robust training approach to\ndefend against data poisoning attacks based on influence functions, named\nHealthy Influential-Noise based Training. Using influence functions, we craft\nhealthy noise that helps to harden the classification model against poisoning\nattacks without significantly affecting the generalization ability on test\ndata. In addition, our method can perform effectively when only a subset of the\ntraining data is modified, instead of the current method of adding noise to all\nexamples that has been used in several previous works. We conduct comprehensive\nevaluations over two image datasets with state-of-the-art poisoning attacks\nunder different realistic attack scenarios. Our empirical results show that\nHINT can efficiently protect deep learning models against the effect of both\nuntargeted and targeted poisoning attacks.\n","authors":["Minh-Hao Van","Alycia N. Carey","Xintao Wu"],"pdf_url":"https://arxiv.org/pdf/2309.08549v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.11280v2","updated":"2023-11-21T22:35:18Z","published":"2023-07-21T00:49:07Z","title":"Epsilon*: Privacy Metric for Machine Learning Models","summary":"  We introduce Epsilon*, a new privacy metric for measuring the privacy risk of\na single model instance prior to, during, or after deployment of privacy\nmitigation strategies. The metric requires only black-box access to model\npredictions, does not require training data re-sampling or model re-training,\nand can be used to measure the privacy risk of models not trained with\ndifferential privacy. Epsilon* is a function of true positive and false\npositive rates in a hypothesis test used by an adversary in a membership\ninference attack. We distinguish between quantifying the privacy loss of a\ntrained model instance, which we refer to as empirical privacy, and quantifying\nthe privacy loss of the training mechanism which produces this model instance.\nExisting approaches in the privacy auditing literature provide lower bounds for\nthe latter, while our metric provides an empirical lower bound for the former\nby relying on an (${\\epsilon}$, ${\\delta}$)-type of quantification of the\nprivacy of the trained model instance. We establish a relationship between\nthese lower bounds and show how to implement Epsilon* to avoid numerical and\nnoise amplification instability. We further show in experiments on benchmark\npublic data sets that Epsilon* is sensitive to privacy risk mitigation by\ntraining with differential privacy (DP), where the value of Epsilon* is reduced\nby up to 800% compared to the Epsilon* values of non-DP trained baseline\nmodels. This metric allows privacy auditors to be independent of model owners,\nand enables visualizing the privacy-utility landscape to make informed\ndecisions regarding the trade-offs between model privacy and utility.\n","authors":["Diana M. Negoescu","Humberto Gonzalez","Saad Eddin Al Orjany","Jilei Yang","Yuliia Lut","Rahul Tandra","Xiaowen Zhang","Xinyi Zheng","Zach Douglas","Vidita Nolkha","Parvez Ahammad","Gennady Samorodnitsky"],"pdf_url":"https://arxiv.org/pdf/2307.11280v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13028v1","updated":"2023-11-21T22:29:25Z","published":"2023-11-21T22:29:25Z","title":"DMLR: Data-centric Machine Learning Research -- Past, Present and Future","summary":"  Drawing from discussions at the inaugural DMLR workshop at ICML 2023 and\nmeetings prior, in this report we outline the relevance of community engagement\nand infrastructure development for the creation of next-generation public\ndatasets that will advance machine learning science. We chart a path forward as\na collective effort to sustain the creation and maintenance of these datasets\nand methods towards positive scientific, societal and business impact.\n","authors":["Luis Oala","Manil Maskey","Lilith Bat-Leah","Alicia Parrish","Nezihe Merve Gürel","Tzu-Sheng Kuo","Yang Liu","Rotem Dror","Danilo Brajovic","Xiaozhe Yao","Max Bartolo","William A Gaviria Rojas","Ryan Hileman","Rainier Aliment","Michael W. Mahoney","Meg Risdal","Matthew Lease","Wojciech Samek","Debojyoti Dutta","Curtis G Northcutt","Cody Coleman","Braden Hancock","Bernard Koch","Girmaw Abebe Tadesse","Bojan Karlaš","Ahmed Alaa","Adji Bousso Dieng","Natasha Noy","Vijay Janapa Reddi","James Zou","Praveen Paritosh","Mihaela van der Schaar","Kurt Bollacker","Lora Aroyo","Ce Zhang","Joaquin Vanschoren","Isabelle Guyon","Peter Mattson"],"pdf_url":"https://arxiv.org/pdf/2311.13028v1.pdf","comment":"This editorial report accompanies the inaugural Data-centric Machine\n  Learning Research (DMLR) Workshop that took place at ICML 2023\n  https://dmlr.ai/"},{"id":"http://arxiv.org/abs/2310.15290v2","updated":"2023-11-21T22:19:09Z","published":"2023-10-23T18:56:01Z","title":"Reliable Generation of EHR Time Series via Diffusion Models","summary":"  Electronic Health Records (EHRs) are rich sources of patient-level data,\nincluding laboratory tests, medications, and diagnoses, offering valuable\nresources for medical data analysis. However, concerns about privacy often\nrestrict access to EHRs, hindering downstream analysis. Researchers have\nexplored various methods for generating privacy-preserving EHR data. In this\nstudy, we introduce a new method for generating diverse and realistic synthetic\nEHR time series data using Denoising Diffusion Probabilistic Models (DDPM). We\nconducted experiments on six datasets, comparing our proposed method with eight\nexisting methods. Our results demonstrate that our approach significantly\noutperforms all existing methods in terms of data utility while requiring less\ntraining effort. Our approach also enhances downstream medical data analysis by\nproviding diverse and realistic synthetic EHR data.\n","authors":["Muhang Tian","Bernie Chen","Allan Guo","Shiyi Jiang","Anru R. Zhang"],"pdf_url":"https://arxiv.org/pdf/2310.15290v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.01897v2","updated":"2023-11-21T22:08:41Z","published":"2023-09-05T02:15:08Z","title":"Inferring Actual Treatment Pathways from Patient Records","summary":"  Treatment pathways are step-by-step plans outlining the recommended medical\ncare for specific diseases; they get revised when different treatments are\nfound to improve patient outcomes. Examining health records is an important\npart of this revision process, but inferring patients' actual treatments from\nhealth data is challenging due to complex event-coding schemes and the absence\nof pathway-related annotations. This study aims to infer the actual treatment\nsteps for a particular patient group from administrative health records (AHR) -\na common form of tabular healthcare data - and address several technique- and\nmethodology-based gaps in treatment pathway-inference research. We introduce\nDefrag, a method for examining AHRs to infer the real-world treatment steps for\na particular patient group. Defrag learns the semantic and temporal meaning of\nhealthcare event sequences, allowing it to reliably infer treatment steps from\ncomplex healthcare data. To our knowledge, Defrag is the first\npathway-inference method to utilise a neural network (NN), an approach made\npossible by a novel, self-supervised learning objective. We also developed a\ntesting and validation framework for pathway inference, which we use to\ncharacterise and evaluate Defrag's pathway inference ability and compare\nagainst baselines. We demonstrate Defrag's effectiveness by identifying\nbest-practice pathway fragments for breast cancer, lung cancer, and melanoma in\npublic healthcare records. Additionally, we use synthetic data experiments to\ndemonstrate the characteristics of the Defrag method, and to compare Defrag to\nseveral baselines where it significantly outperforms non-NN-based methods.\nDefrag significantly outperforms several existing pathway-inference methods and\noffers an innovative and effective approach for inferring treatment pathways\nfrom AHRs. Open-source code is provided to encourage further research in this\narea.\n","authors":["Adrian Wilkins-Caruana","Madhushi Bandara","Katarzyna Musial","Daniel Catchpoole","Paul J. Kennedy"],"pdf_url":"https://arxiv.org/pdf/2309.01897v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03357v2","updated":"2023-11-21T22:05:37Z","published":"2023-07-07T02:40:09Z","title":"Stability and Generalization of Stochastic Compositional Gradient\n  Descent Algorithms","summary":"  Many machine learning tasks can be formulated as a stochastic compositional\noptimization (SCO) problem such as reinforcement learning, AUC maximization,\nand meta-learning, where the objective function involves a nested composition\nassociated with an expectation. While a significant amount of studies has been\ndevoted to studying the convergence behavior of SCO algorithms, there is little\nwork on understanding their generalization, i.e., how these learning algorithms\nbuilt from training examples would behave on future test examples. In this\npaper, we provide the stability and generalization analysis of stochastic\ncompositional gradient descent algorithms through the lens of algorithmic\nstability in the framework of statistical learning theory. Firstly, we\nintroduce a stability concept called compositional uniform stability and\nestablish its quantitative relation with generalization for SCO problems. Then,\nwe establish the compositional uniform stability results for two popular\nstochastic compositional gradient descent algorithms, namely SCGD and SCSC.\nFinally, we derive dimension-independent excess risk bounds for SCGD and SCSC\nby trade-offing their stability results and optimization errors. To the best of\nour knowledge, these are the first-ever-known results on stability and\ngeneralization analysis of stochastic compositional gradient descent\nalgorithms.\n","authors":["Ming Yang","Xiyuan Wei","Tianbao Yang","Yiming Ying"],"pdf_url":"https://arxiv.org/pdf/2307.03357v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13022v1","updated":"2023-11-21T22:05:00Z","published":"2023-11-21T22:05:00Z","title":"Unsupervised Multimodal Surface Registration with Geometric Deep\n  Learning","summary":"  This paper introduces GeoMorph, a novel geometric deep-learning framework\ndesigned for image registration of cortical surfaces. The registration process\nconsists of two main steps. First, independent feature extraction is performed\non each input surface using graph convolutions, generating low-dimensional\nfeature representations that capture important cortical surface\ncharacteristics. Subsequently, features are registered in a deep-discrete\nmanner to optimize the overlap of common structures across surfaces by learning\ndisplacements of a set of control points. To ensure smooth and biologically\nplausible deformations, we implement regularization through a deep conditional\nrandom field implemented with a recurrent neural network. Experimental results\ndemonstrate that GeoMorph surpasses existing deep-learning methods by achieving\nimproved alignment with smoother deformations. Furthermore, GeoMorph exhibits\ncompetitive performance compared to classical frameworks. Such versatility and\nrobustness suggest strong potential for various neuroscience applications.\n","authors":["Mohamed A. Suliman","Logan Z. J. Williams","Abdulah Fawaz","Emma C. Robinson"],"pdf_url":"https://arxiv.org/pdf/2311.13022v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13015v1","updated":"2023-11-21T21:44:28Z","published":"2023-11-21T21:44:28Z","title":"Fast and Interpretable Mortality Risk Scores for Critical Care Patients","summary":"  Prediction of mortality in intensive care unit (ICU) patients is an important\ntask in critical care medicine. Prior work in creating mortality risk models\nfalls into two major categories: domain-expert-created scoring systems, and\nblack box machine learning (ML) models. Both of these have disadvantages: black\nbox models are unacceptable for use in hospitals, whereas manual creation of\nmodels (including hand-tuning of logistic regression parameters) relies on\nhumans to perform high-dimensional constrained optimization, which leads to a\nloss in performance. In this work, we bridge the gap between accurate black box\nmodels and hand-tuned interpretable models. We build on modern interpretable ML\ntechniques to design accurate and interpretable mortality risk scores. We\nleverage the largest existing public ICU monitoring datasets, namely the MIMIC\nIII and eICU datasets. By evaluating risk across medical centers, we are able\nto study generalization across domains. In order to customize our risk score\nmodels, we develop a new algorithm, GroupFasterRisk, which has several\nimportant benefits: (1) it uses hard sparsity constraint, allowing users to\ndirectly control the number of features; (2) it incorporates group sparsity to\nallow more cohesive models; (3) it allows for monotonicity correction on models\nfor including domain knowledge; (4) it produces many equally-good models at\nonce, which allows domain experts to choose among them. GroupFasterRisk creates\nits risk scores within hours, even on the large datasets we study here.\nGroupFasterRisk's risk scores perform better than risk scores currently used in\nhospitals, and have similar prediction performance to black box ML models\n(despite being much sparser). Because GroupFasterRisk produces a variety of\nrisk scores and handles constraints, it allows design flexibility, which is the\nkey enabler of practical and trustworthy model creation.\n","authors":["Chloe Qinyu Zhu","Muhang Tian","Lesia Semenova","Jiachang Liu","Jack Xu","Joseph Scarpa","Cynthia Rudin"],"pdf_url":"https://arxiv.org/pdf/2311.13015v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10747v2","updated":"2023-11-21T21:40:21Z","published":"2023-10-31T18:21:24Z","title":"Safety-aware Causal Representation for Trustworthy Reinforcement\n  Learning in Autonomous Driving","summary":"  In the domain of autonomous driving, the Learning from Demonstration (LfD)\nparadigm has exhibited notable efficacy in addressing sequential\ndecision-making problems. However, consistently achieving safety in varying\ntraffic contexts, especially in safety-critical scenarios, poses a significant\nchallenge due to the long-tailed and unforeseen scenarios absent from offline\ndatasets. In this paper, we introduce the saFety-aware strUctured Scenario\nrepresentatION (FUSION), a pioneering methodology conceived to facilitate the\nlearning of an adaptive end-to-end driving policy by leveraging structured\nscenario information. FUSION capitalizes on the causal relationships between\ndecomposed reward, cost, state, and action space, constructing a framework for\nstructured sequential reasoning under dynamic traffic environments. We conduct\nrigorous evaluations in two typical real-world settings of distribution shift\nin autonomous vehicles, demonstrating the good balance between safety cost and\nutility reward of FUSION compared to contemporary state-of-the-art safety-aware\nLfD baselines. Empirical evidence under diverse driving scenarios attests that\nFUSION significantly enhances the safety and generalizability of autonomous\ndriving agents, even in the face of challenging and unseen environments.\nFurthermore, our ablation studies reveal noticeable improvements in the\nintegration of causal representation into the safe offline RL problem.\n","authors":["Haohong Lin","Wenhao Ding","Zuxin Liu","Yaru Niu","Jiacheng Zhu","Yuming Niu","Ding Zhao"],"pdf_url":"https://arxiv.org/pdf/2311.10747v2.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2311.12751v1","updated":"2023-11-21T17:52:30Z","published":"2023-11-21T17:52:30Z","title":"Towards Natural Language-Guided Drones: GeoText-1652 Benchmark with\n  Spatially Relation Matching","summary":"  Drone navigation through natural language commands remains a significant\nchallenge due to the lack of publicly available multi-modal datasets and the\nintricate demands of fine-grained visual-text alignment. In response to this\npressing need, we present a new human-computer interaction annotation benchmark\ncalled GeoText-1652, meticulously curated through a robust Large Language Model\n(LLM)-based data generation framework and the expertise of pre-trained vision\nmodels. This new dataset seamlessly extends the existing image dataset, \\ie,\nUniversity-1652, with spatial-aware text annotations, encompassing intricate\nimage-text-bounding box associations. Besides, we introduce a new optimization\nobjective to leverage fine-grained spatial associations, called blending\nspatial matching, for region-level spatial relation matching. Extensive\nexperiments reveal that our approach maintains an exceptional recall rate under\nvarying description complexities. This underscores the promising potential of\nour approach in elevating drone control and navigation through the seamless\nintegration of natural language commands in real-world scenarios.\n","authors":["Meng Chu","Zhedong Zheng","Wei Ji","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2311.12751v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2309.06255v2","updated":"2023-11-21T11:11:57Z","published":"2023-09-12T14:16:34Z","title":"Enhancing Multi-modal Cooperation via Fine-grained Modality Valuation","summary":"  One primary topic of multi-modal learning is to jointly incorporate\nheterogeneous information from different modalities. However, most models often\nsuffer from unsatisfactory multi-modal cooperation, which could not jointly\nutilize all modalities well. Some methods are proposed to identify and enhance\nthe worse learnt modality, but are often hard to provide the fine-grained\nobservation of multi-modal cooperation at sample-level with theoretical\nsupport. Hence, it is essential to reasonably observe and improve the\nfine-grained cooperation between modalities, especially when facing realistic\nscenarios where the modality discrepancy could vary across different samples.\nTo this end, we introduce a fine-grained modality valuation metric to evaluate\nthe contribution of each modality at sample-level. Via modality valuation, we\nregretfully observe that the multi-modal model tends to rely on one specific\nmodality, resulting in other modalities being low-contributing. We further\nanalyze this issue and improve cooperation between modalities by enhancing the\ndiscriminative ability of low-contributing modalities in a targeted manner.\nOverall, our methods reasonably observe the fine-grained uni-modal contribution\nat sample-level and achieve considerable improvement on different multi-modal\nmodels.\n","authors":["Yake Wei","Ruoxuan Feng","Zihe Wang","Di Hu"],"pdf_url":"https://arxiv.org/pdf/2309.06255v2.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2311.12454v1","updated":"2023-11-21T09:07:11Z","published":"2023-11-21T09:07:11Z","title":"HierSpeech++: Bridging the Gap between Semantic and Acoustic\n  Representation of Speech by Hierarchical Variational Inference for Zero-shot\n  Speech Synthesis","summary":"  Large language models (LLM)-based speech synthesis has been widely adopted in\nzero-shot speech synthesis. However, they require a large-scale data and\npossess the same limitations as previous autoregressive speech models,\nincluding slow inference speed and lack of robustness. This paper proposes\nHierSpeech++, a fast and strong zero-shot speech synthesizer for text-to-speech\n(TTS) and voice conversion (VC). We verified that hierarchical speech synthesis\nframeworks could significantly improve the robustness and expressiveness of the\nsynthetic speech. Furthermore, we significantly improve the naturalness and\nspeaker similarity of synthetic speech even in zero-shot speech synthesis\nscenarios. For text-to-speech, we adopt the text-to-vec framework, which\ngenerates a self-supervised speech representation and an F0 representation\nbased on text representations and prosody prompts. Then, HierSpeech++ generates\nspeech from the generated vector, F0, and voice prompt. We further introduce a\nhigh-efficient speech super-resolution framework from 16 kHz to 48 kHz. The\nexperimental results demonstrated that the hierarchical variational autoencoder\ncould be a strong zero-shot speech synthesizer given that it outperforms\nLLM-based and diffusion-based models. Moreover, we achieved the first\nhuman-level quality zero-shot speech synthesis. Audio samples and source code\nare available at https://github.com/sh-lee-prml/HierSpeechpp.\n","authors":["Sang-Hoon Lee","Ha-Yeong Choi","Seung-Bin Kim","Seong-Whan Lee"],"pdf_url":"https://arxiv.org/pdf/2311.12454v1.pdf","comment":"16 pages, 9 figures, 12 tables"},{"id":"http://arxiv.org/abs/2311.12401v1","updated":"2023-11-21T07:28:51Z","published":"2023-11-21T07:28:51Z","title":"CASR: Refining Action Segmentation via Magrinalizing Frame-levle Causal\n  Relationships","summary":"  Integrating deep learning and causal discovery has increased the\ninterpretability of Temporal Action Segmentation (TAS) tasks. However,\nframe-level causal relationships exist many complicated noises outside the\nsegment-level, making it infeasible to directly express macro action semantics.\nThus, we propose \\textit{\\textbf{Causal Abstraction Segmentation Refiner\n(CASR)}}, which can refine TAS results from various models by enhancing video\ncausality in marginalizing frame-level casual relationships. Specifically, we\ndefine the equivalent frame-level casual model and segment-level causal model,\nso that the causal adjacency matrix constructed from marginalized frame-level\ncausal relationships has the ability to represent the segmnet-level causal\nrelationships. CASR works out by reducing the difference in the causal\nadjacency matrix between we constructed and pre-segmentation results of\nbackbone models. In addition, we propose a novel evaluation metric Causal Edit\nDistance (CED) to evaluate the causal interpretability. Extensive experimental\nresults on mainstream datasets indicate that CASR significantly surpasses\nexisting various methods in action segmentation performance, as well as in\ncausal explainability and generalization. Our code will be available soon.\n","authors":["Keqing Du","Xinyu Yang","Hang Chen"],"pdf_url":"https://arxiv.org/pdf/2311.12401v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12257v1","updated":"2023-11-21T00:37:47Z","published":"2023-11-21T00:37:47Z","title":"Equipping Pretrained Unconditional Music Transformers with Instrument\n  and Genre Controls","summary":"  The ''pretraining-and-finetuning'' paradigm has become a norm for training\ndomain-specific models in natural language processing and computer vision. In\nthis work, we aim to examine this paradigm for symbolic music generation\nthrough leveraging the largest ever symbolic music dataset sourced from the\nMuseScore forum. We first pretrain a large unconditional transformer model\nusing 1.5 million songs. We then propose a simple technique to equip this\npretrained unconditional music transformer model with instrument and genre\ncontrols by finetuning the model with additional control tokens. Our proposed\nrepresentation offers improved high-level controllability and expressiveness\nagainst two existing representations. The experimental results show that the\nproposed model can successfully generate music with user-specified instruments\nand genre. In a subjective listening test, the proposed model outperforms the\npretrained baseline model in terms of coherence, harmony, arrangement and\noverall quality.\n","authors":["Weihan Xu","Julian McAuley","Shlomo Dubnov","Hao-Wen Dong"],"pdf_url":"https://arxiv.org/pdf/2311.12257v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10256v2","updated":"2023-11-21T23:52:32Z","published":"2023-11-17T00:56:55Z","title":"Exploring User Perceptions of Virtual Reality Scene Design in Metaverse\n  Learning Environments","summary":"  Metaverse learning environments allow for a seamless and intuitive transition\nbetween activities compared to Virtual Reality (VR) learning environments, due\nto their interconnected design. The design of VR scenes is important for\ncreating effective learning experiences in the Metaverse. However, there is\nlimited research on the impact of different design elements on user's learning\nexperiences in VR scenes. To address this, a study was conducted with 16\nparticipants who interacted with two VR scenes, each with varying design\nelements such as style, color, texture, object, and background, while watching\na short tutorial. Participant rankings of the scenes for learning were obtained\nusing a seven-point Likert scale, and the Mann-Whitney U test was used to\nvalidate differences in preference between the scenes. The results showed a\nsignificant difference in preference between the scenes. Further analysis using\nthe NASA TLX questionnaire was conducted to examine the impact of this\ndifference on cognitive load, and participant feedback was also considered. The\nstudy emphasizes the importance of careful VR scene design to improve the\nuser's learning experience.\n","authors":["Rahatara Ferdousi","Mohammed Faisal","Fedwa Laamarti","Chunsheng Yang","Abdulmotaleb El Saddik"],"pdf_url":"https://arxiv.org/pdf/2311.10256v2.pdf","comment":"6 pages,3 figures, accepted to present at IEEE 42nd International\n  Conference on Consumer Electronics"},{"id":"http://arxiv.org/abs/2311.12894v1","updated":"2023-11-21T08:20:38Z","published":"2023-11-21T08:20:38Z","title":"Attribute-Aware Deep Hashing with Self-Consistency for Large-Scale\n  Fine-Grained Image Retrieval","summary":"  Our work focuses on tackling large-scale fine-grained image retrieval as\nranking the images depicting the concept of interests (i.e., the same\nsub-category labels) highest based on the fine-grained details in the query. It\nis desirable to alleviate the challenges of both fine-grained nature of small\ninter-class variations with large intra-class variations and explosive growth\nof fine-grained data for such a practical task. In this paper, we propose\nattribute-aware hashing networks with self-consistency for generating\nattribute-aware hash codes to not only make the retrieval process efficient,\nbut also establish explicit correspondences between hash codes and visual\nattributes. Specifically, based on the captured visual representations by\nattention, we develop an encoder-decoder structure network of a reconstruction\ntask to unsupervisedly distill high-level attribute-specific vectors from the\nappearance-specific visual representations without attribute annotations. Our\nmodels are also equipped with a feature decorrelation constraint upon these\nattribute vectors to strengthen their representative abilities. Then, driven by\npreserving original entities' similarity, the required hash codes can be\ngenerated from these attribute-specific vectors and thus become\nattribute-aware. Furthermore, to combat simplicity bias in deep hashing, we\nconsider the model design from the perspective of the self-consistency\nprinciple and propose to further enhance models' self-consistency by equipping\nan additional image reconstruction path. Comprehensive quantitative experiments\nunder diverse empirical settings on six fine-grained retrieval datasets and two\ngeneric retrieval datasets show the superiority of our models over competing\nmethods.\n","authors":["Xiu-Shen Wei","Yang Shen","Xuhao Sun","Peng Wang","Yuxin Peng"],"pdf_url":"https://arxiv.org/pdf/2311.12894v1.pdf","comment":"Accepted by IEEE TPAMI"}]},"2023-11-22T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2311.13581v1","updated":"2023-11-22T18:37:27Z","published":"2023-11-22T18:37:27Z","title":"PaSS: Parallel Speculative Sampling","summary":"  Scaling the size of language models to tens of billions of parameters has led\nto impressive performance on a wide range of tasks. At generation, these models\nare used auto-regressively, requiring a forward pass for each generated token,\nand thus reading the full set of parameters from memory. This memory access\nforms the primary bottleneck for generation and it worsens as the model size\nincreases. Moreover, executing a forward pass for multiple tokens in parallel\noften takes nearly the same time as it does for just one token. These two\nobservations lead to the development of speculative sampling, where a second\nsmaller model is used to draft a few tokens, that are then validated or\nrejected using a single forward pass of the large model. Unfortunately, this\nmethod requires two models that share the same tokenizer and thus limits its\nadoption. As an alternative, we propose to use parallel decoding as a way to\ndraft multiple tokens from a single model with no computational cost, nor the\nneed for a second model. Our approach only requires an additional input token\nthat marks the words that will be generated simultaneously. We show promising\nperformance (up to $30\\%$ speed-up) while requiring only as few as $O(d_{emb})$\nadditional parameters.\n","authors":["Giovanni Monea","Armand Joulin","Edouard Grave"],"pdf_url":"https://arxiv.org/pdf/2311.13581v1.pdf","comment":"Accepted at the 3rd workshop on Efficient Natural Language and Speech\n  Processing (ENLSP, NeurIPS 2023)"},{"id":"http://arxiv.org/abs/2311.13565v1","updated":"2023-11-22T18:22:56Z","published":"2023-11-22T18:22:56Z","title":"Drilling Down into the Discourse Structure with LLMs for Long Document\n  Question Answering","summary":"  We address the task of evidence retrieval for long document question\nanswering, which involves locating relevant paragraphs within a document to\nanswer a question. We aim to assess the applicability of large language models\n(LLMs) in the task of zero-shot long document evidence retrieval, owing to\ntheir unprecedented performance across various NLP tasks. However, currently\nthe LLMs can consume limited context lengths as input, thus providing document\nchunks as inputs might overlook the global context while missing out on\ncapturing the inter-segment dependencies. Moreover, directly feeding the large\ninput sets can incur significant computational costs, particularly when\nprocessing the entire document (and potentially incurring monetary expenses\nwith enterprise APIs like OpenAI's GPT variants). To address these challenges,\nwe propose a suite of techniques that exploit the discourse structure commonly\nfound in documents. By utilizing this structure, we create a condensed\nrepresentation of the document, enabling a more comprehensive understanding and\nanalysis of relationships between different parts. We retain $99.6\\%$ of the\nbest zero-shot approach's performance, while processing only $26\\%$ of the\ntotal tokens used by the best approach in the information seeking evidence\nretrieval setup. We also show how our approach can be combined with\n\\textit{self-ask} reasoning agent to achieve best zero-shot performance in\ncomplex multi-hop question answering, just $\\approx 4\\%$ short of zero-shot\nperformance using gold evidence.\n","authors":["Inderjeet Nair","Shwetha Somasundaram","Apoorv Saxena","Koustava Goswami"],"pdf_url":"https://arxiv.org/pdf/2311.13565v1.pdf","comment":"Accepted to the Findings of EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.13534v1","updated":"2023-11-22T17:14:54Z","published":"2023-11-22T17:14:54Z","title":"LM-Cocktail: Resilient Tuning of Language Models via Model Merging","summary":"  The pre-trained language models are continually fine-tuned to better support\ndownstream applications. However, this operation may result in significant\nperformance degeneration on general tasks beyond the targeted domain. To\novercome this problem, we propose a novel method which enables the fine-tuned\nmodel to stay resilient in general perspectives. Our method is conducted in the\nform of model merging (namely LM-Cocktail), where the fine-tuned language model\nis merged with the pre-trained base model or the peer models from other domains\nthrough weighted average. Despite simplicity, LM-Cocktail is surprisingly\neffective: the resulted model is able to achieve a strong empirical performance\nin the whole scope of general tasks while preserving a superior capacity in its\ntargeted domain. We conduct comprehensive experiments with LLama and BGE model\non popular benchmarks, including FLAN, MMLU, MTEB, whose results validate the\nefficacy of our proposed method. The code and checkpoints are available at\nhttps://github.com/FlagOpen/FlagEmbedding.\n","authors":["Shitao Xiao","Zheng Liu","Peitian Zhang","Xingrun Xing"],"pdf_url":"https://arxiv.org/pdf/2311.13534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.12261v4","updated":"2023-11-22T16:59:55Z","published":"2022-07-06T13:56:48Z","title":"GraphCFC: A Directed Graph Based Cross-Modal Feature Complementation\n  Approach for Multimodal Conversational Emotion Recognition","summary":"  Emotion Recognition in Conversation (ERC) plays a significant part in\nHuman-Computer Interaction (HCI) systems since it can provide empathetic\nservices. Multimodal ERC can mitigate the drawbacks of uni-modal approaches.\nRecently, Graph Neural Networks (GNNs) have been widely used in a variety of\nfields due to their superior performance in relation modeling. In multimodal\nERC, GNNs are capable of extracting both long-distance contextual information\nand inter-modal interactive information. Unfortunately, since existing methods\nsuch as MMGCN directly fuse multiple modalities, redundant information may be\ngenerated and diverse information may be lost. In this work, we present a\ndirected Graph based Cross-modal Feature Complementation (GraphCFC) module that\ncan efficiently model contextual and interactive information. GraphCFC\nalleviates the problem of heterogeneity gap in multimodal fusion by utilizing\nmultiple subspace extractors and Pair-wise Cross-modal Complementary (PairCC)\nstrategy. We extract various types of edges from the constructed graph for\nencoding, thus enabling GNNs to extract crucial contextual and interactive\ninformation more accurately when performing message passing. Furthermore, we\ndesign a GNN structure called GAT-MLP, which can provide a new unified network\nframework for multimodal learning. The experimental results on two benchmark\ndatasets show that our GraphCFC outperforms the state-of-the-art (SOTA)\napproaches.\n","authors":["Jiang Li","Xiaoping Wang","Guoqing Lv","Zhigang Zeng"],"pdf_url":"https://arxiv.org/pdf/2207.12261v4.pdf","comment":"Accepted by IEEE Transactions on Multimedia (TMM)"},{"id":"http://arxiv.org/abs/2311.13495v1","updated":"2023-11-22T16:12:42Z","published":"2023-11-22T16:12:42Z","title":"Current Topological and Machine Learning Applications for Bias Detection\n  in Text","summary":"  Institutional bias can impact patient outcomes, educational attainment, and\nlegal system navigation. Written records often reflect bias, and once bias is\nidentified; it is possible to refer individuals for training to reduce bias.\nMany machine learning tools exist to explore text data and create predictive\nmodels that can search written records to identify real-time bias. However, few\nprevious studies investigate large language model embeddings and geometric\nmodels of biased text data to understand geometry's impact on bias modeling\naccuracy. To overcome this issue, this study utilizes the RedditBias database\nto analyze textual biases. Four transformer models, including BERT and RoBERTa\nvariants, were explored. Post-embedding, t-SNE allowed two-dimensional\nvisualization of data. KNN classifiers differentiated bias types, with lower\nk-values proving more effective. Findings suggest BERT, particularly mini BERT,\nexcels in bias classification, while multilingual models lag. The\nrecommendation emphasizes refining monolingual models and exploring\ndomain-specific biases.\n","authors":["Colleen Farrelly","Yashbir Singh","Quincy A. Hathaway","Gunnar Carlsson","Ashok Choudhary","Rahul Paul","Gianfranco Doretto","Yassine Himeur","Shadi Atalls","Wathiq Mansoor"],"pdf_url":"https://arxiv.org/pdf/2311.13495v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.19680v3","updated":"2023-11-22T16:12:39Z","published":"2023-10-30T16:00:13Z","title":"Integrating Pre-trained Language Model into Neural Machine Translation","summary":"  Neural Machine Translation (NMT) has become a significant technology in\nnatural language processing through extensive research and development.\nHowever, the deficiency of high-quality bilingual language pair data still\nposes a major challenge to improving NMT performance. Recent studies have been\nexploring the use of contextual information from pre-trained language model\n(PLM) to address this problem. Yet, the issue of incompatibility between PLM\nand NMT model remains unresolved. This study proposes PLM-integrated NMT\n(PiNMT) model to overcome the identified problems. PiNMT model consists of\nthree critical components, PLM Multi Layer Converter, Embedding Fusion, and\nCosine Alignment, each playing a vital role in providing effective PLM\ninformation to NMT. Furthermore, two training strategies, Separate Learning\nRates and Dual Step Training, are also introduced in this paper. By\nimplementing the proposed PiNMT model and training strategy, we achieve\nstate-of-the-art performance on the IWSLT'14 En$\\leftrightarrow$De dataset.\nThis study's outcomes are noteworthy as they demonstrate a novel approach for\nefficiently integrating PLM with NMT to overcome incompatibility and enhance\nperformance.\n","authors":["Soon-Jae Hwang","Chang-Sung Jeong"],"pdf_url":"https://arxiv.org/pdf/2310.19680v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.00449v2","updated":"2023-11-22T15:43:23Z","published":"2023-07-02T01:25:47Z","title":"A Dual-Stream Recurrence-Attention Network With Global-Local Awareness\n  for Emotion Recognition in Textual Dialog","summary":"  In real-world dialog systems, the ability to understand the user's emotions\nand interact anthropomorphically is of great significance. Emotion Recognition\nin Conversation (ERC) is one of the key ways to accomplish this goal and has\nattracted growing attention. How to model the context in a conversation is a\ncentral aspect and a major challenge of ERC tasks. Most existing approaches\nstruggle to adequately incorporate both global and local contextual\ninformation, and their network structures are overly sophisticated. For this\nreason, we propose a simple and effective Dual-stream Recurrence-Attention\nNetwork (DualRAN), which is based on Recurrent Neural Network (RNN) and\nMulti-head ATtention network (MAT). DualRAN eschews the complex components of\ncurrent methods and focuses on combining recurrence-based methods with\nattention-based ones. DualRAN is a dual-stream structure mainly consisting of\nlocal- and global-aware modules, modeling a conversation simultaneously from\ndistinct perspectives. In addition, we develop two single-stream network\nvariants for DualRAN, i.e., SingleRANv1 and SingleRANv2. According to the\nexperimental findings, DualRAN boosts the weighted F1 scores by 1.43% and 0.64%\non the IEMOCAP and MELD datasets, respectively, in comparison to the strongest\nbaseline. On two other datasets (i.e., EmoryNLP and DailyDialog), our method\nalso attains competitive results.\n","authors":["Jiang Li","Xiaoping Wang","Zhigang Zeng"],"pdf_url":"https://arxiv.org/pdf/2307.00449v2.pdf","comment":"Accepted by Engineering Applications of Artificial Intelligence\n  (EAAI)"},{"id":"http://arxiv.org/abs/2311.13475v1","updated":"2023-11-22T15:42:51Z","published":"2023-11-22T15:42:51Z","title":"Machine Translation to Control Formality Features in the Target Language","summary":"  Formality plays a significant role in language communication, especially in\nlow-resource languages such as Hindi, Japanese and Korean. These languages\nutilise formal and informal expressions to convey messages based on social\ncontexts and relationships. When a language translation technique is used to\ntranslate from a source language that does not pertain the formality (e.g.\nEnglish) to a target language that does, there is a missing information on\nformality that could be a challenge in producing an accurate outcome. This\nresearch explores how this issue should be resolved when machine learning\nmethods are used to translate from English to languages with formality, using\nHindi as the example data. This was done by training a bilingual model in a\nformality-controlled setting and comparing its performance with a pre-trained\nmultilingual model in a similar setting. Since there are not a lot of training\ndata with ground truth, automated annotation techniques were employed to\nincrease the data size. The primary modeling approach involved leveraging\ntransformer models, which have demonstrated effectiveness in various natural\nlanguage processing tasks. We evaluate the official formality accuracy(ACC) by\ncomparing the predicted masked tokens with the ground truth. This metric\nprovides a quantitative measure of how well the translations align with the\ndesired outputs. Our study showcases a versatile translation strategy that\nconsiders the nuances of formality in the target language, catering to diverse\nlanguage communication needs and scenarios.\n","authors":["Harshita Tyagi","Prashasta Jung","Hyowon Lee"],"pdf_url":"https://arxiv.org/pdf/2311.13475v1.pdf","comment":"9 pages, based on DCU MCM Practicum 2022/2023"},{"id":"http://arxiv.org/abs/2311.13472v1","updated":"2023-11-22T15:40:57Z","published":"2023-11-22T15:40:57Z","title":"Complexity-Guided Curriculum Learning for Text Graphs","summary":"  Curriculum learning provides a systematic approach to training. It refines\ntraining progressively, tailors training to task requirements, and improves\ngeneralization through exposure to diverse examples. We present a curriculum\nlearning approach that builds on existing knowledge about text and graph\ncomplexity formalisms for training with text graph data. The core part of our\napproach is a novel data scheduler, which employs \"spaced repetition\" and\ncomplexity formalisms to guide the training process. We demonstrate the\neffectiveness of the proposed approach on several text graph tasks and graph\nneural network architectures. The proposed model gains more and uses less data;\nconsistently prefers text over graph complexity indices throughout training,\nwhile the best curricula derived from text and graph complexity indices are\nequally effective; and it learns transferable curricula across GNN models and\ndatasets. In addition, we find that both node-level (local) and graph-level\n(global) graph complexity indices, as well as shallow and traditional text\ncomplexity indices play a crucial role in effective curriculum learning.\n","authors":["Nidhi Vakil","Hadi Amiri"],"pdf_url":"https://arxiv.org/pdf/2311.13472v1.pdf","comment":"Long Paper Accepted at EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.13455v1","updated":"2023-11-22T15:22:04Z","published":"2023-11-22T15:22:04Z","title":"Generation of Explanations for Logic Reasoning","summary":"  This thesis delves into a fortiori arguments in deductive reasoning,\nunderscoring their relevance in various domains such as law, philosophy, and\nartificial intelligence. The research is centred on employing GPT-3.5-turbo to\nautomate the analysis of these arguments, with a focus on understanding\nintricate reasoning processes, generating clear and coherent explanations, and\ncreating novel arguments. The methodology encompasses a series of tasks\nincluding detailed reasoning, interpretation, and the augmentation of a\nfortiori arguments. It involves meticulously identifying these arguments in\ndiverse contexts, differentiating comparative elements, and categorizing them\nbased on their logical structure.\n  Extensive experiments reveals the challenges encountered by GPT-3.5-turbo in\naccurately detecting and classifying a fortiori arguments. Nevertheless, the\nmodel demonstrates a performance that rivals specialized models, particularly\nin extracting key components and interpreting underlying properties. The\nintegration of external information into the model's processing significantly\nelevates the quality of the generated explanations. Additionally, the model\nexhibits a noteworthy capability in augmenting arguments, thus contributing to\nthe enrichment of the data set.\n  Despite facing certain limitations, this thesis makes significant\ncontributions to the fields of artificial intelligence and logical reasoning.\nIt introduces novel methodologies, establishes a rigorous evaluation framework,\nand provides deep insights that set the stage for future advancements in\nautomated logical reasoning. The findings and methodologies presented herein\nnot only underscore the potential of AI in complex reasoning tasks but also\nhighlight areas for future research and development.\n","authors":["Yanyi Pu"],"pdf_url":"https://arxiv.org/pdf/2311.13455v1.pdf","comment":"78 Pages, 16 Figures, Thesis Presentation is available at\n  https://drive.google.com/file/d/1wLIBsjfLvO11PjCS6qx4Y9UgRBUfq3wQ/view?usp=sharing"},{"id":"http://arxiv.org/abs/2311.13350v1","updated":"2023-11-22T12:39:28Z","published":"2023-11-22T12:39:28Z","title":"Fact-based Court Judgment Prediction","summary":"  This extended abstract extends the research presented in \"ILDC for CJPE:\nIndian Legal Documents Corpus for Court Judgment Prediction and Explanation\"\n\\cite{malik-etal-2021-ildc}, focusing on fact-based judgment prediction within\nthe context of Indian legal documents. We introduce two distinct problem\nvariations: one based solely on facts, and another combining facts with rulings\nfrom lower courts (RLC). Our research aims to enhance early-phase case outcome\nprediction, offering significant benefits to legal professionals and the\ngeneral public. The results, however, indicated a performance decline compared\nto the original ILDC for CJPE study, even after implementing various weightage\nschemes in our DELSumm algorithm. Additionally, using only facts for legal\njudgment prediction with different transformer models yielded results inferior\nto the state-of-the-art outcomes reported in the \"ILDC for CJPE\" study.\n","authors":["Shubham Kumar Nigam","Aniket Deroy"],"pdf_url":"https://arxiv.org/pdf/2311.13350v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13314v1","updated":"2023-11-22T11:08:38Z","published":"2023-11-22T11:08:38Z","title":"Mitigating Large Language Model Hallucinations via Autonomous Knowledge\n  Graph-based Retrofitting","summary":"  Incorporating factual knowledge in knowledge graph is regarded as a promising\napproach for mitigating the hallucination of large language models (LLMs).\nExisting methods usually only use the user's input to query the knowledge\ngraph, thus failing to address the factual hallucination generated by LLMs\nduring its reasoning process. To address this problem, this paper proposes\nKnowledge Graph-based Retrofitting (KGR), a new framework that incorporates\nLLMs with KGs to mitigate factual hallucination during the reasoning process by\nretrofitting the initial draft responses of LLMs based on the factual knowledge\nstored in KGs. Specifically, KGR leverages LLMs to extract, select, validate,\nand retrofit factual statements within the model-generated responses, which\nenables an autonomous knowledge verifying and refining procedure without any\nadditional manual efforts. Experiments show that KGR can significantly improve\nthe performance of LLMs on factual QA benchmarks especially when involving\ncomplex reasoning processes, which demonstrates the necessity and effectiveness\nof KGR in mitigating hallucination and enhancing the reliability of LLMs.\n","authors":["Xinyan Guan","Yanjiang Liu","Hongyu Lin","Yaojie Lu","Ben He","Xianpei Han","Le Sun"],"pdf_url":"https://arxiv.org/pdf/2311.13314v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13307v1","updated":"2023-11-22T10:55:36Z","published":"2023-11-22T10:55:36Z","title":"Rethinking Radiology Report Generation via Causal Reasoning and\n  Counterfactual Augmentation","summary":"  Radiology Report Generation (RRG) draws attention as an interaction between\nvision and language fields. Previous works inherited the ideology of\nvision-to-language generation tasks,aiming to generate paragraphs with high\nconsistency as reports. However, one unique characteristic of RRG, the\nindependence between diseases, was neglected, leading to the injection of the\nspurious confounder, i.e., the disease co-occurrence. Unfortunately, this\nconfounder confuses the process of report generation worse because of the\nbiased RRG data distribution. In this paper, to rethink this issue thoroughly,\nwe reason about its causes and effects from a novel perspective of statistics\nand causality, where the Joint Vision Coupling and the Conditional Sentence\nCoherence Coupling are two aspects prone to implicitly decrease the accuracy of\nreports. Then, a counterfactual augmentation strategy that contains the\nCounterfactual Sample Synthesis and the Counterfactual Report Reconstruction\nsub-methods is proposed to break these two aspects of spurious effects.\nExperimental results and further analyses on two widely used datasets justify\nour reasoning and proposed methods.\n","authors":["Xiao Song","Jiafan Liu","Yun Li","Wenbin Lei","Ruxin Wang"],"pdf_url":"https://arxiv.org/pdf/2311.13307v1.pdf","comment":"10 pages,5 figures"},{"id":"http://arxiv.org/abs/2305.14264v2","updated":"2023-11-22T10:22:18Z","published":"2023-05-23T17:16:04Z","title":"Active Learning Principles for In-Context Learning with Large Language\n  Models","summary":"  The remarkable advancements in large language models (LLMs) have\nsignificantly enhanced the performance in few-shot learning settings. By using\nonly a small number of labeled examples, referred to as demonstrations, LLMs\ncan effectively grasp the task at hand through in-context learning. However,\nthe process of selecting appropriate demonstrations has received limited\nattention in prior work. This paper addresses the issue of identifying the most\ninformative demonstrations for few-shot learning by approaching it as a\npool-based Active Learning (AL) problem over a single iteration. Our objective\nis to investigate how AL algorithms can serve as effective demonstration\nselection methods for in-context learning. We compare various standard AL\nalgorithms based on uncertainty, diversity, and similarity, and consistently\nobserve that the latter outperforms all other methods, including random\nsampling. Notably, uncertainty sampling, despite its success in conventional\nsupervised learning scenarios, performs poorly in this context. Our extensive\nexperimentation involving a diverse range of GPT and OPT models across $24$\nclassification and multi-choice tasks, coupled with thorough analysis,\nunambiguously demonstrates that in-context example selection through AL\nprioritizes high-quality examples that exhibit low uncertainty and bear\nsimilarity to the test examples.\n","authors":["Katerina Margatina","Timo Schick","Nikolaos Aletras","Jane Dwivedi-Yu"],"pdf_url":"https://arxiv.org/pdf/2305.14264v2.pdf","comment":"To appear at Findings of EMNLP (Camera Ready version)"},{"id":"http://arxiv.org/abs/2311.13281v1","updated":"2023-11-22T10:04:29Z","published":"2023-11-22T10:04:29Z","title":"Intention and Context Elicitation with Large Language Models in the\n  Legal Aid Intake Process","summary":"  Large Language Models (LLMs) and chatbots show significant promise in\nstreamlining the legal intake process. This advancement can greatly reduce the\nworkload and costs for legal aid organizations, improving availability while\nmaking legal assistance more accessible to a broader audience. However, a key\nchallenge with current LLMs is their tendency to overconfidently deliver an\nimmediate 'best guess' to a client's question based on the output distribution\nlearned over the training data. This approach often overlooks the client's\nactual intentions or the specifics of their legal situation. As a result,\nclients may not realize the importance of providing essential additional\ncontext or expressing their underlying intentions, which are crucial for their\nlegal cases. Traditionally, logic based decision trees have been used to\nautomate intake for specific access to justice issues, such as immigration and\neviction. But those solutions lack scalability. We demonstrate a\nproof-of-concept using LLMs to elicit and infer clients' underlying intentions\nand specific legal circumstances through free-form, language-based\ninteractions. We also propose future research directions to use supervised\nfine-tuning or offline reinforcement learning to automatically incorporate\nintention and context elicitation in chatbots without explicit prompting.\n","authors":["Nick Goodson","Rongfei Lu"],"pdf_url":"https://arxiv.org/pdf/2311.13281v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13274v1","updated":"2023-11-22T09:51:53Z","published":"2023-11-22T09:51:53Z","title":"Enhancing Summarization Performance through Transformer-Based Prompt\n  Engineering in Automated Medical Reporting","summary":"  Customized medical prompts enable Large Language Models (LLM) to effectively\naddress medical dialogue summarization. The process of medical reporting is\noften time-consuming for healthcare professionals. Implementing medical\ndialogue summarization techniques presents a viable solution to alleviate this\ntime constraint by generating automated medical reports. The effectiveness of\nLLMs in this process is significantly influenced by the formulation of the\nprompt, which plays a crucial role in determining the quality and relevance of\nthe generated reports. In this research, we used a combination of two distinct\nprompting strategies, known as shot prompting and pattern prompting to enhance\nthe performance of automated medical reporting. The evaluation of the automated\nmedical reports is carried out using the ROUGE score and a human evaluation\nwith the help of an expert panel. The two-shot prompting approach in\ncombination with scope and domain context outperforms other methods and\nachieves the highest score when compared to the human reference set by a\ngeneral practitioner. However, the automated reports are approximately twice as\nlong as the human references, due to the addition of both redundant and\nrelevant statements that are added to the report.\n","authors":["Daphne van Zandvoort","Laura Wiersema","Tom Huibers","Sandra van Dulmen","Sjaak Brinkkemper"],"pdf_url":"https://arxiv.org/pdf/2311.13274v1.pdf","comment":"12 pages, 4 figures, submitted to Healthinf 2024, author roles:\n  research conducted and written by Daphne van Zandvoort and Laura Wiersema,\n  research suggested and used software created by Tom Huibers, data provided\n  and feedback provided by Sandra van Dulmen, supervision and feedback provided\n  by Sjaak Brinkkemper"},{"id":"http://arxiv.org/abs/2311.13273v1","updated":"2023-11-22T09:51:43Z","published":"2023-11-22T09:51:43Z","title":"Comparative Experimentation of Accuracy Metrics in Automated Medical\n  Reporting: The Case of Otitis Consultations","summary":"  Generative Artificial Intelligence (AI) can be used to automatically generate\nmedical reports based on transcripts of medical consultations. The aim is to\nreduce the administrative burden that healthcare professionals face. The\naccuracy of the generated reports needs to be established to ensure their\ncorrectness and usefulness. There are several metrics for measuring the\naccuracy of AI generated reports, but little work has been done towards the\napplication of these metrics in medical reporting. A comparative\nexperimentation of 10 accuracy metrics has been performed on AI generated\nmedical reports against their corresponding General Practitioner's (GP) medical\nreports concerning Otitis consultations. The number of missing, incorrect, and\nadditional statements of the generated reports have been correlated with the\nmetric scores. In addition, we introduce and define a Composite Accuracy Score\nwhich produces a single score for comparing the metrics within the field of\nautomated medical reporting. Findings show that based on the correlation study\nand the Composite Accuracy Score, the ROUGE-L and Word Mover's Distance metrics\nare the preferred metrics, which is not in line with previous work. These\nfindings help determine the accuracy of an AI generated medical report, which\naids the development of systems that generate medical reports for GPs to reduce\nthe administrative burden.\n","authors":["Wouter Faber","Renske Eline Bootsma","Tom Huibers","Sandra van Dulmen","Sjaak Brinkkemper"],"pdf_url":"https://arxiv.org/pdf/2311.13273v1.pdf","comment":"10 pages, 1 figure, submitted to HEALTHINF 2024, Author\n  contributions: Wouter Faber and Renske Eline Bootsma performed research and\n  wrote paper, Tom Huibers provided needed software and research inspiration,\n  Sandra van Dulmen provided the data and feedback on paper, Sjaak Brinkkemper\n  supervised the project and provided continuous feedback"},{"id":"http://arxiv.org/abs/2311.13258v1","updated":"2023-11-22T09:23:34Z","published":"2023-11-22T09:23:34Z","title":"ViStruct: Visual Structural Knowledge Extraction via Curriculum Guided\n  Code-Vision Representation","summary":"  State-of-the-art vision-language models (VLMs) still have limited performance\nin structural knowledge extraction, such as relations between objects. In this\nwork, we present ViStruct, a training framework to learn VLMs for effective\nvisual structural knowledge extraction. Two novel designs are incorporated.\nFirst, we propose to leverage the inherent structure of programming language to\ndepict visual structural information. This approach enables explicit and\nconsistent representation of visual structural information of multiple\ngranularities, such as concepts, relations, and events, in a well-organized\nstructured format. Second, we introduce curriculum-based learning for VLMs to\nprogressively comprehend visual structures, from fundamental visual concepts to\nintricate event structures. Our intuition is that lower-level knowledge may\ncontribute to complex visual structure understanding. Furthermore, we compile\nand release a collection of datasets tailored for visual structural knowledge\nextraction. We adopt a weakly-supervised approach to directly generate visual\nevent structures from captions for ViStruct training, capitalizing on abundant\nimage-caption pairs from the web. In experiments, we evaluate ViStruct on\nvisual structure prediction tasks, demonstrating its effectiveness in improving\nthe understanding of visual structures. The code is public at\n\\url{https://github.com/Yangyi-Chen/vi-struct}.\n","authors":["Yangyi Chen","Xingyao Wang","Manling Li","Derek Hoiem","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2311.13258v1.pdf","comment":"Accepted to EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.00321v2","updated":"2023-11-22T09:08:03Z","published":"2023-11-01T06:09:54Z","title":"HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning","summary":"  With the proliferation of social media, accurate detection of hate speech has\nbecome critical to ensure safety online. To combat nuanced forms of hate\nspeech, it is important to identify and thoroughly explain hate speech to help\nusers understand its harmful effects. Recent benchmarks have attempted to\ntackle this issue by training generative models on free-text annotations of\nimplications in hateful text. However, we find significant reasoning gaps in\nthe existing annotations schemes, which may hinder the supervision of detection\nmodels. In this paper, we introduce a hate speech detection framework, HARE,\nwhich harnesses the reasoning capabilities of large language models (LLMs) to\nfill these gaps in explanations of hate speech, thus enabling effective\nsupervision of detection models. Experiments on SBIC and Implicit Hate\nbenchmarks show that our method, using model-generated data, consistently\noutperforms baselines, using existing free-text human annotations. Analysis\ndemonstrates that our method enhances the explanation quality of trained models\nand improves generalization to unseen datasets. Our code is available at\nhttps://github.com/joonkeekim/hare-hate-speech.git.\n","authors":["Yongjin Yang","Joonkee Kim","Yujin Kim","Namgyu Ho","James Thorne","Se-young Yun"],"pdf_url":"https://arxiv.org/pdf/2311.00321v2.pdf","comment":"Findings of EMNLP 2023; The first three authors contribute equally"},{"id":"http://arxiv.org/abs/2311.13246v1","updated":"2023-11-22T09:04:57Z","published":"2023-11-22T09:04:57Z","title":"Automatic Instruction Optimization for Open-source LLM Instruction\n  Tuning","summary":"  Instruction tuning is crucial for enabling Language Learning Models (LLMs) in\nresponding to human instructions. The quality of instruction pairs used for\ntuning greatly affects the performance of LLMs. However, the manual creation of\nhigh-quality instruction datasets is costly, leading to the adoption of\nautomatic generation of instruction pairs by LLMs as a popular alternative in\nthe training of open-source LLMs. To ensure the high quality of LLM-generated\ninstruction datasets, several approaches have been proposed. Nevertheless,\nexisting methods either compromise dataset integrity by filtering a large\nproportion of samples, or are unsuitable for industrial applications. In this\npaper, instead of discarding low-quality samples, we propose CoachLM, a novel\napproach to enhance the quality of instruction datasets through automatic\nrevisions on samples in the dataset. CoachLM is trained from the samples\nrevised by human experts and significantly increases the proportion of\nhigh-quality samples in the dataset from 17.7% to 78.9%. The effectiveness of\nCoachLM is further assessed on various real-world instruction test sets. The\nresults show that CoachLM improves the instruction-following capabilities of\nthe instruction-tuned LLM by an average of 29.9%, which even surpasses larger\nLLMs with nearly twice the number of parameters. Furthermore, CoachLM is\nsuccessfully deployed in a data management system for LLMs at Huawei, resulting\nin an efficiency improvement of up to 20% in the cleaning of 40k real-world\ninstruction pairs. We release the training data and code of CoachLM\n(https://github.com/lunyiliu/CoachLM).\n","authors":["Yilun Liu","Shimin Tao","Xiaofeng Zhao","Ming Zhu","Wenbing Ma","Junhao Zhu","Chang Su","Yutai Hou","Miao Zhang","Min Zhang","Hongxia Ma","Li Zhang","Hao Yang","Yanfei Jiang"],"pdf_url":"https://arxiv.org/pdf/2311.13246v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13240v1","updated":"2023-11-22T08:57:55Z","published":"2023-11-22T08:57:55Z","title":"On the Calibration of Large Language Models and Alignment","summary":"  As large language models attract increasing attention and find widespread\napplication, concurrent challenges of reliability also arise at the same time.\nConfidence calibration, an effective analysis method for gauging the\nreliability of deep models, serves as a crucial tool for assessing and\nimproving their reliability. However, such investigation has been comparatively\nunderexplored. In this work, we conduct a systematic examination of the\ncalibration of aligned language models throughout the entire construction\nprocess, including pretraining and alignment training. At each stage, we\ninvestigate how different training settings, such as parameter scales and\ntraining data, affect model calibration. To thoroughly assess model\ncalibration, we evaluate models on three most concerned aspects: generation,\nfactuality and understanding. Our work sheds light on whether popular LLMs are\nwell-calibrated and how the training process influences model calibration.\n","authors":["Chiwei Zhu","Benfeng Xu","Quan Wang","Yongdong Zhang","Zhendong Mao"],"pdf_url":"https://arxiv.org/pdf/2311.13240v1.pdf","comment":"to be published in findings of EMNLP-2023"},{"id":"http://arxiv.org/abs/2311.12538v2","updated":"2023-11-22T08:44:34Z","published":"2023-11-21T11:33:03Z","title":"In-Context Learning Functions with Varying Number of Minima","summary":"  Large Language Models (LLMs) have proven effective at In-Context Learning\n(ICL), an ability that allows them to create predictors from labeled examples.\nFew studies have explored the interplay between ICL and specific properties of\nfunctions it attempts to approximate. In our study, we use a formal framework\nto explore ICL and propose a new task of approximating functions with varying\nnumber of minima. We implement a method that allows for producing functions\nwith given inputs as minima. We find that increasing the number of minima\ndegrades ICL performance. At the same time, our evaluation shows that ICL\noutperforms 2-layer Neural Network (2NN) model. Furthermore, ICL learns faster\nthan 2NN in all settings. We validate the findings through a set of few-shot\nexperiments across various hyperparameter configurations.\n","authors":["David Oniani","Yanshan Wang"],"pdf_url":"https://arxiv.org/pdf/2311.12538v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13230v1","updated":"2023-11-22T08:39:17Z","published":"2023-11-22T08:39:17Z","title":"Enhancing Uncertainty-Based Hallucination Detection with Stronger Focus","summary":"  Large Language Models (LLMs) have gained significant popularity for their\nimpressive performance across diverse fields. However, LLMs are prone to\nhallucinate untruthful or nonsensical outputs that fail to meet user\nexpectations in many real-world applications. Existing works for detecting\nhallucinations in LLMs either rely on external knowledge for reference\nretrieval or require sampling multiple responses from the LLM for consistency\nverification, making these methods costly and inefficient. In this paper, we\npropose a novel reference-free, uncertainty-based method for detecting\nhallucinations in LLMs. Our approach imitates human focus in factuality\nchecking from three aspects: 1) focus on the most informative and important\nkeywords in the given text; 2) focus on the unreliable tokens in historical\ncontext which may lead to a cascade of hallucinations; and 3) focus on the\ntoken properties such as token type and token frequency. Experimental results\non relevant datasets demonstrate the effectiveness of our proposed method,\nwhich achieves state-of-the-art performance across all the evaluation metrics\nand eliminates the need for additional information.\n","authors":["Tianhang Zhang","Lin Qiu","Qipeng Guo","Cheng Deng","Yue Zhang","Zheng Zhang","Chenghu Zhou","Xinbing Wang","Luoyi Fu"],"pdf_url":"https://arxiv.org/pdf/2311.13230v1.pdf","comment":"Accepted by EMNLP 2023 (main conference)"},{"id":"http://arxiv.org/abs/2310.00603v2","updated":"2023-11-22T08:00:10Z","published":"2023-10-01T07:31:04Z","title":"Faithful Explanations of Black-box NLP Models Using LLM-generated\n  Counterfactuals","summary":"  Causal explanations of the predictions of NLP systems are essential to ensure\nsafety and establish trust. Yet, existing methods often fall short of\nexplaining model predictions effectively or efficiently and are often\nmodel-specific. In this paper, we address model-agnostic explanations,\nproposing two approaches for counterfactual (CF) approximation. The first\napproach is CF generation, where a large language model (LLM) is prompted to\nchange a specific text concept while keeping confounding concepts unchanged.\nWhile this approach is demonstrated to be very effective, applying LLM at\ninference-time is costly. We hence present a second approach based on matching,\nand propose a method that is guided by an LLM at training-time and learns a\ndedicated embedding space. This space is faithful to a given causal graph and\neffectively serves to identify matches that approximate CFs. After showing\ntheoretically that approximating CFs is required in order to construct faithful\nexplanations, we benchmark our approaches and explain several models, including\nLLMs with billions of parameters. Our empirical results demonstrate the\nexcellent performance of CF generation models as model-agnostic explainers.\nMoreover, our matching approach, which requires far less test-time resources,\nalso provides effective explanations, surpassing many baselines. We also find\nthat Top-K techniques universally improve every tested method. Finally, we\nshowcase the potential of LLMs in constructing new benchmarks for model\nexplanation and subsequently validate our conclusions. Our work illuminates new\npathways for efficient and accurate approaches to interpreting NLP systems.\n","authors":["Yair Gat","Nitay Calderon","Amir Feder","Alexander Chapanin","Amit Sharma","Roi Reichart"],"pdf_url":"https://arxiv.org/pdf/2310.00603v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.03214v2","updated":"2023-11-22T07:28:19Z","published":"2023-10-05T00:04:12Z","title":"FreshLLMs: Refreshing Large Language Models with Search Engine\n  Augmentation","summary":"  Most large language models (LLMs) are trained once and never updated; thus,\nthey lack the ability to dynamically adapt to our ever-changing world. In this\nwork, we perform a detailed study of the factuality of LLM-generated text in\nthe context of answering questions that test current world knowledge.\nSpecifically, we introduce FreshQA, a novel dynamic QA benchmark encompassing a\ndiverse range of question and answer types, including questions that require\nfast-changing world knowledge as well as questions with false premises that\nneed to be debunked. We benchmark a diverse array of both closed and\nopen-source LLMs under a two-mode evaluation procedure that allows us to\nmeasure both correctness and hallucination. Through human evaluations involving\nmore than 50K judgments, we shed light on limitations of these models and\ndemonstrate significant room for improvement: for instance, all models\n(regardless of model size) struggle on questions that involve fast-changing\nknowledge and false premises. Motivated by these results, we present\nFreshPrompt, a simple few-shot prompting method that substantially boosts the\nperformance of an LLM on FreshQA by incorporating relevant and up-to-date\ninformation retrieved from a search engine into the prompt. Our experiments\nshow that FreshPrompt outperforms both competing search engine-augmented\nprompting methods such as Self-Ask (Press et al., 2022) as well as commercial\nsystems such as Perplexity.AI. Further analysis of FreshPrompt reveals that\nboth the number of retrieved evidences and their order play a key role in\ninfluencing the correctness of LLM-generated answers. Additionally, instructing\nthe LLM to generate concise and direct answers helps reduce hallucination\ncompared to encouraging more verbose answers. To facilitate future work, we\nrelease FreshQA at github.com/freshllms/freshqa and commit to updating it at\nregular intervals.\n","authors":["Tu Vu","Mohit Iyyer","Xuezhi Wang","Noah Constant","Jerry Wei","Jason Wei","Chris Tar","Yun-Hsuan Sung","Denny Zhou","Quoc Le","Thang Luong"],"pdf_url":"https://arxiv.org/pdf/2310.03214v2.pdf","comment":"Preprint, 26 pages, 10 figures, 5 tables; Added FreshEval"},{"id":"http://arxiv.org/abs/2310.09886v4","updated":"2023-11-22T06:44:16Z","published":"2023-10-15T16:51:11Z","title":"Lifelong Sequence Generation with Dynamic Module Expansion and\n  Adaptation","summary":"  Lifelong sequence generation (LSG), a problem in continual learning, aims to\ncontinually train a model on a sequence of generation tasks to learn constantly\nemerging new generation patterns while avoiding the forgetting of previous\nknowledge. Existing LSG methods mainly focus on maintaining old knowledge while\npaying little attention to knowledge transfer across tasks. In contrast, humans\ncan better learn new tasks by leveraging previously acquired knowledge from\nsimilar tasks. Inspired by the learning paradigm of humans, we propose Dynamic\nModule Expansion and Adaptation (DMEA), which enables the model to dynamically\ndetermine the architecture for acquiring new knowledge based on task\ncorrelation and select the most similar previous tasks to facilitate adaptation\nto new tasks. In addition, as the learning process can easily be biased towards\nthe current task which might cause more severe forgetting of previously learned\nknowledge, we propose dynamic gradient scaling to balance the learning of the\ncurrent task and replayed tasks. With extensive experiments, we demonstrate\nthat DMEA can consistently outperform existing methods in different LSG\nsettings.\n","authors":["Chengwei Qin","Chen Chen","Shafiq Joty"],"pdf_url":"https://arxiv.org/pdf/2310.09886v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13184v1","updated":"2023-11-22T06:23:18Z","published":"2023-11-22T06:23:18Z","title":"AS-LLM: When Algorithm Selection Meets Large Language Model","summary":"  Algorithm selection aims to identify the most suitable algorithm for solving\na specific problem before execution, which has become a critical process of the\nAutoML. Current mainstream algorithm selection techniques rely heavily on\nfeature representations of various problems and employ the performance of each\nalgorithm as supervised information. However, there is a significant research\ngap concerning the consideration of algorithm features. This gap is primarily\nattributed to the inherent complexity of algorithms, making it particularly\nchallenging to find a universally effective feature extraction method that is\napplicable across a diverse range of algorithms. Unfortunately, neglecting this\naspect undoubtedly impacts the accuracy of algorithm selection and indirectly\nnecessitates an increased volume of problem data for training purposes. This\npaper takes a significant stride towards addressing this gap by proposing an\napproach that integrates algorithm representation into the algorithm selection\nprocess. Specifically, our proposed model employs distinct modules to extract\nrepresentations of both problems and algorithms, where the algorithm\nrepresentation leverages the capabilities of pre-trained LLMs in the realm of\ncode comprehension. Following the extraction of embedding vectors for both\nalgorithms and problems, the most suitable algorithm is determined through\ncalculations of matching degrees. Our experiments not only validate the\neffectiveness of the proposed model but also showcase the performance of\ndifferent embedded pre-trained LLMs, which suggests that the proposed algorithm\nselection framework holds the potential to serve as a baseline task for\nevaluating the code representation capabilities of LLMs.\n","authors":["Xingyu Wu","Yan Zhong","Jibin Wu","Kay Chen Tan"],"pdf_url":"https://arxiv.org/pdf/2311.13184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13171v1","updated":"2023-11-22T05:28:59Z","published":"2023-11-22T05:28:59Z","title":"ComPEFT: Compression for Communicating Parameter Efficient Updates via\n  Sparsification and Quantization","summary":"  Parameter-efficient fine-tuning (PEFT) techniques make it possible to\nefficiently adapt a language model to create \"expert\" models that specialize to\nnew tasks or domains. Recent techniques in model merging and compositional\ngeneralization leverage these expert models by dynamically composing modules to\nimprove zero/few-shot generalization. Despite the efficiency of PEFT methods,\nthe size of expert models can make it onerous to retrieve expert models per\nquery over high-latency networks like the Internet or serve multiple experts on\na single GPU. To address these issues, we present ComPEFT, a novel method for\ncompressing fine-tuning residuals (task vectors) of PEFT based models. ComPEFT\nemploys sparsification and ternary quantization to reduce the size of the PEFT\nmodule without performing any additional retraining while preserving or\nenhancing model performance. In extensive evaluation across T5, T0, and\nLLaMA-based models with 200M - 65B parameters, ComPEFT achieves compression\nratios of 8x - 50x. In particular, we show that ComPEFT improves with scale -\nstronger models exhibit higher compressibility and better performance. For\nexample, we show that ComPEFT applied to LLaMA outperforms QLoRA by 4.16% on\nMMLU with a storage size reduction of up to 26x. In addition, we show that the\ncompressed experts produced by ComPEFT maintain few-shot compositional\ngeneralization capabilities, facilitate efficient communication and\ncomputation, and exhibit enhanced performance when merged. Lastly, we provide\nan analysis of different method components, compare it with other PEFT methods,\nand test ComPEFT's efficacy for compressing the residual of full-finetuning.\nOur code is available at https://github.com/prateeky2806/compeft.\n","authors":["Prateek Yadav","Leshem Choshen","Colin Raffel","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2311.13171v1.pdf","comment":"25 Pages, 6 Figures, 16 Tables"},{"id":"http://arxiv.org/abs/2311.13133v1","updated":"2023-11-22T03:37:01Z","published":"2023-11-22T03:37:01Z","title":"LIMIT: Less Is More for Instruction Tuning Across Evaluation Paradigms","summary":"  Large Language Models are traditionally finetuned on large instruction\ndatasets. However recent studies suggest that small, high-quality datasets can\nsuffice for general purpose instruction following. This lack of consensus\nsurrounding finetuning best practices is in part due to rapidly diverging\napproaches to LLM evaluation. In this study, we ask whether a small amount of\ndiverse finetuning samples can improve performance on both traditional\nperplexity-based NLP benchmarks, and on open-ended, model-based evaluation. We\nfinetune open-source MPT-7B and MPT-30B models on instruction finetuning\ndatasets of various sizes ranging from 1k to 60k samples. We find that subsets\nof 1k-6k instruction finetuning samples are sufficient to achieve good\nperformance on both (1) traditional NLP benchmarks and (2) model-based\nevaluation. Finally, we show that mixing textbook-style and open-ended QA\nfinetuning datasets optimizes performance on both evaluation paradigms.\n","authors":["Aditi Jha","Sam Havens","Jeremey Dohmann","Alex Trott","Jacob Portes"],"pdf_url":"https://arxiv.org/pdf/2311.13133v1.pdf","comment":"36 pages, 12 figures, NeurIPS 2023 Workshop on Instruction Tuning and\n  Instruction Following"},{"id":"http://arxiv.org/abs/2311.13126v1","updated":"2023-11-22T03:28:34Z","published":"2023-11-22T03:28:34Z","title":"Towards Better Parameter-Efficient Fine-Tuning for Large Language\n  Models: A Position Paper","summary":"  This paper delves into the pressing need in Parameter-Efficient Fine-Tuning\n(PEFT) for Large Language Models (LLMs). While LLMs possess remarkable\ncapabilities, their extensive parameter requirements and associated\ncomputational demands hinder their practicality and scalability for real-world\napplications. Our position paper highlights current states and the necessity of\nfurther studying into the topic, and recognizes significant challenges and open\nissues that must be addressed to fully harness the powerful abilities of LLMs.\nThese challenges encompass novel efficient PEFT architectures, PEFT for\ndifferent learning settings, PEFT combined with model compression techniques,\nand the exploration of PEFT for multi-modal LLMs. By presenting this position\npaper, we aim to stimulate further research and foster discussions surrounding\nmore efficient and accessible PEFT for LLMs.\n","authors":["Chengyu Wang","Junbing Yan","Wei Zhang","Jun Huang"],"pdf_url":"https://arxiv.org/pdf/2311.13126v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13118v1","updated":"2023-11-22T02:45:01Z","published":"2023-11-22T02:45:01Z","title":"Combatting Human Trafficking in the Cyberspace: A Natural Language\n  Processing-Based Methodology to Analyze the Language in Online Advertisements","summary":"  This project tackles the pressing issue of human trafficking in online C2C\nmarketplaces through advanced Natural Language Processing (NLP) techniques. We\nintroduce a novel methodology for generating pseudo-labeled datasets with\nminimal supervision, serving as a rich resource for training state-of-the-art\nNLP models. Focusing on tasks like Human Trafficking Risk Prediction (HTRP) and\nOrganized Activity Detection (OAD), we employ cutting-edge Transformer models\nfor analysis. A key contribution is the implementation of an interpretability\nframework using Integrated Gradients, providing explainable insights crucial\nfor law enforcement. This work not only fills a critical gap in the literature\nbut also offers a scalable, machine learning-driven approach to combat human\nexploitation online. It serves as a foundation for future research and\npractical applications, emphasizing the role of machine learning in addressing\ncomplex social issues.\n","authors":["Alejandro Rodriguez Perez","Pablo Rivas"],"pdf_url":"https://arxiv.org/pdf/2311.13118v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13110v1","updated":"2023-11-22T02:23:32Z","published":"2023-11-22T02:23:32Z","title":"White-Box Transformers via Sparse Rate Reduction: Compression Is All\n  There Is?","summary":"  In this paper, we contend that a natural objective of representation learning\nis to compress and transform the distribution of the data, say sets of tokens,\ntowards a low-dimensional Gaussian mixture supported on incoherent subspaces.\nThe goodness of such a representation can be evaluated by a principled measure,\ncalled sparse rate reduction, that simultaneously maximizes the intrinsic\ninformation gain and extrinsic sparsity of the learned representation. From\nthis perspective, popular deep network architectures, including transformers,\ncan be viewed as realizing iterative schemes to optimize this measure.\nParticularly, we derive a transformer block from alternating optimization on\nparts of this objective: the multi-head self-attention operator compresses the\nrepresentation by implementing an approximate gradient descent step on the\ncoding rate of the features, and the subsequent multi-layer perceptron\nsparsifies the features. This leads to a family of white-box transformer-like\ndeep network architectures, named CRATE, which are mathematically fully\ninterpretable. We show, by way of a novel connection between denoising and\ncompression, that the inverse to the aforementioned compressive encoding can be\nrealized by the same class of CRATE architectures. Thus, the so-derived\nwhite-box architectures are universal to both encoders and decoders.\nExperiments show that these networks, despite their simplicity, indeed learn to\ncompress and sparsify representations of large-scale real-world image and text\ndatasets, and achieve performance very close to highly engineered\ntransformer-based models: ViT, MAE, DINO, BERT, and GPT2. We believe the\nproposed computational framework demonstrates great potential in bridging the\ngap between theory and practice of deep learning, from a unified perspective of\ndata compression. Code is available at: https://ma-lab-berkeley.github.io/CRATE .\n","authors":["Yaodong Yu","Sam Buchanan","Druv Pai","Tianzhe Chu","Ziyang Wu","Shengbang Tong","Hao Bai","Yuexiang Zhai","Benjamin D. Haeffele","Yi Ma"],"pdf_url":"https://arxiv.org/pdf/2311.13110v1.pdf","comment":"This paper integrates the works arXiv:2306.01129 and\n  arXiv:2308.16271, as well as this under-review work:\n  https://openreview.net/forum?id=PvyOYleymy into a complete story. In this\n  paper, we improve the writing and organization, and also add conceptual,\n  empirical, and theoretical improvements over the previous work"},{"id":"http://arxiv.org/abs/2311.13105v1","updated":"2023-11-22T02:12:36Z","published":"2023-11-22T02:12:36Z","title":"Perceptual Structure in the Absence of Grounding for LLMs: The Impact of\n  Abstractedness and Subjectivity in Color Language","summary":"  The need for grounding in language understanding is an active research topic.\nPrevious work has suggested that color perception and color language appear as\na suitable test bed to empirically study the problem, given its cognitive\nsignificance and showing that there is considerable alignment between a defined\ncolor space and the feature space defined by a language model. To further study\nthis issue, we collect a large scale source of colors and their descriptions,\ncontaining almost a 1 million examples , and perform an empirical analysis to\ncompare two kinds of alignments: (i) inter-space, by learning a mapping between\nembedding space and color space, and (ii) intra-space, by means of prompting\ncomparatives between color descriptions. Our results show that while color\nspace alignment holds for monolexemic, highly pragmatic color descriptions,\nthis alignment drops considerably in the presence of examples that exhibit\nelements of real linguistic usage such as subjectivity and abstractedness,\nsuggesting that grounding may be required in such cases.\n","authors":["Pablo Loyola","Edison Marrese-Taylor","Andres Hoyos-Idobro"],"pdf_url":"https://arxiv.org/pdf/2311.13105v1.pdf","comment":"EMNLP 2023 Findings"},{"id":"http://arxiv.org/abs/2311.13102v1","updated":"2023-11-22T02:04:35Z","published":"2023-11-22T02:04:35Z","title":"Detecting out-of-distribution text using topological features of\n  transformer-based language models","summary":"  We attempt to detect out-of-distribution (OOD) text samples though applying\nTopological Data Analysis (TDA) to attention maps in transformer-based language\nmodels. We evaluate our proposed TDA-based approach for out-of-distribution\ndetection on BERT, a transformer-based language model, and compare the to a\nmore traditional OOD approach based on BERT CLS embeddings. We found that our\nTDA approach outperforms the CLS embedding approach at distinguishing\nin-distribution data (politics and entertainment news articles from HuffPost)\nfrom far out-of-domain samples (IMDB reviews), but its effectiveness\ndeteriorates with near out-of-domain (CNN/Dailymail) or same-domain (business\nnews articles from HuffPost) datasets.\n","authors":["Andres Pollano","Anupam Chaudhuri","Anj Simmons"],"pdf_url":"https://arxiv.org/pdf/2311.13102v1.pdf","comment":"12 pages, 6 figures, 3 tables"},{"id":"http://arxiv.org/abs/2311.13095v1","updated":"2023-11-22T01:51:50Z","published":"2023-11-22T01:51:50Z","title":"Enhancing Logical Reasoning in Large Language Models to Facilitate Legal\n  Applications","summary":"  Language serves as a vehicle for conveying thought, enabling communication\namong individuals. The ability to distinguish between diverse concepts,\nidentify fairness and injustice, and comprehend a range of legal notions\nfundamentally relies on logical reasoning. Large Language Models (LLMs) attempt\nto emulate human language understanding and generation, but their competency in\nlogical reasoning remains limited. This paper seeks to address the\nphilosophical question: How can we effectively teach logical reasoning to LLMs\nwhile maintaining a deep understanding of the intricate relationship between\nlanguage and logic? By focusing on bolstering LLMs' capabilities in logical\nreasoning, we aim to expand their applicability in law and other\nlogic-intensive disciplines. To this end, we propose a Reinforcement Learning\nfrom Logical Feedback (RLLF) approach, which serves as a potential framework\nfor refining LLMs' reasoning capacities. Through RLLF and a revised evaluation\nmethodology, we explore new avenues for research in this domain and contribute\nto the development of LLMs capable of handling complex legal reasoning tasks\nwhile acknowledging the fundamental connection between language and logic.\n","authors":["Ha-Thanh Nguyen","Wachara Fungwacharakorn","Ken Satoh"],"pdf_url":"https://arxiv.org/pdf/2311.13095v1.pdf","comment":"ALP@JURIX2023"},{"id":"http://arxiv.org/abs/2310.12942v3","updated":"2023-11-22T01:39:59Z","published":"2023-10-19T17:39:47Z","title":"On the Representational Capacity of Recurrent Neural Language Models","summary":"  This work investigates the computational expressivity of language models\n(LMs) based on recurrent neural networks (RNNs). Siegelmann and Sontag (1992)\nfamously showed that RNNs with rational weights and hidden states and unbounded\ncomputation time are Turing complete. However, LMs define weightings over\nstrings in addition to just (unweighted) language membership and the analysis\nof the computational power of RNN LMs (RLMs) should reflect this. We extend the\nTuring completeness result to the probabilistic case, showing how a rationally\nweighted RLM with unbounded computation time can simulate any deterministic\nprobabilistic Turing machine (PTM) with rationally weighted transitions. Since,\nin practice, RLMs work in real-time, processing a symbol at every time step, we\ntreat the above result as an upper bound on the expressivity of RLMs. We also\nprovide a lower bound by showing that under the restriction to real-time\ncomputation, such models can simulate deterministic real-time rational PTMs.\n","authors":["Franz Nowak","Anej Svete","Li Du","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2310.12942v3.pdf","comment":"To be published at EMNLP 2023"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2311.13602v1","updated":"2023-11-22T18:59:53Z","published":"2023-11-22T18:59:53Z","title":"Retrieval-Augmented Layout Transformer for Content-Aware Layout\n  Generation","summary":"  Content-aware graphic layout generation aims to automatically arrange visual\nelements along with a given content, such as an e-commerce product image. In\nthis paper, we argue that the current layout generation approaches suffer from\nthe limited training data for the high-dimensional layout structure. We show\nthat a simple retrieval augmentation can significantly improve the generation\nquality. Our model, which is named Retrieval-Augmented Layout Transformer\n(RALF), retrieves nearest neighbor layout examples based on an input image and\nfeeds these results into an autoregressive generator. Our model can apply\nretrieval augmentation to various controllable generation tasks and yield\nhigh-quality layouts within a unified architecture. Our extensive experiments\nshow that RALF successfully generates content-aware layouts in both constrained\nand unconstrained settings and significantly outperforms the baselines.\n","authors":["Daichi Horita","Naoto Inoue","Kotaro Kikuchi","Kota Yamaguchi","Kiyoharu Aizawa"],"pdf_url":"https://arxiv.org/pdf/2311.13602v1.pdf","comment":"Webpage: https://udonda.github.io/RALF/"},{"id":"http://arxiv.org/abs/2311.13601v1","updated":"2023-11-22T18:59:48Z","published":"2023-11-22T18:59:48Z","title":"Visual In-Context Prompting","summary":"  In-context prompting in large language models (LLMs) has become a prevalent\napproach to improve zero-shot capabilities, but this idea is less explored in\nthe vision domain. Existing visual prompting methods focus on referring\nsegmentation to segment the most relevant object, falling short of addressing\nmany generic vision tasks like open-set segmentation and detection. In this\npaper, we introduce a universal visual in-context prompting framework for both\ntasks. In particular, we build on top of an encoder-decoder architecture, and\ndevelop a versatile prompt encoder to support a variety of prompts like\nstrokes, boxes, and points. We further enhance it to take an arbitrary number\nof reference image segments as the context. Our extensive explorations show\nthat the proposed visual in-context prompting elicits extraordinary referring\nand generic segmentation capabilities to refer and detect, yielding competitive\nperformance to close-set in-domain datasets and showing promising results on\nmany open-set segmentation datasets. By joint training on COCO and SA-1B, our\nmodel achieves $57.7$ PQ on COCO and $23.2$ PQ on ADE20K. Code will be\navailable at https://github.com/UX-Decoder/DINOv.\n","authors":["Feng Li","Qing Jiang","Hao Zhang","Tianhe Ren","Shilong Liu","Xueyan Zou","Huaizhe Xu","Hongyang Li","Chunyuan Li","Jianwei Yang","Lei Zhang","Jianfeng Gao"],"pdf_url":"https://arxiv.org/pdf/2311.13601v1.pdf","comment":"technical report"},{"id":"http://arxiv.org/abs/2311.13600v1","updated":"2023-11-22T18:59:36Z","published":"2023-11-22T18:59:36Z","title":"ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs","summary":"  Methods for finetuning generative models for concept-driven personalization\ngenerally achieve strong results for subject-driven or style-driven generation.\nRecently, low-rank adaptations (LoRA) have been proposed as a\nparameter-efficient way of achieving concept-driven personalization. While\nrecent work explores the combination of separate LoRAs to achieve joint\ngeneration of learned styles and subjects, existing techniques do not reliably\naddress the problem; they often compromise either subject fidelity or style\nfidelity. We propose ZipLoRA, a method to cheaply and effectively merge\nindependently trained style and subject LoRAs in order to achieve generation of\nany user-provided subject in any user-provided style. Experiments on a wide\nrange of subject and style combinations show that ZipLoRA can generate\ncompelling results with meaningful improvements over baselines in subject and\nstyle fidelity while preserving the ability to recontextualize. Project page:\nhttps://ziplora.github.io\n","authors":["Viraj Shah","Nataniel Ruiz","Forrester Cole","Erika Lu","Svetlana Lazebnik","Yuanzhen Li","Varun Jampani"],"pdf_url":"https://arxiv.org/pdf/2311.13600v1.pdf","comment":"Project page: https://ziplora.github.io"},{"id":"http://arxiv.org/abs/2311.13596v1","updated":"2023-11-22T18:57:24Z","published":"2023-11-22T18:57:24Z","title":"T-Rex: Counting by Visual Prompting","summary":"  We introduce T-Rex, an interactive object counting model designed to first\ndetect and then count any objects. We formulate object counting as an open-set\nobject detection task with the integration of visual prompts. Users can specify\nthe objects of interest by marking points or boxes on a reference image, and\nT-Rex then detects all objects with a similar pattern. Guided by the visual\nfeedback from T-Rex, users can also interactively refine the counting results\nby prompting on missing or falsely-detected objects. T-Rex has achieved\nstate-of-the-art performance on several class-agnostic counting benchmarks. To\nfurther exploit its potential, we established a new counting benchmark\nencompassing diverse scenarios and challenges. Both quantitative and\nqualitative results show that T-Rex possesses exceptional zero-shot counting\ncapabilities. We also present various practical application scenarios for\nT-Rex, illustrating its potential in the realm of visual prompting.\n","authors":["Qing Jiang","Feng Li","Tianhe Ren","Shilong Liu","Zhaoyang Zeng","Kent Yu","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.13596v1.pdf","comment":"Technical report. Work in progress"},{"id":"http://arxiv.org/abs/2311.12764v2","updated":"2023-11-22T18:52:11Z","published":"2023-11-21T18:18:50Z","title":"Investigating Weight-Perturbed Deep Neural Networks With Application in\n  Iris Presentation Attack Detection","summary":"  Deep neural networks (DNNs) exhibit superior performance in various machine\nlearning tasks, e.g., image classification, speech recognition, biometric\nrecognition, object detection, etc. However, it is essential to analyze their\nsensitivity to parameter perturbations before deploying them in real-world\napplications. In this work, we assess the sensitivity of DNNs against\nperturbations to their weight and bias parameters. The sensitivity analysis\ninvolves three DNN architectures (VGG, ResNet, and DenseNet), three types of\nparameter perturbations (Gaussian noise, weight zeroing, and weight scaling),\nand two settings (entire network and layer-wise). We perform experiments in the\ncontext of iris presentation attack detection and evaluate on two publicly\navailable datasets: LivDet-Iris-2017 and LivDet-Iris-2020. Based on the\nsensitivity analysis, we propose improved models simply by perturbing\nparameters of the network without undergoing training. We further combine these\nperturbed models at the score-level and at the parameter-level to improve the\nperformance over the original model. The ensemble at the parameter-level shows\nan average improvement of 43.58% on the LivDet-Iris-2017 dataset and 9.25% on\nthe LivDet-Iris-2020 dataset. The source code is available at\nhttps://github.com/redwankarimsony/WeightPerturbation-MSU.\n","authors":["Renu Sharma","Redwan Sony","Arun Ross"],"pdf_url":"https://arxiv.org/pdf/2311.12764v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13574v1","updated":"2023-11-22T18:30:42Z","published":"2023-11-22T18:30:42Z","title":"XAGen: 3D Expressive Human Avatars Generation","summary":"  Recent advances in 3D-aware GAN models have enabled the generation of\nrealistic and controllable human body images. However, existing methods focus\non the control of major body joints, neglecting the manipulation of expressive\nattributes, such as facial expressions, jaw poses, hand poses, and so on. In\nthis work, we present XAGen, the first 3D generative model for human avatars\ncapable of expressive control over body, face, and hands. To enhance the\nfidelity of small-scale regions like face and hands, we devise a multi-scale\nand multi-part 3D representation that models fine details. Based on this\nrepresentation, we propose a multi-part rendering technique that disentangles\nthe synthesis of body, face, and hands to ease model training and enhance\ngeometric quality. Furthermore, we design multi-part discriminators that\nevaluate the quality of the generated avatars with respect to their appearance\nand fine-grained control capabilities. Experiments show that XAGen surpasses\nstate-of-the-art methods in terms of realism, diversity, and expressive control\nabilities. Code and data will be made available at\nhttps://showlab.github.io/xagen.\n","authors":["Zhongcong Xu","Jianfeng Zhang","Jun Hao Liew","Jiashi Feng","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2311.13574v1.pdf","comment":"Accepted to NeurIPS 2023, Project Page at\n  https://showlab.github.io/xagen"},{"id":"http://arxiv.org/abs/2311.13570v1","updated":"2023-11-22T18:25:51Z","published":"2023-11-22T18:25:51Z","title":"WildFusion: Learning 3D-Aware Latent Diffusion Models in View Space","summary":"  Modern learning-based approaches to 3D-aware image synthesis achieve high\nphotorealism and 3D-consistent viewpoint changes for the generated images.\nExisting approaches represent instances in a shared canonical space. However,\nfor in-the-wild datasets a shared canonical system can be difficult to define\nor might not even exist. In this work, we instead model instances in view\nspace, alleviating the need for posed images and learned camera distributions.\nWe find that in this setting, existing GAN-based methods are prone to\ngenerating flat geometry and struggle with distribution coverage. We hence\npropose WildFusion, a new approach to 3D-aware image synthesis based on latent\ndiffusion models (LDMs). We first train an autoencoder that infers a compressed\nlatent representation, which additionally captures the images' underlying 3D\nstructure and enables not only reconstruction but also novel view synthesis. To\nlearn a faithful 3D representation, we leverage cues from monocular depth\nprediction. Then, we train a diffusion model in the 3D-aware latent space,\nthereby enabling synthesis of high-quality 3D-consistent image samples,\noutperforming recent state-of-the-art GAN-based methods. Importantly, our\n3D-aware LDM is trained without any direct supervision from multiview images or\n3D geometry and does not require posed images or learned pose or camera\ndistributions. It directly learns a 3D representation without relying on\ncanonical camera coordinates. This opens up promising research avenues for\nscalable 3D-aware image synthesis and 3D content creation from in-the-wild\nimage data. See https://katjaschwarz.github.io/wildfusion for videos of our 3D\nresults.\n","authors":["Katja Schwarz","Seung Wook Kim","Jun Gao","Sanja Fidler","Andreas Geiger","Karsten Kreis"],"pdf_url":"https://arxiv.org/pdf/2311.13570v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13562v1","updated":"2023-11-22T18:15:43Z","published":"2023-11-22T18:15:43Z","title":"Soulstyler: Using Large Language Model to Guide Image Style Transfer for\n  Target Object","summary":"  Image style transfer occupies an important place in both computer graphics\nand computer vision. However, most current methods require reference to\nstylized images and cannot individually stylize specific objects. To overcome\nthis limitation, we propose the \"Soulstyler\" framework, which allows users to\nguide the stylization of specific objects in an image through simple textual\ndescriptions. We introduce a large language model to parse the text and\nidentify stylization goals and specific styles. Combined with a CLIP-based\nsemantic visual embedding encoder, the model understands and matches text and\nimage content. We also introduce a novel localized text-image block matching\nloss that ensures that style transfer is performed only on specified target\nobjects, while non-target regions remain in their original style. Experimental\nresults demonstrate that our model is able to accurately perform style transfer\non target objects according to textual descriptions without affecting the style\nof background regions. Our code will be available at\nhttps://github.com/yisuanwang/Soulstyler.\n","authors":["Junhao Chen","Peng Rong","Jingbo Sun","Chao Li","Xiang Li","Hongwu Lv"],"pdf_url":"https://arxiv.org/pdf/2311.13562v1.pdf","comment":"5 pages,3 figures,ICASSP2024"},{"id":"http://arxiv.org/abs/2311.13559v1","updated":"2023-11-22T18:09:42Z","published":"2023-11-22T18:09:42Z","title":"Transfer Learning-based Real-time Handgun Detection","summary":"  Traditional surveillance systems rely on human attention, limiting their\neffectiveness. This study employs convolutional neural networks and transfer\nlearning to develop a real-time computer vision system for automatic handgun\ndetection. Comprehensive analysis of online handgun detection methods is\nconducted, emphasizing reducing false positives and learning time. Transfer\nlearning is demonstrated as an effective approach. Despite technical\nchallenges, the proposed system achieves a precision rate of 84.74%,\ndemonstrating promising performance comparable to related works, enabling\nfaster learning and accurate automatic handgun detection for enhanced security.\nThis research advances security measures by reducing human monitoring\ndependence, showcasing the potential of transfer learning-based approaches for\nefficient and reliable handgun detection.\n","authors":["Youssef Elmir","Sid Ahmed Laouar","Larbi Hamdaoui"],"pdf_url":"https://arxiv.org/pdf/2311.13559v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13549v1","updated":"2023-11-22T17:44:29Z","published":"2023-11-22T17:44:29Z","title":"ADriver-I: A General World Model for Autonomous Driving","summary":"  Typically, autonomous driving adopts a modular design, which divides the full\nstack into perception, prediction, planning and control parts. Though\ninterpretable, such modular design tends to introduce a substantial amount of\nredundancy. Recently, multimodal large language models (MLLM) and diffusion\ntechniques have demonstrated their superior performance on comprehension and\ngeneration ability. In this paper, we first introduce the concept of\ninterleaved vision-action pair, which unifies the format of visual features and\ncontrol signals. Based on the vision-action pairs, we construct a general world\nmodel based on MLLM and diffusion model for autonomous driving, termed\nADriver-I. It takes the vision-action pairs as inputs and autoregressively\npredicts the control signal of the current frame. The generated control signals\ntogether with the historical vision-action pairs are further conditioned to\npredict the future frames. With the predicted next frame, ADriver-I performs\nfurther control signal prediction. Such a process can be repeated infinite\ntimes, ADriver-I achieves autonomous driving in the world created by itself.\nExtensive experiments are conducted on nuScenes and our large-scale private\ndatasets. ADriver-I shows impressive performance compared to several\nconstructed baselines. We hope our ADriver-I can provide some new insights for\nfuture autonomous driving and embodied intelligence.\n","authors":["Fan Jia","Weixin Mao","Yingfei Liu","Yucheng Zhao","Yuqing Wen","Chi Zhang","Xiangyu Zhang","Tiancai Wang"],"pdf_url":"https://arxiv.org/pdf/2311.13549v1.pdf","comment":"Tech Report"},{"id":"http://arxiv.org/abs/2311.13547v1","updated":"2023-11-22T17:42:33Z","published":"2023-11-22T17:42:33Z","title":"Medical Image Retrieval Using Pretrained Embeddings","summary":"  A wide range of imaging techniques and data formats available for medical\nimages make accurate retrieval from image databases challenging.\n  Efficient retrieval systems are crucial in advancing medical research,\nenabling large-scale studies and innovative diagnostic tools. Thus, addressing\nthe challenges of medical image retrieval is essential for the continued\nenhancement of healthcare and research.\n  In this study, we evaluated the feasibility of employing four\nstate-of-the-art pretrained models for medical image retrieval at modality,\nbody region, and organ levels and compared the results of two similarity\nindexing approaches. Since the employed networks take 2D images, we analyzed\nthe impacts of weighting and sampling strategies to incorporate 3D information\nduring retrieval of 3D volumes. We showed that medical image retrieval is\nfeasible using pretrained networks without any additional training or\nfine-tuning steps. Using pretrained embeddings, we achieved a recall of 1 for\nvarious tasks at modality, body region, and organ level.\n","authors":["Farnaz Khun Jush","Tuan Truong","Steffen Vogler","Matthias Lenga"],"pdf_url":"https://arxiv.org/pdf/2311.13547v1.pdf","comment":"8 pages, 3 figures, 4 tables"},{"id":"http://arxiv.org/abs/2311.13535v1","updated":"2023-11-22T17:16:44Z","published":"2023-11-22T17:16:44Z","title":"DiffusionMat: Alpha Matting as Sequential Refinement Learning","summary":"  In this paper, we introduce DiffusionMat, a novel image matting framework\nthat employs a diffusion model for the transition from coarse to refined alpha\nmattes. Diverging from conventional methods that utilize trimaps merely as\nloose guidance for alpha matte prediction, our approach treats image matting as\na sequential refinement learning process. This process begins with the addition\nof noise to trimaps and iteratively denoises them using a pre-trained diffusion\nmodel, which incrementally guides the prediction towards a clean alpha matte.\nThe key innovation of our framework is a correction module that adjusts the\noutput at each denoising step, ensuring that the final result is consistent\nwith the input image's structures. We also introduce the Alpha Reliability\nPropagation, a novel technique designed to maximize the utility of available\nguidance by selectively enhancing the trimap regions with confident alpha\ninformation, thus simplifying the correction task. To train the correction\nmodule, we devise specialized loss functions that target the accuracy of the\nalpha matte's edges and the consistency of its opaque and transparent regions.\nWe evaluate our model across several image matting benchmarks, and the results\nindicate that DiffusionMat consistently outperforms existing methods. Project\npage at~\\url{https://cnnlstm.github.io/DiffusionMat\n","authors":["Yangyang Xu","Shengfeng He","Wenqi Shao","Kwan-Yee K. Wong","Yu Qiao","Ping Luo"],"pdf_url":"https://arxiv.org/pdf/2311.13535v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13531v1","updated":"2023-11-22T17:06:57Z","published":"2023-11-22T17:06:57Z","title":"Leveraging CNNs and Ensemble Learning for Automated Disaster Image\n  Classification","summary":"  Natural disasters act as a serious threat globally, requiring effective and\nefficient disaster management and recovery. This paper focuses on classifying\nnatural disaster images using Convolutional Neural Networks (CNNs). Multiple\nCNN architectures were built and trained on a dataset containing images of\nearthquakes, floods, wildfires, and volcanoes. A stacked CNN ensemble approach\nproved to be the most effective, achieving 95% accuracy and an F1 score going\nup to 0.96 for individual classes. Tuning hyperparameters of individual models\nfor optimization was critical to maximize the models' performance. The stacking\nof CNNs with XGBoost acting as the meta-model utilizes the strengths of the CNN\nand ResNet models to improve the overall accuracy of the classification.\nResults obtained from the models illustrated the potency of CNN-based models\nfor automated disaster image classification. This lays the foundation for\nexpanding these techniques to build robust systems for disaster response,\ndamage assessment, and recovery management.\n","authors":["Archit Rathod","Veer Pariawala","Mokshit Surana","Kumkum Saxena"],"pdf_url":"https://arxiv.org/pdf/2311.13531v1.pdf","comment":"13 pages, 11 figures, 4 tables, ICSISCET 2023 Conference"},{"id":"http://arxiv.org/abs/2311.11772v2","updated":"2023-11-22T17:06:31Z","published":"2023-11-20T13:58:26Z","title":"A Good Feature Extractor Is All You Need for Weakly Supervised Learning\n  in Histopathology","summary":"  Deep learning is revolutionising pathology, offering novel opportunities in\ndisease prognosis and personalised treatment. Historically, stain normalisation\nhas been a crucial preprocessing step in computational pathology pipelines, and\npersists into the deep learning era. Yet, with the emergence of feature\nextractors trained using self-supervised learning (SSL) on diverse pathology\ndatasets, we call this practice into question. In an empirical evaluation of\npublicly available feature extractors, we find that omitting stain\nnormalisation and image augmentations does not compromise downstream\nperformance, while incurring substantial savings in memory and compute.\nFurther, we show that the top-performing feature extractors are remarkably\nrobust to variations in stain and augmentations like rotation in their latent\nspace. Contrary to previous patch-level benchmarking studies, our approach\nemphasises clinical relevance by focusing on slide-level prediction tasks in a\nweakly supervised setting with external validation cohorts. This work\nrepresents the most comprehensive robustness evaluation of public pathology SSL\nfeature extractors to date, involving more than 6,000 training runs across nine\ntasks, five datasets, three downstream architectures, and various preprocessing\nsetups. Our findings stand to streamline digital pathology workflows by\nminimising preprocessing needs and informing the selection of feature\nextractors.\n","authors":["Georg Wölflein","Dyke Ferber","Asier Rabasco Meneghetti","Omar S. M. El Nahhas","Daniel Truhn","Zunamys I. Carrero","David J. Harrison","Ognjen Arandjelović","Jakob N. Kather"],"pdf_url":"https://arxiv.org/pdf/2311.11772v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11284v2","updated":"2023-11-22T16:54:17Z","published":"2023-11-19T09:59:09Z","title":"LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval\n  Score Matching","summary":"  The recent advancements in text-to-3D generation mark a significant milestone\nin generative models, unlocking new possibilities for creating imaginative 3D\nassets across various real-world scenarios. While recent advancements in\ntext-to-3D generation have shown promise, they often fall short in rendering\ndetailed and high-quality 3D models. This problem is especially prevalent as\nmany methods base themselves on Score Distillation Sampling (SDS). This paper\nidentifies a notable deficiency in SDS, that it brings inconsistent and\nlow-quality updating direction for the 3D model, causing the over-smoothing\neffect. To address this, we propose a novel approach called Interval Score\nMatching (ISM). ISM employs deterministic diffusing trajectories and utilizes\ninterval-based score matching to counteract over-smoothing. Furthermore, we\nincorporate 3D Gaussian Splatting into our text-to-3D generation pipeline.\nExtensive experiments show that our model largely outperforms the\nstate-of-the-art in quality and training efficiency.\n","authors":["Yixun Liang","Xin Yang","Jiantao Lin","Haodong Li","Xiaogang Xu","Yingcong Chen"],"pdf_url":"https://arxiv.org/pdf/2311.11284v2.pdf","comment":"The first two authors contributed equally to this work. Our code will\n  be available at: https://github.com/EnVision-Research/LucidDreamer"},{"id":"http://arxiv.org/abs/2311.13512v1","updated":"2023-11-22T16:35:43Z","published":"2023-11-22T16:35:43Z","title":"Hybrid Whale-Mud-Ring Optimization for Precise Color Skin Cancer Image\n  Segmentation","summary":"  Timely identification and treatment of rapidly progressing skin cancers can\nsignificantly contribute to the preservation of patients' health and\nwell-being. Dermoscopy, a dependable and accessible tool, plays a pivotal role\nin the initial stages of skin cancer detection. Consequently, the effective\nprocessing of digital dermoscopy images holds significant importance in\nelevating the accuracy of skin cancer diagnoses. Multilevel thresholding is a\nkey tool in medical imaging that extracts objects within the image to\nfacilitate its analysis. In this paper, an enhanced version of the Mud Ring\nAlgorithm hybridized with the Whale Optimization Algorithm, named WMRA, is\nproposed. The proposed approach utilizes bubble-net attack and mud ring\nstrategy to overcome stagnation in local optima and obtain optimal thresholds.\nThe experimental results show that WMRA is powerful against a cluster of recent\nmethods in terms of fitness, Peak Signal to Noise Ratio (PSNR), and Mean Square\nError (MSE).\n","authors":["Amir Hamza","Badis Lekouaghet","Yassine Himeur"],"pdf_url":"https://arxiv.org/pdf/2311.13512v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15755v2","updated":"2023-11-22T16:16:43Z","published":"2023-06-27T19:15:06Z","title":"Adversarial Backdoor Attack by Naturalistic Data Poisoning on Trajectory\n  Prediction in Autonomous Driving","summary":"  In autonomous driving, behavior prediction is fundamental for safe motion\nplanning, hence the security and robustness of prediction models against\nadversarial attacks are of paramount importance. We propose a novel adversarial\nbackdoor attack against trajectory prediction models as a means of studying\ntheir potential vulnerabilities. Our attack affects the victim at training time\nvia naturalistic, hence stealthy, poisoned samples crafted using a novel\ntwo-step approach. First, the triggers are crafted by perturbing the trajectory\nof attacking vehicle and then disguised by transforming the scene using a\nbi-level optimization technique. The proposed attack does not depend on a\nparticular model architecture and operates in a black-box manner, thus can be\neffective without any knowledge of the victim model. We conduct extensive\nempirical studies using state-of-the-art prediction models on two benchmark\ndatasets using metrics customized for trajectory prediction. We show that the\nproposed attack is highly effective, as it can significantly hinder the\nperformance of prediction models, unnoticeable by the victims, and efficient as\nit forces the victim to generate malicious behavior even under constrained\nconditions. Via ablative studies, we analyze the impact of different attack\ndesign choices followed by an evaluation of existing defence mechanisms against\nthe proposed attack.\n","authors":["Mozhgan Pourkeshavarz","Mohammad Sabokrou","Amir Rasouli"],"pdf_url":"https://arxiv.org/pdf/2306.15755v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13485v1","updated":"2023-11-22T16:01:44Z","published":"2023-11-22T16:01:44Z","title":"Deep-learning-based acceleration of MRI for radiotherapy planning of\n  pediatric patients with brain tumors","summary":"  Magnetic Resonance Imaging (MRI) is a non-invasive diagnostic and\nradiotherapy (RT) planning tool, offering detailed insights into the anatomy of\nthe human body. The extensive scan time is stressful for patients, who must\nremain motionless in a prolonged imaging procedure that prioritizes reduction\nof imaging artifacts. This is challenging for pediatric patients who may\nrequire measures for managing voluntary motions such as anesthesia. Several\ncomputational approaches reduce scan time (fast MRI), by recording fewer\nmeasurements and digitally recovering full information via post-acquisition\nreconstruction. However, most fast MRI approaches were developed for diagnostic\nimaging, without addressing reconstruction challenges specific to RT planning.\nIn this work, we developed a deep learning-based method (DeepMRIRec) for MRI\nreconstruction from undersampled data acquired with RT-specific receiver coil\narrangements. We evaluated our method against fully sampled data of T1-weighted\nMR images acquired from 73 children with brain tumors/surgical beds using loop\nand posterior coils (12 channels), with and without applying virtual\ncompression of coil elements. DeepMRIRec reduced scanning time by a factor of\nfour producing a structural similarity score surpassing the evaluated\nstate-of-the-art method (0.960 vs 0.896), thereby demonstrating its potential\nfor accelerating MRI scanning for RT planning.\n","authors":["Shahinur Alam","Jinsoo Uh","Alexander Dresner","Chia-ho Hua","Khaled Khairy"],"pdf_url":"https://arxiv.org/pdf/2311.13485v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.03105v2","updated":"2023-11-22T15:46:00Z","published":"2023-11-06T13:54:52Z","title":"Pelvic floor MRI segmentation based on semi-supervised deep learning","summary":"  The semantic segmentation of pelvic organs via MRI has important clinical\nsignificance. Recently, deep learning-enabled semantic segmentation has\nfacilitated the three-dimensional geometric reconstruction of pelvic floor\norgans, providing clinicians with accurate and intuitive diagnostic results.\nHowever, the task of labeling pelvic floor MRI segmentation, typically\nperformed by clinicians, is labor-intensive and costly, leading to a scarcity\nof labels. Insufficient segmentation labels limit the precise segmentation and\nreconstruction of pelvic floor organs. To address these issues, we propose a\nsemi-supervised framework for pelvic organ segmentation. The implementation of\nthis framework comprises two stages. In the first stage, it performs\nself-supervised pre-training using image restoration tasks. Subsequently,\nfine-tuning of the self-supervised model is performed, using labeled data to\ntrain the segmentation model. In the second stage, the self-supervised\nsegmentation model is used to generate pseudo labels for unlabeled data.\nUltimately, both labeled and unlabeled data are utilized in semi-supervised\ntraining. Upon evaluation, our method significantly enhances the performance in\nthe semantic segmentation and geometric reconstruction of pelvic organs, Dice\ncoefficient can increase by 2.65% averagely. Especially for organs that are\ndifficult to segment, such as the uterus, the accuracy of semantic segmentation\ncan be improved by up to 3.70%.\n","authors":["Jianwei Zuo","Fei Feng","Zhuhui Wang","James A. Ashton-Miller","John O. L. Delancey","Jiajia Luo"],"pdf_url":"https://arxiv.org/pdf/2311.03105v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.02673v2","updated":"2023-11-22T15:27:53Z","published":"2021-07-06T15:27:00Z","title":"Attention-based Adversarial Appearance Learning of Augmented Pedestrians","summary":"  Synthetic data became already an essential component of machine\nlearning-based perception in the field of autonomous driving. Yet it still\ncannot replace real data completely due to the sim2real domain shift. In this\nwork, we propose a method that leverages the advantages of the augmentation\nprocess and adversarial training to synthesize realistic data for the\npedestrian recognition task. Our approach utilizes an attention mechanism\ndriven by an adversarial loss to learn domain discrepancies and improve\nsim2real adaptation. Our experiments confirm that the proposed adaptation\nmethod is robust to such discrepancies and reveals both visual realism and\nsemantic consistency. Furthermore, we evaluate our data generation pipeline on\nthe task of pedestrian recognition and demonstrate that generated data resemble\nproperties of the real domain.\n","authors":["Kevin Strauss","Artem Savkin","Federico Tombari"],"pdf_url":"https://arxiv.org/pdf/2107.02673v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02931v3","updated":"2023-11-22T15:23:44Z","published":"2022-12-06T12:40:45Z","title":"Leveraging Different Learning Styles for Improved Knowledge Distillation\n  in Biomedical Imaging","summary":"  Learning style refers to a type of training mechanism adopted by an\nindividual to gain new knowledge. As suggested by the VARK model, humans have\ndifferent learning preferences, like Visual (V), Auditory (A), Read/Write (R),\nand Kinesthetic (K), for acquiring and effectively processing information. Our\nwork endeavors to leverage this concept of knowledge diversification to improve\nthe performance of model compression techniques like Knowledge Distillation\n(KD) and Mutual Learning (ML). Consequently, we use a single-teacher and\ntwo-student network in a unified framework that not only allows for the\ntransfer of knowledge from teacher to students (KD) but also encourages\ncollaborative learning between students (ML). Unlike the conventional approach,\nwhere the teacher shares the same knowledge in the form of predictions or\nfeature representations with the student network, our proposed approach employs\na more diversified strategy by training one student with predictions and the\nother with feature maps from the teacher. We further extend this knowledge\ndiversification by facilitating the exchange of predictions and feature maps\nbetween the two student networks, enriching their learning experiences. We have\nconducted comprehensive experiments with three benchmark datasets for both\nclassification and segmentation tasks using two different network architecture\ncombinations. These experimental results demonstrate that knowledge\ndiversification in a combined KD and ML framework outperforms conventional KD\nor ML techniques (with similar network configuration) that only use predictions\nwith an average improvement of 2%. Furthermore, consistent improvement in\nperformance across different tasks, with various network architectures, and\nover state-of-the-art techniques establishes the robustness and\ngeneralizability of the proposed model\n","authors":["Usma Niyaz","Abhishek Singh Sambyal","Deepti R. Bathula"],"pdf_url":"https://arxiv.org/pdf/2212.02931v3.pdf","comment":"Accepted in Computers in Biology and Medicine"},{"id":"http://arxiv.org/abs/2311.13444v1","updated":"2023-11-22T15:09:59Z","published":"2023-11-22T15:09:59Z","title":"SkeletonGait: Gait Recognition Using Skeleton Maps","summary":"  The choice of the representations is essential for deep gait recognition\nmethods. The binary silhouettes and skeletal coordinates are two dominant\nrepresentations in recent literature, achieving remarkable advances in many\nscenarios. However, inherent challenges remain, in which silhouettes are not\nalways guaranteed in unconstrained scenes, and structural cues have not been\nfully utilized from skeletons. In this paper, we introduce a novel skeletal\ngait representation named Skeleton Map, together with SkeletonGait, a\nskeleton-based method to exploit structural information from human skeleton\nmaps. Specifically, the skeleton map represents the coordinates of human joints\nas a heatmap with Gaussian approximation, exhibiting a silhouette-like image\ndevoid of exact body structure. Beyond achieving state-of-the-art performances\nover five popular gait datasets, more importantly, SkeletonGait uncovers novel\ninsights about how important structural features are in describing gait and\nwhen do they play a role. Furthermore, we propose a multi-branch architecture,\nnamed SkeletonGait++, to make use of complementary features from both skeletons\nand silhouettes. Experiments indicate that SkeletonGait++ outperforms existing\nstate-of-the-art methods by a significant margin in various scenarios. For\ninstance, it achieves an impressive rank-1 accuracy of over $85\\%$ on the\nchallenging GREW dataset. All the source code will be available at\nhttps://github.com/ShiqiYu/OpenGait.\n","authors":["Chao Fan","Jingzhe Ma","Dongyang Jin","Chuanfu Shen","Shiqi Yu"],"pdf_url":"https://arxiv.org/pdf/2311.13444v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13443v1","updated":"2023-11-22T15:07:59Z","published":"2023-11-22T15:07:59Z","title":"Guided Flows for Generative Modeling and Decision Making","summary":"  Classifier-free guidance is a key component for improving the performance of\nconditional generative models for many downstream tasks. It drastically\nimproves the quality of samples produced, but has so far only been used for\ndiffusion models. Flow Matching (FM), an alternative simulation-free approach,\ntrains Continuous Normalizing Flows (CNFs) based on regressing vector fields.\nIt remains an open question whether classifier-free guidance can be performed\nfor Flow Matching models, and to what extent does it improve performance. In\nthis paper, we explore the usage of Guided Flows for a variety of downstream\napplications involving conditional image generation, speech synthesis, and\nreinforcement learning. In particular, we are the first to apply flow models to\nthe offline reinforcement learning setting. We also show that Guided Flows\nsignificantly improves the sample quality in image generation and zero-shot\ntext-to-speech synthesis, and can make use of drastically low amounts of\ncomputation without affecting the agent's overall performance.\n","authors":["Qinqing Zheng","Matt Le","Neta Shaul","Yaron Lipman","Aditya Grover","Ricky T. Q. Chen"],"pdf_url":"https://arxiv.org/pdf/2311.13443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13435v1","updated":"2023-11-22T14:48:30Z","published":"2023-11-22T14:48:30Z","title":"PG-Video-LLaVA: Pixel Grounding Large Video-Language Models","summary":"  Extending image-based Large Multimodal Models (LMM) to videos is challenging\ndue to the inherent complexity of video data. The recent approaches extending\nimage-based LMM to videos either lack the grounding capabilities (e.g.,\nVideoChat, Video-ChatGPT, Video-LLaMA) or do not utilize the audio-signals for\nbetter video understanding (e.g., Video-ChatGPT). Addressing these gaps, we\npropose Video-LLaVA, the first LMM with pixel-level grounding capability,\nintegrating audio cues by transcribing them into text to enrich video-context\nunderstanding. Our framework uses an off-the-shelf tracker and a novel\ngrounding module, enabling it to spatially and temporally localize objects in\nvideos following user instructions. We evaluate Video-LLaVA using video-based\ngenerative and question-answering benchmarks and introduce new benchmarks\nspecifically designed to measure prompt-based object grounding performance in\nvideos. Further, we propose the use of Vicuna over GPT-3.5, as utilized in\nVideo-ChatGPT, for video-based conversation benchmarking, ensuring\nreproducibility of results which is a concern with the proprietary nature of\nGPT-3.5. Our framework builds on SoTA image-based LLaVA model and extends its\nadvantages to the video domain, delivering promising gains on video-based\nconversation and grounding tasks. Project Page:\nhttps://github.com/mbzuai-oryx/Video-LLaVA\n","authors":["Shehan Munasinghe","Rusiru Thushara","Muhammad Maaz","Hanoona Abdul Rasheed","Salman Khan","Mubarak Shah","Fahad Khan"],"pdf_url":"https://arxiv.org/pdf/2311.13435v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2311.08936v2","updated":"2023-11-22T14:25:55Z","published":"2023-11-15T13:19:02Z","title":"Confident Naturalness Explanation (CNE): A Framework to Explain and\n  Assess Patterns Forming Naturalness","summary":"  Protected natural areas are regions that have been minimally affected by\nhuman activities such as urbanization, agriculture, and other human\ninterventions. To better understand and map the naturalness of these areas,\nmachine learning models can be used to analyze satellite imagery. Specifically,\nexplainable machine learning methods show promise in uncovering patterns that\ncontribute to the concept of naturalness within these protected environments.\nAdditionally, addressing the uncertainty inherent in machine learning models is\ncrucial for a comprehensive understanding of this concept. However, existing\napproaches have limitations. They either fail to provide explanations that are\nboth valid and objective or struggle to offer a quantitative metric that\naccurately measures the contribution of specific patterns to naturalness, along\nwith the associated confidence. In this paper, we propose a novel framework\ncalled the Confident Naturalness Explanation (CNE) framework. This framework\ncombines explainable machine learning and uncertainty quantification to assess\nand explain naturalness. We introduce a new quantitative metric that describes\nthe confident contribution of patterns to the concept of naturalness.\nFurthermore, we generate an uncertainty-aware segmentation mask for each input\nsample, highlighting areas where the model lacks knowledge. To demonstrate the\neffectiveness of our framework, we apply it to a study site in Fennoscandia\nusing two open-source satellite datasets.\n","authors":["Ahmed Emam","Mohamed Farag","Ribana Roscher"],"pdf_url":"https://arxiv.org/pdf/2311.08936v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13409v1","updated":"2023-11-22T14:13:27Z","published":"2023-11-22T14:13:27Z","title":"CompenHR: Efficient Full Compensation for High-resolution Projector","summary":"  Full projector compensation is a practical task of projector-camera systems.\nIt aims to find a projector input image, named compensation image, such that\nwhen projected it cancels the geometric and photometric distortions due to the\nphysical environment and hardware. State-of-the-art methods use deep learning\nto address this problem and show promising performance for low-resolution\nsetups. However, directly applying deep learning to high-resolution setups is\nimpractical due to the long training time and high memory cost. To address this\nissue, this paper proposes a practical full compensation solution. Firstly, we\ndesign an attention-based grid refinement network to improve geometric\ncorrection quality. Secondly, we integrate a novel sampling scheme into an\nend-to-end compensation network to alleviate computation and introduce\nattention blocks to preserve key features. Finally, we construct a benchmark\ndataset for high-resolution projector full compensation. In experiments, our\nmethod demonstrates clear advantages in both efficiency and quality.\n","authors":["Yuxi Wang","Haibin Ling","Bingyao Huang"],"pdf_url":"https://arxiv.org/pdf/2311.13409v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13404v1","updated":"2023-11-22T14:00:23Z","published":"2023-11-22T14:00:23Z","title":"Animatable 3D Gaussians for High-fidelity Synthesis of Human Motions","summary":"  We present a novel animatable 3D Gaussian model for rendering high-fidelity\nfree-view human motions in real time. Compared to existing NeRF-based methods,\nthe model owns better capability in synthesizing high-frequency details without\nthe jittering problem across video frames. The core of our model is a novel\naugmented 3D Gaussian representation, which attaches each Gaussian with a\nlearnable code. The learnable code serves as a pose-dependent appearance\nembedding for refining the erroneous appearance caused by geometric\ntransformation of Gaussians, based on which an appearance refinement model is\nlearned to produce residual Gaussian properties to match the appearance in\ntarget pose. To force the Gaussians to learn the foreground human only without\nbackground interference, we further design a novel alpha loss to explicitly\nconstrain the Gaussians within the human body. We also propose to jointly\noptimize the human joint parameters to improve the appearance accuracy. The\nanimatable 3D Gaussian model can be learned with shallow MLPs, so new human\nmotions can be synthesized in real time (66 fps on avarage). Experiments show\nthat our model has superior performance over NeRF-based methods.\n","authors":["Keyang Ye","Tianjia Shao","Kun Zhou"],"pdf_url":"https://arxiv.org/pdf/2311.13404v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.02185v4","updated":"2023-11-22T13:56:48Z","published":"2023-09-05T12:42:26Z","title":"BEVTrack: A Simple and Strong Baseline for 3D Single Object Tracking in\n  Bird's-Eye View","summary":"  3D Single Object Tracking (SOT) is a fundamental task of computer vision,\nproving essential for applications like autonomous driving. It remains\nchallenging to localize the target from surroundings due to appearance\nvariations, distractors, and the high sparsity of point clouds. The spatial\ninformation indicating objects' spatial adjacency across consecutive frames is\ncrucial for effective object tracking. However, existing trackers typically\nemploy point-wise representation with irregular formats, leading to\ninsufficient use of this important spatial knowledge. As a result, these\ntrackers usually require elaborate designs and solving multiple subtasks. In\nthis paper, we propose BEVTrack, a simple yet effective baseline that performs\ntracking in Bird's-Eye View (BEV). This representation greatly retains spatial\ninformation owing to its ordered structure and inherently encodes the implicit\nmotion relations of the target as well as distractors. To achieve accurate\nregression for targets with diverse attributes (\\textit{e.g.}, sizes and motion\npatterns), BEVTrack constructs the likelihood function with the learned\nunderlying distributions adapted to different targets, rather than making a\nfixed Laplace or Gaussian assumption as in previous works. This provides\nvaluable priors for tracking and thus further boosts performance. While only\nusing a single regression loss with a plain convolutional architecture,\nBEVTrack achieves state-of-the-art performance on three large-scale datasets,\nKITTI, NuScenes, and Waymo Open Dataset while maintaining a high inference\nspeed of about 200 FPS. The code will be released at\nhttps://github.com/xmm-prio/BEVTrack.\n","authors":["Yuxiang Yang","Yingqi Deng","Jing Zhang","Jiahao Nie","Zheng-Jun Zha"],"pdf_url":"https://arxiv.org/pdf/2309.02185v4.pdf","comment":"The code will be released at https://github.com/xmm-prio/BEVTrack"},{"id":"http://arxiv.org/abs/2311.13398v1","updated":"2023-11-22T13:53:04Z","published":"2023-11-22T13:53:04Z","title":"Depth-Regularized Optimization for 3D Gaussian Splatting in Few-Shot\n  Images","summary":"  In this paper, we present a method to optimize Gaussian splatting with a\nlimited number of images while avoiding overfitting. Representing a 3D scene by\ncombining numerous Gaussian splats has yielded outstanding visual quality.\nHowever, it tends to overfit the training views when only a small number of\nimages are available. To address this issue, we introduce a dense depth map as\na geometry guide to mitigate overfitting. We obtained the depth map using a\npre-trained monocular depth estimation model and aligning the scale and offset\nusing sparse COLMAP feature points. The adjusted depth aids in the color-based\noptimization of 3D Gaussian splatting, mitigating floating artifacts, and\nensuring adherence to geometric constraints. We verify the proposed method on\nthe NeRF-LLFF dataset with varying numbers of few images. Our approach\ndemonstrates robust geometry compared to the original method that relies solely\non images.\n","authors":["Jaeyoung Chung","Jeongtaek Oh","Kyoung Mu Lee"],"pdf_url":"https://arxiv.org/pdf/2311.13398v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.13385v1","updated":"2023-11-22T13:27:36Z","published":"2023-11-22T13:27:36Z","title":"SegVol: Universal and Interactive Volumetric Medical Image Segmentation","summary":"  Precise image segmentation provides clinical study with meaningful and\nwell-structured information. Despite the remarkable progress achieved in\nmedical image segmentation, there is still an absence of foundation\nsegmentation model that can segment a wide range of anatomical categories with\neasy user interaction. In this paper, we propose a universal and interactive\nvolumetric medical image segmentation model, named SegVol. By training on 90k\nunlabeled Computed Tomography (CT) volumes and 6k labeled CTs, this foundation\nmodel supports the segmentation of over 200 anatomical categories using\nsemantic and spatial prompts. Extensive experiments verify that SegVol\noutperforms the state of the art by a large margin on multiple segmentation\nbenchmarks. Notably, on three challenging lesion datasets, our method achieves\naround 20% higher Dice score than nnU-Net. The model and data are publicly\navailable at: https://github.com/BAAI-DCAI/SegVol.\n","authors":["Yuxin Du","Fan Bai","Tiejun Huang","Bo Zhao"],"pdf_url":"https://arxiv.org/pdf/2311.13385v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13384v1","updated":"2023-11-22T13:27:34Z","published":"2023-11-22T13:27:34Z","title":"LucidDreamer: Domain-free Generation of 3D Gaussian Splatting Scenes","summary":"  With the widespread usage of VR devices and contents, demands for 3D scene\ngeneration techniques become more popular. Existing 3D scene generation models,\nhowever, limit the target scene to specific domain, primarily due to their\ntraining strategies using 3D scan dataset that is far from the real-world. To\naddress such limitation, we propose LucidDreamer, a domain-free scene\ngeneration pipeline by fully leveraging the power of existing large-scale\ndiffusion-based generative model. Our LucidDreamer has two alternate steps:\nDreaming and Alignment. First, to generate multi-view consistent images from\ninputs, we set the point cloud as a geometrical guideline for each image\ngeneration. Specifically, we project a portion of point cloud to the desired\nview and provide the projection as a guidance for inpainting using the\ngenerative model. The inpainted images are lifted to 3D space with estimated\ndepth maps, composing a new points. Second, to aggregate the new points into\nthe 3D scene, we propose an aligning algorithm which harmoniously integrates\nthe portions of newly generated 3D scenes. The finally obtained 3D scene serves\nas initial points for optimizing Gaussian splats. LucidDreamer produces\nGaussian splats that are highly-detailed compared to the previous 3D scene\ngeneration methods, with no constraint on domain of the target scene.\n","authors":["Jaeyoung Chung","Suyoung Lee","Hyeongjin Nam","Jaerin Lee","Kyoung Mu Lee"],"pdf_url":"https://arxiv.org/pdf/2311.13384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13378v1","updated":"2023-11-22T13:19:41Z","published":"2023-11-22T13:19:41Z","title":"Point Projection Mapping System for Tracking, Registering, Labeling and\n  Validating Optical Tissue Measurements","summary":"  Validation of newly developed optical tissue sensing techniques for tumor\ndetection during cancer surgery requires an accurate correlation with\nhistological results. Additionally, such accurate correlation facilitates\nprecise data labeling for developing high-performance machine-learning tissue\nclassification models. In this paper, a newly developed Point Projection\nMapping system will be introduced, which allows non-destructive tracking of the\nmeasurement locations on tissue specimens. Additionally, a framework for\naccurate registration, validation, and labeling with histopathology results is\nproposed and validated on a case study. The proposed framework provides a more\nrobust and accurate method for tracking and validation of optical tissue\nsensing techniques, which saves time and resources compared to conventional\ntechniques available.\n","authors":["Lianne Feenstra","Stefan D. van der Stel","Marcos Da Silva Guimaraes","Theo J. M Ruers","Behdad Dashtbozorg"],"pdf_url":"https://arxiv.org/pdf/2311.13378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13372v1","updated":"2023-11-22T13:13:19Z","published":"2023-11-22T13:13:19Z","title":"MRGazer: Decoding Eye Gaze Points from Functional Magnetic Resonance\n  Imaging in Individual Space","summary":"  Eye-tracking research has proven valuable in understanding numerous cognitive\nfunctions. Recently, Frey et al. provided an exciting deep learning method for\nlearning eye movements from fMRI data. However, it needed to co-register fMRI\ninto standard space to obtain eyeballs masks, and thus required additional\ntemplates and was time consuming. To resolve this issue, in this paper, we\npropose a framework named MRGazer for predicting eye gaze points from fMRI in\nindividual space. The MRGazer consisted of eyeballs extraction module and a\nresidual network-based eye gaze prediction. Compared to the previous method,\nthe proposed framework skips the fMRI co-registration step, simplifies the\nprocessing protocol and achieves end-to-end eye gaze regression. The proposed\nmethod achieved superior performance in a variety of eye movement tasks than\nthe co-registration-based method, and delivered objective results within a\nshorter time (~ 0.02 Seconds for each volume) than prior method (~0.3 Seconds\nfor each volume).\n","authors":["Xiuwen Wu","Rongjie Hu","Jie Liang","Yanming Wang","Bensheng Qiu","Xiaoxiao Wang"],"pdf_url":"https://arxiv.org/pdf/2311.13372v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11317v2","updated":"2023-11-22T12:52:41Z","published":"2023-11-19T13:07:06Z","title":"Discrete approximations of Gaussian smoothing and Gaussian derivatives","summary":"  This paper develops an in-depth treatment concerning the problem of\napproximating the Gaussian smoothing and Gaussian derivative computations in\nscale-space theory for application on discrete data. With close connections to\nprevious axiomatic treatments of continuous and discrete scale-space theory, we\nconsider three main ways discretizing these scale-space operations in terms of\nexplicit discrete convolutions, based on either (i) sampling the Gaussian\nkernels and the Gaussian derivative kernels, (ii) locally integrating the\nGaussian kernels and the Gaussian derivative kernels over each pixel support\nregion and (iii) basing the scale-space analysis on the discrete analogue of\nthe Gaussian kernel, and then computing derivative approximations by applying\nsmall-support central difference operators to the spatially smoothed image\ndata.\n  We study the properties of these three main discretization methods both\ntheoretically and experimentally, and characterize their performance by\nquantitative measures, including the results they give rise to with respect to\nthe task of scale selection, investigated for four different use cases, and\nwith emphasis on the behaviour at fine scales. The results show that the\nsampled Gaussian kernels and derivatives as well as the integrated Gaussian\nkernels and derivatives perform very poorly at very fine scales. At very fine\nscales, the discrete analogue of the Gaussian kernel with its corresponding\ndiscrete derivative approximations performs substantially better. The sampled\nGaussian kernel and the sampled Gaussian derivatives do, on the other hand,\nlead to numerically very good approximations of the corresponding continuous\nresults, when the scale parameter is sufficiently large, in the experiments\npresented in the paper, when the scale parameter is greater than a value of\nabout 1, in units of the grid spacing.\n","authors":["Tony Lindeberg"],"pdf_url":"https://arxiv.org/pdf/2311.11317v2.pdf","comment":"38 pages, 34 figures"},{"id":"http://arxiv.org/abs/2311.13355v1","updated":"2023-11-22T12:47:12Z","published":"2023-11-22T12:47:12Z","title":"Unified Classification and Rejection: A One-versus-All Framework","summary":"  Classifying patterns of known classes and rejecting ambiguous and novel (also\ncalled as out-of-distribution (OOD)) inputs are involved in open world pattern\nrecognition. Deep neural network models usually excel in closed-set\nclassification while performing poorly in rejecting OOD. To tackle this\nproblem, numerous methods have been designed to perform open set recognition\n(OSR) or OOD rejection/detection tasks. Previous methods mostly take\npost-training score transformation or hybrid models to ensure low scores on OOD\ninputs while separating known classes. In this paper, we attempt to build a\nunified framework for building open set classifiers for both classification and\nOOD rejection. We formulate the open set recognition of $ K $-known-class as a\n$ (K + 1) $-class classification problem with model trained on known-class\nsamples only. By decomposing the $ K $-class problem into $ K $ one-versus-all\n(OVA) binary classification tasks and binding some parameters, we show that\ncombining the scores of OVA classifiers can give $ (K + 1) $-class posterior\nprobabilities, which enables classification and OOD rejection in a unified\nframework. To maintain the closed-set classification accuracy of the OVA\ntrained classifier, we propose a hybrid training strategy combining OVA loss\nand multi-class cross-entropy loss. We implement the OVA framework and hybrid\ntraining strategy on the recently proposed convolutional prototype network.\nExperiments on popular OSR and OOD detection datasets demonstrate that the\nproposed framework, using a single multi-class classifier, yields competitive\nperformance in closed-set classification, OOD detection, and misclassification\ndetection.\n","authors":["Zhen Cheng","Xu-Yao Zhang","Cheng-Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2311.13355v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04225v2","updated":"2023-11-22T12:35:08Z","published":"2023-06-07T08:02:17Z","title":"Efficient Vision Transformer for Human Pose Estimation via Patch\n  Selection","summary":"  While Convolutional Neural Networks (CNNs) have been widely successful in 2D\nhuman pose estimation, Vision Transformers (ViTs) have emerged as a promising\nalternative to CNNs, boosting state-of-the-art performance. However, the\nquadratic computational complexity of ViTs has limited their applicability for\nprocessing high-resolution images. In this paper, we propose three methods for\nreducing ViT's computational complexity, which are based on selecting and\nprocessing a small number of most informative patches while disregarding\nothers. The first two methods leverage a lightweight pose estimation network to\nguide the patch selection process, while the third method utilizes a set of\nlearnable joint tokens to ensure that the selected patches contain the most\nimportant information about body joints. Experiments across six benchmarks show\nthat our proposed methods achieve a significant reduction in computational\ncomplexity, ranging from 30% to 44%, with only a minimal drop in accuracy\nbetween 0% and 3.5%.\n","authors":["Kaleab A. Kinfu","Rene Vidal"],"pdf_url":"https://arxiv.org/pdf/2306.04225v2.pdf","comment":"BMVC 2023 Oral Paper: https://proceedings.bmvc2023.org/167/"},{"id":"http://arxiv.org/abs/2211.14605v2","updated":"2023-11-22T12:16:28Z","published":"2022-11-26T16:13:32Z","title":"Looking at the posterior: accuracy and uncertainty of neural-network\n  predictions","summary":"  Bayesian inference can quantify uncertainty in the predictions of neural\nnetworks using posterior distributions for model parameters and network output.\nBy looking at these posterior distributions, one can separate the origin of\nuncertainty into aleatoric and epistemic contributions. One goal of uncertainty\nquantification is to inform on prediction accuracy. Here we show that\nprediction accuracy depends on both epistemic and aleatoric uncertainty in an\nintricate fashion that cannot be understood in terms of marginalized\nuncertainty distributions alone. How the accuracy relates to epistemic and\naleatoric uncertainties depends not only on the model architecture, but also on\nthe properties of the dataset. We discuss the significance of these results for\nactive learning and introduce a novel acquisition function that outperforms\ncommon uncertainty-based methods. To arrive at our results, we approximated the\nposteriors using deep ensembles, for fully-connected, convolutional and\nattention-based neural networks.\n","authors":["H. Linander","O. Balabanov","H. Yang","B. Mehlig"],"pdf_url":"https://arxiv.org/pdf/2211.14605v2.pdf","comment":"26 pages, 10 figures, 5 tables"},{"id":"http://arxiv.org/abs/2311.13338v1","updated":"2023-11-22T12:03:33Z","published":"2023-11-22T12:03:33Z","title":"High-Quality Face Caricature via Style Translation","summary":"  Caricature is an exaggerated form of artistic portraiture that accentuates\nunique yet subtle characteristics of human faces. Recently, advancements in\ndeep end-to-end techniques have yielded encouraging outcomes in capturing both\nstyle and elevated exaggerations in creating face caricatures. Most of these\napproaches tend to produce cartoon-like results that could be more practical\nfor real-world applications. In this study, we proposed a high-quality,\nunpaired face caricature method that is appropriate for use in the real world\nand uses computer vision techniques and GAN models. We attain the exaggeration\nof facial features and the stylization of appearance through a two-step\nprocess: Face caricature generation and face caricature projection. The face\ncaricature generation step creates new caricature face datasets from real\nimages and trains a generative model using the real and newly created\ncaricature datasets. The Face caricature projection employs an encoder trained\nwith real and caricature faces with the pretrained generator to project real\nand caricature faces. We perform an incremental facial exaggeration from the\nreal image to the caricature faces using the encoder and generator's latent\nspace. Our projection preserves the facial identity, attributes, and\nexpressions from the input image. Also, it accounts for facial occlusions, such\nas reading glasses or sunglasses, to enhance the robustness of our model.\nFurthermore, we conducted a comprehensive comparison of our approach with\nvarious state-of-the-art face caricature methods, highlighting our process's\ndistinctiveness and exceptional realism.\n","authors":["Lamyanba Laishram","Muhammad Shaheryar","Jong Taek Lee","Soon Ki Jung"],"pdf_url":"https://arxiv.org/pdf/2311.13338v1.pdf","comment":"14 pages, 21 figures"},{"id":"http://arxiv.org/abs/2311.13335v1","updated":"2023-11-22T11:55:41Z","published":"2023-11-22T11:55:41Z","title":"Quantum learning and essential cognition under the traction of\n  meta-characteristics in an open world","summary":"  Artificial intelligence has made significant progress in the Close World\nproblem, being able to accurately recognize old knowledge through training and\nclassification. However, AI faces significant challenges in the Open World\nproblem, as it involves a new and unknown exploration journey. AI is not\ninherently proactive in exploration, and its challenge lies in not knowing how\nto approach and adapt to the unknown world. How do humans acquire knowledge of\nthe unknown world. Humans identify new knowledge through intrinsic cognition.\nIn the process of recognizing new colors, the cognitive cues are different from\nknown color features and involve hue, saturation, brightness, and other\ncharacteristics. When AI encounters objects with different features in the new\nworld, it faces another challenge: where are the distinguishing features\nbetween influential features of new and old objects? AI often mistakes a new\nworld's brown bear for a known dog because it has not learned the differences\nin feature distributions between knowledge systems. This is because things in\nthe new and old worlds have different units and dimensions for their features.\nThis paper proposes an open-world model and elemental feature system that\nfocuses on fundamentally recognizing the distribution differences in objective\nfeatures between the new and old worlds. The quantum tunneling effect of\nlearning ability in the new and old worlds is realized through the tractive\nforce of meta-characteristic. The outstanding performance of the model system\nin learning new knowledge (using pedestrian re-identification datasets as an\nexample) demonstrates that AI has acquired the ability to recognize the new\nworld with an accuracy of $96.71\\%$ at most and has gained the capability to\nexplore new knowledge, similar to humans.\n","authors":["Jin Wang","Changlin Song"],"pdf_url":"https://arxiv.org/pdf/2311.13335v1.pdf","comment":"8 pages,5 pages"},{"id":"http://arxiv.org/abs/2311.12437v2","updated":"2023-11-22T11:38:46Z","published":"2023-11-21T08:47:08Z","title":"Learning Site-specific Styles for Multi-institutional Unsupervised\n  Cross-modality Domain Adaptation","summary":"  Unsupervised cross-modality domain adaptation is a challenging task in\nmedical image analysis, and it becomes more challenging when source and target\ndomain data are collected from multiple institutions. In this paper, we present\nour solution to tackle the multi-institutional unsupervised domain adaptation\nfor the crossMoDA 2023 challenge. First, we perform unpaired image translation\nto translate the source domain images to the target domain, where we design a\ndynamic network to generate synthetic target domain images with controllable,\nsite-specific styles. Afterwards, we train a segmentation model using the\nsynthetic images and further reduce the domain gap by self-training. Our\nsolution achieved the 1st place during both the validation and testing phases\nof the challenge. The code repository is publicly available at\nhttps://github.com/MedICL-VU/crossmoda2023.\n","authors":["Han Liu","Yubo Fan","Zhoubing Xu","Benoit M. Dawant","Ipek Oguz"],"pdf_url":"https://arxiv.org/pdf/2311.12437v2.pdf","comment":"crossMoDA 2023 challenge 1st place solution"},{"id":"http://arxiv.org/abs/2201.04819v2","updated":"2023-11-22T11:32:46Z","published":"2022-01-13T07:25:06Z","title":"Deep Rank-Consistent Pyramid Model for Enhanced Crowd Counting","summary":"  Most conventional crowd counting methods utilize a fully-supervised learning\nframework to establish a mapping between scene images and crowd density maps.\nThey usually rely on a large quantity of costly and time-intensive pixel-level\nannotations for training supervision. One way to mitigate the intensive\nlabeling effort and improve counting accuracy is to leverage large amounts of\nunlabeled images. This is attributed to the inherent self-structural\ninformation and rank consistency within a single image, offering additional\nqualitative relation supervision during training. Contrary to earlier methods\nthat utilized the rank relations at the original image level, we explore such\nrank-consistency relation within the latent feature spaces. This approach\nenables the incorporation of numerous pyramid partial orders, strengthening the\nmodel representation capability. A notable advantage is that it can also\nincrease the utilization ratio of unlabeled samples. Specifically, we propose a\nDeep Rank-consistEnt pyrAmid Model (DREAM), which makes full use of rank\nconsistency across coarse-to-fine pyramid features in latent spaces for\nenhanced crowd counting with massive unlabeled images. In addition, we have\ncollected a new unlabeled crowd counting dataset, FUDAN-UCC, comprising 4,000\nimages for training purposes. Extensive experiments on four benchmark datasets,\nnamely UCF-QNRF, ShanghaiTech PartA and PartB, and UCF-CC-50, show the\neffectiveness of our method compared with previous semi-supervised methods. The\ncodes are available at https://github.com/bridgeqiqi/DREAM.\n","authors":["Jiaqi Gao","Zhizhong Huang","Yiming Lei","Hongming Shan","James Z. Wang","Fei-Yue Wang","Junping Zhang"],"pdf_url":"https://arxiv.org/pdf/2201.04819v2.pdf","comment":"Accepted by IEEE Transactions on Neural Networks and Learning Systems"},{"id":"http://arxiv.org/abs/2311.13321v1","updated":"2023-11-22T11:24:04Z","published":"2023-11-22T11:24:04Z","title":"Revisiting Supervision for Continual Representation Learning","summary":"  In the field of continual learning, models are designed to learn tasks one\nafter the other. While most research has centered on supervised continual\nlearning, recent studies have highlighted the strengths of self-supervised\ncontinual representation learning. The improved transferability of\nrepresentations built with self-supervised methods is often associated with the\nrole played by the multi-layer perceptron projector. In this work, we depart\nfrom this observation and reexamine the role of supervision in continual\nrepresentation learning. We reckon that additional information, such as human\nannotations, should not deteriorate the quality of representations. Our\nfindings show that supervised models when enhanced with a multi-layer\nperceptron head, can outperform self-supervised models in continual\nrepresentation learning.\n","authors":["Daniel Marczak","Sebastian Cygert","Tomasz Trzciński","Bartłomiej Twardowski"],"pdf_url":"https://arxiv.org/pdf/2311.13321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13319v1","updated":"2023-11-22T11:15:38Z","published":"2023-11-22T11:15:38Z","title":"Deep Learning for Vascular Segmentation and Applications in Phase\n  Contrast Tomography Imaging","summary":"  Automated blood vessel segmentation is vital for biomedical imaging, as\nvessel changes indicate many pathologies. Still, precise segmentation is\ndifficult due to the complexity of vascular structures, anatomical variations\nacross patients, the scarcity of annotated public datasets, and the quality of\nimages. We present a thorough literature review, highlighting the state of\nmachine learning techniques across diverse organs. Our goal is to provide a\nfoundation on the topic and identify a robust baseline model for application to\nvascular segmentation in a new imaging modality, Hierarchical Phase Contrast\nTomography (HiP CT). Introduced in 2020 at the European Synchrotron Radiation\nFacility, HiP CT enables 3D imaging of complete organs at an unprecedented\nresolution of ca. 20mm per voxel, with the capability for localized zooms in\nselected regions down to 1mm per voxel without sectioning. We have created a\ntraining dataset with double annotator validated vascular data from three\nkidneys imaged with HiP CT in the context of the Human Organ Atlas Project.\nFinally, utilising the nnU Net model, we conduct experiments to assess the\nmodels performance on both familiar and unseen samples, employing vessel\nspecific metrics. Our results show that while segmentations yielded reasonably\nhigh scores such as clDice values ranging from 0.82 to 0.88, certain errors\npersisted. Large vessels that collapsed due to the lack of hydrostatic pressure\n(HiP CT is an ex vivo technique) were segmented poorly. Moreover, decreased\nconnectivity in finer vessels and higher segmentation errors at vessel\nboundaries were observed. Such errors obstruct the understanding of the\nstructures by interrupting vascular tree connectivity. Through our review and\noutputs, we aim to set a benchmark for subsequent model evaluations using\nvarious modalities, especially with the HiP CT imaging database.\n","authors":["Ekin Yagis","Shahab Aslani","Yashvardhan Jain","Yang Zhou","Shahrokh Rahmani","Joseph Brunet","Alexandre Bellier","Christopher Werlein","Maximilian Ackermann","Danny Jonigk","Paul Tafforeau","Peter D Lee","Claire Walsh"],"pdf_url":"https://arxiv.org/pdf/2311.13319v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13317v1","updated":"2023-11-22T11:10:45Z","published":"2023-11-22T11:10:45Z","title":"Recognition-Guided Diffusion Model for Scene Text Image Super-Resolution","summary":"  Scene Text Image Super-Resolution (STISR) aims to enhance the resolution and\nlegibility of text within low-resolution (LR) images, consequently elevating\nrecognition accuracy in Scene Text Recognition (STR). Previous methods\npredominantly employ discriminative Convolutional Neural Networks (CNNs)\naugmented with diverse forms of text guidance to address this issue.\nNevertheless, they remain deficient when confronted with severely blurred\nimages, due to their insufficient generation capability when little structural\nor semantic information can be extracted from original images. Therefore, we\nintroduce RGDiffSR, a Recognition-Guided Diffusion model for scene text image\nSuper-Resolution, which exhibits great generative diversity and fidelity even\nin challenging scenarios. Moreover, we propose a Recognition-Guided Denoising\nNetwork, to guide the diffusion model generating LR-consistent results through\nsuccinct semantic guidance. Experiments on the TextZoom dataset demonstrate the\nsuperiority of RGDiffSR over prior state-of-the-art methods in both text\nrecognition accuracy and image fidelity.\n","authors":["Yuxuan Zhou","Liangcai Gao","Zhi Tang","Baole Wei"],"pdf_url":"https://arxiv.org/pdf/2311.13317v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.00846v2","updated":"2023-11-22T11:02:35Z","published":"2023-09-02T07:13:47Z","title":"pSTarC: Pseudo Source Guided Target Clustering for Fully Test-Time\n  Adaptation","summary":"  Test Time Adaptation (TTA) is a pivotal concept in machine learning, enabling\nmodels to perform well in real-world scenarios, where test data distribution\ndiffers from training. In this work, we propose a novel approach called pseudo\nSource guided Target Clustering (pSTarC) addressing the relatively unexplored\narea of TTA under real-world domain shifts. This method draws inspiration from\ntarget clustering techniques and exploits the source classifier for generating\npseudo-source samples. The test samples are strategically aligned with these\npseudo-source samples, facilitating their clustering and thereby enhancing TTA\nperformance. pSTarC operates solely within the fully test-time adaptation\nprotocol, removing the need for actual source data. Experimental validation on\na variety of domain shift datasets, namely VisDA, Office-Home, DomainNet-126,\nCIFAR-100C verifies pSTarC's effectiveness. This method exhibits significant\nimprovements in prediction accuracy along with efficient computational\nrequirements. Furthermore, we also demonstrate the universality of the pSTarC\nframework by showing its effectiveness for the continuous TTA framework. The\nsource code for our method is available at https://manogna-s.github.io/pstarc\n","authors":["Manogna Sreenivas","Goirik Chakrabarty","Soma Biswas"],"pdf_url":"https://arxiv.org/pdf/2309.00846v2.pdf","comment":"Accepted in WACV 2024"},{"id":"http://arxiv.org/abs/2311.13307v1","updated":"2023-11-22T10:55:36Z","published":"2023-11-22T10:55:36Z","title":"Rethinking Radiology Report Generation via Causal Reasoning and\n  Counterfactual Augmentation","summary":"  Radiology Report Generation (RRG) draws attention as an interaction between\nvision and language fields. Previous works inherited the ideology of\nvision-to-language generation tasks,aiming to generate paragraphs with high\nconsistency as reports. However, one unique characteristic of RRG, the\nindependence between diseases, was neglected, leading to the injection of the\nspurious confounder, i.e., the disease co-occurrence. Unfortunately, this\nconfounder confuses the process of report generation worse because of the\nbiased RRG data distribution. In this paper, to rethink this issue thoroughly,\nwe reason about its causes and effects from a novel perspective of statistics\nand causality, where the Joint Vision Coupling and the Conditional Sentence\nCoherence Coupling are two aspects prone to implicitly decrease the accuracy of\nreports. Then, a counterfactual augmentation strategy that contains the\nCounterfactual Sample Synthesis and the Counterfactual Report Reconstruction\nsub-methods is proposed to break these two aspects of spurious effects.\nExperimental results and further analyses on two widely used datasets justify\nour reasoning and proposed methods.\n","authors":["Xiao Song","Jiafan Liu","Yun Li","Wenbin Lei","Ruxin Wang"],"pdf_url":"https://arxiv.org/pdf/2311.13307v1.pdf","comment":"10 pages,5 figures"},{"id":"http://arxiv.org/abs/2311.13297v1","updated":"2023-11-22T10:27:19Z","published":"2023-11-22T10:27:19Z","title":"Retargeting Visual Data with Deformation Fields","summary":"  Seam carving is an image editing method that enable content-aware resizing,\nincluding operations like removing objects. However, the seam-finding strategy\nbased on dynamic programming or graph-cut limits its applications to broader\nvisual data formats and degrees of freedom for editing. Our observation is that\ndescribing the editing and retargeting of images more generally by a\ndisplacement field yields a generalisation of content-aware deformations. We\npropose to learn a deformation with a neural network that keeps the output\nplausible while trying to deform it only in places with low information\ncontent. This technique applies to different kinds of visual data, including\nimages, 3D scenes given as neural radiance fields, or even polygon meshes.\nExperiments conducted on different visual data show that our method achieves\nbetter content-aware retargeting compared to previous methods.\n","authors":["Tim Elsner","Julia Berger","Tong Wu","Victor Czech","Lin Gao","Leif Kobbelt"],"pdf_url":"https://arxiv.org/pdf/2311.13297v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.13289v2","updated":"2023-11-22T10:14:04Z","published":"2023-09-23T07:08:57Z","title":"USL-Net: Uncertainty Self-Learning Network for Unsupervised Skin Lesion\n  Segmentation","summary":"  Unsupervised skin lesion segmentation offers several benefits, including\nconserving expert human resources, reducing discrepancies due to subjective\nhuman labeling, and adapting to novel environments. However, segmenting\ndermoscopic images without manual labeling guidance presents significant\nchallenges due to dermoscopic image artifacts such as hair noise, blister\nnoise, and subtle edge differences. To address these challenges, we introduce\nan innovative Uncertainty Self-Learning Network (USL-Net) designed for skin\nlesion segmentation. The USL-Net can effectively segment a range of lesions,\neliminating the need for manual labeling guidance. Initially, features are\nextracted using contrastive learning, followed by the generation of Class\nActivation Maps (CAMs) as saliency maps using these features. The different CAM\nlocations correspond to the importance of the lesion region based on their\nsaliency. High-saliency regions in the map serve as pseudo-labels for lesion\nregions while low-saliency regions represent the background. However,\nintermediate regions can be hard to classify, often due to their proximity to\nlesion edges or interference from hair or blisters. Rather than risk potential\npseudo-labeling errors or learning confusion by forcefully classifying these\nregions, we consider them as uncertainty regions, exempting them from\npseudo-labeling and allowing the network to self-learn. Further, we employ\nconnectivity detection and centrality detection to refine foreground\npseudo-labels and reduce noise-induced errors. The application of cycle\nrefining enhances performance further. Our method underwent thorough\nexperimental validation on the ISIC-2017, ISIC-2018, and PH2 datasets,\ndemonstrating that its performance is on par with weakly supervised and\nsupervised methods, and exceeds that of other existing unsupervised methods.\n","authors":["Xiaofan Li","Bo Peng","Jie Hu","Changyou Ma","Daipeng Yang","Zhuyang Xie"],"pdf_url":"https://arxiv.org/pdf/2309.13289v2.pdf","comment":"14 pages, 9 figures, 71 references"},{"id":"http://arxiv.org/abs/2308.10631v3","updated":"2023-11-22T09:53:36Z","published":"2023-08-21T11:06:43Z","title":"PsyMo: A Dataset for Estimating Self-Reported Psychological Traits from\n  Gait","summary":"  Psychological trait estimation from external factors such as movement and\nappearance is a challenging and long-standing problem in psychology, and is\nprincipally based on the psychological theory of embodiment. To date, attempts\nto tackle this problem have utilized private small-scale datasets with\nintrusive body-attached sensors. Potential applications of an automated system\nfor psychological trait estimation include estimation of occupational fatigue\nand psychology, and marketing and advertisement. In this work, we propose PsyMo\n(Psychological traits from Motion), a novel, multi-purpose and multi-modal\ndataset for exploring psychological cues manifested in walking patterns. We\ngathered walking sequences from 312 subjects in 7 different walking variations\nand 6 camera angles. In conjunction with walking sequences, participants filled\nin 6 psychological questionnaires, totalling 17 psychometric attributes related\nto personality, self-esteem, fatigue, aggressiveness and mental health. We\npropose two evaluation protocols for psychological trait estimation. Alongside\nthe estimation of self-reported psychological traits from gait, the dataset can\nbe used as a drop-in replacement to benchmark methods for gait recognition. We\nanonymize all cues related to the identity of the subjects and publicly release\nonly silhouettes, 2D / 3D human skeletons and 3D SMPL human meshes.\n","authors":["Adrian Cosma","Emilian Radoi"],"pdf_url":"https://arxiv.org/pdf/2308.10631v3.pdf","comment":"Accepted at 2024 IEEE/CVF Winter Conference on Applications of\n  Computer Vision (WACV)"},{"id":"http://arxiv.org/abs/2311.13267v1","updated":"2023-11-22T09:37:33Z","published":"2023-11-22T09:37:33Z","title":"FedFN: Feature Normalization for Alleviating Data Heterogeneity Problem\n  in Federated Learning","summary":"  Federated Learning (FL) is a collaborative method for training models while\npreserving data privacy in decentralized settings. However, FL encounters\nchallenges related to data heterogeneity, which can result in performance\ndegradation. In our study, we observe that as data heterogeneity increases,\nfeature representation in the FedAVG model deteriorates more significantly\ncompared to classifier weight. Additionally, we observe that as data\nheterogeneity increases, the gap between higher feature norms for observed\nclasses, obtained from local models, and feature norms of unobserved classes\nwidens, in contrast to the behavior of classifier weight norms. This widening\ngap extends to encompass the feature norm disparities between local and the\nglobal models. To address these issues, we introduce Federated Averaging with\nFeature Normalization Update (FedFN), a straightforward learning method. We\ndemonstrate the superior performance of FedFN through extensive experiments,\neven when applied to pretrained ResNet18. Subsequently, we confirm the\napplicability of FedFN to foundation models.\n","authors":["Seongyoon Kim","Gihun Lee","Jaehoon Oh","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2311.13267v1.pdf","comment":"NeurIPS Workshop: \"Federated Learning in the Age of Foundation\n  Models\" 2023"},{"id":"http://arxiv.org/abs/2311.13263v1","updated":"2023-11-22T09:27:46Z","published":"2023-11-22T09:27:46Z","title":"CMFDFormer: Transformer-based Copy-Move Forgery Detection with Continual\n  Learning","summary":"  Copy-move forgery detection aims at detecting duplicated regions in a\nsuspected forged image, and deep learning based copy-move forgery detection\nmethods are in the ascendant. These deep learning based methods heavily rely on\nsynthetic training data, and the performance will degrade when facing new\ntasks. In this paper, we propose a Transformer-style copy-move forgery\ndetection network named as CMFDFormer, and provide a novel PCSD (Pooled Cube\nand Strip Distillation) continual learning framework to help CMFDFormer handle\nnew tasks. CMFDFormer consists of a MiT (Mix Transformer) backbone network and\na PHD (Pluggable Hybrid Decoder) mask prediction network. The MiT backbone\nnetwork is a Transformer-style network which is adopted on the basis of\ncomprehensive analyses with CNN-style and MLP-style backbones. The PHD network\nis constructed based on self-correlation computation, hierarchical feature\nintegration, a multi-scale cycle fully-connected block and a mask\nreconstruction block. The PHD network is applicable to feature extractors of\ndifferent styles for hierarchical multi-scale information extraction, achieving\ncomparable performance. Last but not least, we propose a PCSD continual\nlearning framework to improve the forgery detectability and avoid catastrophic\nforgetting when handling new tasks. Our continual learning framework restricts\nintermediate features from the PHD network, and takes advantage of both cube\npooling and strip pooling. Extensive experiments on publicly available datasets\ndemonstrate the good performance of CMFDFormer and the effectiveness of the\nPCSD continual learning framework.\n","authors":["Yaqi Liu","Chao Xia","Song Xiao","Qingxiao Guan","Wenqian Dong","Yifan Zhang","Nenghai Yu"],"pdf_url":"https://arxiv.org/pdf/2311.13263v1.pdf","comment":"12pages,6 figures"},{"id":"http://arxiv.org/abs/2311.13261v1","updated":"2023-11-22T09:25:08Z","published":"2023-11-22T09:25:08Z","title":"Immunohistochemistry guided segmentation of benign epithelial cells, in\n  situ lesions, and invasive epithelial cells in breast cancer slides","summary":"  Digital pathology enables automatic analysis of histopathological sections\nusing artificial intelligence (AI). Automatic evaluation could improve\ndiagnostic efficiency and help find associations between morphological features\nand clinical outcome. For development of such prediction models, identifying\ninvasive epithelial cells, and separating these from benign epithelial cells\nand in situ lesions would be the first step. In this study, we aimed to develop\nan AI model for segmentation of epithelial cells in sections from breast\ncancer. We generated epithelial ground truth masks by restaining hematoxylin\nand eosin (HE) sections with cytokeratin (CK) AE1/AE3, and by pathologists'\nannotations. HE/CK image pairs were used to train a convolutional neural\nnetwork, and data augmentation was used to make the model more robust. Tissue\nmicroarrays (TMAs) from 839 patients, and whole slide images from two patients\nwere used for training and evaluation of the models. The sections were derived\nfrom four cohorts of breast cancer patients. TMAs from 21 patients from a fifth\ncohort was used as a second test set. In quantitative evaluation, a mean Dice\nscore of 0.70, 0.79, and 0.75 for invasive epithelial cells, benign epithelial\ncells, and in situ lesions, respectively, were achieved. In qualitative scoring\n(0-5) by pathologists, results were best for all epithelium and invasive\nepithelium, with scores of 4.7 and 4.4. Scores for benign epithelium and in\nsitu lesions were 3.7 and 2.0. The proposed model segmented epithelial cells in\nHE stained breast cancer slides well, but further work is needed for accurate\ndivision between the classes. Immunohistochemistry, together with pathologists'\nannotations, enabled the creation of accurate ground truths. The model is made\nfreely available in FastPathology and the code is available at\nhttps://github.com/AICAN-Research/breast-epithelium-segmentation\n","authors":["Maren Høibø","André Pedersen","Vibeke Grotnes Dale","Sissel Marie Berget","Borgny Ytterhus","Cecilia Lindskog","Elisabeth Wik","Lars A. Akslen","Ingerid Reinertsen","Erik Smistad","Marit Valla"],"pdf_url":"https://arxiv.org/pdf/2311.13261v1.pdf","comment":"19 pages, 6 figures. Submitted to a scientific journal"},{"id":"http://arxiv.org/abs/2311.13258v1","updated":"2023-11-22T09:23:34Z","published":"2023-11-22T09:23:34Z","title":"ViStruct: Visual Structural Knowledge Extraction via Curriculum Guided\n  Code-Vision Representation","summary":"  State-of-the-art vision-language models (VLMs) still have limited performance\nin structural knowledge extraction, such as relations between objects. In this\nwork, we present ViStruct, a training framework to learn VLMs for effective\nvisual structural knowledge extraction. Two novel designs are incorporated.\nFirst, we propose to leverage the inherent structure of programming language to\ndepict visual structural information. This approach enables explicit and\nconsistent representation of visual structural information of multiple\ngranularities, such as concepts, relations, and events, in a well-organized\nstructured format. Second, we introduce curriculum-based learning for VLMs to\nprogressively comprehend visual structures, from fundamental visual concepts to\nintricate event structures. Our intuition is that lower-level knowledge may\ncontribute to complex visual structure understanding. Furthermore, we compile\nand release a collection of datasets tailored for visual structural knowledge\nextraction. We adopt a weakly-supervised approach to directly generate visual\nevent structures from captions for ViStruct training, capitalizing on abundant\nimage-caption pairs from the web. In experiments, we evaluate ViStruct on\nvisual structure prediction tasks, demonstrating its effectiveness in improving\nthe understanding of visual structures. The code is public at\n\\url{https://github.com/Yangyi-Chen/vi-struct}.\n","authors":["Yangyi Chen","Xingyao Wang","Manling Li","Derek Hoiem","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2311.13258v1.pdf","comment":"Accepted to EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.13254v1","updated":"2023-11-22T09:18:49Z","published":"2023-11-22T09:18:49Z","title":"DA-STC: Domain Adaptive Video Semantic Segmentation via Spatio-Temporal\n  Consistency","summary":"  Video semantic segmentation is a pivotal aspect of video representation\nlearning. However, significant domain shifts present a challenge in effectively\nlearning invariant spatio-temporal features across the labeled source domain\nand unlabeled target domain for video semantic segmentation. To solve the\nchallenge, we propose a novel DA-STC method for domain adaptive video semantic\nsegmentation, which incorporates a bidirectional multi-level spatio-temporal\nfusion module and a category-aware spatio-temporal feature alignment module to\nfacilitate consistent learning for domain-invariant features. Firstly, we\nperform bidirectional spatio-temporal fusion at the image sequence level and\nshallow feature level, leading to the construction of two fused intermediate\nvideo domains. This prompts the video semantic segmentation model to\nconsistently learn spatio-temporal features of shared patch sequences which are\ninfluenced by domain-specific contexts, thereby mitigating the feature gap\nbetween the source and target domain. Secondly, we propose a category-aware\nfeature alignment module to promote the consistency of spatio-temporal\nfeatures, facilitating adaptation to the target domain. Specifically, we\nadaptively aggregate the domain-specific deep features of each category along\nspatio-temporal dimensions, which are further constrained to achieve\ncross-domain intra-class feature alignment and inter-class feature separation.\nExtensive experiments demonstrate the effectiveness of our method, which\nachieves state-of-the-art mIOUs on multiple challenging benchmarks.\nFurthermore, we extend the proposed DA-STC to the image domain, where it also\nexhibits superior performance for domain adaptive semantic segmentation. The\nsource code and models will be made available at\n\\url{https://github.com/ZHE-SAPI/DA-STC}.\n","authors":["Zhe Zhang","Gaochang Wu","Jing Zhang","Chunhua Shen","Dacheng Tao","Tianyou Chai"],"pdf_url":"https://arxiv.org/pdf/2311.13254v1.pdf","comment":"18 pages,9 figures"},{"id":"http://arxiv.org/abs/2311.13250v1","updated":"2023-11-22T09:12:50Z","published":"2023-11-22T09:12:50Z","title":"Towards Hetero-Client Federated Multi-Task Learning","summary":"  Federated Learning (FL) enables joint training across distributed clients\nusing their local data privately. Federated Multi-Task Learning (FMTL) builds\non FL to handle multiple tasks, assuming model congruity that identical model\narchitecture is deployed in each client. To relax this assumption and thus\nextend real-world applicability, we introduce a novel problem setting,\nHetero-Client Federated Multi-Task Learning (HC-FMTL), to accommodate diverse\ntask setups. The main challenge of HC-FMTL is the model incongruity issue that\ninvalidates conventional aggregation methods. It also escalates the\ndifficulties in accurate model aggregation to deal with data and task\nheterogeneity inherent in FMTL. To address these challenges, we propose the\nFedHCA$^2$ framework, which allows for federated training of personalized\nmodels by modeling relationships among heterogeneous clients. Drawing on our\ntheoretical insights into the difference between multi-task and federated\noptimization, we propose the Hyper Conflict-Averse Aggregation scheme to\nmitigate conflicts during encoder updates. Additionally, inspired by task\ninteraction in MTL, the Hyper Cross Attention Aggregation scheme uses\nlayer-wise cross attention to enhance decoder interactions while alleviating\nmodel incongruity. Moreover, we employ learnable Hyper Aggregation Weights for\neach client to customize personalized parameter updates. Extensive experiments\ndemonstrate the superior performance of FedHCA$^2$ in various HC-FMTL scenarios\ncompared to representative methods. Our code will be made publicly available.\n","authors":["Yuxiang Lu","Suizhi Huang","Yuwen Yang","Shalayiding Sirejiding","Yue Ding","Hongtao Lu"],"pdf_url":"https://arxiv.org/pdf/2311.13250v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12655v2","updated":"2023-11-22T09:00:02Z","published":"2023-11-21T14:57:24Z","title":"Hand-Eye Calibration","summary":"  Whenever a sensor is mounted on a robot hand it is important to know the\nrelationship between the sensor and the hand. The problem of determining this\nrelationship is referred to as hand-eye calibration, which is important in at\nleast two types of tasks: (i) map sensor centered measurements into the robot\nworkspace and (ii) allow the robot to precisely move the sensor. In the past\nsome solutions were proposed in the particular case of a camera. With almost no\nexception, all existing solutions attempt to solve the homogeneous matrix\nequation AX=XB. First we show that there are two possible formulations of the\nhand-eye calibration problem. One formulation is the classical one that we just\nmentioned. A second formulation takes the form of the following homogeneous\nmatrix equation: MY=M'YB. The advantage of the latter is that the extrinsic and\nintrinsic camera parameters need not be made explicit. Indeed, this formulation\ndirectly uses the 3 by 4 perspective matrices (M and M') associated with two\npositions of the camera. Moreover, this formulation together with the classical\none cover a wider range of camera-based sensors to be calibrated with respect\nto the robot hand. Second, we develop a common mathematical framework to solve\nfor the hand-eye calibration problem using either of the two formulations. We\npresent two methods, (i) a rotation then translation and (ii) a non-linear\nsolver for rotation and translation. Third, we perform a stability analysis\nboth for our two methods and for the classical linear method of Tsai and Lenz\n(1989). In the light of this comparison, the non-linear optimization method,\nthat solves for rotation and translation simultaneously, seems to be the most\nrobust one with respect to noise and to measurement errors.\n","authors":["Radu Horaud","Fadi Dornaika"],"pdf_url":"https://arxiv.org/pdf/2311.12655v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15670v2","updated":"2023-11-22T08:49:44Z","published":"2023-06-27T17:59:46Z","title":"Symphonize 3D Semantic Scene Completion with Contextual Instance Queries","summary":"  `3D Semantic Scene Completion (SSC) has emerged as a nascent and pivotal\nundertaking in autonomous driving, aiming to predict voxel occupancy within\nvolumetric scenes. However, prevailing methodologies primarily focus on\nvoxel-wise feature aggregation, while neglecting instance semantics and scene\ncontext. In this paper, we present a novel paradigm termed Symphonies\n(Scene-from-Insts), that delves into the integration of instance queries to\norchestrate 2D-to-3D reconstruction and 3D scene modeling. Leveraging our\nproposed Serial Instance-Propagated Attentions, Symphonies dynamically encodes\ninstance-centric semantics, facilitating intricate interactions between\nimage-based and volumetric domains. Simultaneously, Symphonies enables holistic\nscene comprehension by capturing context through the efficient fusion of\ninstance queries, alleviating geometric ambiguity such as occlusion and\nperspective errors through contextual scene reasoning. Experimental results\ndemonstrate that Symphonies achieves state-of-the-art performance on\nchallenging benchmarks SemanticKITTI and SSCBench-KITTI-360, yielding\nremarkable mIoU scores of 15.04 and 18.58, respectively. These results showcase\nthe paradigm's promising advancements. The code is available at\nhttps://github.com/hustvl/Symphonies.\n","authors":["Haoyi Jiang","Tianheng Cheng","Naiyu Gao","Haoyang Zhang","Tianwei Lin","Wenyu Liu","Xinggang Wang"],"pdf_url":"https://arxiv.org/pdf/2306.15670v2.pdf","comment":"Technical report. Code and models at:\n  https://github.com/hustvl/Symphonies"},{"id":"http://arxiv.org/abs/2311.13234v1","updated":"2023-11-22T08:45:01Z","published":"2023-11-22T08:45:01Z","title":"TSegFormer: 3D Tooth Segmentation in Intraoral Scans with Geometry\n  Guided Transformer","summary":"  Optical Intraoral Scanners (IOS) are widely used in digital dentistry to\nprovide detailed 3D information of dental crowns and the gingiva. Accurate 3D\ntooth segmentation in IOSs is critical for various dental applications, while\nprevious methods are error-prone at complicated boundaries and exhibit\nunsatisfactory results across patients. In this paper, we propose TSegFormer\nwhich captures both local and global dependencies among different teeth and the\ngingiva in the IOS point clouds with a multi-task 3D transformer architecture.\nMoreover, we design a geometry-guided loss based on a novel point curvature to\nrefine boundaries in an end-to-end manner, avoiding time-consuming\npost-processing to reach clinically applicable segmentation. In addition, we\ncreate a dataset with 16,000 IOSs, the largest ever IOS dataset to the best of\nour knowledge. The experimental results demonstrate that our TSegFormer\nconsistently surpasses existing state-of-the-art baselines. The superiority of\nTSegFormer is corroborated by extensive analysis, visualizations and real-world\nclinical applicability tests. Our code is available at\nhttps://github.com/huiminxiong/TSegFormer.\n","authors":["Huimin Xiong","Kunle Li","Kaiyuan Tan","Yang Feng","Joey Tianyi Zhou","Jin Hao","Haochao Ying","Jian Wu","Zuozhu Liu"],"pdf_url":"https://arxiv.org/pdf/2311.13234v1.pdf","comment":"MICCAI 2023, STAR(Student Travel) award. 11 pages, 3 figures, 5\n  tables. arXiv admin note: text overlap with arXiv:2210.16627"},{"id":"http://arxiv.org/abs/2311.13231v1","updated":"2023-11-22T08:42:46Z","published":"2023-11-22T08:42:46Z","title":"Using Human Feedback to Fine-tune Diffusion Models without Any Reward\n  Model","summary":"  Using reinforcement learning with human feedback (RLHF) has shown significant\npromise in fine-tuning diffusion models. Previous methods start by training a\nreward model that aligns with human preferences, then leverage RL techniques to\nfine-tune the underlying models. However, crafting an efficient reward model\ndemands extensive datasets, optimal architecture, and manual hyperparameter\ntuning, making the process both time and cost-intensive. The direct preference\noptimization (DPO) method, effective in fine-tuning large language models,\neliminates the necessity for a reward model. However, the extensive GPU memory\nrequirement of the diffusion model's denoising process hinders the direct\napplication of the DPO method. To address this issue, we introduce the Direct\nPreference for Denoising Diffusion Policy Optimization (D3PO) method to\ndirectly fine-tune diffusion models. The theoretical analysis demonstrates that\nalthough D3PO omits training a reward model, it effectively functions as the\noptimal reward model trained using human feedback data to guide the learning\nprocess. This approach requires no training of a reward model, proving to be\nmore direct, cost-effective, and minimizing computational overhead. In\nexperiments, our method uses the relative scale of objectives as a proxy for\nhuman preference, delivering comparable results to methods using ground-truth\nrewards. Moreover, D3PO demonstrates the ability to reduce image distortion\nrates and generate safer images, overcoming challenges lacking robust reward\nmodels.\n","authors":["Kai Yang","Jian Tao","Jiafei Lyu","Chunjiang Ge","Jiaxin Chen","Qimai Li","Weihan Shen","Xiaolong Zhu","Xiu Li"],"pdf_url":"https://arxiv.org/pdf/2311.13231v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13222v1","updated":"2023-11-22T08:25:15Z","published":"2023-11-22T08:25:15Z","title":"Towards Detecting, Recognizing, and Parsing the Address Information from\n  Bangla Signboard: A Deep Learning-based Approach","summary":"  Retrieving textual information from natural scene images is an active\nresearch area in the field of computer vision with numerous practical\napplications. Detecting text regions and extracting text from signboards is a\nchallenging problem due to special characteristics like reflecting lights,\nuneven illumination, or shadows found in real-life natural scene images. With\nthe advent of deep learning-based methods, different sophisticated techniques\nhave been proposed for text detection and text recognition from the natural\nscene. Though a significant amount of effort has been devoted to extracting\nnatural scene text for resourceful languages like English, little has been done\nfor low-resource languages like Bangla. In this research work, we have proposed\nan end-to-end system with deep learning-based models for efficiently detecting,\nrecognizing, correcting, and parsing address information from Bangla\nsignboards. We have created manually annotated datasets and synthetic datasets\nto train signboard detection, address text detection, address text recognition,\naddress text correction, and address text parser models. We have conducted a\ncomparative study among different CTC-based and Encoder-Decoder model\narchitectures for Bangla address text recognition. Moreover, we have designed a\nnovel address text correction model using a sequence-to-sequence\ntransformer-based network to improve the performance of Bangla address text\nrecognition model by post-correction. Finally, we have developed a Bangla\naddress text parser using the state-of-the-art transformer-based pre-trained\nlanguage model.\n","authors":["Hasan Murad","Mohammed Eunus Ali"],"pdf_url":"https://arxiv.org/pdf/2311.13222v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.03943v2","updated":"2023-11-22T07:52:06Z","published":"2023-11-07T12:36:20Z","title":"CLIP Guided Image-perceptive Prompt Learning for Image Enhancement","summary":"  Image enhancement is a significant research area in the fields of computer\nvision and image processing. In recent years, many learning-based methods for\nimage enhancement have been developed, where the Look-up-table (LUT) has proven\nto be an effective tool. In this paper, we delve into the potential of\nContrastive Language-Image Pre-Training (CLIP) Guided Prompt Learning,\nproposing a simple structure called CLIP-LUT for image enhancement. We found\nthat the prior knowledge of CLIP can effectively discern the quality of\ndegraded images, which can provide reliable guidance. To be specific, We\ninitially learn image-perceptive prompts to distinguish between original and\ntarget images using CLIP model, in the meanwhile, we introduce a very simple\nnetwork by incorporating a simple baseline to predict the weights of three\ndifferent LUT as enhancement network. The obtained prompts are used to steer\nthe enhancement network like a loss function and improve the performance of\nmodel. We demonstrate that by simply combining a straightforward method with\nCLIP, we can obtain satisfactory results.\n","authors":["Weiwen Chen","Qiuhong Ke","Zinuo Li"],"pdf_url":"https://arxiv.org/pdf/2311.03943v2.pdf","comment":"A trial work to the image enhancement"},{"id":"http://arxiv.org/abs/2311.13209v1","updated":"2023-11-22T07:47:39Z","published":"2023-11-22T07:47:39Z","title":"Test-time Adaptive Vision-and-Language Navigation","summary":"  Vision-and-Language Navigation (VLN) has witnessed significant advancements\nin recent years, largely attributed to meticulously curated datasets and\nproficiently trained models. Nevertheless, when tested in diverse environments,\nthe trained models inevitably encounter significant shifts in data\ndistribution, highlighting that relying solely on pre-trained and fixed\nnavigation models is insufficient. To enhance models' generalization ability,\ntest-time adaptation (TTA) demonstrates significant potential in the computer\nvision field by leveraging unlabeled test samples for model updates. However,\nsimply applying existing TTA methods to the VLN task cannot well handle the\nadaptability-stability dilemma of VLN models, i.e., frequent updates can result\nin drastic changes in model parameters, while occasional updates can make the\nmodels ill-equipped to handle dynamically changing environments. Therefore, we\npropose a Fast-Slow Test-Time Adaptation (FSTTA) approach for VLN by performing\ndecomposition-accumulation analysis for both gradients and parameters in a\nunified framework. Specifically, in the fast update phase, gradients generated\nduring the recent multi-step navigation process are decomposed into components\nwith varying levels of consistency. Then, these components are adaptively\naccumulated to pinpoint a concordant direction for fast model adaptation. In\nthe slow update phase, historically recorded parameters are gathered, and a\nsimilar decomposition-accumulation analysis is conducted to revert the model to\na stable state. Extensive experiments show that our method obtains impressive\nperformance gains on four popular benchmarks.\n","authors":["Junyu Gao","Xuan Yao","Changsheng Xu"],"pdf_url":"https://arxiv.org/pdf/2311.13209v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2305.16213v2","updated":"2023-11-22T07:34:38Z","published":"2023-05-25T16:19:18Z","title":"ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with\n  Variational Score Distillation","summary":"  Score distillation sampling (SDS) has shown great promise in text-to-3D\ngeneration by distilling pretrained large-scale text-to-image diffusion models,\nbut suffers from over-saturation, over-smoothing, and low-diversity problems.\nIn this work, we propose to model the 3D parameter as a random variable instead\nof a constant as in SDS and present variational score distillation (VSD), a\nprincipled particle-based variational framework to explain and address the\naforementioned issues in text-to-3D generation. We show that SDS is a special\ncase of VSD and leads to poor samples with both small and large CFG weights. In\ncomparison, VSD works well with various CFG weights as ancestral sampling from\ndiffusion models and simultaneously improves the diversity and sample quality\nwith a common CFG weight (i.e., $7.5$). We further present various improvements\nin the design space for text-to-3D such as distillation time schedule and\ndensity initialization, which are orthogonal to the distillation algorithm yet\nnot well explored. Our overall approach, dubbed ProlificDreamer, can generate\nhigh rendering resolution (i.e., $512\\times512$) and high-fidelity NeRF with\nrich structure and complex effects (e.g., smoke and drops). Further,\ninitialized from NeRF, meshes fine-tuned by VSD are meticulously detailed and\nphoto-realistic. Project page and codes:\nhttps://ml.cs.tsinghua.edu.cn/prolificdreamer/\n","authors":["Zhengyi Wang","Cheng Lu","Yikai Wang","Fan Bao","Chongxuan Li","Hang Su","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2305.16213v2.pdf","comment":"NeurIPS 2023 (Spotlight)"},{"id":"http://arxiv.org/abs/2311.13200v1","updated":"2023-11-22T07:07:55Z","published":"2023-11-22T07:07:55Z","title":"Self-guided Few-shot Semantic Segmentation for Remote Sensing Imagery\n  Based on Large Vision Models","summary":"  The Segment Anything Model (SAM) exhibits remarkable versatility and\nzero-shot learning abilities, owing largely to its extensive training data\n(SA-1B). Recognizing SAM's dependency on manual guidance given its\ncategory-agnostic nature, we identified unexplored potential within few-shot\nsemantic segmentation tasks for remote sensing imagery. This research\nintroduces a structured framework designed for the automation of few-shot\nsemantic segmentation. It utilizes the SAM model and facilitates a more\nefficient generation of semantically discernible segmentation outcomes. Central\nto our methodology is a novel automatic prompt learning approach, leveraging\nprior guided masks to produce coarse pixel-wise prompts for SAM. Extensive\nexperiments on the DLRSD datasets underline the superiority of our approach,\noutperforming other available few-shot methodologies.\n","authors":["Xiyu Qi","Yifan Wu","Yongqiang Mao","Wenhui Zhang","Yidan Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.13200v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13199v1","updated":"2023-11-22T07:06:38Z","published":"2023-11-22T07:06:38Z","title":"DRIFu: Differentiable Rendering and Implicit Function-based Single-View\n  3D Reconstruction","summary":"  The Differentiable Rendering and Implicit Function-based model (DRIFu) draws\nits roots from the Pixel-aligned Implicit Function (PIFU), a pioneering 3D\ndigitization technique initially designed for clothed human bodies. PIFU excels\nin capturing nuanced body shape variations within a low-dimensional space and\nhas been extensively trained on human 3D scans. However, the application of\nPIFU to live animals poses significant challenges, primarily due to the\ninherent difficulty in obtaining the cooperation of animals for 3D scanning. In\nresponse to this challenge, we introduce the DRIFu model, specifically tailored\nfor animal digitization. To train DRIFu, we employ a curated set of synthetic\n3D animal models, encompassing diverse shapes, sizes, and even accounting for\nvariations such as baby birds. Our innovative alignment tools play a pivotal\nrole in mapping these diverse synthetic animal models onto a unified template,\nfacilitating precise predictions of animal shape and texture. Crucially, our\ntemplate alignment strategy establishes a shared shape space, allowing for the\nseamless sampling of new animal shapes, posing them realistically, animating\nthem, and aligning them with real-world data. This groundbreaking approach\nrevolutionizes our capacity to comprehensively understand and represent avian\nforms. For further details and access to the project, the project website can\nbe found at https://github.com/kuangzijian/drifu-for-animals\n","authors":["Zijian Kuang","Lihang Ying","Shi Jin"],"pdf_url":"https://arxiv.org/pdf/2311.13199v1.pdf","comment":"arXiv admin note: text overlap with arXiv:1905.05172 by other authors"},{"id":"http://arxiv.org/abs/2311.13198v1","updated":"2023-11-22T07:05:54Z","published":"2023-11-22T07:05:54Z","title":"DoubleAUG: Single-domain Generalized Object Detector in Urban via Color\n  Perturbation and Dual-style Memory","summary":"  Object detection in urban scenarios is crucial for autonomous driving in\nintelligent traffic systems. However, unlike conventional object detection\ntasks, urban-scene images vary greatly in style. For example, images taken on\nsunny days differ significantly from those taken on rainy days. Therefore,\nmodels trained on sunny day images may not generalize well to rainy day images.\nIn this paper, we aim to solve the single-domain generalizable object detection\ntask in urban scenarios, meaning that a model trained on images from one\nweather condition should be able to perform well on images from any other\nweather conditions. To address this challenge, we propose a novel Double\nAUGmentation (DoubleAUG) method that includes image- and feature-level\naugmentation schemes. In the image-level augmentation, we consider the\nvariation in color information across different weather conditions and propose\na Color Perturbation (CP) method that randomly exchanges the RGB channels to\ngenerate various images. In the feature-level augmentation, we propose to\nutilize a Dual-Style Memory (DSM) to explore the diverse style information on\nthe entire dataset, further enhancing the model's generalization capability.\nExtensive experiments demonstrate that our proposed method outperforms\nstate-of-the-art methods. Furthermore, ablation studies confirm the\neffectiveness of each module in our proposed method. Moreover, our method is\nplug-and-play and can be integrated into existing methods to further improve\nmodel performance.\n","authors":["Lei Qi","Peng Dong","Tan Xiong","Hui Xue","Xin Geng"],"pdf_url":"https://arxiv.org/pdf/2311.13198v1.pdf","comment":"Accepted by ACM Transactions on Multimedia Computing, Communications,\n  and Applications"},{"id":"http://arxiv.org/abs/2311.13194v1","updated":"2023-11-22T06:46:37Z","published":"2023-11-22T06:46:37Z","title":"Towards Improving Document Understanding: An Exploration on\n  Text-Grounding via MLLMs","summary":"  In the field of document understanding, significant advances have been made\nin the fine-tuning of Multimodal Large Language Models (MLLMs) with\ninstruction-following data. Nevertheless, the potential of text-grounding\ncapability within text-rich scenarios remains underexplored. In this paper, we\npresent a text-grounding document understanding model, termed TGDoc, which\naddresses this deficiency by enhancing MLLMs with the ability to discern the\nspatial positioning of text within images. Empirical evidence suggests that\ntext-grounding improves the model's interpretation of textual content, thereby\nelevating its proficiency in comprehending text-rich images. Specifically, we\ncompile a dataset containing 99K PowerPoint presentations sourced from the\ninternet. We formulate instruction tuning tasks including text detection,\nrecognition, and spotting to facilitate the cohesive alignment between the\nvisual encoder and large language model. Moreover, we curate a collection of\ntext-rich images and prompt the text-only GPT-4 to generate 12K high-quality\nconversations, featuring textual locations within text-rich scenarios. By\nintegrating text location data into the instructions, TGDoc is adept at\ndiscerning text locations during the visual question process. Extensive\nexperiments demonstrate that our method achieves state-of-the-art performance\nacross multiple text-rich benchmarks, validating the effectiveness of our\nmethod.\n","authors":["Yonghui Wang","Wengang Zhou","Hao Feng","Keyi Zhou","Houqiang Li"],"pdf_url":"https://arxiv.org/pdf/2311.13194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12198v2","updated":"2023-11-22T06:46:18Z","published":"2023-11-20T21:34:52Z","title":"PhysGaussian: Physics-Integrated 3D Gaussians for Generative Dynamics","summary":"  We introduce PhysGaussian, a new method that seamlessly integrates physically\ngrounded Newtonian dynamics within 3D Gaussians to achieve high-quality novel\nmotion synthesis. Employing a custom Material Point Method (MPM), our approach\nenriches 3D Gaussian kernels with physically meaningful kinematic deformation\nand mechanical stress attributes, all evolved in line with continuum mechanics\nprinciples. A defining characteristic of our method is the seamless integration\nbetween physical simulation and visual rendering: both components utilize the\nsame 3D Gaussian kernels as their discrete representations. This negates the\nnecessity for triangle/tetrahedron meshing, marching cubes, \"cage meshes,\" or\nany other geometry embedding, highlighting the principle of \"what you see is\nwhat you simulate (WS$^2$).\" Our method demonstrates exceptional versatility\nacross a wide variety of materials--including elastic entities, metals,\nnon-Newtonian fluids, and granular materials--showcasing its strong\ncapabilities in creating diverse visual content with novel viewpoints and\nmovements. Our project page is at: https://xpandora.github.io/PhysGaussian/\n","authors":["Tianyi Xie","Zeshun Zong","Yuxing Qiu","Xuan Li","Yutao Feng","Yin Yang","Chenfanfu Jiang"],"pdf_url":"https://arxiv.org/pdf/2311.12198v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13187v1","updated":"2023-11-22T06:28:30Z","published":"2023-11-22T06:28:30Z","title":"NeISF: Neural Incident Stokes Field for Geometry and Material Estimation","summary":"  Multi-view inverse rendering is the problem of estimating the scene\nparameters such as shapes, materials, or illuminations from a sequence of\nimages captured under different viewpoints. Many approaches, however, assume\nsingle light bounce and thus fail to recover challenging scenarios like\ninter-reflections. On the other hand, simply extending those methods to\nconsider multi-bounced light requires more assumptions to alleviate the\nambiguity. To address this problem, we propose Neural Incident Stokes Fields\n(NeISF), a multi-view inverse rendering framework that reduces ambiguities\nusing polarization cues. The primary motivation for using polarization cues is\nthat it is the accumulation of multi-bounced light, providing rich information\nabout geometry and material. Based on this knowledge, the proposed incident\nStokes field efficiently models the accumulated polarization effect with the\naid of an original physically-based differentiable polarimetric renderer.\nLastly, experimental results show that our method outperforms the existing\nworks in synthetic and real scenarios.\n","authors":["Chenhao Li","Taishi Ono","Takeshi Uemori","Hajime Mihara","Alexander Gatto","Hajime Nagahara","Yuseke Moriuchi"],"pdf_url":"https://arxiv.org/pdf/2311.13187v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13186v1","updated":"2023-11-22T06:26:24Z","published":"2023-11-22T06:26:24Z","title":"Applications of Spiking Neural Networks in Visual Place Recognition","summary":"  In robotics, Spiking Neural Networks (SNNs) are increasingly recognized for\ntheir largely-unrealized potential energy efficiency and low latency\nparticularly when implemented on neuromorphic hardware. Our paper highlights\nthree advancements for SNNs in Visual Place Recognition (VPR). First, we\npropose Modular SNNs, where each SNN represents a set of non-overlapping\ngeographically distinct places, enabling scalable networks for large\nenvironments. Secondly, we present Ensembles of Modular SNNs, where multiple\nnetworks represent the same place, significantly enhancing accuracy compared to\nsingle-network models. Our SNNs are compact and small, comprising only 1500\nneurons and 474k synapses, which makes them ideally suited for ensembling due\nto this small size. Lastly, we investigate the role of sequence matching in\nSNN-based VPR, a technique where consecutive images are used to refine place\nrecognition. We analyze the responsiveness of SNNs to ensembling and sequence\nmatching compared to other VPR techniques. Our contributions highlight the\nviability of SNNs for VPR, offering scalable and robust solutions, paving the\nway for their application in various energy-sensitive robotic tasks.\n","authors":["Somayeh Hussaini","Michael Milford","Tobias Fischer"],"pdf_url":"https://arxiv.org/pdf/2311.13186v1.pdf","comment":"17 pages, 8 figures, under review"},{"id":"http://arxiv.org/abs/2311.13182v1","updated":"2023-11-22T06:13:39Z","published":"2023-11-22T06:13:39Z","title":"Differentiable Radio Frequency Ray Tracing for Millimeter-Wave Sensing","summary":"  Millimeter wave (mmWave) sensing is an emerging technology with applications\nin 3D object characterization and environment mapping. However, realizing\nprecise 3D reconstruction from sparse mmWave signals remains challenging.\nExisting methods rely on data-driven learning, constrained by dataset\navailability and difficulty in generalization. We propose DiffSBR, a\ndifferentiable framework for mmWave-based 3D reconstruction. DiffSBR\nincorporates a differentiable ray tracing engine to simulate radar point clouds\nfrom virtual 3D models. A gradient-based optimizer refines the model parameters\nto minimize the discrepancy between simulated and real point clouds.\nExperiments using various radar hardware validate DiffSBR's capability for\nfine-grained 3D reconstruction, even for novel objects unseen by the radar\npreviously. By integrating physics-based simulation with gradient optimization,\nDiffSBR transcends the limitations of data-driven approaches and pioneers a new\nparadigm for mmWave sensing.\n","authors":["Xingyu Chen","Xinyu Zhang","Qiyue Xia","Xinmin Fang","Chris Xiaoxuan Lu","Zhengxiong Li"],"pdf_url":"https://arxiv.org/pdf/2311.13182v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12467v2","updated":"2023-11-22T06:01:46Z","published":"2023-11-21T09:27:30Z","title":"GLAD: Global-Local View Alignment and Background Debiasing for\n  Unsupervised Video Domain Adaptation with Large Domain Gap","summary":"  In this work, we tackle the challenging problem of unsupervised video domain\nadaptation (UVDA) for action recognition. We specifically focus on scenarios\nwith a substantial domain gap, in contrast to existing works primarily deal\nwith small domain gaps between labeled source domains and unlabeled target\ndomains. To establish a more realistic setting, we introduce a novel UVDA\nscenario, denoted as Kinetics->BABEL, with a more considerable domain gap in\nterms of both temporal dynamics and background shifts. To tackle the temporal\nshift, i.e., action duration difference between the source and target domains,\nwe propose a global-local view alignment approach. To mitigate the background\nshift, we propose to learn temporal order sensitive representations by temporal\norder learning and background invariant representations by background\naugmentation. We empirically validate that the proposed method shows\nsignificant improvement over the existing methods on the Kinetics->BABEL\ndataset with a large domain gap. The code is available at\nhttps://github.com/KHUVLL/GLAD.\n","authors":["Hyogun Lee","Kyungho Bae","Seong Jong Ha","Yumin Ko","Gyeong-Moon Park","Jinwoo Choi"],"pdf_url":"https://arxiv.org/pdf/2311.12467v2.pdf","comment":"This is an accepted WACV 2024 paper. Our code is available at\n  https://github.com/KHUVLL/GLAD"},{"id":"http://arxiv.org/abs/2311.13177v1","updated":"2023-11-22T05:44:51Z","published":"2023-11-22T05:44:51Z","title":"Volumetric Reconstruction Resolves Off-Resonance Artifacts in Static and\n  Dynamic PROPELLER MRI","summary":"  Off-resonance artifacts in magnetic resonance imaging (MRI) are visual\ndistortions that occur when the actual resonant frequencies of spins within the\nimaging volume differ from the expected frequencies used to encode spatial\ninformation. These discrepancies can be caused by a variety of factors,\nincluding magnetic field inhomogeneities, chemical shifts, or susceptibility\ndifferences within the tissues. Such artifacts can manifest as blurring,\nghosting, or misregistration of the reconstructed image, and they often\ncompromise its diagnostic quality. We propose to resolve these artifacts by\nlifting the 2D MRI reconstruction problem to 3D, introducing an additional\n\"spectral\" dimension to model this off-resonance. Our approach is inspired by\nrecent progress in modeling radiance fields, and is capable of reconstructing\nboth static and dynamic MR images as well as separating fat and water, which is\nof independent clinical interest. We demonstrate our approach in the context of\nPROPELLER (Periodically Rotated Overlapping ParallEL Lines with Enhanced\nReconstruction) MRI acquisitions, which are popular for their robustness to\nmotion artifacts. Our method operates in a few minutes on a single GPU, and to\nour knowledge is the first to correct for chemical shift in gradient echo\nPROPELLER MRI reconstruction without additional measurements or pretraining\ndata.\n","authors":["Annesha Ghosh","Gordon Wetzstein","Mert Pilanci","Sara Fridovich-Keil"],"pdf_url":"https://arxiv.org/pdf/2311.13177v1.pdf","comment":"Code is available at\n  https://github.com/sarafridov/volumetric-propeller"},{"id":"http://arxiv.org/abs/2311.13172v1","updated":"2023-11-22T05:31:06Z","published":"2023-11-22T05:31:06Z","title":"Learning to Complement with Multiple Humans (LECOMH): Integrating\n  Multi-rater and Noisy-Label Learning into Human-AI Collaboration","summary":"  The advent of learning with noisy labels (LNL), multi-rater learning, and\nhuman-AI collaboration has revolutionised the development of robust\nclassifiers, enabling them to address the challenges posed by different types\nof data imperfections and complex decision processes commonly encountered in\nreal-world applications. While each of these methodologies has individually\nmade significant strides in addressing their unique challenges, the development\nof techniques that can simultaneously tackle these three problems remains\nunderexplored. This paper addresses this research gap by integrating\nnoisy-label learning, multi-rater learning, and human-AI collaboration with new\nbenchmarks and the innovative Learning to Complement with Multiple Humans\n(LECOMH) approach. LECOMH optimises the level of human collaboration during\ntesting, aiming to optimise classification accuracy while minimising\ncollaboration costs that vary from 0 to M, where M is the maximum number of\nhuman collaborators. We quantitatively compare LECOMH with leading human-AI\ncollaboration methods using our proposed benchmarks. LECOMH consistently\noutperforms the competition, with accuracy improving as collaboration costs\nincrease. Notably, LECOMH is the only method enhancing human labeller\nperformance across all benchmarks.\n","authors":["Zheng Zhang","Kevin Wells","Gustavo Carneiro"],"pdf_url":"https://arxiv.org/pdf/2311.13172v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2311.13168v1","updated":"2023-11-22T05:24:35Z","published":"2023-11-22T05:24:35Z","title":"3D Face Style Transfer with a Hybrid Solution of NeRF and Mesh\n  Rasterization","summary":"  Style transfer for human face has been widely researched in recent years.\nMajority of the existing approaches work in 2D image domain and have 3D\ninconsistency issue when applied on different viewpoints of the same face. In\nthis paper, we tackle the problem of 3D face style transfer which aims at\ngenerating stylized novel views of a 3D human face with multi-view consistency.\nWe propose to use a neural radiance field (NeRF) to represent 3D human face and\ncombine it with 2D style transfer to stylize the 3D face. We find that directly\ntraining a NeRF on stylized images from 2D style transfer brings in 3D\ninconsistency issue and causes blurriness. On the other hand, training a NeRF\njointly with 2D style transfer objectives shows poor convergence due to the\nidentity and head pose gap between style image and content image. It also poses\nchallenge in training time and memory due to the need of volume rendering for\nfull image to apply style transfer loss functions. We therefore propose a\nhybrid framework of NeRF and mesh rasterization to combine the benefits of high\nfidelity geometry reconstruction of NeRF and fast rendering speed of mesh. Our\nframework consists of three stages: 1. Training a NeRF model on input face\nimages to learn the 3D geometry; 2. Extracting a mesh from the trained NeRF\nmodel and optimizing it with style transfer objectives via differentiable\nrasterization; 3. Training a new color network in NeRF conditioned on a style\nembedding to enable arbitrary style transfer to the 3D face. Experiment results\nshow that our approach generates high quality face style transfer with great 3D\nconsistency, while also enabling a flexible style control.\n","authors":["Jianwei Feng","Prateek Singhal"],"pdf_url":"https://arxiv.org/pdf/2311.13168v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.07647v3","updated":"2023-11-22T05:20:22Z","published":"2023-04-15T22:24:05Z","title":"LASER: A Neuro-Symbolic Framework for Learning Spatial-Temporal Scene\n  Graphs with Weak Supervision","summary":"  We propose LASER, a neuro-symbolic approach to learn semantic video\nrepresentations that capture rich spatial and temporal properties in video data\nby leveraging high-level logic specifications. In particular, we formulate the\nproblem in terms of alignment between raw videos and spatio-temporal logic\nspecifications. The alignment algorithm leverages a differentiable symbolic\nreasoner and a combination of contrastive, temporal, and semantics losses. It\neffectively and efficiently trains low-level perception models to extract\nfine-grained video representation in the form of a spatio-temporal scene graph\nthat conforms to the desired high-level specification. In doing so, we explore\na novel methodology that weakly supervises the learning of video semantic\nrepresentations through logic specifications. We evaluate our method on two\ndatasets with rich spatial and temporal specifications:\n20BN-Something-Something and MUGEN. We demonstrate that our method learns\nbetter fine-grained video semantics than existing baselines.\n","authors":["Jiani Huang","Ziyang Li","Mayur Naik","Ser-Nam Lim"],"pdf_url":"https://arxiv.org/pdf/2304.07647v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.08897v3","updated":"2023-11-22T05:15:38Z","published":"2023-10-13T06:58:52Z","title":"Self supervised convolutional kernel based handcrafted feature\n  harmonization: Enhanced left ventricle hypertension disease phenotyping on\n  echocardiography","summary":"  Radiomics, a medical imaging technique, extracts quantitative handcrafted\nfeatures from images to predict diseases. Harmonization in those features\nensures consistent feature extraction across various imaging devices and\nprotocols. Methods for harmonization include standardized imaging protocols,\nstatistical adjustments, and evaluating feature robustness. Myocardial diseases\nsuch as Left Ventricular Hypertrophy (LVH) and Hypertensive Heart Disease (HHD)\nare diagnosed via echocardiography, but variable imaging settings pose\nchallenges. Harmonization techniques are crucial for applying handcrafted\nfeatures in disease diagnosis in such scenario. Self-supervised learning (SSL)\nenhances data understanding within limited datasets and adapts to diverse data\nsettings. ConvNeXt-V2 integrates convolutional layers into SSL, displaying\nsuperior performance in various tasks. This study focuses on convolutional\nfilters within SSL, using them as preprocessing to convert images into feature\nmaps for handcrafted feature harmonization. Our proposed method excelled in\nharmonization evaluation and exhibited superior LVH classification performance\ncompared to existing methods.\n","authors":["Jina Lee","Youngtaek Hong","Dawun Jeong","Yeonggul Jang","Jaeik Jeon","Sihyeon Jeong","Taekgeun Jung","Yeonyee E. Yoon","Inki Moon","Seung-Ah Lee","Hyuk-Jae Chang"],"pdf_url":"https://arxiv.org/pdf/2310.08897v3.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2309.05254v2","updated":"2023-11-22T05:00:56Z","published":"2023-09-11T06:18:05Z","title":"Towards Better Data Exploitation in Self-Supervised Monocular Depth\n  Estimation","summary":"  Depth estimation plays an important role in the robotic perception system.\nSelf-supervised monocular paradigm has gained significant attention since it\ncan free training from the reliance on depth annotations. Despite recent\nadvancements, existing self-supervised methods still underutilize the available\ntraining data, limiting their generalization ability. In this paper, we take\ntwo data augmentation techniques, namely Resizing-Cropping and\nSplitting-Permuting, to fully exploit the potential of training datasets.\nSpecifically, the original image and the generated two augmented images are fed\ninto the training pipeline simultaneously and we leverage them to conduct\nself-distillation. Additionally, we introduce the detail-enhanced DepthNet with\nan extra full-scale branch in the encoder and a grid decoder to enhance the\nrestoration of fine details in depth maps. Experimental results demonstrate our\nmethod can achieve state-of-the-art performance on the KITTI benchmark, with\nboth raw ground truth and improved ground truth. Moreover, our models also show\nsuperior generalization performance when transferring to Make3D and NYUv2\ndatasets. Our codes are available at https://github.com/Sauf4896/BDEdepth.\n","authors":["Jinfeng Liu","Lingtong Kong","Jie Yang","Wei Liu"],"pdf_url":"https://arxiv.org/pdf/2309.05254v2.pdf","comment":"8 pages, 6 figures, accepted by IEEE Robotics and Automation Letters\n  (RA-L, 2023)"},{"id":"http://arxiv.org/abs/2311.13152v1","updated":"2023-11-22T04:31:09Z","published":"2023-11-22T04:31:09Z","title":"Test-Time Augmentation for 3D Point Cloud Classification and\n  Segmentation","summary":"  Data augmentation is a powerful technique to enhance the performance of a\ndeep learning task but has received less attention in 3D deep learning. It is\nwell known that when 3D shapes are sparsely represented with low point density,\nthe performance of the downstream tasks drops significantly. This work explores\ntest-time augmentation (TTA) for 3D point clouds. We are inspired by the recent\nrevolution of learning implicit representation and point cloud upsampling,\nwhich can produce high-quality 3D surface reconstruction and\nproximity-to-surface, respectively. Our idea is to leverage the implicit field\nreconstruction or point cloud upsampling techniques as a systematic way to\naugment point cloud data. Mainly, we test both strategies by sampling points\nfrom the reconstructed results and using the sampled point cloud as test-time\naugmented data. We show that both strategies are effective in improving\naccuracy. We observed that point cloud upsampling for test-time augmentation\ncan lead to more significant performance improvement on downstream tasks such\nas object classification and segmentation on the ModelNet40, ShapeNet,\nScanObjectNN, and SemanticKITTI datasets, especially for sparse point clouds.\n","authors":["Tuan-Anh Vu","Srinjay Sarkar","Zhiyuan Zhang","Binh-Son Hua","Sai-Kit Yeung"],"pdf_url":"https://arxiv.org/pdf/2311.13152v1.pdf","comment":"This paper is accepted in 3DV 2024"},{"id":"http://arxiv.org/abs/2308.09936v2","updated":"2023-11-22T04:29:33Z","published":"2023-08-19T07:53:43Z","title":"BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual\n  Questions","summary":"  Vision Language Models (VLMs), which extend Large Language Models (LLM) by\nincorporating visual understanding capability, have demonstrated significant\nadvancements in addressing open-ended visual question-answering (VQA) tasks.\nHowever, these models cannot accurately interpret images infused with text, a\ncommon occurrence in real-world scenarios. Standard procedures for extracting\ninformation from images often involve learning a fixed set of query embeddings.\nThese embeddings are designed to encapsulate image contexts and are later used\nas soft prompt inputs in LLMs. Yet, this process is limited to the token count,\npotentially curtailing the recognition of scenes with text-rich context. To\nimprove upon them, the present study introduces BLIVA: an augmented version of\nInstructBLIP with Visual Assistant. BLIVA incorporates the query embeddings\nfrom InstructBLIP and also directly projects encoded patch embeddings into the\nLLM, a technique inspired by LLaVA. This approach assists the model to capture\nintricate details potentially missed during the query decoding process.\nEmpirical evidence demonstrates that our model, BLIVA, significantly enhances\nperformance in processing text-rich VQA benchmarks (up to 17.76% in OCR-VQA\nbenchmark) and in undertaking general (not particularly text-rich) VQA\nbenchmarks (up to 7.9% in Visual Spatial Reasoning benchmark), comparing to our\nbaseline InstructBLIP. BLIVA demonstrates significant capability in decoding\nreal-world images, irrespective of text presence. To demonstrate the broad\nindustry applications enabled by BLIVA, we evaluate the model using a new\ndataset comprising YouTube thumbnails paired with question-answer sets across\n11 diverse categories. For researchers interested in further exploration, our\ncode and models are freely accessible at https://github.com/mlpc-ucsd/BLIVA.\n","authors":["Wenbo Hu","Yifan Xu","Yi Li","Weiyue Li","Zeyuan Chen","Zhuowen Tu"],"pdf_url":"https://arxiv.org/pdf/2308.09936v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13144v1","updated":"2023-11-22T04:14:42Z","published":"2023-11-22T04:14:42Z","title":"Single Image Compressed Sensing MRI via a Self-Supervised Deep Denoising\n  Approach","summary":"  Popular methods in compressed sensing (CS) are dependent on deep learning\n(DL), where large amounts of data are used to train non-linear reconstruction\nmodels. However, ensuring generalisability over and access to multiple datasets\nis challenging to realise for real-world applications. To address these\nconcerns, this paper proposes a single image, self-supervised (SS) CS-MRI\nframework that enables a joint deep and sparse regularisation of CS artefacts.\nThe approach effectively dampens structured CS artefacts, which can be\ndifficult to remove assuming sparse reconstruction, or relying solely on the\ninductive biases of CNN to produce noise-free images. Image quality is thereby\nimproved compared to either approach alone. Metrics are evaluated using\nCartesian 1D masks on a brain and knee dataset, with PSNR improving by 2-4dB on\naverage.\n","authors":["Marlon Bran Lorenzana","Feng Liu","Shekhar S. Chandra"],"pdf_url":"https://arxiv.org/pdf/2311.13144v1.pdf","comment":"5 pages, 4 figures, 2 tables, conference"},{"id":"http://arxiv.org/abs/2311.12068v2","updated":"2023-11-22T04:13:38Z","published":"2023-11-19T17:28:28Z","title":"Enhancing Novel Object Detection via Cooperative Foundational Models","summary":"  In this work, we address the challenging and emergent problem of novel object\ndetection (NOD), focusing on the accurate detection of both known and novel\nobject categories during inference. Traditional object detection algorithms are\ninherently closed-set, limiting their capability to handle NOD. We present a\nnovel approach to transform existing closed-set detectors into open-set\ndetectors. This transformation is achieved by leveraging the complementary\nstrengths of pre-trained foundational models, specifically CLIP and SAM,\nthrough our cooperative mechanism. Furthermore, by integrating this mechanism\nwith state-of-the-art open-set detectors such as GDINO, we establish new\nbenchmarks in object detection performance. Our method achieves 17.42 mAP in\nnovel object detection and 42.08 mAP for known objects on the challenging LVIS\ndataset. Adapting our approach to the COCO OVD split, we surpass the current\nstate-of-the-art by a margin of 7.2 $ \\text{AP}_{50} $ for novel classes. Our\ncode is available at\nhttps://github.com/rohit901/cooperative-foundational-models .\n","authors":["Rohit Bharadwaj","Muzammal Naseer","Salman Khan","Fahad Shahbaz Khan"],"pdf_url":"https://arxiv.org/pdf/2311.12068v2.pdf","comment":"Code: https://github.com/rohit901/cooperative-foundational-models"},{"id":"http://arxiv.org/abs/2311.13141v1","updated":"2023-11-22T04:06:39Z","published":"2023-11-22T04:06:39Z","title":"Diffusion360: Seamless 360 Degree Panoramic Image Generation based on\n  Diffusion Models","summary":"  This is a technical report on the 360-degree panoramic image generation task\nbased on diffusion models. Unlike ordinary 2D images, 360-degree panoramic\nimages capture the entire $360^\\circ\\times 180^\\circ$ field of view. So the\nrightmost and the leftmost sides of the 360 panoramic image should be\ncontinued, which is the main challenge in this field. However, the current\ndiffusion pipeline is not appropriate for generating such a seamless 360-degree\npanoramic image. To this end, we propose a circular blending strategy on both\nthe denoising and VAE decoding stages to maintain the geometry continuity.\nBased on this, we present two models for \\textbf{Text-to-360-panoramas} and\n\\textbf{Single-Image-to-360-panoramas} tasks. The code has been released as an\nopen-source project at\n\\href{https://github.com/ArcherFMY/SD-T2I-360PanoImage}{https://github.com/ArcherFMY/SD-T2I-360PanoImage}\nand\n\\href{https://www.modelscope.cn/models/damo/cv_diffusion_text-to-360panorama-image_generation/summary}{ModelScope}\n","authors":["Mengyang Feng","Jinlin Liu","Miaomiao Cui","Xuansong Xie"],"pdf_url":"https://arxiv.org/pdf/2311.13141v1.pdf","comment":"2 pages, 8 figures, Tech. Report"},{"id":"http://arxiv.org/abs/2311.13134v1","updated":"2023-11-22T03:41:13Z","published":"2023-11-22T03:41:13Z","title":"Lightweight High-Speed Photography Built on Coded Exposure and Implicit\n  Neural Representation of Videos","summary":"  The compact cameras recording high-speed scenes with high resolution are\nhighly demanded, but the required high bandwidth often leads to bulky, heavy\nsystems, which limits their applications on low-capacity platforms. Adopting a\ncoded exposure setup to encode a frame sequence into a blurry snapshot and\nretrieve the latent sharp video afterward can serve as a lightweight solution.\nHowever, restoring motion from blur is quite challenging due to the high\nill-posedness of motion blur decomposition, intrinsic ambiguity in motion\ndirection, and diverse motions in natural videos. In this work, by leveraging\nclassical coded exposure imaging technique and emerging implicit neural\nrepresentation for videos, we tactfully embed the motion direction cues into\nthe blurry image during the imaging process and develop a novel self-recursive\nneural network to sequentially retrieve the latent video sequence from the\nblurry image utilizing the embedded motion direction cues. To validate the\neffectiveness and efficiency of the proposed framework, we conduct extensive\nexperiments on benchmark datasets and real-captured blurry images. The results\ndemonstrate that our proposed framework significantly outperforms existing\nmethods in quality and flexibility. The code for our work is available at\nhttps://github.com/zhihongz/BDINR\n","authors":["Zhihong Zhang","Runzhao Yang","Jinli Suo","Yuxiao Cheng","Qionghai Dai"],"pdf_url":"https://arxiv.org/pdf/2311.13134v1.pdf","comment":"19 pages, 10 figures"},{"id":"http://arxiv.org/abs/2309.08273v2","updated":"2023-11-22T03:36:22Z","published":"2023-09-15T09:34:05Z","title":"Unsupervised Disentangling of Facial Representations with 3D-aware\n  Latent Diffusion Models","summary":"  Unsupervised learning of facial representations has gained increasing\nattention for face understanding ability without heavily relying on large-scale\nannotated datasets. However, it remains unsolved due to the coupling of facial\nidentities, expressions, and external factors like pose and light. Prior\nmethods primarily focus on 2D factors and pixel-level consistency, leading to\nincomplete disentangling and suboptimal performance in downstream tasks. In\nthis paper, we propose LatentFace, a novel unsupervised disentangling framework\nfor facial expression and identity representation. We suggest the disentangling\nproblem should be performed in latent space and propose the solution using a\n3D-aware latent diffusion model. First, we introduce a 3D-aware autoencoder to\nencode face images into 3D latent embeddings. Second, we propose a novel\nrepresentation diffusion model (RDM) to disentangle 3D latent into facial\nidentity and expression. Consequently, our method achieves state-of-the-art\nperformance in facial expression recognition and face verification among\nunsupervised facial representation learning models. Codes are available at\n\\url{https://github.com/ryanhe312/LatentFace}.\n","authors":["Ruian He","Zhen Xing","Weimin Tan","Bo Yan"],"pdf_url":"https://arxiv.org/pdf/2309.08273v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13128v1","updated":"2023-11-22T03:33:00Z","published":"2023-11-22T03:33:00Z","title":"P2RBox: A Single Point is All You Need for Oriented Object Detection","summary":"  Oriented object detection, a specialized subfield in computer vision, finds\napplications across diverse scenarios, excelling particularly when dealing with\nobjects of arbitrary orientations. Conversely, point annotation, which treats\nobjects as single points, offers a cost-effective alternative to rotated and\nhorizontal bounding boxes but sacrifices performance due to the loss of size\nand orientation information. In this study, we introduce the P2RBox network,\nwhich leverages point annotations and a mask generator to create mask\nproposals, followed by filtration through our Inspector Module and Constrainer\nModule. This process selects high-quality masks, which are subsequently\nconverted into rotated box annotations for training a fully supervised\ndetector. Specifically, we've thoughtfully crafted an Inspector Module rooted\nin multi-instance learning principles to evaluate the semantic score of masks.\nWe've also proposed a more robust mask quality assessment in conjunction with\nthe Constrainer Module. Furthermore, we've introduced a Symmetry Axis\nEstimation (SAE) Module inspired by the spectral theorem for symmetric matrices\nto transform the top-performing mask proposal into rotated bounding boxes.\nP2RBox performs well with three fully supervised rotated object detectors:\nRetinaNet, Rotated FCOS, and Oriented R-CNN. By combining with Oriented R-CNN,\nP2RBox achieves 62.26% on DOTA-v1.0 test dataset. As far as we know, this is\nthe first attempt at training an oriented object detector with point\nsupervision.\n","authors":["Guangming Cao","Xuehui Yu","Wenwen Yu","Xumeng Han","Xue Yang","Guorong Li","Jianbin Jiao","Zhenjun Han"],"pdf_url":"https://arxiv.org/pdf/2311.13128v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13127v1","updated":"2023-11-22T03:31:31Z","published":"2023-11-22T03:31:31Z","title":"Toward Robust Imperceptible Perturbation against Unauthorized\n  Text-to-image Diffusion-based Synthesis","summary":"  Text-to-image diffusion models allow seamless generation of personalized\nimages from scant reference photos. Yet, these tools, in the wrong hands, can\nfabricate misleading or harmful content, endangering individuals. To address\nthis problem, existing poisoning-based approaches perturb user images in an\nimperceptible way to render them \"unlearnable\" from malicious uses. We identify\ntwo limitations of these defending approaches: i) sub-optimal due to the\nhand-crafted heuristics for solving the intractable bilevel optimization and\nii) lack of robustness against simple data transformations like Gaussian\nfiltering. To solve these challenges, we propose MetaCloak, which solves the\nbi-level poisoning problem with a meta-learning framework with an additional\ntransformation sampling process to craft transferable and robust perturbation.\nSpecifically, we employ a pool of surrogate diffusion models to craft\ntransferable and model-agnostic perturbation. Furthermore, by incorporating an\nadditional transformation process, we design a simple denoising-error\nmaximization loss that is sufficient for causing transformation-robust semantic\ndistortion and degradation in a personalized generation. Extensive experiments\non the VGGFace2 and CelebA-HQ datasets show that MetaCloak outperforms existing\napproaches. Notably, MetaCloak can successfully fool online training services\nlike Replicate, in a black-box manner, demonstrating the effectiveness of\nMetaCloak in real-world scenarios. Our code is available at\nhttps://github.com/liuyixin-louis/MetaCloak.\n","authors":["Yixin Liu","Chenrui Fan","Yutong Dai","Xun Chen","Pan Zhou","Lichao Sun"],"pdf_url":"https://arxiv.org/pdf/2311.13127v1.pdf","comment":"26 pages, 15 figures, 8 tables"},{"id":"http://arxiv.org/abs/2311.13125v1","updated":"2023-11-22T03:26:07Z","published":"2023-11-22T03:26:07Z","title":"DAE-Net: Deforming Auto-Encoder for fine-grained shape co-segmentation","summary":"  We present an unsupervised 3D shape co-segmentation method which learns a set\nof deformable part templates from a shape collection. To accommodate structural\nvariations in the collection, our network composes each shape by a selected\nsubset of template parts which are affine-transformed. To maximize the\nexpressive power of the part templates, we introduce a per-part deformation\nnetwork to enable the modeling of diverse parts with substantial geometry\nvariations, while imposing constraints on the deformation capacity to ensure\nfidelity to the originally represented parts. We also propose a training scheme\nto effectively overcome local minima. Architecturally, our network is a\nbranched autoencoder, with a CNN encoder taking a voxel shape as input and\nproducing per-part transformation matrices, latent codes, and part existence\nscores, and the decoder outputting point occupancies to define the\nreconstruction loss. Our network, coined DAE-Net for Deforming Auto-Encoder,\ncan achieve unsupervised 3D shape co-segmentation that yields fine-grained,\ncompact, and meaningful parts that are consistent across diverse shapes. We\nconduct extensive experiments on the ShapeNet Part dataset, DFAUST, and an\nanimal subset of Objaverse to show superior performance over prior methods.\n","authors":["Zhiqin Chen","Qimin Chen","Hang Zhou","Hao Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.13125v1.pdf","comment":"Code: https://github.com/czq142857/DAE-Net"},{"id":"http://arxiv.org/abs/2311.12161v2","updated":"2023-11-22T03:23:17Z","published":"2023-11-20T20:27:42Z","title":"ChemScraper: Graphics Extraction, Molecular Diagram Parsing, and\n  Annotated Data Generation for PDF Images","summary":"  Existing visual parsers for molecule diagrams translate pixel-based raster\nimages such as PNGs to chemical structure representations (e.g., SMILES).\nHowever, PDFs created by word processors including LaTeX and Word provide\nexplicit locations and shapes for characters, lines, and polygons. We extract\nsymbols from born-digital PDF molecule images and then apply simple graph\ntransformations to capture both visual and chemical structure in editable\nChemDraw files (CDXML). Our fast ( PDF $\\rightarrow$ visual graph $\\rightarrow$\nchemical graph ) pipeline does not require GPUs, Optical Character Recognition\n(OCR) or vectorization. We evaluate on standard benchmarks using SMILES\nstrings, along with a novel evaluation that provides graph-based metrics and\nerror compilation using LgEval. The geometric information in born-digital PDFs\nproduces a highly accurate parser, motivating generating training data for\nvisual parsers that recognize from raster images, with extracted graphics,\nvisual structure, and chemical structure as annotations. To do this we render\nSMILES strings in Indigo, parse molecule structure, and then validate\nrecognized structure to select correct files.\n","authors":["Ayush Kumar Shah","Bryan Manrique Amador","Abhisek Dey","Ming Creekmore","Blake Ocampo","Scott Denmark","Richard Zanibbi"],"pdf_url":"https://arxiv.org/pdf/2311.12161v2.pdf","comment":"20 pages without references, 10 figures, 3 Tables, submitted to\n  International Journal on Document Analysis and Recognition (IJDAR)"},{"id":"http://arxiv.org/abs/2306.04889v2","updated":"2023-11-22T03:02:46Z","published":"2023-06-08T02:35:30Z","title":"ShaDDR: Interactive Example-Based Geometry and Texture Generation via 3D\n  Shape Detailization and Differentiable Rendering","summary":"  We present ShaDDR, an example-based deep generative neural network which\nproduces a high-resolution textured 3D shape through geometry detailization and\nconditional texture generation applied to an input coarse voxel shape. Trained\non a small set of detailed and textured exemplar shapes, our method learns to\ndetailize the geometry via multi-resolution voxel upsampling and generate\ntextures on voxel surfaces via differentiable rendering against exemplar\ntexture images from a few views. The generation is interactive, taking less\nthan 1 second to produce a 3D model with voxel resolutions up to 512^3. The\ngenerated shape preserves the overall structure of the input coarse voxel\nmodel, while the style of the generated geometric details and textures can be\nmanipulated through learned latent codes. In the experiments, we show that our\nmethod can generate higher-resolution shapes with plausible and improved\ngeometric details and clean textures compared to prior works. Furthermore, we\nshowcase the ability of our method to learn geometric details and textures from\nshapes reconstructed from real-world photos. In addition, we have developed an\ninteractive modeling application to demonstrate the generalizability of our\nmethod to various user inputs and the controllability it offers, allowing users\nto interactively sculpt a coarse voxel shape to define the overall structure of\nthe detailized 3D shape. Code and data are available at\nhttps://github.com/qiminchen/ShaDDR.\n","authors":["Qimin Chen","Zhiqin Chen","Hang Zhou","Hao Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.04889v2.pdf","comment":"Accepted to SIGGRAPH Asia 2023 conference track. Code:\n  https://github.com/qiminchen/ShaDDR"},{"id":"http://arxiv.org/abs/2311.13120v1","updated":"2023-11-22T02:46:57Z","published":"2023-11-22T02:46:57Z","title":"Multi-modal In-Context Learning Makes an Ego-evolving Scene Text\n  Recognizer","summary":"  Scene text recognition (STR) in the wild frequently encounters challenges\nwhen coping with domain variations, font diversity, shape deformations, etc. A\nstraightforward solution is performing model fine-tuning tailored to a specific\nscenario, but it is computationally intensive and requires multiple model\ncopies for various scenarios. Recent studies indicate that large language\nmodels (LLMs) can learn from a few demonstration examples in a training-free\nmanner, termed \"In-Context Learning\" (ICL). Nevertheless, applying LLMs as a\ntext recognizer is unacceptably resource-consuming. Moreover, our pilot\nexperiments on LLMs show that ICL fails in STR, mainly attributed to the\ninsufficient incorporation of contextual information from diverse samples in\nthe training stage. To this end, we introduce E$^2$STR, a STR model trained\nwith context-rich scene text sequences, where the sequences are generated via\nour proposed in-context training strategy. E$^2$STR demonstrates that a\nregular-sized model is sufficient to achieve effective ICL capabilities in STR.\nExtensive experiments show that E$^2$STR exhibits remarkable training-free\nadaptation in various scenarios and outperforms even the fine-tuned\nstate-of-the-art approaches on public benchmarks.\n","authors":["Zhen Zhao","Can Huang","Binghong Wu","Chunhui Lin","Hao Liu","Zhizhong Zhang","Xin Tan","Jingqun Tang","Yuan Xie"],"pdf_url":"https://arxiv.org/pdf/2311.13120v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.08326v2","updated":"2023-11-22T02:43:01Z","published":"2023-06-14T07:58:14Z","title":"Early Detection of Late Blight Tomato Disease using Histogram Oriented\n  Gradient based Support Vector Machine","summary":"  The tomato is one of the most important fruits on earth. It plays an\nimportant and useful role in the agricultural production of any country. This\nresearch propose a novel smart technique for early detection of late blight\ndiseases in tomatoes. This work improve the dataset with an increase in images\nfrom the field (the Plant Village dataset) and proposed a hybrid algorithm\ncomposed of support vector machines (SVM) and histogram-oriented gradients\n(HOG) for real-time detection of late blight tomato disease. To propose a\nHOG-based SVM model for early detection of late blight tomato leaf disease. To\ncheck the performance of the proposed model in terms of MSE, accuracy,\nprecision, and recall as compared to Decision Tree and KNN. The integration of\nadvanced technology in agriculture has the potential to revolutionize the\nindustry, making it more efficient, sustainable, and profitable. This research\nwork on the early detection of tomato diseases contributes to the growing\nimportance of smart farming, the need for climate-smart agriculture, the rising\nneed to more efficiently utilize natural resources, and the demand for higher\ncrop yields. The proposed hybrid algorithm of SVM and HOG has significant\npotential for the early detection of late blight disease in tomato plants. The\nperformance of the proposed model against decision tree and KNN algorithms and\nthe results may assist in selecting the best algorithm for future applications.\nThe research work can help farmers make data-driven decisions to optimize crop\nyield and quality while also reducing the environmental impact of farming\npractices.\n","authors":["M. Ishaq","M. Waqas"],"pdf_url":"https://arxiv.org/pdf/2306.08326v2.pdf","comment":"The article titled \"Early Detection of Late Blight Tomato Disease\n  using Histogram Oriented Gradient based Support Vector Machine\" need to be\n  withdrawn there are other contributors in the improvement of this article"},{"id":"http://arxiv.org/abs/2311.13110v1","updated":"2023-11-22T02:23:32Z","published":"2023-11-22T02:23:32Z","title":"White-Box Transformers via Sparse Rate Reduction: Compression Is All\n  There Is?","summary":"  In this paper, we contend that a natural objective of representation learning\nis to compress and transform the distribution of the data, say sets of tokens,\ntowards a low-dimensional Gaussian mixture supported on incoherent subspaces.\nThe goodness of such a representation can be evaluated by a principled measure,\ncalled sparse rate reduction, that simultaneously maximizes the intrinsic\ninformation gain and extrinsic sparsity of the learned representation. From\nthis perspective, popular deep network architectures, including transformers,\ncan be viewed as realizing iterative schemes to optimize this measure.\nParticularly, we derive a transformer block from alternating optimization on\nparts of this objective: the multi-head self-attention operator compresses the\nrepresentation by implementing an approximate gradient descent step on the\ncoding rate of the features, and the subsequent multi-layer perceptron\nsparsifies the features. This leads to a family of white-box transformer-like\ndeep network architectures, named CRATE, which are mathematically fully\ninterpretable. We show, by way of a novel connection between denoising and\ncompression, that the inverse to the aforementioned compressive encoding can be\nrealized by the same class of CRATE architectures. Thus, the so-derived\nwhite-box architectures are universal to both encoders and decoders.\nExperiments show that these networks, despite their simplicity, indeed learn to\ncompress and sparsify representations of large-scale real-world image and text\ndatasets, and achieve performance very close to highly engineered\ntransformer-based models: ViT, MAE, DINO, BERT, and GPT2. We believe the\nproposed computational framework demonstrates great potential in bridging the\ngap between theory and practice of deep learning, from a unified perspective of\ndata compression. Code is available at: https://ma-lab-berkeley.github.io/CRATE .\n","authors":["Yaodong Yu","Sam Buchanan","Druv Pai","Tianzhe Chu","Ziyang Wu","Shengbang Tong","Hao Bai","Yuexiang Zhai","Benjamin D. Haeffele","Yi Ma"],"pdf_url":"https://arxiv.org/pdf/2311.13110v1.pdf","comment":"This paper integrates the works arXiv:2306.01129 and\n  arXiv:2308.16271, as well as this under-review work:\n  https://openreview.net/forum?id=PvyOYleymy into a complete story. In this\n  paper, we improve the writing and organization, and also add conceptual,\n  empirical, and theoretical improvements over the previous work"},{"id":"http://arxiv.org/abs/2311.12144v2","updated":"2023-11-22T02:19:41Z","published":"2023-11-20T19:45:27Z","title":"Applications of Large Scale Foundation Models for Autonomous Driving","summary":"  Since DARPA Grand Challenges (rural) in 2004/05 and Urban Challenges in 2007,\nautonomous driving has been the most active field of AI applications. Recently\npowered by large language models (LLMs), chat systems, such as chatGPT and\nPaLM, emerge and rapidly become a promising direction to achieve artificial\ngeneral intelligence (AGI) in natural language processing (NLP). There comes a\nnatural thinking that we could employ these abilities to reformulate autonomous\ndriving. By combining LLM with foundation models, it is possible to utilize the\nhuman knowledge, commonsense and reasoning to rebuild autonomous driving\nsystems from the current long-tailed AI dilemma. In this paper, we investigate\nthe techniques of foundation models and LLMs applied for autonomous driving,\ncategorized as simulation, world model, data annotation and planning or E2E\nsolutions etc.\n","authors":["Yu Huang","Yue Chen","Zhu Li"],"pdf_url":"https://arxiv.org/pdf/2311.12144v2.pdf","comment":"23 pages. arXiv admin note: text overlap with arXiv:2304.03589,\n  arXiv:2111.05849, arXiv:2306.03000, arXiv:2301.02691, arXiv:2309.16292,\n  arXiv:2309.17080, arXiv:2309.10228, arXiv:2310.01415 by other authors"},{"id":"http://arxiv.org/abs/2309.00168v2","updated":"2023-11-22T02:16:48Z","published":"2023-08-31T23:17:44Z","title":"Pose-Graph Attentional Graph Neural Network for Lidar Place Recognition","summary":"  This paper proposes a pose-graph attentional graph neural network, called\nP-GAT, which compares (key)nodes between sequential and non-sequential\nsub-graphs for place recognition tasks as opposed to a common frame-to-frame\nretrieval problem formulation currently implemented in SOTA place recognition\nmethods. P-GAT uses the maximum spatial and temporal information between\nneighbour cloud descriptors -- generated by an existing encoder -- utilising\nthe concept of pose-graph SLAM. Leveraging intra- and inter-attention and graph\nneural network, P-GAT relates point clouds captured in nearby locations in\nEuclidean space and their embeddings in feature space. Experimental results on\nthe large-scale publically available datasets demonstrate the effectiveness of\nour approach in scenes lacking distinct features and when training and testing\nenvironments have different distributions (domain adaptation). Further, an\nexhaustive comparison with the state-of-the-art shows improvements in\nperformance gains. Code is available at\nhttps://github.com/csiro-robotics/P-GAT.\n","authors":["Milad Ramezani","Liang Wang","Joshua Knights","Zhibin Li","Pauline Pounds","Peyman Moghadam"],"pdf_url":"https://arxiv.org/pdf/2309.00168v2.pdf","comment":"10 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2311.12603v2","updated":"2023-11-22T02:15:51Z","published":"2023-11-21T13:43:16Z","title":"Surgical Temporal Action-aware Network with Sequence Regularization for\n  Phase Recognition","summary":"  To assist surgeons in the operating theatre, surgical phase recognition is\ncritical for developing computer-assisted surgical systems, which requires\ncomprehensive understanding of surgical videos. Although existing studies made\ngreat progress, there are still two significant limitations worthy of\nimprovement. First, due to the compromise of resource consumption, frame-wise\nvisual features are extracted by 2D networks and disregard spatial and temporal\nknowledge of surgical actions, which hinders subsequent inter-frame modeling\nfor phase prediction. Second, these works simply utilize ordinary\nclassification loss with one-hot phase labels to optimize the phase\npredictions, and cannot fully explore surgical videos under inadequate\nsupervision. To overcome these two limitations, we propose a Surgical Temporal\nAction-aware Network with sequence Regularization, named STAR-Net, to recognize\nsurgical phases more accurately from input videos. Specifically, we propose an\nefficient multi-scale surgical temporal action (MS-STA) module, which\nintegrates visual features with spatial and temporal knowledge of surgical\nactions at the cost of 2D networks. Moreover, we devise the dual-classifier\nsequence regularization (DSR) to facilitate the training of STAR-Net by the\nsequence guidance of an auxiliary classifier with a smaller capacity. Our\nSTAR-Net with MS-STA and DSR can exploit visual features of surgical actions\nwith effective regularization, thereby leading to the superior performance of\nsurgical phase recognition. Extensive experiments on a large-scale gastrectomy\nsurgery dataset and the public Cholec80 benchmark prove that our STAR-Net\nsignificantly outperforms state-of-the-arts of surgical phase recognition.\n","authors":["Zhen Chen","Yuhao Zhai","Jun Zhang","Jinqiao Wang"],"pdf_url":"https://arxiv.org/pdf/2311.12603v2.pdf","comment":"Accepted by 2023 IEEE International Conference on Bioinformatics and\n  Biomedicine (BIBM 2023)"},{"id":"http://arxiv.org/abs/2311.13100v1","updated":"2023-11-22T01:59:19Z","published":"2023-11-22T01:59:19Z","title":"Automated Measurement of Pericoronary Adipose Tissue Attenuation and\n  Volume in CT Angiography","summary":"  Pericoronary adipose tissue (PCAT) is the deposition of fat in the vicinity\nof the coronary arteries. It is an indicator of coronary inflammation and\nassociated with coronary artery disease. Non-invasive coronary CT angiography\n(CCTA) is presently used to obtain measures of the thickness, volume, and\nattenuation of fat deposition. However, prior works solely focus on measuring\nPCAT using semi-automated approaches at the right coronary artery (RCA) over\nthe left coronary artery (LCA). In this pilot work, we developed a fully\nautomated approach for the measurement of PCAT mean attenuation and volume in\nthe region around both coronary arteries. First, we used a large subset of\npatients from the public ImageCAS dataset (n = 735) to train a 3D full\nresolution nnUNet to segment LCA and RCA. Then, we automatically measured PCAT\nin the surrounding arterial regions. We evaluated our method on a held-out test\nset of patients (n = 183) from the same dataset. A mean Dice score of 83% and\nPCAT attenuation of -73.81 $\\pm$ 12.69 HU was calculated for the RCA, while a\nmean Dice score of 81% and PCAT attenuation of -77.51 $\\pm$ 7.94 HU was\ncomputed for the LCA. To the best of our knowledge, we are the first to develop\na fully automated method to measure PCAT attenuation and volume at both the RCA\nand LCA. Our work underscores how automated PCAT measurement holds promise as a\nbiomarker for identification of inflammation and cardiac disease.\n","authors":["Andrew M. Nguyen","Tejas Sudharshan Mathai","Liangchen Liu","Jianfei Liu","Ronald M. Summers"],"pdf_url":"https://arxiv.org/pdf/2311.13100v1.pdf","comment":"5 pages, 4 figures, IEE ISBI2024 conference"},{"id":"http://arxiv.org/abs/2311.13099v1","updated":"2023-11-22T01:58:26Z","published":"2023-11-22T01:58:26Z","title":"PIE-NeRF: Physics-based Interactive Elastodynamics with NeRF","summary":"  We show that physics-based simulations can be seamlessly integrated with NeRF\nto generate high-quality elastodynamics of real-world objects. Unlike existing\nmethods, we discretize nonlinear hyperelasticity in a meshless way, obviating\nthe necessity for intermediate auxiliary shape proxies like a tetrahedral mesh\nor voxel grid. A quadratic generalized moving least square (Q-GMLS) is employed\nto capture nonlinear dynamics and large deformation on the implicit model. Such\nmeshless integration enables versatile simulations of complex and codimensional\nshapes. We adaptively place the least-square kernels according to the NeRF\ndensity field to significantly reduce the complexity of the nonlinear\nsimulation. As a result, physically realistic animations can be conveniently\nsynthesized using our method for a wide range of hyperelastic materials at an\ninteractive rate. For more information, please visit our project page at\nhttps://fytalon.github.io/pienerf/.\n","authors":["Yutao Feng","Yintong Shang","Xuan Li","Tianjia Shao","Chenfanfu Jiang","Yin Yang"],"pdf_url":"https://arxiv.org/pdf/2311.13099v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13091v1","updated":"2023-11-22T01:43:57Z","published":"2023-11-22T01:43:57Z","title":"Stable Unlearnable Example: Enhancing the Robustness of Unlearnable\n  Examples via Stable Error-Minimizing Noise","summary":"  The open source of large amounts of image data promotes the development of\ndeep learning techniques. Along with this comes the privacy risk of these\nopen-source image datasets being exploited by unauthorized third parties to\ntrain deep learning models for commercial or illegal purposes. To avoid the\nabuse of public data, a poisoning-based technique, the unlearnable example, is\nproposed to significantly degrade the generalization performance of models by\nadding a kind of imperceptible noise to the data. To further enhance its\nrobustness against adversarial training, existing works leverage iterative\nadversarial training on both the defensive noise and the surrogate model.\nHowever, it still remains unknown whether the robustness of unlearnable\nexamples primarily comes from the effect of enhancement in the surrogate model\nor the defensive noise. Observing that simply removing the adversarial noise on\nthe training process of the defensive noise can improve the performance of\nrobust unlearnable examples, we identify that solely the surrogate model's\nrobustness contributes to the performance. Furthermore, we found a negative\ncorrelation exists between the robustness of defensive noise and the protection\nperformance, indicating defensive noise's instability issue. Motivated by this,\nto further boost the robust unlearnable example, we introduce stable\nerror-minimizing noise (SEM), which trains the defensive noise against random\nperturbation instead of the time-consuming adversarial perturbation to improve\nthe stability of defensive noise. Through extensive experiments, we demonstrate\nthat SEM achieves a new state-of-the-art performance on CIFAR-10, CIFAR-100,\nand ImageNet Subset in terms of both effectiveness and efficiency. The code is\navailable at https://github.com/liuyixin-louis/Stable-Unlearnable-Example.\n","authors":["Yixin Liu","Kaidi Xu","Xun Chen","Lichao Sun"],"pdf_url":"https://arxiv.org/pdf/2311.13091v1.pdf","comment":"14 pages, 11 figures, 13 tables"},{"id":"http://arxiv.org/abs/2311.13090v1","updated":"2023-11-22T01:42:23Z","published":"2023-11-22T01:42:23Z","title":"On the Limitation of Diffusion Models for Synthesizing Training Datasets","summary":"  Synthetic samples from diffusion models are promising for leveraging in\ntraining discriminative models as replications of real training datasets.\nHowever, we found that the synthetic datasets degrade classification\nperformance over real datasets even when using state-of-the-art diffusion\nmodels. This means that modern diffusion models do not perfectly represent the\ndata distribution for the purpose of replicating datasets for training\ndiscriminative tasks. This paper investigates the gap between synthetic and\nreal samples by analyzing the synthetic samples reconstructed from real samples\nthrough the diffusion and reverse process. By varying the time steps starting\nthe reverse process in the reconstruction, we can control the trade-off between\nthe information in the original real data and the information added by\ndiffusion models. Through assessing the reconstructed samples and trained\nmodels, we found that the synthetic data are concentrated in modes of the\ntraining data distribution as the reverse step increases, and thus, they are\ndifficult to cover the outer edges of the distribution. Our findings imply that\nmodern diffusion models are insufficient to replicate training data\ndistribution perfectly, and there is room for the improvement of generative\nmodeling in the replication of training datasets.\n","authors":["Shin'ya Yamaguchi","Takuma Fukuda"],"pdf_url":"https://arxiv.org/pdf/2311.13090v1.pdf","comment":"NeurIPS 2023 SyntheticData4ML Workshop"},{"id":"http://arxiv.org/abs/2309.04153v2","updated":"2023-11-22T01:36:14Z","published":"2023-09-08T06:37:25Z","title":"Mapping EEG Signals to Visual Stimuli: A Deep Learning Approach to Match\n  vs. Mismatch Classification","summary":"  Existing approaches to modeling associations between visual stimuli and brain\nresponses are facing difficulties in handling between-subject variance and\nmodel generalization. Inspired by the recent progress in modeling speech-brain\nresponse, we propose in this work a \"match-vs-mismatch\" deep learning model to\nclassify whether a video clip induces excitatory responses in recorded EEG\nsignals and learn associations between the visual content and corresponding\nneural recordings. Using an exclusive experimental dataset, we demonstrate that\nthe proposed model is able to achieve the highest accuracy on unseen subjects\nas compared to other baseline models. Furthermore, we analyze the inter-subject\nnoise using a subject-level silhouette score in the embedding space and show\nthat the developed model is able to mitigate inter-subject noise and\nsignificantly reduce the silhouette score. Moreover, we examine the Grad-CAM\nactivation score and show that the brain regions associated with language\nprocessing contribute most to the model predictions, followed by regions\nassociated with visual processing. These results have the potential to\nfacilitate the development of neural recording-based video reconstruction and\nits related applications.\n","authors":["Yiqian Yang","Zhengqiao Zhao","Qian Wang","Yan Yang","Jingdong Chen"],"pdf_url":"https://arxiv.org/pdf/2309.04153v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13073v1","updated":"2023-11-22T00:26:15Z","published":"2023-11-22T00:26:15Z","title":"FusionFrames: Efficient Architectural Aspects for Text-to-Video\n  Generation Pipeline","summary":"  Multimedia generation approaches occupy a prominent place in artificial\nintelligence research. Text-to-image models achieved high-quality results over\nthe last few years. However, video synthesis methods recently started to\ndevelop. This paper presents a new two-stage latent diffusion text-to-video\ngeneration architecture based on the text-to-image diffusion model. The first\nstage concerns keyframes synthesis to figure the storyline of a video, while\nthe second one is devoted to interpolation frames generation to make movements\nof the scene and objects smooth. We compare several temporal conditioning\napproaches for keyframes generation. The results show the advantage of using\nseparate temporal blocks over temporal layers in terms of metrics reflecting\nvideo generation quality aspects and human preference. The design of our\ninterpolation model significantly reduces computational costs compared to other\nmasked frame interpolation approaches. Furthermore, we evaluate different\nconfigurations of MoVQ-based video decoding scheme to improve consistency and\nachieve higher PSNR, SSIM, MSE, and LPIPS scores. Finally, we compare our\npipeline with existing solutions and achieve top-2 scores overall and top-1\namong open-source solutions: CLIPSIM = 0.2976 and FVD = 433.054. Project page:\nhttps://ai-forever.github.io/kandinsky-video/\n","authors":["Vladimir Arkhipkin","Zein Shaheen","Viacheslav Vasilev","Elizaveta Dakhova","Andrey Kuznetsov","Denis Dimitrov"],"pdf_url":"https://arxiv.org/pdf/2311.13073v1.pdf","comment":"Project page: https://ai-forever.github.io/kandinsky-video/"},{"id":"http://arxiv.org/abs/2311.13069v1","updated":"2023-11-22T00:03:16Z","published":"2023-11-22T00:03:16Z","title":"FuseNet: Self-Supervised Dual-Path Network for Medical Image\n  Segmentation","summary":"  Semantic segmentation, a crucial task in computer vision, often relies on\nlabor-intensive and costly annotated datasets for training. In response to this\nchallenge, we introduce FuseNet, a dual-stream framework for self-supervised\nsemantic segmentation that eliminates the need for manual annotation. FuseNet\nleverages the shared semantic dependencies between the original and augmented\nimages to create a clustering space, effectively assigning pixels to\nsemantically related clusters, and ultimately generating the segmentation map.\nAdditionally, FuseNet incorporates a cross-modal fusion technique that extends\nthe principles of CLIP by replacing textual data with augmented images. This\napproach enables the model to learn complex visual representations, enhancing\nrobustness against variations similar to CLIP's text invariance. To further\nimprove edge alignment and spatial consistency between neighboring pixels, we\nintroduce an edge refinement loss. This loss function considers edge\ninformation to enhance spatial coherence, facilitating the grouping of nearby\npixels with similar visual features. Extensive experiments on skin lesion and\nlung segmentation datasets demonstrate the effectiveness of our method.\n\\href{https://github.com/xmindflow/FuseNet}{Codebase.}\n","authors":["Amirhossein Kazerouni","Sanaz Karimijafarbigloo","Reza Azad","Yury Velichko","Ulas Bagci","Dorit Merhof"],"pdf_url":"https://arxiv.org/pdf/2311.13069v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2311.13565v1","updated":"2023-11-22T18:22:56Z","published":"2023-11-22T18:22:56Z","title":"Drilling Down into the Discourse Structure with LLMs for Long Document\n  Question Answering","summary":"  We address the task of evidence retrieval for long document question\nanswering, which involves locating relevant paragraphs within a document to\nanswer a question. We aim to assess the applicability of large language models\n(LLMs) in the task of zero-shot long document evidence retrieval, owing to\ntheir unprecedented performance across various NLP tasks. However, currently\nthe LLMs can consume limited context lengths as input, thus providing document\nchunks as inputs might overlook the global context while missing out on\ncapturing the inter-segment dependencies. Moreover, directly feeding the large\ninput sets can incur significant computational costs, particularly when\nprocessing the entire document (and potentially incurring monetary expenses\nwith enterprise APIs like OpenAI's GPT variants). To address these challenges,\nwe propose a suite of techniques that exploit the discourse structure commonly\nfound in documents. By utilizing this structure, we create a condensed\nrepresentation of the document, enabling a more comprehensive understanding and\nanalysis of relationships between different parts. We retain $99.6\\%$ of the\nbest zero-shot approach's performance, while processing only $26\\%$ of the\ntotal tokens used by the best approach in the information seeking evidence\nretrieval setup. We also show how our approach can be combined with\n\\textit{self-ask} reasoning agent to achieve best zero-shot performance in\ncomplex multi-hop question answering, just $\\approx 4\\%$ short of zero-shot\nperformance using gold evidence.\n","authors":["Inderjeet Nair","Shwetha Somasundaram","Apoorv Saxena","Koustava Goswami"],"pdf_url":"https://arxiv.org/pdf/2311.13565v1.pdf","comment":"Accepted to the Findings of EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.13534v1","updated":"2023-11-22T17:14:54Z","published":"2023-11-22T17:14:54Z","title":"LM-Cocktail: Resilient Tuning of Language Models via Model Merging","summary":"  The pre-trained language models are continually fine-tuned to better support\ndownstream applications. However, this operation may result in significant\nperformance degeneration on general tasks beyond the targeted domain. To\novercome this problem, we propose a novel method which enables the fine-tuned\nmodel to stay resilient in general perspectives. Our method is conducted in the\nform of model merging (namely LM-Cocktail), where the fine-tuned language model\nis merged with the pre-trained base model or the peer models from other domains\nthrough weighted average. Despite simplicity, LM-Cocktail is surprisingly\neffective: the resulted model is able to achieve a strong empirical performance\nin the whole scope of general tasks while preserving a superior capacity in its\ntargeted domain. We conduct comprehensive experiments with LLama and BGE model\non popular benchmarks, including FLAN, MMLU, MTEB, whose results validate the\nefficacy of our proposed method. The code and checkpoints are available at\nhttps://github.com/FlagOpen/FlagEmbedding.\n","authors":["Shitao Xiao","Zheng Liu","Peitian Zhang","Xingrun Xing"],"pdf_url":"https://arxiv.org/pdf/2311.13534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13494v1","updated":"2023-11-22T16:12:41Z","published":"2023-11-22T16:12:41Z","title":"A Comparative Analysis of Supportive Navigation on Movie Recommenders","summary":"  This literature review covers the research and thought process that went into\nmaking a solution for the infinite scrolling problem faced in streaming\nservices such as Netflix. Using the data collected, we have come to the\nconclusion that an alternate layout can somewhat alleviate the problems it\ntakes in navigating a list of movies. We also found out by a comparative\nanalysis that some layouts, the circular one in particular, is advantageous in\ncertain settings making it an ideal candidate for a movie recommender system.\n","authors":["Mohammad Sualeh Ali","Muhammed Maaz Tariq","Alina Ahmed","Abdul Razaque Soomro","Danysh Syed"],"pdf_url":"https://arxiv.org/pdf/2311.13494v1.pdf","comment":"This was an extensive survey and prototyping we did to purpose and\n  alternative user interface for movie recommender systems like Netflix"},{"id":"http://arxiv.org/abs/2311.13350v1","updated":"2023-11-22T12:39:28Z","published":"2023-11-22T12:39:28Z","title":"Fact-based Court Judgment Prediction","summary":"  This extended abstract extends the research presented in \"ILDC for CJPE:\nIndian Legal Documents Corpus for Court Judgment Prediction and Explanation\"\n\\cite{malik-etal-2021-ildc}, focusing on fact-based judgment prediction within\nthe context of Indian legal documents. We introduce two distinct problem\nvariations: one based solely on facts, and another combining facts with rulings\nfrom lower courts (RLC). Our research aims to enhance early-phase case outcome\nprediction, offering significant benefits to legal professionals and the\ngeneral public. The results, however, indicated a performance decline compared\nto the original ILDC for CJPE study, even after implementing various weightage\nschemes in our DELSumm algorithm. Additionally, using only facts for legal\njudgment prediction with different transformer models yielded results inferior\nto the state-of-the-art outcomes reported in the \"ILDC for CJPE\" study.\n","authors":["Shubham Kumar Nigam","Aniket Deroy"],"pdf_url":"https://arxiv.org/pdf/2311.13350v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13277v1","updated":"2023-11-22T09:53:57Z","published":"2023-11-22T09:53:57Z","title":"Hierarchical Matrix Factorization for Interpretable Collaborative\n  Filtering","summary":"  Matrix factorization (MF) is a simple collaborative filtering technique that\nachieves superior recommendation accuracy by decomposing the user-item rating\nmatrix into user and item latent matrices. This approach relies on learning\nfrom user-item interactions, which may not effectively capture the underlying\nshared dependencies between users or items. Therefore, there is scope to\nexplicitly capture shared dependencies to further improve recommendation\naccuracy and the interpretability of learning results by summarizing user-item\ninteractions. Based on these insights, we propose \"Hierarchical Matrix\nFactorization\" (HMF), which incorporates clustering concepts to capture the\nhierarchy, where leaf nodes and other nodes correspond to users/items and\nclusters, respectively. Central to our approach, called hierarchical\nembeddings, is the additional decomposition of the user and item latent\nmatrices (embeddings) into probabilistic connection matrices, which link the\nhierarchy, and a root cluster latent matrix. Thus, each node is represented by\nthe weighted average of the embeddings of its parent clusters. The embeddings\nare differentiable, allowing simultaneous learning of interactions and\nclustering using a single gradient descent method. Furthermore, the obtained\ncluster-specific interactions naturally summarize user-item interactions and\nprovide interpretability. Experimental results on rating and ranking\npredictions demonstrated the competitiveness of HMF over vanilla and\nhierarchical MF methods, especially its robustness in sparse interactions.\nAdditionally, it was confirmed that the clustering integration of HMF has the\npotential for faster learning convergence and mitigation of overfitting\ncompared to MF, and also provides interpretability through a cluster-centered\ncase study.\n","authors":["Kai Sugahara","Kazushi Okamoto"],"pdf_url":"https://arxiv.org/pdf/2311.13277v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13121v1","updated":"2023-11-22T02:49:14Z","published":"2023-11-22T02:49:14Z","title":"GENET: Unleashing the Power of Side Information for Recommendation via\n  Hypergraph Pre-training","summary":"  Recommendation with side information has drawn significant research interest\ndue to its potential to mitigate user feedback sparsity. However, existing\nmodels struggle with generalization across diverse domains and types of side\ninformation. In particular, three challenges have not been addressed, and they\nare (1) the diverse formats of side information, including text sequences. (2)\nThe diverse semantics of side information that describes items and users from\nmulti-level in a context different from recommendation systems. (3) The diverse\ncorrelations in side information to measure similarity over multiple objects\nbeyond pairwise relations. In this paper, we introduce GENET (Generalized\nhypErgraph pretraiNing on sidE informaTion), which pre-trains user and item\nrepresentations on feedback-irrelevant side information and fine-tunes the\nrepresentations on user feedback data. GENET leverages pre-training as a means\nto prevent side information from overshadowing critical ID features and\nfeedback signals. It employs a hypergraph framework to accommodate various\ntypes of diverse side information. During pre-training, GENET integrates tasks\nfor hyperlink prediction and self-supervised contrast to capture fine-grained\nsemantics at both local and global levels. Additionally, it introduces a unique\nstrategy to enhance pre-training robustness by perturbing positive samples\nwhile maintaining high-order relations. Extensive experiments demonstrate that\nGENET exhibits strong generalization capabilities, outperforming the SOTA\nmethod by up to 38% in TOP-N recommendation and Sequential recommendation tasks\non various datasets with different side information.\n","authors":["Yang Li","Qi'ao Zhao","Chen Lin","Zhenjie Zhang","Xiaomin Zhu"],"pdf_url":"https://arxiv.org/pdf/2311.13121v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2311.13601v1","updated":"2023-11-22T18:59:48Z","published":"2023-11-22T18:59:48Z","title":"Visual In-Context Prompting","summary":"  In-context prompting in large language models (LLMs) has become a prevalent\napproach to improve zero-shot capabilities, but this idea is less explored in\nthe vision domain. Existing visual prompting methods focus on referring\nsegmentation to segment the most relevant object, falling short of addressing\nmany generic vision tasks like open-set segmentation and detection. In this\npaper, we introduce a universal visual in-context prompting framework for both\ntasks. In particular, we build on top of an encoder-decoder architecture, and\ndevelop a versatile prompt encoder to support a variety of prompts like\nstrokes, boxes, and points. We further enhance it to take an arbitrary number\nof reference image segments as the context. Our extensive explorations show\nthat the proposed visual in-context prompting elicits extraordinary referring\nand generic segmentation capabilities to refer and detect, yielding competitive\nperformance to close-set in-domain datasets and showing promising results on\nmany open-set segmentation datasets. By joint training on COCO and SA-1B, our\nmodel achieves $57.7$ PQ on COCO and $23.2$ PQ on ADE20K. Code will be\navailable at https://github.com/UX-Decoder/DINOv.\n","authors":["Feng Li","Qing Jiang","Hao Zhang","Tianhe Ren","Shilong Liu","Xueyan Zou","Huaizhe Xu","Hongyang Li","Chunyuan Li","Jianwei Yang","Lei Zhang","Jianfeng Gao"],"pdf_url":"https://arxiv.org/pdf/2311.13601v1.pdf","comment":"technical report"},{"id":"http://arxiv.org/abs/2311.13600v1","updated":"2023-11-22T18:59:36Z","published":"2023-11-22T18:59:36Z","title":"ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs","summary":"  Methods for finetuning generative models for concept-driven personalization\ngenerally achieve strong results for subject-driven or style-driven generation.\nRecently, low-rank adaptations (LoRA) have been proposed as a\nparameter-efficient way of achieving concept-driven personalization. While\nrecent work explores the combination of separate LoRAs to achieve joint\ngeneration of learned styles and subjects, existing techniques do not reliably\naddress the problem; they often compromise either subject fidelity or style\nfidelity. We propose ZipLoRA, a method to cheaply and effectively merge\nindependently trained style and subject LoRAs in order to achieve generation of\nany user-provided subject in any user-provided style. Experiments on a wide\nrange of subject and style combinations show that ZipLoRA can generate\ncompelling results with meaningful improvements over baselines in subject and\nstyle fidelity while preserving the ability to recontextualize. Project page:\nhttps://ziplora.github.io\n","authors":["Viraj Shah","Nataniel Ruiz","Forrester Cole","Erika Lu","Svetlana Lazebnik","Yuanzhen Li","Varun Jampani"],"pdf_url":"https://arxiv.org/pdf/2311.13600v1.pdf","comment":"Project page: https://ziplora.github.io"},{"id":"http://arxiv.org/abs/2311.13595v1","updated":"2023-11-22T18:55:27Z","published":"2023-11-22T18:55:27Z","title":"Covariance alignment: from maximum likelihood estimation to\n  Gromov-Wasserstein","summary":"  Feature alignment methods are used in many scientific disciplines for data\npooling, annotation, and comparison. As an instance of a permutation learning\nproblem, feature alignment presents significant statistical and computational\nchallenges. In this work, we propose the covariance alignment model to study\nand compare various alignment methods and establish a minimax lower bound for\ncovariance alignment that has a non-standard dimension scaling because of the\npresence of a nuisance parameter. This lower bound is in fact minimax optimal\nand is achieved by a natural quasi MLE. However, this estimator involves a\nsearch over all permutations which is computationally infeasible even when the\nproblem has moderate size. To overcome this limitation, we show that the\ncelebrated Gromov-Wasserstein algorithm from optimal transport which is more\namenable to fast implementation even on large-scale problems is also minimax\noptimal. These results give the first statistical justification for the\ndeployment of the Gromov-Wasserstein algorithm in practice.\n","authors":["Yanjun Han","Philippe Rigollet","George Stepaniants"],"pdf_url":"https://arxiv.org/pdf/2311.13595v1.pdf","comment":"41 pages, 2 figures"},{"id":"http://arxiv.org/abs/2311.13594v1","updated":"2023-11-22T18:55:25Z","published":"2023-11-22T18:55:25Z","title":"Labeling Neural Representations with Inverse Recognition","summary":"  Deep Neural Networks (DNNs) demonstrated remarkable capabilities in learning\ncomplex hierarchical data representations, but the nature of these\nrepresentations remains largely unknown. Existing global explainability\nmethods, such as Network Dissection, face limitations such as reliance on\nsegmentation masks, lack of statistical significance testing, and high\ncomputational demands. We propose Inverse Recognition (INVERT), a scalable\napproach for connecting learned representations with human-understandable\nconcepts by leveraging their capacity to discriminate between these concepts.\nIn contrast to prior work, INVERT is capable of handling diverse types of\nneurons, exhibits less computational complexity, and does not rely on the\navailability of segmentation masks. Moreover, INVERT provides an interpretable\nmetric assessing the alignment between the representation and its corresponding\nexplanation and delivering a measure of statistical significance, emphasizing\nits utility and credibility. We demonstrate the applicability of INVERT in\nvarious scenarios, including the identification of representations affected by\nspurious correlations, and the interpretation of the hierarchical structure of\ndecision-making within the models.\n","authors":["Kirill Bykov","Laura Kopf","Shinichi Nakajima","Marius Kloft","Marina M. -C. Höhne"],"pdf_url":"https://arxiv.org/pdf/2311.13594v1.pdf","comment":"24 pages, 16 figures"},{"id":"http://arxiv.org/abs/2311.13589v1","updated":"2023-11-22T18:50:06Z","published":"2023-11-22T18:50:06Z","title":"Risk-sensitive Markov Decision Process and Learning under General\n  Utility Functions","summary":"  Reinforcement Learning (RL) has gained substantial attention across diverse\napplication domains and theoretical investigations. Existing literature on RL\ntheory largely focuses on risk-neutral settings where the decision-maker learns\nto maximize the expected cumulative reward. However, in practical scenarios\nsuch as portfolio management and e-commerce recommendations, decision-makers\noften persist in heterogeneous risk preferences subject to outcome\nuncertainties, which can not be well-captured by the risk-neural framework.\nIncorporating these preferences can be approached through utility theory, yet\nthe development of risk-sensitive RL under general utility functions remains an\nopen question for theoretical exploration.\n  In this paper, we consider a scenario where the decision-maker seeks to\noptimize a general utility function of the cumulative reward in the framework\nof a Markov decision process (MDP). To facilitate the Dynamic Programming\nPrinciple and Bellman equation, we enlarge the state space with an additional\ndimension that accounts for the cumulative reward. We propose a discretized\napproximation scheme to the MDP under enlarged state space, which is tractable\nand key for algorithmic design. We then propose a modified value iteration\nalgorithm that employs an epsilon-covering over the space of cumulative reward.\nWhen a simulator is accessible, our algorithm efficiently learns a near-optimal\npolicy with guaranteed sample complexity. In the absence of a simulator, our\nalgorithm, designed with an upper-confidence-bound exploration approach,\nidentifies a near-optimal policy while ensuring a guaranteed regret bound. For\nboth algorithms, we match the theoretical lower bounds for the risk-neutral\nsetting.\n","authors":["Zhengqi Wu","Renyuan Xu"],"pdf_url":"https://arxiv.org/pdf/2311.13589v1.pdf","comment":"36 pages"},{"id":"http://arxiv.org/abs/2311.13587v1","updated":"2023-11-22T18:46:05Z","published":"2023-11-22T18:46:05Z","title":"A Survey of Serverless Machine Learning Model Inference","summary":"  Recent developments in Generative AI, Computer Vision, and Natural Language\nProcessing have led to an increased integration of AI models into various\nproducts. This widespread adoption of AI requires significant efforts in\ndeploying these models in production environments. When hosting machine\nlearning models for real-time predictions, it is important to meet defined\nService Level Objectives (SLOs), ensuring reliability, minimal downtime, and\noptimizing operational costs of the underlying infrastructure. Large machine\nlearning models often demand GPU resources for efficient inference to meet\nSLOs. In the context of these trends, there is growing interest in hosting AI\nmodels in a serverless architecture while still providing GPU access for\ninference tasks. This survey aims to summarize and categorize the emerging\nchallenges and optimization opportunities for large-scale deep learning serving\nsystems. By providing a novel taxonomy and summarizing recent trends, we hope\nthat this survey could shed light on new optimization perspectives and motivate\nnovel works in large-scale deep learning serving systems.\n","authors":["Kamil Kojs"],"pdf_url":"https://arxiv.org/pdf/2311.13587v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2311.13584v1","updated":"2023-11-22T18:40:45Z","published":"2023-11-22T18:40:45Z","title":"On diffusion-based generative models and their error bounds: The\n  log-concave case with full convergence estimates","summary":"  We provide full theoretical guarantees for the convergence behaviour of\ndiffusion-based generative models under the assumption of strongly logconcave\ndata distributions while our approximating class of functions used for score\nestimation is made of Lipschitz continuous functions. We demonstrate via a\nmotivating example, sampling from a Gaussian distribution with unknown mean,\nthe powerfulness of our approach. In this case, explicit estimates are provided\nfor the associated optimization problem, i.e. score approximation, while these\nare combined with the corresponding sampling estimates. As a result, we obtain\nthe best known upper bound estimates in terms of key quantities of interest,\nsuch as the dimension and rates of convergence, for the Wasserstein-2 distance\nbetween the data distribution (Gaussian with unknown mean) and our sampling\nalgorithm.\n  Beyond the motivating example and in order to allow for the use of a diverse\nrange of stochastic optimizers, we present our results using an $L^2$-accurate\nscore estimation assumption, which crucially is formed under an expectation\nwith respect to the stochastic optimizer and our novel auxiliary process that\nuses only known information. This approach yields the best known convergence\nrate for our sampling algorithm.\n","authors":["Stefano Bruno","Ying Zhang","Dong-Young Lim","Ömer Deniz Akyildiz","Sotirios Sabanis"],"pdf_url":"https://arxiv.org/pdf/2311.13584v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13583v1","updated":"2023-11-22T18:40:18Z","published":"2023-11-22T18:40:18Z","title":"Adaptive Sampling for Deep Learning via Efficient Nonparametric Proxies","summary":"  Data sampling is an effective method to improve the training speed of neural\nnetworks, with recent results demonstrating that it can even break the neural\nscaling laws. These results critically rely on high-quality scores to estimate\nthe importance of an input to the network. We observe that there are two\ndominant strategies: static sampling, where the scores are determined before\ntraining, and dynamic sampling, where the scores can depend on the model\nweights. Static algorithms are computationally inexpensive but less effective\nthan their dynamic counterparts, which can cause end-to-end slowdown due to\ntheir need to explicitly compute losses. To address this problem, we propose a\nnovel sampling distribution based on nonparametric kernel regression that\nlearns an effective importance score as the neural network trains. However,\nnonparametric regression models are too computationally expensive to accelerate\nend-to-end training. Therefore, we develop an efficient sketch-based\napproximation to the Nadaraya-Watson estimator. Using recent techniques from\nhigh-dimensional statistics and randomized algorithms, we prove that our\nNadaraya-Watson sketch approximates the estimator with exponential convergence\nguarantees. Our sampling algorithm outperforms the baseline in terms of\nwall-clock time and accuracy on four datasets.\n","authors":["Shabnam Daghaghi","Benjamin Coleman","Benito Geordie","Anshumali Shrivastava"],"pdf_url":"https://arxiv.org/pdf/2311.13583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13580v1","updated":"2023-11-22T18:34:49Z","published":"2023-11-22T18:34:49Z","title":"$σ$-PCA: a unified neural model for linear and nonlinear principal\n  component analysis","summary":"  Linear principal component analysis (PCA), nonlinear PCA, and linear\nindependent component analysis (ICA) -- those are three methods with\nsingle-layer autoencoder formulations for learning linear transformations from\ndata. Linear PCA learns orthogonal transformations (rotations) that orient axes\nto maximise variance, but it suffers from a subspace rotational indeterminacy:\nit fails to find a unique rotation for axes that share the same variance. Both\nnonlinear PCA and linear ICA reduce the subspace indeterminacy from rotational\nto permutational by maximising statistical independence under the assumption of\nunit variance. The main difference between them is that nonlinear PCA only\nlearns rotations while linear ICA learns not just rotations but any linear\ntransformation with unit variance. The relationship between all three can be\nunderstood by the singular value decomposition of the linear ICA transformation\ninto a sequence of rotation, scale, rotation. Linear PCA learns the first\nrotation; nonlinear PCA learns the second. The scale is simply the inverse of\nthe standard deviations. The problem is that, in contrast to linear PCA,\nconventional nonlinear PCA cannot be used directly on the data to learn the\nfirst rotation, the first being special as it reduces dimensionality and orders\nby variances. In this paper, we have identified the cause, and as a solution we\npropose $\\sigma$-PCA: a unified neural model for linear and nonlinear PCA as\nsingle-layer autoencoders. One of its key ingredients: modelling not just the\nrotation but also the scale -- the variances. This model bridges the disparity\nbetween linear and nonlinear PCA. And so, like linear PCA, it can learn a\nsemi-orthogonal transformation that reduces dimensionality and orders by\nvariances, but, unlike linear PCA, it does not suffer from rotational\nindeterminacy.\n","authors":["Fahdi Kanavati","Lucy Katsnith","Masayuki Tsuneki"],"pdf_url":"https://arxiv.org/pdf/2311.13580v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.19274v2","updated":"2023-11-22T18:27:15Z","published":"2023-10-30T05:13:58Z","title":"Prediction of Effective Elastic Moduli of Rocks using Graph Neural\n  Networks","summary":"  This study presents a Graph Neural Networks (GNNs)-based approach for\npredicting the effective elastic moduli of rocks from their digital CT-scan\nimages. We use the Mapper algorithm to transform 3D digital rock images into\ngraph datasets, encapsulating essential geometrical information. These graphs,\nafter training, prove effective in predicting elastic moduli. Our GNN model\nshows robust predictive capabilities across various graph sizes derived from\nvarious subcube dimensions. Not only does it perform well on the test dataset,\nbut it also maintains high prediction accuracy for unseen rocks and unexplored\nsubcube sizes. Comparative analysis with Convolutional Neural Networks (CNNs)\nreveals the superior performance of GNNs in predicting unseen rock properties.\nMoreover, the graph representation of microstructures significantly reduces GPU\nmemory requirements (compared to the grid representation for CNNs), enabling\ngreater flexibility in the batch size selection. This work demonstrates the\npotential of GNN models in enhancing the prediction accuracy of rock properties\nand boosting the efficiency of digital rock analysis.\n","authors":["Jaehong Chung","Rasool Ahmad","WaiChing Sun","Wei Cai","Tapan Mukerji"],"pdf_url":"https://arxiv.org/pdf/2310.19274v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13552v1","updated":"2023-11-22T17:50:00Z","published":"2023-11-22T17:50:00Z","title":"A Unified Framework for Trace-induced Quantum Kernels","summary":"  Quantum kernel methods are promising candidates for achieving a practical\nquantum advantage for certain machine learning tasks. Similar to classical\nmachine learning, an exact form of a quantum kernel is expected to have a great\nimpact on the model performance. In this work we combine all trace-induced\nquantum kernels, including the commonly-used global fidelity and local\nprojected quantum kernels, into a common framework. We show how generalized\ntrace-induced quantum kernels can be constructed as combinations of the\nfundamental building blocks we coin \"Lego\" kernels, which impose an inductive\nbias on the resulting quantum models. We relate the expressive power and\ngeneralization ability to the number of non-zero weight Lego kernels and\npropose a systematic approach to increase the complexity of a quantum kernel\nmodel, leading to a new form of the local projected kernels that require fewer\nquantum resources in terms of the number of quantum gates and measurement\nshots. We show numerically that models based on local projected kernels can\nachieve comparable performance to the global fidelity quantum kernel. Our work\nunifies existing quantum kernels and provides a systematic framework to compare\ntheir properties.\n","authors":["Beng Yee Gan","Daniel Leykam","Supanut Thanasilp"],"pdf_url":"https://arxiv.org/pdf/2311.13552v1.pdf","comment":"12 + 15 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.13548v1","updated":"2023-11-22T17:44:18Z","published":"2023-11-22T17:44:18Z","title":"Efficient Numerical Integration in Reproducing Kernel Hilbert Spaces via\n  Leverage Scores Sampling","summary":"  In this work we consider the problem of numerical integration, i.e.,\napproximating integrals with respect to a target probability measure using only\npointwise evaluations of the integrand. We focus on the setting in which the\ntarget distribution is only accessible through a set of $n$ i.i.d.\nobservations, and the integrand belongs to a reproducing kernel Hilbert space.\nWe propose an efficient procedure which exploits a small i.i.d. random subset\nof $m<n$ samples drawn either uniformly or using approximate leverage scores\nfrom the initial observations. Our main result is an upper bound on the\napproximation error of this procedure for both sampling strategies. It yields\nsufficient conditions on the subsample size to recover the standard (optimal)\n$n^{-1/2}$ rate while reducing drastically the number of functions evaluations,\nand thus the overall computational cost. Moreover, we obtain rates with respect\nto the number $m$ of evaluations of the integrand which adapt to its\nsmoothness, and match known optimal rates for instance for Sobolev spaces. We\nillustrate our theoretical findings with numerical experiments on real\ndatasets, which highlight the attractive efficiency-accuracy tradeoff of our\nmethod compared to existing randomized and greedy quadrature methods. We note\nthat, the problem of numerical integration in RKHS amounts to designing a\ndiscrete approximation of the kernel mean embedding of the target distribution.\nAs a consequence, direct applications of our results also include the efficient\ncomputation of maximum mean discrepancies between distributions and the design\nof efficient kernel-based tests.\n","authors":["Antoine Chatalic","Nicolas Schreuder","Ernesto De Vito","Lorenzo Rosasco"],"pdf_url":"https://arxiv.org/pdf/2311.13548v1.pdf","comment":"46 pages, 5 figures. Submitted to JMLR"},{"id":"http://arxiv.org/abs/2311.13541v1","updated":"2023-11-22T17:30:41Z","published":"2023-11-22T17:30:41Z","title":"Linear Log-Normal Attention with Unbiased Concentration","summary":"  Transformer models have achieved remarkable results in a wide range of\napplications. However, their scalability is hampered by the quadratic time and\nmemory complexity of the self-attention mechanism concerning the sequence\nlength. This limitation poses a substantial obstacle when dealing with long\ndocuments or high-resolution images. In this work, we study the self-attention\nmechanism by analyzing the distribution of the attention matrix and its\nconcentration ability. Furthermore, we propose instruments to measure these\nquantities and introduce a novel self-attention mechanism, Linear Log-Normal\nAttention, designed to emulate the distribution and concentration behavior of\nthe original self-attention. Our experimental results on popular natural\nlanguage benchmarks reveal that our proposed Linear Log-Normal Attention\noutperforms other linearized attention alternatives, offering a promising\navenue for enhancing the scalability of transformer models. Our code is\navailable in supplementary materials.\n","authors":["Yury Nahshan","Joseph Kampeas","Emir Haleva"],"pdf_url":"https://arxiv.org/pdf/2311.13541v1.pdf","comment":"22 pages, 20 figures, 5 tables, submitted to ICLR2024"},{"id":"http://arxiv.org/abs/2311.13539v1","updated":"2023-11-22T17:26:54Z","published":"2023-11-22T17:26:54Z","title":"Learned Nonlinear Predictor for Critically Sampled 3D Point Cloud\n  Attribute Compression","summary":"  We study 3D point cloud attribute compression via a volumetric approach:\nassuming point cloud geometry is known at both encoder and decoder, parameters\n$\\theta$ of a continuous attribute function $f: \\mathbb{R}^3 \\mapsto\n\\mathbb{R}$ are quantized to $\\hat{\\theta}$ and encoded, so that discrete\nsamples $f_{\\hat{\\theta}}(\\mathbf{x}_i)$ can be recovered at known 3D points\n$\\mathbf{x}_i \\in \\mathbb{R}^3$ at the decoder. Specifically, we consider a\nnested sequences of function subspaces $\\mathcal{F}^{(p)}_{l_0} \\subseteq\n\\cdots \\subseteq \\mathcal{F}^{(p)}_L$, where $\\mathcal{F}_l^{(p)}$ is a family\nof functions spanned by B-spline basis functions of order $p$, $f_l^*$ is the\nprojection of $f$ on $\\mathcal{F}_l^{(p)}$ and encoded as low-pass coefficients\n$F_l^*$, and $g_l^*$ is the residual function in orthogonal subspace\n$\\mathcal{G}_l^{(p)}$ (where $\\mathcal{G}_l^{(p)} \\oplus \\mathcal{F}_l^{(p)} =\n\\mathcal{F}_{l+1}^{(p)}$) and encoded as high-pass coefficients $G_l^*$. In\nthis paper, to improve coding performance over [1], we study predicting\n$f_{l+1}^*$ at level $l+1$ given $f_l^*$ at level $l$ and encoding of $G_l^*$\nfor the $p=1$ case (RAHT($1$)). For the prediction, we formalize RAHT(1) linear\nprediction in MPEG-PCC in a theoretical framework, and propose a new nonlinear\npredictor using a polynomial of bilateral filter. We derive equations to\nefficiently compute the critically sampled high-pass coefficients $G_l^*$\namenable to encoding. We optimize parameters in our resulting feed-forward\nnetwork on a large training set of point clouds by minimizing a rate-distortion\nLagrangian. Experimental results show that our improved framework outperformed\nthe MPEG G-PCC predictor by $11$ to $12\\%$ in bit rate reduction.\n","authors":["Tam Thuc Do","Philip A. Chou","Gene Cheung"],"pdf_url":"https://arxiv.org/pdf/2311.13539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02921v3","updated":"2023-11-22T17:26:08Z","published":"2023-11-06T07:28:16Z","title":"Edge2Node: Reducing Edge Prediction to Node Classification","summary":"  Despite the success of graph neural network models in node classification,\nedge prediction (the task of predicting missing or potential links between\nnodes in a graph) remains a challenging problem for these models. A common\napproach for edge prediction is to first obtain the embeddings of two nodes,\nand then a predefined scoring function is used to predict the existence of an\nedge between the two nodes. Here, we introduce a preliminary idea called\nEdge2Node which suggests to directly obtain an embedding for each edge, without\nthe need for a scoring function. This idea wants to create a new graph H based\non the graph G given for the edge prediction task, and then suggests reducing\nthe edge prediction task on G to a node classification task on H. We anticipate\nthat this introductory method could stimulate further investigations for edge\nprediction task.\n","authors":["Zahed Rahmati"],"pdf_url":"https://arxiv.org/pdf/2311.02921v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13538v1","updated":"2023-11-22T17:24:21Z","published":"2023-11-22T17:24:21Z","title":"Speak Like a Native: Prompting Large Language Models in a Native Style","summary":"  Existing work has found that the prompt engineering heavily influences the\nperformance of large language models (LLMs). Chain-of-thought (CoT), as a\npopular prompt engineering technique, prompted LLMs using in-context examples\nwith reasoning steps. In current studies, the few-shot examples of CoT are\ngenerally handcrafted by humans. However, how the text style of in-context\nexamples influence the outputs of LLMs still remains under-explored. This paper\npresents a novel and effective approach, named \\textbf{AlignCoT}, to improve\nthe reasoning capability of LLMs by aligning the in-context examples with the\nnative style of LLMs. ``Native'' refers to the inherent characteristic style of\nLLMs which can be probed by original zero-shot scenarios. AlignCoT is\northogonal to other prompt engineering methods, making it easy to combine with\nstate-of-the-art techniques to further improve the LLMs' performance. We\nconduct extensive and comprehensive experiments on several benchmarks. The\nempirical results demonstrate that our AlignCoTsignificantly improves\nperformance over the carefully handcrafted in-context examples. For instance,\nwith GPT-3.5-turbo, we observed a +2.5\\% improvement on GSM8K. Furthermore, our\nAlignCoT consistently improve the performance when combined with other\nstate-of-the-art prompt engineering methods. The source code and dataset will\nbe available at\n\\href{https://github.com/yangzhch6/AlignCoT}{https://github.com/yangzhch6/AlignCoT}.\n","authors":["Zhicheng Yang","Yiwei Wang","Yinya Huang","Jing Xiong","Xiaodan Liang","Jing Tang"],"pdf_url":"https://arxiv.org/pdf/2311.13538v1.pdf","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.13531v1","updated":"2023-11-22T17:06:57Z","published":"2023-11-22T17:06:57Z","title":"Leveraging CNNs and Ensemble Learning for Automated Disaster Image\n  Classification","summary":"  Natural disasters act as a serious threat globally, requiring effective and\nefficient disaster management and recovery. This paper focuses on classifying\nnatural disaster images using Convolutional Neural Networks (CNNs). Multiple\nCNN architectures were built and trained on a dataset containing images of\nearthquakes, floods, wildfires, and volcanoes. A stacked CNN ensemble approach\nproved to be the most effective, achieving 95% accuracy and an F1 score going\nup to 0.96 for individual classes. Tuning hyperparameters of individual models\nfor optimization was critical to maximize the models' performance. The stacking\nof CNNs with XGBoost acting as the meta-model utilizes the strengths of the CNN\nand ResNet models to improve the overall accuracy of the classification.\nResults obtained from the models illustrated the potency of CNN-based models\nfor automated disaster image classification. This lays the foundation for\nexpanding these techniques to build robust systems for disaster response,\ndamage assessment, and recovery management.\n","authors":["Archit Rathod","Veer Pariawala","Mokshit Surana","Kumkum Saxena"],"pdf_url":"https://arxiv.org/pdf/2311.13531v1.pdf","comment":"13 pages, 11 figures, 4 tables, ICSISCET 2023 Conference"},{"id":"http://arxiv.org/abs/2311.11772v2","updated":"2023-11-22T17:06:31Z","published":"2023-11-20T13:58:26Z","title":"A Good Feature Extractor Is All You Need for Weakly Supervised Learning\n  in Histopathology","summary":"  Deep learning is revolutionising pathology, offering novel opportunities in\ndisease prognosis and personalised treatment. Historically, stain normalisation\nhas been a crucial preprocessing step in computational pathology pipelines, and\npersists into the deep learning era. Yet, with the emergence of feature\nextractors trained using self-supervised learning (SSL) on diverse pathology\ndatasets, we call this practice into question. In an empirical evaluation of\npublicly available feature extractors, we find that omitting stain\nnormalisation and image augmentations does not compromise downstream\nperformance, while incurring substantial savings in memory and compute.\nFurther, we show that the top-performing feature extractors are remarkably\nrobust to variations in stain and augmentations like rotation in their latent\nspace. Contrary to previous patch-level benchmarking studies, our approach\nemphasises clinical relevance by focusing on slide-level prediction tasks in a\nweakly supervised setting with external validation cohorts. This work\nrepresents the most comprehensive robustness evaluation of public pathology SSL\nfeature extractors to date, involving more than 6,000 training runs across nine\ntasks, five datasets, three downstream architectures, and various preprocessing\nsetups. Our findings stand to streamline digital pathology workflows by\nminimising preprocessing needs and informing the selection of feature\nextractors.\n","authors":["Georg Wölflein","Dyke Ferber","Asier Rabasco Meneghetti","Omar S. M. El Nahhas","Daniel Truhn","Zunamys I. Carrero","David J. Harrison","Ognjen Arandjelović","Jakob N. Kather"],"pdf_url":"https://arxiv.org/pdf/2311.11772v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.12261v4","updated":"2023-11-22T16:59:55Z","published":"2022-07-06T13:56:48Z","title":"GraphCFC: A Directed Graph Based Cross-Modal Feature Complementation\n  Approach for Multimodal Conversational Emotion Recognition","summary":"  Emotion Recognition in Conversation (ERC) plays a significant part in\nHuman-Computer Interaction (HCI) systems since it can provide empathetic\nservices. Multimodal ERC can mitigate the drawbacks of uni-modal approaches.\nRecently, Graph Neural Networks (GNNs) have been widely used in a variety of\nfields due to their superior performance in relation modeling. In multimodal\nERC, GNNs are capable of extracting both long-distance contextual information\nand inter-modal interactive information. Unfortunately, since existing methods\nsuch as MMGCN directly fuse multiple modalities, redundant information may be\ngenerated and diverse information may be lost. In this work, we present a\ndirected Graph based Cross-modal Feature Complementation (GraphCFC) module that\ncan efficiently model contextual and interactive information. GraphCFC\nalleviates the problem of heterogeneity gap in multimodal fusion by utilizing\nmultiple subspace extractors and Pair-wise Cross-modal Complementary (PairCC)\nstrategy. We extract various types of edges from the constructed graph for\nencoding, thus enabling GNNs to extract crucial contextual and interactive\ninformation more accurately when performing message passing. Furthermore, we\ndesign a GNN structure called GAT-MLP, which can provide a new unified network\nframework for multimodal learning. The experimental results on two benchmark\ndatasets show that our GraphCFC outperforms the state-of-the-art (SOTA)\napproaches.\n","authors":["Jiang Li","Xiaoping Wang","Guoqing Lv","Zhigang Zeng"],"pdf_url":"https://arxiv.org/pdf/2207.12261v4.pdf","comment":"Accepted by IEEE Transactions on Multimedia (TMM)"},{"id":"http://arxiv.org/abs/2206.05077v5","updated":"2023-11-22T16:45:11Z","published":"2022-06-10T13:18:26Z","title":"Tensor Train for Global Optimization Problems in Robotics","summary":"  The convergence of many numerical optimization techniques is highly dependent\non the initial guess given to the solver. To address this issue, we propose a\nnovel approach that utilizes tensor methods to initialize existing optimization\nsolvers near global optima. Our method does not require access to a database of\ngood solutions. We first transform the cost function, which depends on both\ntask parameters and optimization variables, into a probability density\nfunction. Unlike existing approaches, the joint probability distribution of the\ntask parameters and optimization variables is approximated using the Tensor\nTrain model, which enables efficient conditioning and sampling. We treat the\ntask parameters as random variables, and for a given task, we generate samples\nfor decision variables from the conditional distribution to initialize the\noptimization solver. Our method can produce multiple solutions (when they\nexist) faster than existing methods. We first evaluate the approach on\nbenchmark functions for numerical optimization that are hard to solve using\ngradient-based optimization solvers with a naive initialization. The results\nshow that the proposed method can generate samples close to global optima and\nfrom multiple modes. We then demonstrate the generality and relevance of our\nframework to robotics by applying it to inverse kinematics with obstacles and\nmotion planning problems with a 7-DoF manipulator.\n","authors":["Suhan Shetty","Teguh Lembono","Tobias Loew","Sylvain Calinon"],"pdf_url":"https://arxiv.org/pdf/2206.05077v5.pdf","comment":"25 pages, 21 figures"},{"id":"http://arxiv.org/abs/2311.13508v1","updated":"2023-11-22T16:34:12Z","published":"2023-11-22T16:34:12Z","title":"Naturalness of Attention: Revisiting Attention in Code Language Models","summary":"  Language models for code such as CodeBERT offer the capability to learn\nadvanced source code representation, but their opacity poses barriers to\nunderstanding of captured properties. Recent attention analysis studies provide\ninitial interpretability insights by focusing solely on attention weights\nrather than considering the wider context modeling of Transformers. This study\naims to shed some light on the previously ignored factors of the attention\nmechanism beyond the attention weights. We conduct an initial empirical study\nanalyzing both attention distributions and transformed representations in\nCodeBERT. Across two programming languages, Java and Python, we find that the\nscaled transformation norms of the input better capture syntactic structure\ncompared to attention weights alone. Our analysis reveals characterization of\nhow CodeBERT embeds syntactic code properties. The findings demonstrate the\nimportance of incorporating factors beyond just attention weights for\nrigorously understanding neural code models. This lays the groundwork for\ndeveloping more interpretable models and effective uses of attention mechanisms\nin program analysis.\n","authors":["Mootez Saad","Tushar Sharma"],"pdf_url":"https://arxiv.org/pdf/2311.13508v1.pdf","comment":"Accepted at ICSE-NIER (2024) track"},{"id":"http://arxiv.org/abs/2311.13507v1","updated":"2023-11-22T16:34:06Z","published":"2023-11-22T16:34:06Z","title":"Applying Dimensionality Reduction as Precursor to LSTM-CNN Models for\n  Classifying Imagery and Motor Signals in ECoG-Based BCIs","summary":"  Motor impairments, frequently caused by neurological incidents like strokes\nor traumatic brain injuries, present substantial obstacles in rehabilitation\ntherapy. This research aims to elevate the field by optimizing motor imagery\nclassification algorithms within Brain-Computer Interfaces (BCIs). By improving\nthe efficiency of BCIs, we offer a novel approach that holds significant\npromise for enhancing motor rehabilitation outcomes. Utilizing unsupervised\ntechniques for dimensionality reduction, namely Uniform Manifold Approximation\nand Projection (UMAP) coupled with K-Nearest Neighbors (KNN), we evaluate the\nnecessity of employing supervised methods such as Long Short-Term Memory (LSTM)\nand Convolutional Neural Networks (CNNs) for classification tasks. Importantly,\nparticipants who exhibited high KNN scores following UMAP dimensionality\nreduction also achieved high accuracy in supervised deep learning (DL) models.\nDue to individualized model requirements and massive neural training data,\ndimensionality reduction becomes an effective preprocessing step that minimizes\nthe need for extensive data labeling and supervised deep learning techniques.\nThis approach has significant implications not only for targeted therapies in\nmotor dysfunction but also for addressing regulatory, safety, and reliability\nconcerns in the rapidly evolving BCI field.\n","authors":["Soham Bafana"],"pdf_url":"https://arxiv.org/pdf/2311.13507v1.pdf","comment":"10 Pages, 12 Figures. The dataset used in this paper can be found\n  here: https://osf.io/ksqv8/download, from the Miller 2010 paper. All code\n  used in this research can be found at\n  https://github.com/bafanaS/dim-reduction-with-cnn-lstm.git"},{"id":"http://arxiv.org/abs/2311.13502v1","updated":"2023-11-22T16:20:24Z","published":"2023-11-22T16:20:24Z","title":"Bitformer: An efficient Transformer with bitwise operation-based\n  attention for Big Data Analytics at low-cost low-precision devices","summary":"  In the current landscape of large models, the Transformer stands as a\ncornerstone, playing a pivotal role in shaping the trajectory of modern models.\nHowever, its application encounters challenges attributed to the substantial\ncomputational intricacies intrinsic to its attention mechanism. Moreover, its\nreliance on high-precision floating-point operations presents specific hurdles,\nparticularly evident in computation-intensive scenarios such as edge computing\nenvironments. These environments, characterized by resource-constrained devices\nand a preference for lower precision, necessitate innovative solutions.\n  To tackle the exacting data processing demands posed by edge devices, we\nintroduce the Bitformer model, an inventive extension of the Transformer\nparadigm. Central to this innovation is a novel attention mechanism that\nadeptly replaces conventional floating-point matrix multiplication with bitwise\noperations. This strategic substitution yields dual advantages. Not only does\nit maintain the attention mechanism's prowess in capturing intricate long-range\ninformation dependencies, but it also orchestrates a profound reduction in the\ncomputational complexity inherent in the attention operation. The transition\nfrom an $O(n^2d)$ complexity, typical of floating-point operations, to an\n$O(n^2T)$ complexity characterizing bitwise operations, substantiates this\nadvantage. Notably, in this context, the parameter $T$ remains markedly smaller\nthan the conventional dimensionality parameter $d$.\n  The Bitformer model in essence endeavors to reconcile the indomitable\nrequirements of modern computing landscapes with the constraints posed by edge\ncomputing scenarios. By forging this innovative path, we bridge the gap between\nhigh-performing models and resource-scarce environments, thus unveiling a\npromising trajectory for further advancements in the field.\n","authors":["Gaoxiang Duan","Junkai Zhang","Xiaoying Zheng","Yongxin Zhu"],"pdf_url":"https://arxiv.org/pdf/2311.13502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13495v1","updated":"2023-11-22T16:12:42Z","published":"2023-11-22T16:12:42Z","title":"Current Topological and Machine Learning Applications for Bias Detection\n  in Text","summary":"  Institutional bias can impact patient outcomes, educational attainment, and\nlegal system navigation. Written records often reflect bias, and once bias is\nidentified; it is possible to refer individuals for training to reduce bias.\nMany machine learning tools exist to explore text data and create predictive\nmodels that can search written records to identify real-time bias. However, few\nprevious studies investigate large language model embeddings and geometric\nmodels of biased text data to understand geometry's impact on bias modeling\naccuracy. To overcome this issue, this study utilizes the RedditBias database\nto analyze textual biases. Four transformer models, including BERT and RoBERTa\nvariants, were explored. Post-embedding, t-SNE allowed two-dimensional\nvisualization of data. KNN classifiers differentiated bias types, with lower\nk-values proving more effective. Findings suggest BERT, particularly mini BERT,\nexcels in bias classification, while multilingual models lag. The\nrecommendation emphasizes refining monolingual models and exploring\ndomain-specific biases.\n","authors":["Colleen Farrelly","Yashbir Singh","Quincy A. Hathaway","Gunnar Carlsson","Ashok Choudhary","Rahul Paul","Gianfranco Doretto","Yassine Himeur","Shadi Atalls","Wathiq Mansoor"],"pdf_url":"https://arxiv.org/pdf/2311.13495v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.19680v3","updated":"2023-11-22T16:12:39Z","published":"2023-10-30T16:00:13Z","title":"Integrating Pre-trained Language Model into Neural Machine Translation","summary":"  Neural Machine Translation (NMT) has become a significant technology in\nnatural language processing through extensive research and development.\nHowever, the deficiency of high-quality bilingual language pair data still\nposes a major challenge to improving NMT performance. Recent studies have been\nexploring the use of contextual information from pre-trained language model\n(PLM) to address this problem. Yet, the issue of incompatibility between PLM\nand NMT model remains unresolved. This study proposes PLM-integrated NMT\n(PiNMT) model to overcome the identified problems. PiNMT model consists of\nthree critical components, PLM Multi Layer Converter, Embedding Fusion, and\nCosine Alignment, each playing a vital role in providing effective PLM\ninformation to NMT. Furthermore, two training strategies, Separate Learning\nRates and Dual Step Training, are also introduced in this paper. By\nimplementing the proposed PiNMT model and training strategy, we achieve\nstate-of-the-art performance on the IWSLT'14 En$\\leftrightarrow$De dataset.\nThis study's outcomes are noteworthy as they demonstrate a novel approach for\nefficiently integrating PLM with NMT to overcome incompatibility and enhance\nperformance.\n","authors":["Soon-Jae Hwang","Chang-Sung Jeong"],"pdf_url":"https://arxiv.org/pdf/2310.19680v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13491v1","updated":"2023-11-22T16:08:38Z","published":"2023-11-22T16:08:38Z","title":"Grad-Shafranov equilibria via data-free physics informed neural networks","summary":"  A large number of magnetohydrodynamic (MHD) equilibrium calculations are\noften required for uncertainty quantification, optimization, and real-time\ndiagnostic information, making MHD equilibrium codes vital to the field of\nplasma physics. In this paper, we explore a method for solving the\nGrad-Shafranov equation by using Physics-Informed Neural Networks (PINNs). For\nPINNs, we optimize neural networks by directly minimizing the residual of the\nPDE as a loss function. We show that PINNs can accurately and effectively solve\nthe Grad-Shafranov equation with several different boundary conditions. We also\nexplore the parameter space by varying the size of the model, the learning\nrate, and boundary conditions to map various trade-offs such as between\nreconstruction error and computational speed. Additionally, we introduce a\nparameterized PINN framework, expanding the input space to include variables\nsuch as pressure, aspect ratio, elongation, and triangularity in order to\nhandle a broader range of plasma scenarios within a single network.\nParametrized PINNs could be used in future work to solve inverse problems such\nas shape optimization.\n","authors":["Byoungchan Jang","Alan A. Kaptanoglu","Rahul Gaur","Shaw Pan","Matt Landreman","William Dorland"],"pdf_url":"https://arxiv.org/pdf/2311.13491v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13490v1","updated":"2023-11-22T16:07:32Z","published":"2023-11-22T16:07:32Z","title":"Benchmarking Toxic Molecule Classification using Graph Neural Networks\n  and Few Shot Learning","summary":"  Traditional methods like Graph Convolutional Networks (GCNs) face challenges\nwith limited data and class imbalance, leading to suboptimal performance in\ngraph classification tasks during toxicity prediction of molecules as a whole.\nTo address these issues, we harness the power of Graph Isomorphic Networks,\nMulti Headed Attention and Free Large-scale Adversarial Augmentation separately\non Graphs for precisely capturing the structural data of molecules and their\ntoxicological properties. Additionally, we incorporate Few-Shot Learning to\nimprove the model's generalization with limited annotated samples. Extensive\nexperiments on a diverse toxicology dataset demonstrate that our method\nachieves an impressive state-of-art AUC-ROC value of 0.816, surpassing the\nbaseline GCN model by 11.4%. This highlights the significance of our proposed\nmethodology and Few Shot Learning in advancing Toxic Molecular Classification,\nwith the potential to enhance drug discovery and environmental risk assessment\nprocesses.\n","authors":["Bhavya Mehta","Kush Kothari","Reshmika Nambiar","Seema Shrawne"],"pdf_url":"https://arxiv.org/pdf/2311.13490v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13485v1","updated":"2023-11-22T16:01:44Z","published":"2023-11-22T16:01:44Z","title":"Deep-learning-based acceleration of MRI for radiotherapy planning of\n  pediatric patients with brain tumors","summary":"  Magnetic Resonance Imaging (MRI) is a non-invasive diagnostic and\nradiotherapy (RT) planning tool, offering detailed insights into the anatomy of\nthe human body. The extensive scan time is stressful for patients, who must\nremain motionless in a prolonged imaging procedure that prioritizes reduction\nof imaging artifacts. This is challenging for pediatric patients who may\nrequire measures for managing voluntary motions such as anesthesia. Several\ncomputational approaches reduce scan time (fast MRI), by recording fewer\nmeasurements and digitally recovering full information via post-acquisition\nreconstruction. However, most fast MRI approaches were developed for diagnostic\nimaging, without addressing reconstruction challenges specific to RT planning.\nIn this work, we developed a deep learning-based method (DeepMRIRec) for MRI\nreconstruction from undersampled data acquired with RT-specific receiver coil\narrangements. We evaluated our method against fully sampled data of T1-weighted\nMR images acquired from 73 children with brain tumors/surgical beds using loop\nand posterior coils (12 channels), with and without applying virtual\ncompression of coil elements. DeepMRIRec reduced scanning time by a factor of\nfour producing a structural similarity score surpassing the evaluated\nstate-of-the-art method (0.960 vs 0.896), thereby demonstrating its potential\nfor accelerating MRI scanning for RT planning.\n","authors":["Shahinur Alam","Jinsoo Uh","Alexander Dresner","Chia-ho Hua","Khaled Khairy"],"pdf_url":"https://arxiv.org/pdf/2311.13485v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13475v1","updated":"2023-11-22T15:42:51Z","published":"2023-11-22T15:42:51Z","title":"Machine Translation to Control Formality Features in the Target Language","summary":"  Formality plays a significant role in language communication, especially in\nlow-resource languages such as Hindi, Japanese and Korean. These languages\nutilise formal and informal expressions to convey messages based on social\ncontexts and relationships. When a language translation technique is used to\ntranslate from a source language that does not pertain the formality (e.g.\nEnglish) to a target language that does, there is a missing information on\nformality that could be a challenge in producing an accurate outcome. This\nresearch explores how this issue should be resolved when machine learning\nmethods are used to translate from English to languages with formality, using\nHindi as the example data. This was done by training a bilingual model in a\nformality-controlled setting and comparing its performance with a pre-trained\nmultilingual model in a similar setting. Since there are not a lot of training\ndata with ground truth, automated annotation techniques were employed to\nincrease the data size. The primary modeling approach involved leveraging\ntransformer models, which have demonstrated effectiveness in various natural\nlanguage processing tasks. We evaluate the official formality accuracy(ACC) by\ncomparing the predicted masked tokens with the ground truth. This metric\nprovides a quantitative measure of how well the translations align with the\ndesired outputs. Our study showcases a versatile translation strategy that\nconsiders the nuances of formality in the target language, catering to diverse\nlanguage communication needs and scenarios.\n","authors":["Harshita Tyagi","Prashasta Jung","Hyowon Lee"],"pdf_url":"https://arxiv.org/pdf/2311.13475v1.pdf","comment":"9 pages, based on DCU MCM Practicum 2022/2023"},{"id":"http://arxiv.org/abs/2306.16430v2","updated":"2023-11-22T15:39:14Z","published":"2023-06-28T15:21:27Z","title":"DNA-TEQ: An Adaptive Exponential Quantization of Tensors for DNN\n  Inference","summary":"  Quantization is commonly used in Deep Neural Networks (DNNs) to reduce the\nstorage and computational complexity by decreasing the arithmetical precision\nof activations and weights, a.k.a. tensors. Efficient hardware architectures\nemploy linear quantization to enable the deployment of recent DNNs onto\nembedded systems and mobile devices. However, linear uniform quantization\ncannot usually reduce the numerical precision to less than 8 bits without\nsacrificing high performance in terms of model accuracy. The performance loss\nis due to the fact that tensors do not follow uniform distributions. In this\npaper, we show that a significant amount of tensors fit into an exponential\ndistribution. Then, we propose DNA-TEQ to exponentially quantize DNN tensors\nwith an adaptive scheme that achieves the best trade-off between numerical\nprecision and accuracy loss. The experimental results show that DNA-TEQ\nprovides a much lower quantization bit-width compared to previous proposals,\nresulting in an average compression ratio of 40% over the linear INT8 baseline,\nwith negligible accuracy loss and without retraining the DNNs. Besides, DNA-TEQ\nleads the way in performing dot-product operations in the exponential domain,\nwhich saves 66% of energy consumption on average for a set of widely used DNNs.\n","authors":["Bahareh Khabbazan","Marc Riera","Antonio González"],"pdf_url":"https://arxiv.org/pdf/2306.16430v2.pdf","comment":"10 pages, 8 figures, 5 tables"},{"id":"http://arxiv.org/abs/2305.13318v2","updated":"2023-11-22T15:38:47Z","published":"2023-05-12T14:21:14Z","title":"A principled deep learning approach for geological facies generation","summary":"  The simulation of geological facies in an unobservable volume is essential in\nvarious geoscience applications. Given the complexity of the problem, deep\ngenerative learning is a promising approach to overcome the limitations of\ntraditional geostatistical simulation models, in particular their lack of\nphysical realism. This research aims to investigate the application of\ngenerative adversarial networks and deep variational inference for\nconditionally simulating meandering channels in underground volumes. In this\npaper, we review the generative deep learning approaches, in particular the\nadversarial ones and the stabilization techniques that aim to facilitate their\ntraining. The proposed approach is tested on 2D and 3D simulations generated by\nthe stochastic process-based model Flumy. Morphological metrics are utilized to\ncompare our proposed method with earlier iterations of generative adversarial\nnetworks. The results indicate that by utilizing recent stabilization\ntechniques, generative adversarial networks can efficiently sample from target\ndata distributions. Moreover, we demonstrate the ability to simulate\nconditioned simulations through the latent variable model property of the\nproposed approach.\n","authors":["Ferdinand Bhavsar","Nicolas Desassis","Fabien Ors","Thomas Romary"],"pdf_url":"https://arxiv.org/pdf/2305.13318v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13471v1","updated":"2023-11-22T15:35:56Z","published":"2023-11-22T15:35:56Z","title":"Comparative Analysis of Linear Regression, Gaussian Elimination, and LU\n  Decomposition for CT Real Estate Purchase Decisions","summary":"  This paper presents a comprehensive evaluation of three distinct\ncomputational algorithms applied to the decision-making process of real estate\npurchases. Specifically, we analyze the efficacy of Linear Regression from\nScikit-learn library, Gaussian Elimination with partial pivoting, and LU\nDecomposition in predicting the advisability of buying a house in the State of\nConnecticut based on a set of financial and market-related parameters. The\nalgorithms' performances were compared using a dataset encompassing\ntown-specific details, yearly data, interest rates, and median sale ratios. Our\nresults demonstrate significant differences in predictive accuracy, with Linear\nRegression and LU Decomposition providing the most reliable recommendations and\nGaussian Elimination showing limitations in stability and performance. The\nstudy's findings emphasize the importance of algorithm selection in predictive\nanalytic and offer insights into the practical applications of computational\nmethods in real estate investment strategies. By evaluating model efficacy\nthrough metrics such as R-squared scores and Mean Squared Error, we provide a\nnuanced understanding of each method's strengths and weaknesses, contributing\nvaluable knowledge to the fields of real estate analysis and predictive\nmodeling.\n","authors":["Xilin Cheng"],"pdf_url":"https://arxiv.org/pdf/2311.13471v1.pdf","comment":"5 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.13469v1","updated":"2023-11-22T15:34:44Z","published":"2023-11-22T15:34:44Z","title":"Span-Based Optimal Sample Complexity for Average Reward MDPs","summary":"  We study the sample complexity of learning an $\\varepsilon$-optimal policy in\nan average-reward Markov decision process (MDP) under a generative model. We\nestablish the complexity bound $\\widetilde{O}\\left(SA\\frac{H}{\\varepsilon^2}\n\\right)$, where $H$ is the span of the bias function of the optimal policy and\n$SA$ is the cardinality of the state-action space. Our result is the first that\nis minimax optimal (up to log factors) in all parameters $S,A,H$ and\n$\\varepsilon$, improving on existing work that either assumes uniformly bounded\nmixing times for all policies or has suboptimal dependence on the parameters.\n  Our result is based on reducing the average-reward MDP to a discounted MDP.\nTo establish the optimality of this reduction, we develop improved bounds for\n$\\gamma$-discounted MDPs, showing that\n$\\widetilde{O}\\left(SA\\frac{H}{(1-\\gamma)^2\\varepsilon^2} \\right)$ samples\nsuffice to learn a $\\varepsilon$-optimal policy in weakly communicating MDPs\nunder the regime that $\\gamma \\geq 1 - \\frac{1}{H}$, circumventing the\nwell-known lower bound of\n$\\widetilde{\\Omega}\\left(SA\\frac{1}{(1-\\gamma)^3\\varepsilon^2} \\right)$ for\ngeneral $\\gamma$-discounted MDPs. Our analysis develops upper bounds on certain\ninstance-dependent variance parameters in terms of the span parameter. These\nbounds are tighter than those based on the mixing time or diameter of the MDP\nand may be of broader use.\n","authors":["Matthew Zurek","Yudong Chen"],"pdf_url":"https://arxiv.org/pdf/2311.13469v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2311.13466v1","updated":"2023-11-22T15:32:31Z","published":"2023-11-22T15:32:31Z","title":"Accelerating Inference in Molecular Diffusion Models with Latent\n  Representations of Protein Structure","summary":"  Diffusion generative models have emerged as a powerful framework for\naddressing problems in structural biology and structure-based drug design.\nThese models operate directly on 3D molecular structures. Due to the\nunfavorable scaling of graph neural networks (GNNs) with graph size as well as\nthe relatively slow inference speeds inherent to diffusion models, many\nexisting molecular diffusion models rely on coarse-grained representations of\nprotein structure to make training and inference feasible. However, such\ncoarse-grained representations discard essential information for modeling\nmolecular interactions and impair the quality of generated structures. In this\nwork, we present a novel GNN-based architecture for learning latent\nrepresentations of molecular structure. When trained end-to-end with a\ndiffusion model for de novo ligand design, our model achieves comparable\nperformance to one with an all-atom protein representation while exhibiting a\n3-fold reduction in inference time.\n","authors":["Ian Dunn","David Ryan Koes"],"pdf_url":"https://arxiv.org/pdf/2311.13466v1.pdf","comment":"This paper appeared as a spotlight paper at the NeurIPS 2023\n  Generative AI and Biology Workshop"},{"id":"http://arxiv.org/abs/2311.13460v1","updated":"2023-11-22T15:24:36Z","published":"2023-11-22T15:24:36Z","title":"Multi-Objective Bayesian Optimization with Active Preference Learning","summary":"  There are a lot of real-world black-box optimization problems that need to\noptimize multiple criteria simultaneously. However, in a multi-objective\noptimization (MOO) problem, identifying the whole Pareto front requires the\nprohibitive search cost, while in many practical scenarios, the decision maker\n(DM) only needs a specific solution among the set of the Pareto optimal\nsolutions. We propose a Bayesian optimization (BO) approach to identifying the\nmost preferred solution in the MOO with expensive objective functions, in which\na Bayesian preference model of the DM is adaptively estimated by an interactive\nmanner based on the two types of supervisions called the pairwise preference\nand improvement request. To explore the most preferred solution, we define an\nacquisition function in which the uncertainty both in the objective functions\nand the DM preference is incorporated. Further, to minimize the interaction\ncost with the DM, we also propose an active learning strategy for the\npreference estimation. We empirically demonstrate the effectiveness of our\nproposed method through the benchmark function optimization and the\nhyper-parameter optimization problems for machine learning models.\n","authors":["Ryota Ozaki","Kazuki Ishikawa","Youhei Kanzaki","Shinya Suzuki","Shion Takeno","Ichiro Takeuchi","Masayuki Karasuyama"],"pdf_url":"https://arxiv.org/pdf/2311.13460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13459v1","updated":"2023-11-22T15:24:29Z","published":"2023-11-22T15:24:29Z","title":"The Tempered Hilbert Simplex Distance and Its Application To Non-linear\n  Embeddings of TEMs","summary":"  Tempered Exponential Measures (TEMs) are a parametric generalization of the\nexponential family of distributions maximizing the tempered entropy function\namong positive measures subject to a probability normalization of their power\ndensities. Calculus on TEMs relies on a deformed algebra of arithmetic\noperators induced by the deformed logarithms used to define the tempered\nentropy. In this work, we introduce three different parameterizations of finite\ndiscrete TEMs via Legendre functions of the negative tempered entropy function.\nIn particular, we establish an isometry between such parameterizations in terms\nof a generalization of the Hilbert log cross-ratio simplex distance to a\ntempered Hilbert co-simplex distance. Similar to the Hilbert geometry, the\ntempered Hilbert distance is characterized as a $t$-symmetrization of the\noriented tempered Funk distance. We motivate our construction by introducing\nthe notion of $t$-lengths of smooth curves in a tautological Finsler manifold.\nWe then demonstrate the properties of our generalized structure in different\nsettings and numerically examine the quality of its differentiable\napproximations for optimization in machine learning settings.\n","authors":["Ehsan Amid","Frank Nielsen","Richard Nock","Manfred K. Warmuth"],"pdf_url":"https://arxiv.org/pdf/2311.13459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02931v3","updated":"2023-11-22T15:23:44Z","published":"2022-12-06T12:40:45Z","title":"Leveraging Different Learning Styles for Improved Knowledge Distillation\n  in Biomedical Imaging","summary":"  Learning style refers to a type of training mechanism adopted by an\nindividual to gain new knowledge. As suggested by the VARK model, humans have\ndifferent learning preferences, like Visual (V), Auditory (A), Read/Write (R),\nand Kinesthetic (K), for acquiring and effectively processing information. Our\nwork endeavors to leverage this concept of knowledge diversification to improve\nthe performance of model compression techniques like Knowledge Distillation\n(KD) and Mutual Learning (ML). Consequently, we use a single-teacher and\ntwo-student network in a unified framework that not only allows for the\ntransfer of knowledge from teacher to students (KD) but also encourages\ncollaborative learning between students (ML). Unlike the conventional approach,\nwhere the teacher shares the same knowledge in the form of predictions or\nfeature representations with the student network, our proposed approach employs\na more diversified strategy by training one student with predictions and the\nother with feature maps from the teacher. We further extend this knowledge\ndiversification by facilitating the exchange of predictions and feature maps\nbetween the two student networks, enriching their learning experiences. We have\nconducted comprehensive experiments with three benchmark datasets for both\nclassification and segmentation tasks using two different network architecture\ncombinations. These experimental results demonstrate that knowledge\ndiversification in a combined KD and ML framework outperforms conventional KD\nor ML techniques (with similar network configuration) that only use predictions\nwith an average improvement of 2%. Furthermore, consistent improvement in\nperformance across different tasks, with various network architectures, and\nover state-of-the-art techniques establishes the robustness and\ngeneralizability of the proposed model\n","authors":["Usma Niyaz","Abhishek Singh Sambyal","Deepti R. Bathula"],"pdf_url":"https://arxiv.org/pdf/2212.02931v3.pdf","comment":"Accepted in Computers in Biology and Medicine"},{"id":"http://arxiv.org/abs/2311.13454v1","updated":"2023-11-22T15:20:12Z","published":"2023-11-22T15:20:12Z","title":"Explaining high-dimensional text classifiers","summary":"  Explainability has become a valuable tool in the last few years, helping\nhumans better understand AI-guided decisions. However, the classic\nexplainability tools are sometimes quite limited when considering\nhigh-dimensional inputs and neural network classifiers. We present a new\nexplainability method using theoretically proven high-dimensional properties in\nneural network classifiers. We present two usages of it: 1) On the classical\nsentiment analysis task for the IMDB reviews dataset, and 2) our\nMalware-Detection task for our PowerShell scripts dataset.\n","authors":["Odelia Melamed","Rich Caruana"],"pdf_url":"https://arxiv.org/pdf/2311.13454v1.pdf","comment":"Accepted to \"XAI in Action\" workshop @ NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.13447v1","updated":"2023-11-22T15:12:42Z","published":"2023-11-22T15:12:42Z","title":"Differentially Private Non-Convex Optimization under the KL Condition\n  with Optimal Rates","summary":"  We study private empirical risk minimization (ERM) problem for losses\nsatisfying the $(\\gamma,\\kappa)$-Kurdyka-{\\L}ojasiewicz (KL) condition. The\nPolyak-{\\L}ojasiewicz (PL) condition is a special case of this condition when\n$\\kappa=2$. Specifically, we study this problem under the constraint of $\\rho$\nzero-concentrated differential privacy (zCDP). When $\\kappa\\in[1,2]$ and the\nloss function is Lipschitz and smooth over a sufficiently large region, we\nprovide a new algorithm based on variance reduced gradient descent that\nachieves the rate\n$\\tilde{O}\\big(\\big(\\frac{\\sqrt{d}}{n\\sqrt{\\rho}}\\big)^\\kappa\\big)$ on the\nexcess empirical risk, where $n$ is the dataset size and $d$ is the dimension.\nWe further show that this rate is nearly optimal. When $\\kappa \\geq 2$ and the\nloss is instead Lipschitz and weakly convex, we show it is possible to achieve\nthe rate $\\tilde{O}\\big(\\big(\\frac{\\sqrt{d}}{n\\sqrt{\\rho}}\\big)^\\kappa\\big)$\nwith a private implementation of the proximal point method. When the KL\nparameters are unknown, we provide a novel modification and analysis of the\nnoisy gradient descent algorithm and show that this algorithm achieves a rate\nof\n$\\tilde{O}\\big(\\big(\\frac{\\sqrt{d}}{n\\sqrt{\\rho}}\\big)^{\\frac{2\\kappa}{4-\\kappa}}\\big)$\nadaptively, which is nearly optimal when $\\kappa = 2$. We further show that,\nwithout assuming the KL condition, the same gradient descent algorithm can\nachieve fast convergence to a stationary point when the gradient stays\nsufficiently large during the run of the algorithm. Specifically, we show that\nthis algorithm can approximate stationary points of Lipschitz, smooth (and\npossibly nonconvex) objectives with rate as fast as\n$\\tilde{O}\\big(\\frac{\\sqrt{d}}{n\\sqrt{\\rho}}\\big)$ and never worse than\n$\\tilde{O}\\big(\\big(\\frac{\\sqrt{d}}{n\\sqrt{\\rho}}\\big)^{1/2}\\big)$. The latter\nrate matches the best known rate for methods that do not rely on variance\nreduction.\n","authors":["Michael Menart","Enayat Ullah","Raman Arora","Raef Bassily","Cristóbal Guzmán"],"pdf_url":"https://arxiv.org/pdf/2311.13447v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13445v1","updated":"2023-11-22T15:11:35Z","published":"2023-11-22T15:11:35Z","title":"Transfer Attacks and Defenses for Large Language Models on Coding Tasks","summary":"  Modern large language models (LLMs), such as ChatGPT, have demonstrated\nimpressive capabilities for coding tasks including writing and reasoning about\ncode. They improve upon previous neural network models of code, such as\ncode2seq or seq2seq, that already demonstrated competitive results when\nperforming tasks such as code summarization and identifying code\nvulnerabilities. However, these previous code models were shown vulnerable to\nadversarial examples, i.e. small syntactic perturbations that do not change the\nprogram's semantics, such as the inclusion of \"dead code\" through false\nconditions or the addition of inconsequential print statements, designed to\n\"fool\" the models. LLMs can also be vulnerable to the same adversarial\nperturbations but a detailed study on this concern has been lacking so far. In\nthis paper we aim to investigate the effect of adversarial perturbations on\ncoding tasks with LLMs. In particular, we study the transferability of\nadversarial examples, generated through white-box attacks on smaller code\nmodels, to LLMs. Furthermore, to make the LLMs more robust against such\nadversaries without incurring the cost of retraining, we propose prompt-based\ndefenses that involve modifying the prompt to include additional information\nsuch as examples of adversarially perturbed code and explicit instructions for\nreversing adversarial perturbations. Our experiments show that adversarial\nexamples obtained with a smaller code model are indeed transferable, weakening\nthe LLMs' performance. The proposed defenses show promise in improving the\nmodel's resilience, paving the way to more robust defensive solutions for LLMs\nin code-related applications.\n","authors":["Chi Zhang","Zifan Wang","Ravi Mangal","Matt Fredrikson","Limin Jia","Corina Pasareanu"],"pdf_url":"https://arxiv.org/pdf/2311.13445v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13443v1","updated":"2023-11-22T15:07:59Z","published":"2023-11-22T15:07:59Z","title":"Guided Flows for Generative Modeling and Decision Making","summary":"  Classifier-free guidance is a key component for improving the performance of\nconditional generative models for many downstream tasks. It drastically\nimproves the quality of samples produced, but has so far only been used for\ndiffusion models. Flow Matching (FM), an alternative simulation-free approach,\ntrains Continuous Normalizing Flows (CNFs) based on regressing vector fields.\nIt remains an open question whether classifier-free guidance can be performed\nfor Flow Matching models, and to what extent does it improve performance. In\nthis paper, we explore the usage of Guided Flows for a variety of downstream\napplications involving conditional image generation, speech synthesis, and\nreinforcement learning. In particular, we are the first to apply flow models to\nthe offline reinforcement learning setting. We also show that Guided Flows\nsignificantly improves the sample quality in image generation and zero-shot\ntext-to-speech synthesis, and can make use of drastically low amounts of\ncomputation without affecting the agent's overall performance.\n","authors":["Qinqing Zheng","Matt Le","Neta Shaul","Yaron Lipman","Aditya Grover","Ricky T. Q. Chen"],"pdf_url":"https://arxiv.org/pdf/2311.13443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13434v1","updated":"2023-11-22T14:47:54Z","published":"2023-11-22T14:47:54Z","title":"Recurrent neural networks and transfer learning for elasto-plasticity in\n  woven composites","summary":"  As a surrogate for computationally intensive meso-scale simulation of woven\ncomposites, this article presents Recurrent Neural Network (RNN) models.\nLeveraging the power of transfer learning, the initialization challenges and\nsparse data issues inherent in cyclic shear strain loads are addressed in the\nRNN models. A mean-field model generates a comprehensive data set representing\nelasto-plastic behavior. In simulations, arbitrary six-dimensional strain\nhistories are used to predict stresses under random walking as the source task\nand cyclic loading conditions as the target task. Incorporating sub-scale\nproperties enhances RNN versatility. In order to achieve accurate predictions,\nthe model uses a grid search method to tune network architecture and\nhyper-parameter configurations. The results of this study demonstrate that\ntransfer learning can be used to effectively adapt the RNN to varying strain\nconditions, which establishes its potential as a useful tool for modeling\npath-dependent responses in woven composites.\n","authors":["Ehsan Ghane","Martin Fagerström","Mohsen Mirkhalaf"],"pdf_url":"https://arxiv.org/pdf/2311.13434v1.pdf","comment":"There are 25 pages and 13 EPS images. The paper includes links to\n  supporting materials"},{"id":"http://arxiv.org/abs/2311.13431v1","updated":"2023-11-22T14:45:30Z","published":"2023-11-22T14:45:30Z","title":"Extracting individual variable information for their decoupling, direct\n  mutual information and multi-feature Granger causality","summary":"  Working with multiple variables they usually contain difficult to control\ncomplex dependencies. This article proposes extraction of their individual\ninformation, e.g. $\\overline{X|Y}$ as random variable containing information\nfrom $X$, but with removed information about $Y$, by using $(x,y)\n\\leftrightarrow (\\bar{x}=\\textrm{CDF}_{X|Y=y}(x),y)$ reversible normalization.\nOne application can be decoupling of individual information of variables:\nreversibly transform $(X_1,\\ldots,X_n)\\leftrightarrow(\\tilde{X}_1,\\ldots\n\\tilde{X}_n)$ together containing the same information, but being independent:\n$\\forall_{i\\neq j} \\tilde{X}_i\\perp \\tilde{X}_j, \\tilde{X}_i\\perp X_j$. It\nrequires detailed models of complex conditional probability distributions - it\nis generally a difficult task, but here can be done through multiple dependency\nreducing iterations, using imperfect methods (here HCR: Hierarchical\nCorrelation Reconstruction). It could be also used for direct mutual\ninformation - evaluating direct information transfer: without use of\nintermediate variables. For causality direction there is discussed\nmulti-feature Granger causality, e.g. to trace various types of individual\ninformation transfers between such decoupled variables, including propagation\ntime (delay).\n","authors":["Jarek Duda"],"pdf_url":"https://arxiv.org/pdf/2311.13431v1.pdf","comment":"3 pages, 1 figure"},{"id":"http://arxiv.org/abs/2311.10500v2","updated":"2023-11-22T14:42:12Z","published":"2023-11-17T13:01:09Z","title":"From Principle to Practice: Vertical Data Minimization for Machine\n  Learning","summary":"  Aiming to train and deploy predictive models, organizations collect large\namounts of detailed client data, risking the exposure of private information in\nthe event of a breach. To mitigate this, policymakers increasingly demand\ncompliance with the data minimization (DM) principle, restricting data\ncollection to only that data which is relevant and necessary for the task.\nDespite regulatory pressure, the problem of deploying machine learning models\nthat obey DM has so far received little attention. In this work, we address\nthis challenge in a comprehensive manner. We propose a novel vertical DM (vDM)\nworkflow based on data generalization, which by design ensures that no\nfull-resolution client data is collected during training and deployment of\nmodels, benefiting client privacy by reducing the attack surface in case of a\nbreach. We formalize and study the corresponding problem of finding\ngeneralizations that both maximize data utility and minimize empirical privacy\nrisk, which we quantify by introducing a diverse set of policy-aligned\nadversarial scenarios. Finally, we propose a range of baseline vDM algorithms,\nas well as Privacy-aware Tree (PAT), an especially effective vDM algorithm that\noutperforms all baselines across several settings. We plan to release our code\nas a publicly available library, helping advance the standardization of DM for\nmachine learning. Overall, we believe our work can help lay the foundation for\nfurther exploration and adoption of DM principles in real-world applications.\n","authors":["Robin Staab","Nikola Jovanović","Mislav Balunović","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2311.10500v2.pdf","comment":"Accepted at IEEE S&P 2024"},{"id":"http://arxiv.org/abs/2311.08936v2","updated":"2023-11-22T14:25:55Z","published":"2023-11-15T13:19:02Z","title":"Confident Naturalness Explanation (CNE): A Framework to Explain and\n  Assess Patterns Forming Naturalness","summary":"  Protected natural areas are regions that have been minimally affected by\nhuman activities such as urbanization, agriculture, and other human\ninterventions. To better understand and map the naturalness of these areas,\nmachine learning models can be used to analyze satellite imagery. Specifically,\nexplainable machine learning methods show promise in uncovering patterns that\ncontribute to the concept of naturalness within these protected environments.\nAdditionally, addressing the uncertainty inherent in machine learning models is\ncrucial for a comprehensive understanding of this concept. However, existing\napproaches have limitations. They either fail to provide explanations that are\nboth valid and objective or struggle to offer a quantitative metric that\naccurately measures the contribution of specific patterns to naturalness, along\nwith the associated confidence. In this paper, we propose a novel framework\ncalled the Confident Naturalness Explanation (CNE) framework. This framework\ncombines explainable machine learning and uncertainty quantification to assess\nand explain naturalness. We introduce a new quantitative metric that describes\nthe confident contribution of patterns to the concept of naturalness.\nFurthermore, we generate an uncertainty-aware segmentation mask for each input\nsample, highlighting areas where the model lacks knowledge. To demonstrate the\neffectiveness of our framework, we apply it to a study site in Fennoscandia\nusing two open-source satellite datasets.\n","authors":["Ahmed Emam","Mohamed Farag","Ribana Roscher"],"pdf_url":"https://arxiv.org/pdf/2311.08936v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13414v1","updated":"2023-11-22T14:20:15Z","published":"2023-11-22T14:20:15Z","title":"From Images to Connections: Can DQN with GNNs learn the Strategic Game\n  of Hex?","summary":"  The gameplay of strategic board games such as chess, Go and Hex is often\ncharacterized by combinatorial, relational structures -- capturing distinct\ninteractions and non-local patterns -- and not just images. Nonetheless, most\ncommon self-play reinforcement learning (RL) approaches simply approximate\npolicy and value functions using convolutional neural networks (CNN). A key\nfeature of CNNs is their relational inductive bias towards locality and\ntranslational invariance. In contrast, graph neural networks (GNN) can encode\nmore complicated and distinct relational structures. Hence, we investigate the\ncrucial question: Can GNNs, with their ability to encode complex connections,\nreplace CNNs in self-play reinforcement learning? To this end, we do a\ncomparison with Hex -- an abstract yet strategically rich board game -- serving\nas our experimental platform. Our findings reveal that GNNs excel at dealing\nwith long range dependency situations in game states and are less prone to\noverfitting, but also showing a reduced proficiency in discerning local\npatterns. This suggests a potential paradigm shift, signaling the use of\ngame-specific structures to reshape self-play reinforcement learning.\n","authors":["Yannik Keller","Jannis Blüml","Gopika Sudhakaran","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2311.13414v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13411v1","updated":"2023-11-22T14:16:20Z","published":"2023-11-22T14:16:20Z","title":"Bayesian inference of a new Mallows model for characterising symptom\n  sequences applied in primary progressive aphasia","summary":"  Machine learning models offer the potential to understand diverse datasets in\na data-driven way, powering insights into individual disease experiences and\nensuring equitable healthcare. In this study, we explore Bayesian inference for\ncharacterising symptom sequences, and the associated modelling challenges. We\nadapted the Mallows model to account for partial rankings and right-censored\ndata, employing custom MCMC fitting. Our evaluation, encompassing synthetic\ndata and a primary progressive aphasia dataset, highlights the model's efficacy\nin revealing mean orderings and estimating ranking variance. This holds the\npotential to enhance clinical comprehension of symptom occurrence. However, our\nwork encounters limitations concerning model scalability and small dataset\nsizes.\n","authors":["Beatrice Taylor","Cameron Shand","Chris J. D. Hardy","Neil Oxtoby"],"pdf_url":"https://arxiv.org/pdf/2311.13411v1.pdf","comment":"Extended Abstract presented at Machine Learning for Health (ML4H)\n  symposium 2023, December 10th, 2023, New Orleans, United States, 8 pages"},{"id":"http://arxiv.org/abs/2204.06450v3","updated":"2023-11-22T14:10:56Z","published":"2022-04-13T15:17:00Z","title":"The effect of speech pathology on automatic speaker verification -- a\n  large-scale study","summary":"  Navigating the challenges of data-driven speech processing, one of the\nprimary hurdles is accessing reliable pathological speech data. While public\ndatasets appear to offer solutions, they come with inherent risks of potential\nunintended exposure of patient health information via re-identification\nattacks. Using a comprehensive real-world pathological speech corpus, with over\nn=3,800 test subjects spanning various age groups and speech disorders, we\nemployed a deep-learning-driven automatic speaker verification (ASV) approach.\nThis resulted in a notable mean equal error rate (EER) of 0.89% with a standard\ndeviation of 0.06%, outstripping traditional benchmarks. Our comprehensive\nassessments demonstrate that pathological speech overall faces heightened\nprivacy breach risks compared to healthy speech. Specifically, adults with\ndysphonia are at heightened re-identification risks, whereas conditions like\ndysarthria yield results comparable to those of healthy speakers. Crucially,\nspeech intelligibility does not influence the ASV system's performance metrics.\nIn pediatric cases, particularly those with cleft lip and palate, the recording\nenvironment plays a decisive role in re-identification. Merging data across\npathological types led to a marked EER decrease, suggesting the potential\nbenefits of pathological diversity in ASV, accompanied by a logarithmic boost\nin ASV effectiveness. In essence, this research sheds light on the dynamics\nbetween pathological speech and speaker verification, emphasizing its crucial\nrole in safeguarding patient confidentiality in our increasingly digitized\nhealthcare era.\n","authors":["Soroosh Tayebi Arasteh","Tobias Weise","Maria Schuster","Elmar Noeth","Andreas Maier","Seung Hee Yang"],"pdf_url":"https://arxiv.org/pdf/2204.06450v3.pdf","comment":"Published in Scientific Reports"},{"id":"http://arxiv.org/abs/2306.00560v2","updated":"2023-11-22T14:02:07Z","published":"2023-06-01T11:20:09Z","title":"Hinge-Wasserstein: Mitigating Overconfidence in Regression by\n  Classification","summary":"  Computer vision systems that are deployed in safety-critical applications\nneed to quantify their output uncertainty. We study regression from images to\nparameter values and here it is common to detect uncertainty by predicting\nprobability distributions. In this context, we investigate the\nregression-by-classification paradigm which can represent multimodal\ndistributions, without a prior assumption on the number of modes. Through\nexperiments on a specifically designed synthetic dataset, we demonstrate that\ntraditional loss functions lead to poor probability distribution estimates and\nsevere overconfidence, in the absence of full ground truth distributions. In\norder to alleviate these issues, we propose hinge-Wasserstein -- a simple\nimprovement of the Wasserstein loss that reduces the penalty for weak secondary\nmodes during training. This enables prediction of complex distributions with\nmultiple modes, and allows training on datasets where full ground truth\ndistributions are not available. In extensive experiments, we show that the\nproposed loss leads to substantially better uncertainty estimation on two\nchallenging computer vision tasks: horizon line detection and stereo disparity\nestimation.\n","authors":["Ziliang Xiong","Arvi Jonnarth","Abdelrahman Eldesokey","Joakim Johnander","Bastian Wandt","Per-Erik Forssen"],"pdf_url":"https://arxiv.org/pdf/2306.00560v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13381v1","updated":"2023-11-22T13:20:59Z","published":"2023-11-22T13:20:59Z","title":"Confidant: Customizing Transformer-based LLMs via Collaborative Edge\n  Training","summary":"  Transformer-based large language models (LLMs) have demonstrated impressive\ncapabilities in a variety of natural language processing (NLP) tasks.\nNonetheless, it is challenging to deploy and fine-tune LLMs on mobile edge\ndevices with limited computing, memory, and energy budgets. In this paper, we\npropose Confidant, a multi-backend collaborative training framework for\ncustomizing state-of-the-art LLMs on commodity mobile devices like smartphones.\nConfidant partitions an LLM into several sub-models so that each fits into a\nmobile device's memory. A pipeline parallel training mechanism is further\ndeveloped to ensure fast and efficient distributed training. In addition, we\npropose a novel backend scheduler to allocate different attention heads to\nheterogeneous compute hardware, including mobile CPU and GPUs, to maximize the\ncompute resource utilization on each edge device. Our preliminary experimental\nresults show that Confidant achieves at most 45.3% memory reduction and 8.03x\ninference speedup in practical settings.\n","authors":["Yuhao Chen","Yuxuan Yan","Qianqian Yang","Yuanchao Shu","Shibo He","Jiming Chen"],"pdf_url":"https://arxiv.org/pdf/2311.13381v1.pdf","comment":"6 pages, 7 figures; Submitted to HotMobile 2024"},{"id":"http://arxiv.org/abs/2311.13374v1","updated":"2023-11-22T13:17:55Z","published":"2023-11-22T13:17:55Z","title":"An Empirical Study of Uncertainty Estimation Techniques for Detecting\n  Drift in Data Streams","summary":"  In safety-critical domains such as autonomous driving and medical diagnosis,\nthe reliability of machine learning models is crucial. One significant\nchallenge to reliability is concept drift, which can cause model deterioration\nover time. Traditionally, drift detectors rely on true labels, which are often\nscarce and costly. This study conducts a comprehensive empirical evaluation of\nusing uncertainty values as substitutes for error rates in detecting drifts,\naiming to alleviate the reliance on labeled post-deployment data. We examine\nfive uncertainty estimation methods in conjunction with the ADWIN detector\nacross seven real-world datasets. Our results reveal that while the SWAG method\nexhibits superior calibration, the overall accuracy in detecting drifts is not\nnotably impacted by the choice of uncertainty estimation method, with even the\nmost basic method demonstrating competitive performance. These findings offer\nvaluable insights into the practical applicability of uncertainty-based drift\ndetection in real-world, safety-critical applications.\n","authors":["Anton Winter","Nicolas Jourdan","Tristan Wirth","Volker Knauthe","Arjan Kuijper"],"pdf_url":"https://arxiv.org/pdf/2311.13374v1.pdf","comment":"NeurIPS 2023: Workshop on Distribution Shifts"},{"id":"http://arxiv.org/abs/2310.03789v2","updated":"2023-11-22T12:55:08Z","published":"2023-10-05T18:00:01Z","title":"Droplets of Good Representations: Grokking as a First Order Phase\n  Transition in Two Layer Networks","summary":"  A key property of deep neural networks (DNNs) is their ability to learn new\nfeatures during training. This intriguing aspect of deep learning stands out\nmost clearly in recently reported Grokking phenomena. While mainly reflected as\na sudden increase in test accuracy, Grokking is also believed to be a beyond\nlazy-learning/Gaussian Process (GP) phenomenon involving feature learning. Here\nwe apply a recent development in the theory of feature learning, the adaptive\nkernel approach, to two teacher-student models with cubic-polynomial and\nmodular addition teachers. We provide analytical predictions on feature\nlearning and Grokking properties of these models and demonstrate a mapping\nbetween Grokking and the theory of phase transitions. We show that after\nGrokking, the state of the DNN is analogous to the mixed phase following a\nfirst-order phase transition. In this mixed phase, the DNN generates useful\ninternal representations of the teacher that are sharply distinct from those\nbefore the transition.\n","authors":["Noa Rubin","Inbar Seroussi","Zohar Ringel"],"pdf_url":"https://arxiv.org/pdf/2310.03789v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13355v1","updated":"2023-11-22T12:47:12Z","published":"2023-11-22T12:47:12Z","title":"Unified Classification and Rejection: A One-versus-All Framework","summary":"  Classifying patterns of known classes and rejecting ambiguous and novel (also\ncalled as out-of-distribution (OOD)) inputs are involved in open world pattern\nrecognition. Deep neural network models usually excel in closed-set\nclassification while performing poorly in rejecting OOD. To tackle this\nproblem, numerous methods have been designed to perform open set recognition\n(OSR) or OOD rejection/detection tasks. Previous methods mostly take\npost-training score transformation or hybrid models to ensure low scores on OOD\ninputs while separating known classes. In this paper, we attempt to build a\nunified framework for building open set classifiers for both classification and\nOOD rejection. We formulate the open set recognition of $ K $-known-class as a\n$ (K + 1) $-class classification problem with model trained on known-class\nsamples only. By decomposing the $ K $-class problem into $ K $ one-versus-all\n(OVA) binary classification tasks and binding some parameters, we show that\ncombining the scores of OVA classifiers can give $ (K + 1) $-class posterior\nprobabilities, which enables classification and OOD rejection in a unified\nframework. To maintain the closed-set classification accuracy of the OVA\ntrained classifier, we propose a hybrid training strategy combining OVA loss\nand multi-class cross-entropy loss. We implement the OVA framework and hybrid\ntraining strategy on the recently proposed convolutional prototype network.\nExperiments on popular OSR and OOD detection datasets demonstrate that the\nproposed framework, using a single multi-class classifier, yields competitive\nperformance in closed-set classification, OOD detection, and misclassification\ndetection.\n","authors":["Zhen Cheng","Xu-Yao Zhang","Cheng-Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2311.13355v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13350v1","updated":"2023-11-22T12:39:28Z","published":"2023-11-22T12:39:28Z","title":"Fact-based Court Judgment Prediction","summary":"  This extended abstract extends the research presented in \"ILDC for CJPE:\nIndian Legal Documents Corpus for Court Judgment Prediction and Explanation\"\n\\cite{malik-etal-2021-ildc}, focusing on fact-based judgment prediction within\nthe context of Indian legal documents. We introduce two distinct problem\nvariations: one based solely on facts, and another combining facts with rulings\nfrom lower courts (RLC). Our research aims to enhance early-phase case outcome\nprediction, offering significant benefits to legal professionals and the\ngeneral public. The results, however, indicated a performance decline compared\nto the original ILDC for CJPE study, even after implementing various weightage\nschemes in our DELSumm algorithm. Additionally, using only facts for legal\njudgment prediction with different transformer models yielded results inferior\nto the state-of-the-art outcomes reported in the \"ILDC for CJPE\" study.\n","authors":["Shubham Kumar Nigam","Aniket Deroy"],"pdf_url":"https://arxiv.org/pdf/2311.13350v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04225v2","updated":"2023-11-22T12:35:08Z","published":"2023-06-07T08:02:17Z","title":"Efficient Vision Transformer for Human Pose Estimation via Patch\n  Selection","summary":"  While Convolutional Neural Networks (CNNs) have been widely successful in 2D\nhuman pose estimation, Vision Transformers (ViTs) have emerged as a promising\nalternative to CNNs, boosting state-of-the-art performance. However, the\nquadratic computational complexity of ViTs has limited their applicability for\nprocessing high-resolution images. In this paper, we propose three methods for\nreducing ViT's computational complexity, which are based on selecting and\nprocessing a small number of most informative patches while disregarding\nothers. The first two methods leverage a lightweight pose estimation network to\nguide the patch selection process, while the third method utilizes a set of\nlearnable joint tokens to ensure that the selected patches contain the most\nimportant information about body joints. Experiments across six benchmarks show\nthat our proposed methods achieve a significant reduction in computational\ncomplexity, ranging from 30% to 44%, with only a minimal drop in accuracy\nbetween 0% and 3.5%.\n","authors":["Kaleab A. Kinfu","Rene Vidal"],"pdf_url":"https://arxiv.org/pdf/2306.04225v2.pdf","comment":"BMVC 2023 Oral Paper: https://proceedings.bmvc2023.org/167/"},{"id":"http://arxiv.org/abs/2311.13349v1","updated":"2023-11-22T12:34:51Z","published":"2023-11-22T12:34:51Z","title":"REDS: Resource-Efficient Deep Subnetworks for Dynamic Resource\n  Constraints","summary":"  Deep models deployed on edge devices frequently encounter resource\nvariability, which arises from fluctuating energy levels, timing constraints,\nor prioritization of other critical tasks within the system. State-of-the-art\nmachine learning pipelines generate resource-agnostic models, not capable to\nadapt at runtime. In this work we introduce Resource-Efficient Deep Subnetworks\n(REDS) to tackle model adaptation to variable resources. In contrast to the\nstate-of-the-art, REDS use structured sparsity constructively by exploiting\npermutation invariance of neurons, which allows for hardware-specific\noptimizations. Specifically, REDS achieve computational efficiency by (1)\nskipping sequential computational blocks identified by a novel iterative\nknapsack optimizer, and (2) leveraging simple math to re-arrange the order of\noperations in REDS computational graph to take advantage of the data cache.\nREDS support conventional deep networks frequently deployed on the edge and\nprovide computational benefits even for small and simple networks. We evaluate\nREDS on six benchmark architectures trained on the Google Speech Commands,\nFMNIST and CIFAR10 datasets, and test on four off-the-shelf mobile and embedded\nhardware platforms. We provide a theoretical result and empirical evidence for\nREDS outstanding performance in terms of submodels' test set accuracy, and\ndemonstrate an adaptation time in response to dynamic resource constraints of\nunder 40$\\mu$s, utilizing a 2-layer fully-connected network on Arduino Nano 33\nBLE Sense.\n","authors":["Francesco Corti","Balz Maag","Joachim Schauer","Ulrich Pferschy","Olga Saukh"],"pdf_url":"https://arxiv.org/pdf/2311.13349v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.11494v3","updated":"2023-11-22T12:25:41Z","published":"2023-07-21T10:56:36Z","title":"Predict, Refine, Synthesize: Self-Guiding Diffusion Models for\n  Probabilistic Time Series Forecasting","summary":"  Diffusion models have achieved state-of-the-art performance in generative\nmodeling tasks across various domains. Prior works on time series diffusion\nmodels have primarily focused on developing conditional models tailored to\nspecific forecasting or imputation tasks. In this work, we explore the\npotential of task-agnostic, unconditional diffusion models for several time\nseries applications. We propose TSDiff, an unconditionally-trained diffusion\nmodel for time series. Our proposed self-guidance mechanism enables\nconditioning TSDiff for downstream tasks during inference, without requiring\nauxiliary networks or altering the training procedure. We demonstrate the\neffectiveness of our method on three different time series tasks: forecasting,\nrefinement, and synthetic data generation. First, we show that TSDiff is\ncompetitive with several task-specific conditional forecasting methods\n(predict). Second, we leverage the learned implicit probability density of\nTSDiff to iteratively refine the predictions of base forecasters with reduced\ncomputational overhead over reverse diffusion (refine). Notably, the generative\nperformance of the model remains intact -- downstream forecasters trained on\nsynthetic samples from TSDiff outperform forecasters that are trained on\nsamples from other state-of-the-art generative time series models, occasionally\neven outperforming models trained on real data (synthesize).\n","authors":["Marcel Kollovieh","Abdul Fatir Ansari","Michael Bohlke-Schneider","Jasper Zschiegner","Hao Wang","Yuyang Wang"],"pdf_url":"https://arxiv.org/pdf/2307.11494v3.pdf","comment":"Code available at\n  https://github.com/amazon-science/unconditional-time-series-diffusion"},{"id":"http://arxiv.org/abs/2311.13348v1","updated":"2023-11-22T12:25:02Z","published":"2023-11-22T12:25:02Z","title":"MergeSFL: Split Federated Learning with Feature Merging and Batch Size\n  Regulation","summary":"  Recently, federated learning (FL) has emerged as a popular technique for edge\nAI to mine valuable knowledge in edge computing (EC) systems. To mitigate the\ncomputing/communication burden on resource-constrained workers and protect\nmodel privacy, split federated learning (SFL) has been released by integrating\nboth data and model parallelism. Despite resource limitations, SFL still faces\ntwo other critical challenges in EC, i.e., statistical heterogeneity and system\nheterogeneity. To address these challenges, we propose a novel SFL framework,\ntermed MergeSFL, by incorporating feature merging and batch size regulation in\nSFL. Concretely, feature merging aims to merge the features from workers into a\nmixed feature sequence, which is approximately equivalent to the features\nderived from IID data and is employed to promote model accuracy. While batch\nsize regulation aims to assign diverse and suitable batch sizes for\nheterogeneous workers to improve training efficiency. Moreover, MergeSFL\nexplores to jointly optimize these two strategies upon their coupled\nrelationship to better enhance the performance of SFL. Extensive experiments\nare conducted on a physical platform with 80 NVIDIA Jetson edge devices, and\nthe experimental results show that MergeSFL can improve the final model\naccuracy by 5.82% to 26.22%, with a speedup by about 1.74x to 4.14x, compared\nto the baselines.\n","authors":["Yunming Liao","Yang Xu","Hongli Xu","Lun Wang","Zhiwei Yao","Chunming Qiao"],"pdf_url":"https://arxiv.org/pdf/2311.13348v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14605v2","updated":"2023-11-22T12:16:28Z","published":"2022-11-26T16:13:32Z","title":"Looking at the posterior: accuracy and uncertainty of neural-network\n  predictions","summary":"  Bayesian inference can quantify uncertainty in the predictions of neural\nnetworks using posterior distributions for model parameters and network output.\nBy looking at these posterior distributions, one can separate the origin of\nuncertainty into aleatoric and epistemic contributions. One goal of uncertainty\nquantification is to inform on prediction accuracy. Here we show that\nprediction accuracy depends on both epistemic and aleatoric uncertainty in an\nintricate fashion that cannot be understood in terms of marginalized\nuncertainty distributions alone. How the accuracy relates to epistemic and\naleatoric uncertainties depends not only on the model architecture, but also on\nthe properties of the dataset. We discuss the significance of these results for\nactive learning and introduce a novel acquisition function that outperforms\ncommon uncertainty-based methods. To arrive at our results, we approximated the\nposteriors using deep ensembles, for fully-connected, convolutional and\nattention-based neural networks.\n","authors":["H. Linander","O. Balabanov","H. Yang","B. Mehlig"],"pdf_url":"https://arxiv.org/pdf/2211.14605v2.pdf","comment":"26 pages, 10 figures, 5 tables"},{"id":"http://arxiv.org/abs/2311.08228v2","updated":"2023-11-22T12:10:39Z","published":"2023-11-14T15:08:14Z","title":"Counterfactual Explanation for Regression via Disentanglement in Latent\n  Space","summary":"  Counterfactual Explanations (CEs) help address the question: How can the\nfactors that influence the prediction of a predictive model be changed to\nachieve a more favorable outcome from a user's perspective? Thus, they bear the\npotential to guide the user's interaction with AI systems since they represent\neasy-to-understand explanations. To be applicable, CEs need to be realistic and\nactionable. In the literature, various methods have been proposed to generate\nCEs. However, the majority of research on CEs focuses on classification\nproblems where questions like \"What should I do to get my rejected loan\napproved?\" are raised. In practice, answering questions like \"What should I do\nto increase my salary?\" are of a more regressive nature. In this paper, we\nintroduce a novel method to generate CEs for a pre-trained regressor by first\ndisentangling the label-relevant from the label-irrelevant dimensions in the\nlatent space. CEs are then generated by combining the label-irrelevant\ndimensions and the predefined output. The intuition behind this approach is\nthat the ideal counterfactual search should focus on the label-irrelevant\ncharacteristics of the input and suggest changes toward target-relevant\ncharacteristics. Searching in the latent space could help achieve this goal. We\nshow that our method maintains the characteristics of the query sample during\nthe counterfactual search. In various experiments, we demonstrate that the\nproposed method is competitive based on different quality measures on image and\ntabular datasets in regression problem settings. It efficiently returns results\ncloser to the original data manifold compared to three state-of-the-art\nmethods, which is essential for realistic high-dimensional machine learning\napplications. Our code will be made available as an open-source package upon\nthe publication of this work.\n","authors":["Xuan Zhao","Klaus Broelemann","Gjergji Kasneci"],"pdf_url":"https://arxiv.org/pdf/2311.08228v2.pdf","comment":"CXAI workshop @ ICDM 2023. arXiv admin note: text overlap with\n  arXiv:2307.13390"},{"id":"http://arxiv.org/abs/2311.13341v1","updated":"2023-11-22T12:08:01Z","published":"2023-11-22T12:08:01Z","title":"Learning principle and mathematical realization of the learning\n  mechanism in the brain","summary":"  While deep learning has achieved remarkable success, there is no clear\nexplanation about why it works so well. In order to discuss this question\nquantitatively, we need a mathematical framework that explains what learning is\nin the first place. After several considerations, we succeeded in constructing\na mathematical framework that can provide a unified understanding of all types\nof learning, including deep learning and learning in the brain. We call it\nlearning principle, and it follows that all learning is equivalent to\nestimating the probability of input data. We not only derived this principle,\nbut also mentioned its application to actual machine learning models. For\nexample, we found that conventional supervised learning is equivalent to\nestimating conditional probabilities, and succeeded in making supervised\nlearning more effective and generalized. We also proposed a new method of\ndefining the values of estimated probability using differentiation, and showed\nthat unsupervised learning can be performed on arbitrary dataset without any\nprior knowledge. Namely, this method is a general-purpose machine learning in\nthe true sense. Moreover, we succeeded in describing the learning mechanism in\nthe brain by considering the time evolution of a fully or partially connected\nmodel and applying this new method. The learning principle provides solutions\nto many unsolved problems in deep learning and cognitive neuroscience.\n","authors":["Taisuke Katayose"],"pdf_url":"https://arxiv.org/pdf/2311.13341v1.pdf","comment":"31 pages, 14 figures"},{"id":"http://arxiv.org/abs/2311.13326v1","updated":"2023-11-22T11:42:50Z","published":"2023-11-22T11:42:50Z","title":"Curriculum Learning and Imitation Learning for Model-free Control on\n  Financial Time-series","summary":"  Curriculum learning and imitation learning have been leveraged extensively in\nthe robotics domain. However, minimal research has been done on leveraging\nthese ideas on control tasks over highly stochastic time-series data. Here, we\ntheoretically and empirically explore these approaches in a representative\ncontrol task over complex time-series data. We implement the fundamental ideas\nof curriculum learning via data augmentation, while imitation learning is\nimplemented via policy distillation from an oracle. Our findings reveal that\ncurriculum learning should be considered a novel direction in improving\ncontrol-task performance over complex time-series. Our ample random-seed\nout-sample empirics and ablation studies are highly encouraging for curriculum\nlearning for time-series control. These findings are especially encouraging as\nwe tune all overlapping hyperparameters on the baseline -- giving an advantage\nto the baseline. On the other hand, we find that imitation learning should be\nused with caution.\n","authors":["Woosung Koh","Insu Choi","Yuntae Jang","Gimin Kang","Woo Chang Kim"],"pdf_url":"https://arxiv.org/pdf/2311.13326v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2311.13321v1","updated":"2023-11-22T11:24:04Z","published":"2023-11-22T11:24:04Z","title":"Revisiting Supervision for Continual Representation Learning","summary":"  In the field of continual learning, models are designed to learn tasks one\nafter the other. While most research has centered on supervised continual\nlearning, recent studies have highlighted the strengths of self-supervised\ncontinual representation learning. The improved transferability of\nrepresentations built with self-supervised methods is often associated with the\nrole played by the multi-layer perceptron projector. In this work, we depart\nfrom this observation and reexamine the role of supervision in continual\nrepresentation learning. We reckon that additional information, such as human\nannotations, should not deteriorate the quality of representations. Our\nfindings show that supervised models when enhanced with a multi-layer\nperceptron head, can outperform self-supervised models in continual\nrepresentation learning.\n","authors":["Daniel Marczak","Sebastian Cygert","Tomasz Trzciński","Bartłomiej Twardowski"],"pdf_url":"https://arxiv.org/pdf/2311.13321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13319v1","updated":"2023-11-22T11:15:38Z","published":"2023-11-22T11:15:38Z","title":"Deep Learning for Vascular Segmentation and Applications in Phase\n  Contrast Tomography Imaging","summary":"  Automated blood vessel segmentation is vital for biomedical imaging, as\nvessel changes indicate many pathologies. Still, precise segmentation is\ndifficult due to the complexity of vascular structures, anatomical variations\nacross patients, the scarcity of annotated public datasets, and the quality of\nimages. We present a thorough literature review, highlighting the state of\nmachine learning techniques across diverse organs. Our goal is to provide a\nfoundation on the topic and identify a robust baseline model for application to\nvascular segmentation in a new imaging modality, Hierarchical Phase Contrast\nTomography (HiP CT). Introduced in 2020 at the European Synchrotron Radiation\nFacility, HiP CT enables 3D imaging of complete organs at an unprecedented\nresolution of ca. 20mm per voxel, with the capability for localized zooms in\nselected regions down to 1mm per voxel without sectioning. We have created a\ntraining dataset with double annotator validated vascular data from three\nkidneys imaged with HiP CT in the context of the Human Organ Atlas Project.\nFinally, utilising the nnU Net model, we conduct experiments to assess the\nmodels performance on both familiar and unseen samples, employing vessel\nspecific metrics. Our results show that while segmentations yielded reasonably\nhigh scores such as clDice values ranging from 0.82 to 0.88, certain errors\npersisted. Large vessels that collapsed due to the lack of hydrostatic pressure\n(HiP CT is an ex vivo technique) were segmented poorly. Moreover, decreased\nconnectivity in finer vessels and higher segmentation errors at vessel\nboundaries were observed. Such errors obstruct the understanding of the\nstructures by interrupting vascular tree connectivity. Through our review and\noutputs, we aim to set a benchmark for subsequent model evaluations using\nvarious modalities, especially with the HiP CT imaging database.\n","authors":["Ekin Yagis","Shahab Aslani","Yashvardhan Jain","Yang Zhou","Shahrokh Rahmani","Joseph Brunet","Alexandre Bellier","Christopher Werlein","Maximilian Ackermann","Danny Jonigk","Paul Tafforeau","Peter D Lee","Claire Walsh"],"pdf_url":"https://arxiv.org/pdf/2311.13319v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.00846v2","updated":"2023-11-22T11:02:35Z","published":"2023-09-02T07:13:47Z","title":"pSTarC: Pseudo Source Guided Target Clustering for Fully Test-Time\n  Adaptation","summary":"  Test Time Adaptation (TTA) is a pivotal concept in machine learning, enabling\nmodels to perform well in real-world scenarios, where test data distribution\ndiffers from training. In this work, we propose a novel approach called pseudo\nSource guided Target Clustering (pSTarC) addressing the relatively unexplored\narea of TTA under real-world domain shifts. This method draws inspiration from\ntarget clustering techniques and exploits the source classifier for generating\npseudo-source samples. The test samples are strategically aligned with these\npseudo-source samples, facilitating their clustering and thereby enhancing TTA\nperformance. pSTarC operates solely within the fully test-time adaptation\nprotocol, removing the need for actual source data. Experimental validation on\na variety of domain shift datasets, namely VisDA, Office-Home, DomainNet-126,\nCIFAR-100C verifies pSTarC's effectiveness. This method exhibits significant\nimprovements in prediction accuracy along with efficient computational\nrequirements. Furthermore, we also demonstrate the universality of the pSTarC\nframework by showing its effectiveness for the continuous TTA framework. The\nsource code for our method is available at https://manogna-s.github.io/pstarc\n","authors":["Manogna Sreenivas","Goirik Chakrabarty","Soma Biswas"],"pdf_url":"https://arxiv.org/pdf/2309.00846v2.pdf","comment":"Accepted in WACV 2024"},{"id":"http://arxiv.org/abs/2309.07675v2","updated":"2023-11-22T10:24:26Z","published":"2023-09-14T12:39:26Z","title":"Goal Space Abstraction in Hierarchical Reinforcement Learning via\n  Set-Based Reachability Analysis","summary":"  Open-ended learning benefits immensely from the use of symbolic methods for\ngoal representation as they offer ways to structure knowledge for efficient and\ntransferable learning. However, the existing Hierarchical Reinforcement\nLearning (HRL) approaches relying on symbolic reasoning are often limited as\nthey require a manual goal representation. The challenge in autonomously\ndiscovering a symbolic goal representation is that it must preserve critical\ninformation, such as the environment dynamics. In this paper, we propose a\ndevelopmental mechanism for goal discovery via an emergent representation that\nabstracts (i.e., groups together) sets of environment states that have similar\nroles in the task. We introduce a Feudal HRL algorithm that concurrently learns\nboth the goal representation and a hierarchical policy. The algorithm uses\nsymbolic reachability analysis for neural networks to approximate the\ntransition relation among sets of states and to refine the goal representation.\nWe evaluate our approach on complex navigation tasks, showing the learned\nrepresentation is interpretable, transferrable and results in data efficient\nlearning.\n","authors":["Mehdi Zadem","Sergio Mover","Sao Mai Nguyen"],"pdf_url":"https://arxiv.org/pdf/2309.07675v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13294v1","updated":"2023-11-22T10:23:14Z","published":"2023-11-22T10:23:14Z","title":"Probabilistic Inference in Reinforcement Learning Done Right","summary":"  A popular perspective in Reinforcement learning (RL) casts the problem as\nprobabilistic inference on a graphical model of the Markov decision process\n(MDP). The core object of study is the probability of each state-action pair\nbeing visited under the optimal policy. Previous approaches to approximate this\nquantity can be arbitrarily poor, leading to algorithms that do not implement\ngenuine statistical inference and consequently do not perform well in\nchallenging problems. In this work, we undertake a rigorous Bayesian treatment\nof the posterior probability of state-action optimality and clarify how it\nflows through the MDP. We first reveal that this quantity can indeed be used to\ngenerate a policy that explores efficiently, as measured by regret.\nUnfortunately, computing it is intractable, so we derive a new variational\nBayesian approximation yielding a tractable convex optimization problem and\nestablish that the resulting policy also explores efficiently. We call our\napproach VAPOR and show that it has strong connections to Thompson sampling,\nK-learning, and maximum entropy exploration. We conclude with some experiments\ndemonstrating the performance advantage of a deep RL version of VAPOR.\n","authors":["Jean Tarbouriech","Tor Lattimore","Brendan O'Donoghue"],"pdf_url":"https://arxiv.org/pdf/2311.13294v1.pdf","comment":"NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.13293v1","updated":"2023-11-22T10:22:59Z","published":"2023-11-22T10:22:59Z","title":"The Influence of Neural Networks on Hydropower Plant Management in\n  Agriculture: Addressing Challenges and Exploring Untapped Opportunities","summary":"  Hydropower plants are crucial for stable renewable energy and serve as vital\nwater sources for sustainable agriculture. However, it is essential to assess\nthe current water management practices associated with hydropower plant\nmanagement software. A key concern is the potential conflict between\nelectricity generation and agricultural water needs. Prioritising water for\nelectricity generation can reduce irrigation availability in agriculture during\ncrucial periods like droughts, impacting crop yields and regional food\nsecurity. Coordination between electricity and agricultural water allocation is\nnecessary to ensure optimal and environmentally sound practices. Neural\nnetworks have become valuable tools for hydropower plant management, but their\nblack-box nature raises concerns about transparency in decision making.\nAdditionally, current approaches often do not take advantage of their potential\nto create a system that effectively balances water allocation.\n  This work is a call for attention and highlights the potential risks of\ndeploying neural network-based hydropower plant management software without\nproper scrutiny and control. To address these concerns, we propose the adoption\nof the Agriculture Conscious Hydropower Plant Management framework, aiming to\nmaximise electricity production while prioritising stable irrigation for\nagriculture. We also advocate reevaluating government-imposed minimum water\nguidelines for irrigation to ensure flexibility and effective water allocation.\nAdditionally, we suggest a set of regulatory measures to promote model\ntransparency and robustness, certifying software that makes conscious and\nintelligent water allocation decisions, ultimately safeguarding agriculture\nfrom undue strain during droughts.\n","authors":["C. Coelho","M. Fernanda P. Costa","L. L. Ferrás"],"pdf_url":"https://arxiv.org/pdf/2311.13293v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13285v1","updated":"2023-11-22T10:08:33Z","published":"2023-11-22T10:08:33Z","title":"Improving performance of heart rate time series classification by\n  grouping subjects","summary":"  Unlike the more commonly analyzed ECG or PPG data for activity\nclassification, heart rate time series data is less detailed, often noisier and\ncan contain missing data points. Using the BigIdeasLab_STEP dataset, which\nincludes heart rate time series annotated with specific tasks performed by\nindividuals, we sought to determine if general classification was achievable.\nOur analyses showed that the accuracy is sensitive to the choice of\nwindow/stride size. Moreover, we found variable classification performances\nbetween subjects due to differences in the physical structure of their hearts.\nVarious techniques were used to minimize this variability. First of all,\nnormalization proved to be a crucial step and significantly improved the\nperformance. Secondly, grouping subjects and performing classification inside a\ngroup helped to improve performance and decrease inter-subject variability.\nFinally, we show that including handcrafted features as input to a deep\nlearning (DL) network improves the classification performance further.\nTogether, these findings indicate that heart rate time series can be utilized\nfor classification tasks like predicting activity. However, normalization or\ngrouping techniques need to be chosen carefully to minimize the issue of\nsubject variability.\n","authors":["Michael Beekhuizen","Arman Naseri","David Tax","Ivo van der Bilt","Marcel Reinders"],"pdf_url":"https://arxiv.org/pdf/2311.13285v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.20477v2","updated":"2023-11-22T09:57:54Z","published":"2023-10-31T14:10:30Z","title":"Exploring Practitioner Perspectives On Training Data Attribution\n  Explanations","summary":"  Explainable AI (XAI) aims to provide insight into opaque model reasoning to\nhumans and as such is an interdisciplinary field by nature. In this paper, we\ninterviewed 10 practitioners to understand the possible usability of training\ndata attribution (TDA) explanations and to explore the design space of such an\napproach. We confirmed that training data quality is often the most important\nfactor for high model performance in practice and model developers mainly rely\non their own experience to curate data. End-users expect explanations to\nenhance their interaction with the model and do not necessarily prioritise but\nare open to training data as a means of explanation. Within our participants,\nwe found that TDA explanations are not well-known and therefore not used. We\nurge the community to focus on the utility of TDA techniques from the\nhuman-machine collaboration perspective and broaden the TDA evaluation to\nreflect common use cases in practice.\n","authors":["Elisa Nguyen","Evgenii Kortukov","Jean Y. Song","Seong Joon Oh"],"pdf_url":"https://arxiv.org/pdf/2310.20477v2.pdf","comment":"Accepted to NeurIPS XAI in Action workshop 2023"},{"id":"http://arxiv.org/abs/2311.13279v1","updated":"2023-11-22T09:55:20Z","published":"2023-11-22T09:55:20Z","title":"Comprehensive Evaluation of GNN Training Systems: A Data Management\n  Perspective","summary":"  Many Graph Neural Network (GNN) training systems have emerged recently to\nsupport efficient GNN training. Since GNNs embody complex data dependencies\nbetween training samples, the training of GNNs should address distinct\nchallenges different from DNN training in data management, such as data\npartitioning, batch preparation for mini-batch training, and data transferring\nbetween CPUs and GPUs. These factors, which take up a large proportion of\ntraining time, make data management in GNN training more significant. This\npaper reviews GNN training from a data management perspective and provides a\ncomprehensive analysis and evaluation of the representative approaches. We\nconduct extensive experiments on various benchmark datasets and show many\ninteresting and valuable results. We also provide some practical tips learned\nfrom these experiments, which are helpful for designing GNN training systems in\nthe future.\n","authors":["Hao Yuan","Yajiong Liu","Yanfeng Zhang","Xin Ai","Qiange Wang","Chaoyi Chen","Yu Gu","Ge Yu"],"pdf_url":"https://arxiv.org/pdf/2311.13279v1.pdf","comment":"12 pages, 17 figures"},{"id":"http://arxiv.org/abs/2311.12550v2","updated":"2023-11-22T09:45:11Z","published":"2023-11-21T11:59:16Z","title":"Explainable Anomaly Detection using Masked Latent Generative Modeling","summary":"  We present a novel time series anomaly detection method that achieves\nexcellent detection accuracy while offering a superior level of explainability.\nOur proposed method, TimeVQVAE-AD, leverages masked generative modeling adapted\nfrom the cutting-edge time series generation method known as TimeVQVAE. The\nprior model is trained on the discrete latent space of a time-frequency domain.\nNotably, the dimensional semantics of the time-frequency domain are preserved\nin the latent space, enabling us to compute anomaly scores across different\nfrequency bands, which provides a better insight into the detected anomalies.\nAdditionally, the generative nature of the prior model allows for sampling\nlikely normal states for detected anomalies, enhancing the explainability of\nthe detected anomalies through counterfactuals. Our experimental evaluation on\nthe UCR Time Series Anomaly archive demonstrates that TimeVQVAE-AD\nsignificantly surpasses the existing methods in terms of detection accuracy and\nexplainability.\n","authors":["Daesoo Lee","Sara Malacarne","Erlend Aune"],"pdf_url":"https://arxiv.org/pdf/2311.12550v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12526v2","updated":"2023-11-22T09:39:02Z","published":"2023-11-21T11:12:03Z","title":"Neural Network Pruning by Gradient Descent","summary":"  The rapid increase in the parameters of deep learning models has led to\nsignificant costs, challenging computational efficiency and model\ninterpretability. In this paper, we introduce a novel and straightforward\nneural network pruning framework that incorporates the Gumbel-Softmax\ntechnique. This framework enables the simultaneous optimization of a network's\nweights and topology in an end-to-end process using stochastic gradient\ndescent. Empirical results demonstrate its exceptional compression capability,\nmaintaining high accuracy on the MNIST dataset with only 0.15\\% of the original\nnetwork parameters. Moreover, our framework enhances neural network\ninterpretability, not only by allowing easy extraction of feature importance\ndirectly from the pruned network but also by enabling visualization of feature\nsymmetry and the pathways of information propagation from features to outcomes.\nAlthough the pruning strategy is learned through deep learning, it is\nsurprisingly intuitive and understandable, focusing on selecting key\nrepresentative features and exploiting data patterns to achieve extreme sparse\npruning. We believe our method opens a promising new avenue for deep learning\npruning and the creation of interpretable machine learning systems.\n","authors":["Zhang Zhang","Ruyi Tao","Jiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12526v2.pdf","comment":"21 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.13267v1","updated":"2023-11-22T09:37:33Z","published":"2023-11-22T09:37:33Z","title":"FedFN: Feature Normalization for Alleviating Data Heterogeneity Problem\n  in Federated Learning","summary":"  Federated Learning (FL) is a collaborative method for training models while\npreserving data privacy in decentralized settings. However, FL encounters\nchallenges related to data heterogeneity, which can result in performance\ndegradation. In our study, we observe that as data heterogeneity increases,\nfeature representation in the FedAVG model deteriorates more significantly\ncompared to classifier weight. Additionally, we observe that as data\nheterogeneity increases, the gap between higher feature norms for observed\nclasses, obtained from local models, and feature norms of unobserved classes\nwidens, in contrast to the behavior of classifier weight norms. This widening\ngap extends to encompass the feature norm disparities between local and the\nglobal models. To address these issues, we introduce Federated Averaging with\nFeature Normalization Update (FedFN), a straightforward learning method. We\ndemonstrate the superior performance of FedFN through extensive experiments,\neven when applied to pretrained ResNet18. Subsequently, we confirm the\napplicability of FedFN to foundation models.\n","authors":["Seongyoon Kim","Gihun Lee","Jaehoon Oh","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2311.13267v1.pdf","comment":"NeurIPS Workshop: \"Federated Learning in the Age of Foundation\n  Models\" 2023"},{"id":"http://arxiv.org/abs/2311.13265v1","updated":"2023-11-22T09:31:19Z","published":"2023-11-22T09:31:19Z","title":"Improved identification accuracy in equation learning via comprehensive\n  $\\boldsymbol{R^2}$-elimination and Bayesian model selection","summary":"  In the field of equation learning, exhaustively considering all possible\nequations derived from a basis function dictionary is infeasible. Sparse\nregression and greedy algorithms have emerged as popular approaches to tackle\nthis challenge. However, the presence of multicollinearity poses difficulties\nfor sparse regression techniques, and greedy steps may inadvertently exclude\nterms of the true equation, leading to reduced identification accuracy. In this\narticle, we present an approach that strikes a balance between\ncomprehensiveness and efficiency in equation learning. Inspired by stepwise\nregression, our approach combines the coefficient of determination, $R^2$, and\nthe Bayesian model evidence, $p(\\boldsymbol y|\\mathcal M)$, in a novel way. Our\nprocedure is characterized by a comprehensive search with just a minor\nreduction of the model space at each iteration step. With two flavors of our\napproach and the adoption of $p(\\boldsymbol y|\\mathcal M)$ for bi-directional\nstepwise regression, we present a total of three new avenues for equation\nlearning. Through three extensive numerical experiments involving random\npolynomials and dynamical systems, we compare our approach against four\nstate-of-the-art methods and two standard approaches. The results demonstrate\nthat our comprehensive search approach surpasses all other methods in terms of\nidentification accuracy. In particular, the second flavor of our approach\nestablishes an efficient overfitting penalty solely based on $R^2$, which\nachieves highest rates of exact equation recovery.\n","authors":["Daniel Nickelsen","Bubacarr Bah"],"pdf_url":"https://arxiv.org/pdf/2311.13265v1.pdf","comment":"12 pages main text and 11 pages appendix, accepted in Transactions on\n  Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2311.13261v1","updated":"2023-11-22T09:25:08Z","published":"2023-11-22T09:25:08Z","title":"Immunohistochemistry guided segmentation of benign epithelial cells, in\n  situ lesions, and invasive epithelial cells in breast cancer slides","summary":"  Digital pathology enables automatic analysis of histopathological sections\nusing artificial intelligence (AI). Automatic evaluation could improve\ndiagnostic efficiency and help find associations between morphological features\nand clinical outcome. For development of such prediction models, identifying\ninvasive epithelial cells, and separating these from benign epithelial cells\nand in situ lesions would be the first step. In this study, we aimed to develop\nan AI model for segmentation of epithelial cells in sections from breast\ncancer. We generated epithelial ground truth masks by restaining hematoxylin\nand eosin (HE) sections with cytokeratin (CK) AE1/AE3, and by pathologists'\nannotations. HE/CK image pairs were used to train a convolutional neural\nnetwork, and data augmentation was used to make the model more robust. Tissue\nmicroarrays (TMAs) from 839 patients, and whole slide images from two patients\nwere used for training and evaluation of the models. The sections were derived\nfrom four cohorts of breast cancer patients. TMAs from 21 patients from a fifth\ncohort was used as a second test set. In quantitative evaluation, a mean Dice\nscore of 0.70, 0.79, and 0.75 for invasive epithelial cells, benign epithelial\ncells, and in situ lesions, respectively, were achieved. In qualitative scoring\n(0-5) by pathologists, results were best for all epithelium and invasive\nepithelium, with scores of 4.7 and 4.4. Scores for benign epithelium and in\nsitu lesions were 3.7 and 2.0. The proposed model segmented epithelial cells in\nHE stained breast cancer slides well, but further work is needed for accurate\ndivision between the classes. Immunohistochemistry, together with pathologists'\nannotations, enabled the creation of accurate ground truths. The model is made\nfreely available in FastPathology and the code is available at\nhttps://github.com/AICAN-Research/breast-epithelium-segmentation\n","authors":["Maren Høibø","André Pedersen","Vibeke Grotnes Dale","Sissel Marie Berget","Borgny Ytterhus","Cecilia Lindskog","Elisabeth Wik","Lars A. Akslen","Ingerid Reinertsen","Erik Smistad","Marit Valla"],"pdf_url":"https://arxiv.org/pdf/2311.13261v1.pdf","comment":"19 pages, 6 figures. Submitted to a scientific journal"},{"id":"http://arxiv.org/abs/2311.13258v1","updated":"2023-11-22T09:23:34Z","published":"2023-11-22T09:23:34Z","title":"ViStruct: Visual Structural Knowledge Extraction via Curriculum Guided\n  Code-Vision Representation","summary":"  State-of-the-art vision-language models (VLMs) still have limited performance\nin structural knowledge extraction, such as relations between objects. In this\nwork, we present ViStruct, a training framework to learn VLMs for effective\nvisual structural knowledge extraction. Two novel designs are incorporated.\nFirst, we propose to leverage the inherent structure of programming language to\ndepict visual structural information. This approach enables explicit and\nconsistent representation of visual structural information of multiple\ngranularities, such as concepts, relations, and events, in a well-organized\nstructured format. Second, we introduce curriculum-based learning for VLMs to\nprogressively comprehend visual structures, from fundamental visual concepts to\nintricate event structures. Our intuition is that lower-level knowledge may\ncontribute to complex visual structure understanding. Furthermore, we compile\nand release a collection of datasets tailored for visual structural knowledge\nextraction. We adopt a weakly-supervised approach to directly generate visual\nevent structures from captions for ViStruct training, capitalizing on abundant\nimage-caption pairs from the web. In experiments, we evaluate ViStruct on\nvisual structure prediction tasks, demonstrating its effectiveness in improving\nthe understanding of visual structures. The code is public at\n\\url{https://github.com/Yangyi-Chen/vi-struct}.\n","authors":["Yangyi Chen","Xingyao Wang","Manling Li","Derek Hoiem","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2311.13258v1.pdf","comment":"Accepted to EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.13250v1","updated":"2023-11-22T09:12:50Z","published":"2023-11-22T09:12:50Z","title":"Towards Hetero-Client Federated Multi-Task Learning","summary":"  Federated Learning (FL) enables joint training across distributed clients\nusing their local data privately. Federated Multi-Task Learning (FMTL) builds\non FL to handle multiple tasks, assuming model congruity that identical model\narchitecture is deployed in each client. To relax this assumption and thus\nextend real-world applicability, we introduce a novel problem setting,\nHetero-Client Federated Multi-Task Learning (HC-FMTL), to accommodate diverse\ntask setups. The main challenge of HC-FMTL is the model incongruity issue that\ninvalidates conventional aggregation methods. It also escalates the\ndifficulties in accurate model aggregation to deal with data and task\nheterogeneity inherent in FMTL. To address these challenges, we propose the\nFedHCA$^2$ framework, which allows for federated training of personalized\nmodels by modeling relationships among heterogeneous clients. Drawing on our\ntheoretical insights into the difference between multi-task and federated\noptimization, we propose the Hyper Conflict-Averse Aggregation scheme to\nmitigate conflicts during encoder updates. Additionally, inspired by task\ninteraction in MTL, the Hyper Cross Attention Aggregation scheme uses\nlayer-wise cross attention to enhance decoder interactions while alleviating\nmodel incongruity. Moreover, we employ learnable Hyper Aggregation Weights for\neach client to customize personalized parameter updates. Extensive experiments\ndemonstrate the superior performance of FedHCA$^2$ in various HC-FMTL scenarios\ncompared to representative methods. Our code will be made publicly available.\n","authors":["Yuxiang Lu","Suizhi Huang","Yuwen Yang","Shalayiding Sirejiding","Yue Ding","Hongtao Lu"],"pdf_url":"https://arxiv.org/pdf/2311.13250v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2006.09365v6","updated":"2023-11-22T09:08:15Z","published":"2020-06-16T17:58:53Z","title":"Byzantine-Robust Learning on Heterogeneous Datasets via Bucketing","summary":"  In Byzantine robust distributed or federated learning, a central server wants\nto train a machine learning model over data distributed across multiple\nworkers. However, a fraction of these workers may deviate from the prescribed\nalgorithm and send arbitrary messages. While this problem has received\nsignificant attention recently, most current defenses assume that the workers\nhave identical data. For realistic cases when the data across workers are\nheterogeneous (non-iid), we design new attacks which circumvent current\ndefenses, leading to significant loss of performance. We then propose a simple\nbucketing scheme that adapts existing robust algorithms to heterogeneous\ndatasets at a negligible computational cost. We also theoretically and\nexperimentally validate our approach, showing that combining bucketing with\nexisting robust algorithms is effective against challenging attacks. Our work\nis the first to establish guaranteed convergence for the non-iid Byzantine\nrobust problem under realistic assumptions.\n","authors":["Sai Praneeth Karimireddy","Lie He","Martin Jaggi"],"pdf_url":"https://arxiv.org/pdf/2006.09365v6.pdf","comment":"v5 is the camera-ready version of this paper on ICLR 2022"},{"id":"http://arxiv.org/abs/2305.15851v3","updated":"2023-11-22T09:02:40Z","published":"2023-05-25T08:43:11Z","title":"On sampling determinantal and Pfaffian point processes on a quantum\n  computer","summary":"  DPPs were introduced by Macchi as a model in quantum optics the 1970s. Since\nthen, they have been widely used as models and subsampling tools in statistics\nand computer science. Most applications require sampling from a DPP, and given\ntheir quantum origin, it is natural to wonder whether sampling a DPP on a\nquantum computer is easier than on a classical one. We focus here on DPPs over\na finite state space, which are distributions over the subsets of\n$\\{1,\\dots,N\\}$ parametrized by an $N\\times N$ Hermitian kernel matrix. Vanilla\nsampling consists in two steps, of respective costs $\\mathcal{O}(N^3)$ and\n$\\mathcal{O}(Nr^2)$ operations on a classical computer, where $r$ is the rank\nof the kernel matrix. A large first part of the current paper consists in\nexplaining why the state-of-the-art in quantum simulation of fermionic systems\nalready yields quantum DPP sampling algorithms. We then modify existing quantum\ncircuits, and discuss their insertion in a full DPP sampling pipeline that\nstarts from practical kernel specifications. The bottom line is that, with $P$\n(classical) parallel processors, we can divide the preprocessing cost by $P$\nand build a quantum circuit with $\\mathcal{O}(Nr)$ gates that sample a given\nDPP, with depth varying from $\\mathcal{O}(N)$ to $\\mathcal{O}(r\\log N)$\ndepending on qubit-communication constraints on the target machine. We also\nconnect existing work on the simulation of superconductors to Pfaffian point\nprocesses, which generalize DPPs and would be a natural addition to the machine\nlearner's toolbox. In particular, we describe \"projective\" Pfaffian point\nprocesses, the cardinality of which has constant parity, almost surely.\nFinally, the circuits are empirically validated on a classical simulator and on\n5-qubit IBM machines.\n","authors":["Rémi Bardenet","Michaël Fanuel","Alexandre Feller"],"pdf_url":"https://arxiv.org/pdf/2305.15851v3.pdf","comment":"53 pages, 9 figures. Additional results about parity of cardinality\n  of PfPP samples. Minor corrections in Section 5 and slight generalization of\n  Lemma 5.4. Extra example and derivations in appendix"},{"id":"http://arxiv.org/abs/2311.13244v1","updated":"2023-11-22T09:02:04Z","published":"2023-11-22T09:02:04Z","title":"Hard Label Black Box Node Injection Attack on Graph Neural Networks","summary":"  While graph neural networks have achieved state-of-the-art performances in\nmany real-world tasks including graph classification and node classification,\nrecent works have demonstrated they are also extremely vulnerable to\nadversarial attacks. Most previous works have focused on attacking node\nclassification networks under impractical white-box scenarios. In this work, we\nwill propose a non-targeted Hard Label Black Box Node Injection Attack on Graph\nNeural Networks, which to the best of our knowledge, is the first of its kind.\nUnder this setting, more real world tasks can be studied because our attack\nassumes no prior knowledge about (1): the model architecture of the GNN we are\nattacking; (2): the model's gradients; (3): the output logits of the target GNN\nmodel. Our attack is based on an existing edge perturbation attack, from which\nwe restrict the optimization process to formulate a node injection attack. In\nthe work, we will evaluate the performance of the attack using three datasets,\nCOIL-DEL, IMDB-BINARY, and NCI1.\n","authors":["Yu Zhou","Zihao Dong","Guofeng Zhang","Jingchen Tang"],"pdf_url":"https://arxiv.org/pdf/2311.13244v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.01483v2","updated":"2023-11-22T08:55:37Z","published":"2023-11-02T14:47:06Z","title":"FedSN: A General Federated Learning Framework over LEO Satellite\n  Networks","summary":"  Recently, a large number of Low Earth Orbit (LEO) satellites have been\nlaunched and deployed successfully in space by commercial companies, such as\nSpaceX. Due to multimodal sensors equipped by the LEO satellites, they serve\nnot only for communication but also for various machine learning applications,\nsuch as space modulation recognition, remote sensing image classification, etc.\nHowever, the ground station (GS) may be incapable of downloading such a large\nvolume of raw sensing data for centralized model training due to the limited\ncontact time with LEO satellites (e.g. 5 minutes). Therefore, federated\nlearning (FL) has emerged as the promising solution to address this problem via\non-device training. Unfortunately, to enable FL on LEO satellites, we still\nface three critical challenges that are i) heterogeneous computing and memory\ncapabilities, ii) limited uplink rate, and iii) model staleness. To this end,\nwe propose FedSN as a general FL framework to tackle the above challenges, and\nfully explore data diversity on LEO satellites. Specifically, we first present\na novel sub-structure scheme to enable heterogeneous local model training\nconsidering different computing, memory, and communication constraints on LEO\nsatellites. Additionally, we propose a pseudo-synchronous model aggregation\nstrategy to dynamically schedule model aggregation for compensating model\nstaleness. To further demonstrate the effectiveness of the FedSN, we evaluate\nit using space modulation recognition and remote sensing image classification\ntasks by leveraging the data from real-world satellite networks. Extensive\nexperimental results demonstrate that FedSN framework achieves higher accuracy,\nlower computing, and communication overhead than the state-of-the-art\nbenchmarks and the effectiveness of each components in FedSN.\n","authors":["Zheng Lin","Zhe Chen","Zihan Fang","Xianhao Chen","Xiong Wang","Yue Gao"],"pdf_url":"https://arxiv.org/pdf/2311.01483v2.pdf","comment":"14 pages, 17 figures"},{"id":"http://arxiv.org/abs/2311.12538v2","updated":"2023-11-22T08:44:34Z","published":"2023-11-21T11:33:03Z","title":"In-Context Learning Functions with Varying Number of Minima","summary":"  Large Language Models (LLMs) have proven effective at In-Context Learning\n(ICL), an ability that allows them to create predictors from labeled examples.\nFew studies have explored the interplay between ICL and specific properties of\nfunctions it attempts to approximate. In our study, we use a formal framework\nto explore ICL and propose a new task of approximating functions with varying\nnumber of minima. We implement a method that allows for producing functions\nwith given inputs as minima. We find that increasing the number of minima\ndegrades ICL performance. At the same time, our evaluation shows that ICL\noutperforms 2-layer Neural Network (2NN) model. Furthermore, ICL learns faster\nthan 2NN in all settings. We validate the findings through a set of few-shot\nexperiments across various hyperparameter configurations.\n","authors":["David Oniani","Yanshan Wang"],"pdf_url":"https://arxiv.org/pdf/2311.12538v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13231v1","updated":"2023-11-22T08:42:46Z","published":"2023-11-22T08:42:46Z","title":"Using Human Feedback to Fine-tune Diffusion Models without Any Reward\n  Model","summary":"  Using reinforcement learning with human feedback (RLHF) has shown significant\npromise in fine-tuning diffusion models. Previous methods start by training a\nreward model that aligns with human preferences, then leverage RL techniques to\nfine-tune the underlying models. However, crafting an efficient reward model\ndemands extensive datasets, optimal architecture, and manual hyperparameter\ntuning, making the process both time and cost-intensive. The direct preference\noptimization (DPO) method, effective in fine-tuning large language models,\neliminates the necessity for a reward model. However, the extensive GPU memory\nrequirement of the diffusion model's denoising process hinders the direct\napplication of the DPO method. To address this issue, we introduce the Direct\nPreference for Denoising Diffusion Policy Optimization (D3PO) method to\ndirectly fine-tune diffusion models. The theoretical analysis demonstrates that\nalthough D3PO omits training a reward model, it effectively functions as the\noptimal reward model trained using human feedback data to guide the learning\nprocess. This approach requires no training of a reward model, proving to be\nmore direct, cost-effective, and minimizing computational overhead. In\nexperiments, our method uses the relative scale of objectives as a proxy for\nhuman preference, delivering comparable results to methods using ground-truth\nrewards. Moreover, D3PO demonstrates the ability to reduce image distortion\nrates and generate safer images, overcoming challenges lacking robust reward\nmodels.\n","authors":["Kai Yang","Jian Tao","Jiafei Lyu","Chunjiang Ge","Jiaxin Chen","Qimai Li","Weihan Shen","Xiaolong Zhu","Xiu Li"],"pdf_url":"https://arxiv.org/pdf/2311.13231v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13225v1","updated":"2023-11-22T08:26:42Z","published":"2023-11-22T08:26:42Z","title":"NeutronOrch: Rethinking Sample-based GNN Training under CPU-GPU\n  Heterogeneous Environments","summary":"  Graph Neural Networks (GNNs) have demonstrated outstanding performance in\nvarious applications. Existing frameworks utilize CPU-GPU heterogeneous\nenvironments to train GNN models and integrate mini-batch and sampling\ntechniques to overcome the GPU memory limitation. In CPU-GPU heterogeneous\nenvironments, we can divide sample-based GNN training into three steps: sample,\ngather, and train. Existing GNN systems use different task orchestrating\nmethods to employ each step on CPU or GPU. After extensive experiments and\nanalysis, we find that existing task orchestrating methods fail to fully\nutilize the heterogeneous resources, limited by inefficient CPU processing or\nGPU resource contention. In this paper, we propose NeutronOrch, a system for\nsample-based GNN training that incorporates a layer-based task orchestrating\nmethod and ensures balanced utilization of the CPU and GPU. NeutronOrch\ndecouples the training process by layer and pushes down the training task of\nthe bottom layer to the CPU. This significantly reduces the computational load\nand memory footprint of GPU training. To avoid inefficient CPU processing,\nNeutronOrch only offloads the training of frequently accessed vertices to the\nCPU and lets GPU reuse their embeddings with bounded staleness. Furthermore,\nNeutronOrch provides a fine-grained pipeline design for the layer-based task\norchestrating method, fully overlapping different tasks on heterogeneous\nresources while strictly guaranteeing bounded staleness. The experimental\nresults show that compared with the state-of-the-art GNN systems, NeutronOrch\ncan achieve up to 4.61x performance speedup.\n","authors":["Xin Ai","Qiange Wang","Chunyu Cao","Yanfeng Zhang","Chaoyi Chen","Hao Yuan","Yu Gu","Ge Yu"],"pdf_url":"https://arxiv.org/pdf/2311.13225v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.10209v5","updated":"2023-11-22T08:08:14Z","published":"2022-02-21T13:35:03Z","title":"Degree-Preserving Randomized Response for Graph Neural Networks under\n  Local Differential Privacy","summary":"  Differentially private GNNs (Graph Neural Networks) have been recently\nstudied to provide high accuracy in various tasks on graph data while strongly\nprotecting user privacy. In particular, a recent study proposes an algorithm to\nprotect each user's feature vector in an attributed graph with LDP (Local\nDifferential Privacy), a strong privacy notion without a trusted third party.\nHowever, this algorithm does not protect edges (friendships) in a social graph,\nhence cannot protect user privacy in unattributed graphs. How to provide strong\nprivacy with high accuracy in unattributed graphs remains open.\n  In this paper, we propose a novel LDP algorithm called the DPRR\n(Degree-Preserving Randomized Response) to provide LDP for edges in GNNs. Our\nDPRR preserves each user's degree hence a graph structure while providing edge\nLDP. Technically, our DPRR uses Warner's RR (Randomized Response) and strategic\nedge sampling, where each user's sampling probability is automatically tuned\nusing the Laplacian mechanism to preserve the degree information under edge\nLDP. We also propose a privacy budget allocation method to make the noise in\nboth Warner's RR and the Laplacian mechanism small. We focus on graph\nclassification as a task of GNNs and evaluate the DPRR using three social graph\ndatasets. Our experimental results show that the DPRR significantly outperforms\nthree baselines and provides accuracy close to a non-private algorithm in all\ndatasets with a reasonable privacy budget, e.g., epsilon=1.\n","authors":["Seira Hidano","Takao Murakami"],"pdf_url":"https://arxiv.org/pdf/2202.10209v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.16213v2","updated":"2023-11-22T07:34:38Z","published":"2023-05-25T16:19:18Z","title":"ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with\n  Variational Score Distillation","summary":"  Score distillation sampling (SDS) has shown great promise in text-to-3D\ngeneration by distilling pretrained large-scale text-to-image diffusion models,\nbut suffers from over-saturation, over-smoothing, and low-diversity problems.\nIn this work, we propose to model the 3D parameter as a random variable instead\nof a constant as in SDS and present variational score distillation (VSD), a\nprincipled particle-based variational framework to explain and address the\naforementioned issues in text-to-3D generation. We show that SDS is a special\ncase of VSD and leads to poor samples with both small and large CFG weights. In\ncomparison, VSD works well with various CFG weights as ancestral sampling from\ndiffusion models and simultaneously improves the diversity and sample quality\nwith a common CFG weight (i.e., $7.5$). We further present various improvements\nin the design space for text-to-3D such as distillation time schedule and\ndensity initialization, which are orthogonal to the distillation algorithm yet\nnot well explored. Our overall approach, dubbed ProlificDreamer, can generate\nhigh rendering resolution (i.e., $512\\times512$) and high-fidelity NeRF with\nrich structure and complex effects (e.g., smoke and drops). Further,\ninitialized from NeRF, meshes fine-tuned by VSD are meticulously detailed and\nphoto-realistic. Project page and codes:\nhttps://ml.cs.tsinghua.edu.cn/prolificdreamer/\n","authors":["Zhengyi Wang","Cheng Lu","Yikai Wang","Fan Bao","Chongxuan Li","Hang Su","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2305.16213v2.pdf","comment":"NeurIPS 2023 (Spotlight)"},{"id":"http://arxiv.org/abs/2305.14032v4","updated":"2023-11-22T07:01:36Z","published":"2023-05-23T13:04:07Z","title":"Patch-Mix Contrastive Learning with Audio Spectrogram Transformer on\n  Respiratory Sound Classification","summary":"  Respiratory sound contains crucial information for the early diagnosis of\nfatal lung diseases. Since the COVID-19 pandemic, there has been a growing\ninterest in contact-free medical care based on electronic stethoscopes. To this\nend, cutting-edge deep learning models have been developed to diagnose lung\ndiseases; however, it is still challenging due to the scarcity of medical data.\nIn this study, we demonstrate that the pretrained model on large-scale visual\nand audio datasets can be generalized to the respiratory sound classification\ntask. In addition, we introduce a straightforward Patch-Mix augmentation, which\nrandomly mixes patches between different samples, with Audio Spectrogram\nTransformer (AST). We further propose a novel and effective Patch-Mix\nContrastive Learning to distinguish the mixed representations in the latent\nspace. Our method achieves state-of-the-art performance on the ICBHI dataset,\noutperforming the prior leading score by an improvement of 4.08%.\n","authors":["Sangmin Bae","June-Woo Kim","Won-Yang Cho","Hyerim Baek","Soyoun Son","Byungjo Lee","Changwan Ha","Kyongpil Tae","Sungnyun Kim","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2305.14032v4.pdf","comment":"INTERSPEECH 2023, Code URL:\n  https://github.com/raymin0223/patch-mix_contrastive_learning"},{"id":"http://arxiv.org/abs/2311.12198v2","updated":"2023-11-22T06:46:18Z","published":"2023-11-20T21:34:52Z","title":"PhysGaussian: Physics-Integrated 3D Gaussians for Generative Dynamics","summary":"  We introduce PhysGaussian, a new method that seamlessly integrates physically\ngrounded Newtonian dynamics within 3D Gaussians to achieve high-quality novel\nmotion synthesis. Employing a custom Material Point Method (MPM), our approach\nenriches 3D Gaussian kernels with physically meaningful kinematic deformation\nand mechanical stress attributes, all evolved in line with continuum mechanics\nprinciples. A defining characteristic of our method is the seamless integration\nbetween physical simulation and visual rendering: both components utilize the\nsame 3D Gaussian kernels as their discrete representations. This negates the\nnecessity for triangle/tetrahedron meshing, marching cubes, \"cage meshes,\" or\nany other geometry embedding, highlighting the principle of \"what you see is\nwhat you simulate (WS$^2$).\" Our method demonstrates exceptional versatility\nacross a wide variety of materials--including elastic entities, metals,\nnon-Newtonian fluids, and granular materials--showcasing its strong\ncapabilities in creating diverse visual content with novel viewpoints and\nmovements. Our project page is at: https://xpandora.github.io/PhysGaussian/\n","authors":["Tianyi Xie","Zeshun Zong","Yuxing Qiu","Xuan Li","Yutao Feng","Yin Yang","Chenfanfu Jiang"],"pdf_url":"https://arxiv.org/pdf/2311.12198v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13188v1","updated":"2023-11-22T06:30:54Z","published":"2023-11-22T06:30:54Z","title":"Cracking the Code of Negative Transfer: A Cooperative Game Theoretic\n  Approach for Cross-Domain Sequential Recommendation","summary":"  This paper investigates Cross-Domain Sequential Recommendation (CDSR), a\npromising method that uses information from multiple domains (more than three)\nto generate accurate and diverse recommendations, and takes into account the\nsequential nature of user interactions. The effectiveness of these systems\noften depends on the complex interplay among the multiple domains. In this\ndynamic landscape, the problem of negative transfer arises, where heterogeneous\nknowledge between dissimilar domains leads to performance degradation due to\ndifferences in user preferences across these domains. As a remedy, we propose a\nnew CDSR framework that addresses the problem of negative transfer by assessing\nthe extent of negative transfer from one domain to another and adaptively\nassigning low weight values to the corresponding prediction losses. To this\nend, the amount of negative transfer is estimated by measuring the marginal\ncontribution of each domain to model performance based on a cooperative game\ntheory. In addition, a hierarchical contrastive learning approach that\nincorporates information from the sequence of coarse-level categories into that\nof fine-level categories (e.g., item level) when implementing contrastive\nlearning was developed to mitigate negative transfer. Despite the potentially\nlow relevance between domains at the fine-level, there may be higher relevance\nat the category level due to its generalised and broader preferences. We show\nthat our model is superior to prior works in terms of model performance on two\nreal-world datasets across ten different domains.\n","authors":["Chung Park","Taesan Kim","Taekyoon Choi","Junui Hong","Yelim Yu","Mincheol Cho","Kyunam Lee","Sungil Ryu","Hyungjun Yoon","Minsung Choi","Jaegul Choo"],"pdf_url":"https://arxiv.org/pdf/2311.13188v1.pdf","comment":"Accepted at 32nd ACM International Conference on Information and\n  Knowledge Management (CIKM 2023)"},{"id":"http://arxiv.org/abs/2311.13184v1","updated":"2023-11-22T06:23:18Z","published":"2023-11-22T06:23:18Z","title":"AS-LLM: When Algorithm Selection Meets Large Language Model","summary":"  Algorithm selection aims to identify the most suitable algorithm for solving\na specific problem before execution, which has become a critical process of the\nAutoML. Current mainstream algorithm selection techniques rely heavily on\nfeature representations of various problems and employ the performance of each\nalgorithm as supervised information. However, there is a significant research\ngap concerning the consideration of algorithm features. This gap is primarily\nattributed to the inherent complexity of algorithms, making it particularly\nchallenging to find a universally effective feature extraction method that is\napplicable across a diverse range of algorithms. Unfortunately, neglecting this\naspect undoubtedly impacts the accuracy of algorithm selection and indirectly\nnecessitates an increased volume of problem data for training purposes. This\npaper takes a significant stride towards addressing this gap by proposing an\napproach that integrates algorithm representation into the algorithm selection\nprocess. Specifically, our proposed model employs distinct modules to extract\nrepresentations of both problems and algorithms, where the algorithm\nrepresentation leverages the capabilities of pre-trained LLMs in the realm of\ncode comprehension. Following the extraction of embedding vectors for both\nalgorithms and problems, the most suitable algorithm is determined through\ncalculations of matching degrees. Our experiments not only validate the\neffectiveness of the proposed model but also showcase the performance of\ndifferent embedded pre-trained LLMs, which suggests that the proposed algorithm\nselection framework holds the potential to serve as a baseline task for\nevaluating the code representation capabilities of LLMs.\n","authors":["Xingyu Wu","Yan Zhong","Jibin Wu","Kay Chen Tan"],"pdf_url":"https://arxiv.org/pdf/2311.13184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10986v2","updated":"2023-11-22T06:15:00Z","published":"2023-11-18T06:40:39Z","title":"EdgeFM: Leveraging Foundation Model for Open-set Learning on the Edge","summary":"  Deep Learning (DL) models have been widely deployed on IoT devices with the\nhelp of advancements in DL algorithms and chips. However, the limited resources\nof edge devices make these on-device DL models hard to be generalizable to\ndiverse environments and tasks. Although the recently emerged foundation models\n(FMs) show impressive generalization power, how to effectively leverage the\nrich knowledge of FMs on resource-limited edge devices is still not explored.\nIn this paper, we propose EdgeFM, a novel edge-cloud cooperative system with\nopen-set recognition capability. EdgeFM selectively uploads unlabeled data to\nquery the FM on the cloud and customizes the specific knowledge and\narchitectures for edge models. Meanwhile, EdgeFM conducts dynamic model\nswitching at run-time taking into account both data uncertainty and dynamic\nnetwork variations, which ensures the accuracy always close to the original FM.\nWe implement EdgeFM using two FMs on two edge platforms. We evaluate EdgeFM on\nthree public datasets and two self-collected datasets. Results show that EdgeFM\ncan reduce the end-to-end latency up to 3.2x and achieve 34.3% accuracy\nincrease compared with the baseline.\n","authors":["Bufang Yang","Lixing He","Neiwen Ling","Zhenyu Yan","Guoliang Xing","Xian Shuai","Xiaozhe Ren","Xin Jiang"],"pdf_url":"https://arxiv.org/pdf/2311.10986v2.pdf","comment":"Accepted to the 21th ACM Conference on Embedded Networked Sensor\n  Systems (SenSys 2023)"},{"id":"http://arxiv.org/abs/2311.13180v1","updated":"2023-11-22T06:06:54Z","published":"2023-11-22T06:06:54Z","title":"Provably Efficient High-Dimensional Bandit Learning with Batched\n  Feedbacks","summary":"  We study high-dimensional multi-armed contextual bandits with batched\nfeedback where the $T$ steps of online interactions are divided into $L$\nbatches. In specific, each batch collects data according to a policy that\ndepends on previous batches and the rewards are revealed only at the end of the\nbatch. Such a feedback structure is popular in applications such as\npersonalized medicine and online advertisement, where the online data often do\nnot arrive in a fully serial manner. We consider high-dimensional and linear\nsettings where the reward function of the bandit model admits either a sparse\nor low-rank structure and ask how small a number of batches are needed for a\ncomparable performance with fully dynamic data in which $L = T$. For these\nsettings, we design a provably sample-efficient algorithm which achieves a $\n\\mathcal{\\tilde O}(s_0^2 \\log^2 T)$ regret in the sparse case and $\n\\mathcal{\\tilde O} ( r ^2 \\log^2 T)$ regret in the low-rank case, using only $L\n= \\mathcal{O}( \\log T)$ batches. Here $s_0$ and $r$ are the sparsity and rank\nof the reward parameter in sparse and low-rank cases, respectively, and $\n\\mathcal{\\tilde O}(\\cdot)$ omits logarithmic factors involving the feature\ndimensions. In other words, our algorithm achieves regret bounds comparable to\nthose in fully sequential setting with only $\\mathcal{O}( \\log T)$ batches. Our\nalgorithm features a novel batch allocation method that adjusts the batch sizes\naccording to the estimation accuracy within each batch and cumulative regret.\nFurthermore, we also conduct experiments with synthetic and real-world data to\nvalidate our theory.\n","authors":["Jianqing Fan","Zhaoran Wang","Zhuoran Yang","Chenlu Ye"],"pdf_url":"https://arxiv.org/pdf/2311.13180v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13174v1","updated":"2023-11-22T05:38:53Z","published":"2023-11-22T05:38:53Z","title":"SecureCut: Federated Gradient Boosting Decision Trees with Efficient\n  Machine Unlearning","summary":"  In response to legislation mandating companies to honor the \\textit{right to\nbe forgotten} by erasing user data, it has become imperative to enable data\nremoval in Vertical Federated Learning (VFL) where multiple parties provide\nprivate features for model training. In VFL, data removal, i.e.,\n\\textit{machine unlearning}, often requires removing specific features across\nall samples under privacy guarentee in federated learning. To address this\nchallenge, we propose \\methname, a novel Gradient Boosting Decision Tree (GBDT)\nframework that effectively enables both \\textit{instance unlearning} and\n\\textit{feature unlearning} without the need for retraining from scratch.\nLeveraging a robust GBDT structure, we enable effective data deletion while\nreducing degradation of model performance. Extensive experimental results on\npopular datasets demonstrate that our method achieves superior model utility\nand forgetfulness compared to \\textit{state-of-the-art} methods. To our best\nknowledge, this is the first work that investigates machine unlearning in VFL\nscenarios.\n","authors":["Jian Zhang","Bowen Li Jie Li","Chentao Wu"],"pdf_url":"https://arxiv.org/pdf/2311.13174v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.08837v2","updated":"2023-11-22T05:32:14Z","published":"2023-04-18T09:05:07Z","title":"Sensor Fault Detection and Isolation in Autonomous Nonlinear Systems\n  Using Neural Network-Based Observers","summary":"  This paper presents a novel observer-based approach to detect and isolate\nfaulty sensors in nonlinear systems. The proposed sensor fault detection and\nisolation (s-FDI) method applies to a general class of nonlinear systems. Our\nfocus is on s-FDI for two types of faults: complete failure and sensor\ndegradation. The key aspect of this approach lies in the utilization of a\nneural network-based Kazantzis-Kravaris/Luenberger (KKL) observer. The neural\nnetwork is trained to learn the dynamics of the observer, enabling accurate\noutput predictions of the system. Sensor faults are detected by comparing the\nactual output measurements with the predicted values. If the difference\nsurpasses a theoretical threshold, a sensor fault is detected. To identify and\nisolate which sensor is faulty, we compare the numerical difference of each\nsensor meassurement with an empirically derived threshold. We derive both\ntheoretical and empirical thresholds for detection and isolation, respectively.\nNotably, the proposed approach is robust to measurement noise and system\nuncertainties. Its effectiveness is demonstrated through numerical simulations\nof sensor faults in a network of Kuramoto oscillators.\n","authors":["John Cao","Muhammad Umar B. Niazi","Matthieu Barreau","Karl Henrik Johansson"],"pdf_url":"https://arxiv.org/pdf/2304.08837v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13171v1","updated":"2023-11-22T05:28:59Z","published":"2023-11-22T05:28:59Z","title":"ComPEFT: Compression for Communicating Parameter Efficient Updates via\n  Sparsification and Quantization","summary":"  Parameter-efficient fine-tuning (PEFT) techniques make it possible to\nefficiently adapt a language model to create \"expert\" models that specialize to\nnew tasks or domains. Recent techniques in model merging and compositional\ngeneralization leverage these expert models by dynamically composing modules to\nimprove zero/few-shot generalization. Despite the efficiency of PEFT methods,\nthe size of expert models can make it onerous to retrieve expert models per\nquery over high-latency networks like the Internet or serve multiple experts on\na single GPU. To address these issues, we present ComPEFT, a novel method for\ncompressing fine-tuning residuals (task vectors) of PEFT based models. ComPEFT\nemploys sparsification and ternary quantization to reduce the size of the PEFT\nmodule without performing any additional retraining while preserving or\nenhancing model performance. In extensive evaluation across T5, T0, and\nLLaMA-based models with 200M - 65B parameters, ComPEFT achieves compression\nratios of 8x - 50x. In particular, we show that ComPEFT improves with scale -\nstronger models exhibit higher compressibility and better performance. For\nexample, we show that ComPEFT applied to LLaMA outperforms QLoRA by 4.16% on\nMMLU with a storage size reduction of up to 26x. In addition, we show that the\ncompressed experts produced by ComPEFT maintain few-shot compositional\ngeneralization capabilities, facilitate efficient communication and\ncomputation, and exhibit enhanced performance when merged. Lastly, we provide\nan analysis of different method components, compare it with other PEFT methods,\nand test ComPEFT's efficacy for compressing the residual of full-finetuning.\nOur code is available at https://github.com/prateeky2806/compeft.\n","authors":["Prateek Yadav","Leshem Choshen","Colin Raffel","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2311.13171v1.pdf","comment":"25 Pages, 6 Figures, 16 Tables"},{"id":"http://arxiv.org/abs/2311.13169v1","updated":"2023-11-22T05:25:24Z","published":"2023-11-22T05:25:24Z","title":"SiGeo: Sub-One-Shot NAS via Information Theory and Geometry of Loss\n  Landscape","summary":"  Neural Architecture Search (NAS) has become a widely used tool for automating\nneural network design. While one-shot NAS methods have successfully reduced\ncomputational requirements, they often require extensive training. On the other\nhand, zero-shot NAS utilizes training-free proxies to evaluate a candidate\narchitecture's test performance but has two limitations: (1) inability to use\nthe information gained as a network improves with training and (2) unreliable\nperformance, particularly in complex domains like RecSys, due to the\nmulti-modal data inputs and complex architecture configurations. To synthesize\nthe benefits of both methods, we introduce a \"sub-one-shot\" paradigm that\nserves as a bridge between zero-shot and one-shot NAS. In sub-one-shot NAS, the\nsupernet is trained using only a small subset of the training data, a phase we\nrefer to as \"warm-up.\" Within this framework, we present SiGeo, a proxy founded\non a novel theoretical framework that connects the supernet warm-up with the\nefficacy of the proxy. Extensive experiments have shown that SiGeo, with the\nbenefit of warm-up, consistently outperforms state-of-the-art NAS proxies on\nvarious established NAS benchmarks. When a supernet is warmed up, it can\nachieve comparable performance to weight-sharing one-shot NAS methods, but with\na significant reduction ($\\sim 60$\\%) in computational costs.\n","authors":["Hua Zheng","Kuang-Hung Liu","Igor Fedorov","Xin Zhang","Wen-Yen Chen","Wei Wen"],"pdf_url":"https://arxiv.org/pdf/2311.13169v1.pdf","comment":"24 pages, 7 figures"},{"id":"http://arxiv.org/abs/2304.07647v3","updated":"2023-11-22T05:20:22Z","published":"2023-04-15T22:24:05Z","title":"LASER: A Neuro-Symbolic Framework for Learning Spatial-Temporal Scene\n  Graphs with Weak Supervision","summary":"  We propose LASER, a neuro-symbolic approach to learn semantic video\nrepresentations that capture rich spatial and temporal properties in video data\nby leveraging high-level logic specifications. In particular, we formulate the\nproblem in terms of alignment between raw videos and spatio-temporal logic\nspecifications. The alignment algorithm leverages a differentiable symbolic\nreasoner and a combination of contrastive, temporal, and semantics losses. It\neffectively and efficiently trains low-level perception models to extract\nfine-grained video representation in the form of a spatio-temporal scene graph\nthat conforms to the desired high-level specification. In doing so, we explore\na novel methodology that weakly supervises the learning of video semantic\nrepresentations through logic specifications. We evaluate our method on two\ndatasets with rich spatial and temporal specifications:\n20BN-Something-Something and MUGEN. We demonstrate that our method learns\nbetter fine-grained video semantics than existing baselines.\n","authors":["Jiani Huang","Ziyang Li","Mayur Naik","Ser-Nam Lim"],"pdf_url":"https://arxiv.org/pdf/2304.07647v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13166v1","updated":"2023-11-22T05:17:42Z","published":"2023-11-22T05:17:42Z","title":"AdaptiveFL: Adaptive Heterogeneous Federated Learning for\n  Resource-Constrained AIoT Systems","summary":"  Although Federated Learning (FL) is promising to enable collaborative\nlearning among Artificial Intelligence of Things (AIoT) devices, it suffers\nfrom the problem of low classification performance due to various heterogeneity\nfactors (e.g., computing capacity, memory size) of devices and uncertain\noperating environments. To address these issues, this paper introduces an\neffective FL approach named AdaptiveFL based on a novel fine-grained width-wise\nmodel pruning strategy, which can generate various heterogeneous local models\nfor heterogeneous AIoT devices. By using our proposed reinforcement\nlearning-based device selection mechanism, AdaptiveFL can adaptively dispatch\nsuitable heterogeneous models to corresponding AIoT devices on the fly based on\ntheir available resources for local training. Experimental results show that,\ncompared to state-of-the-art methods, AdaptiveFL can achieve up to 16.83%\ninference improvements for both IID and non-IID scenarios.\n","authors":["Chentao Jia","Ming Hu","Zekai Chen","Yanxin Yang","Xiaofei Xie","Yang Liu","Mingsong Chen"],"pdf_url":"https://arxiv.org/pdf/2311.13166v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.08897v3","updated":"2023-11-22T05:15:38Z","published":"2023-10-13T06:58:52Z","title":"Self supervised convolutional kernel based handcrafted feature\n  harmonization: Enhanced left ventricle hypertension disease phenotyping on\n  echocardiography","summary":"  Radiomics, a medical imaging technique, extracts quantitative handcrafted\nfeatures from images to predict diseases. Harmonization in those features\nensures consistent feature extraction across various imaging devices and\nprotocols. Methods for harmonization include standardized imaging protocols,\nstatistical adjustments, and evaluating feature robustness. Myocardial diseases\nsuch as Left Ventricular Hypertrophy (LVH) and Hypertensive Heart Disease (HHD)\nare diagnosed via echocardiography, but variable imaging settings pose\nchallenges. Harmonization techniques are crucial for applying handcrafted\nfeatures in disease diagnosis in such scenario. Self-supervised learning (SSL)\nenhances data understanding within limited datasets and adapts to diverse data\nsettings. ConvNeXt-V2 integrates convolutional layers into SSL, displaying\nsuperior performance in various tasks. This study focuses on convolutional\nfilters within SSL, using them as preprocessing to convert images into feature\nmaps for handcrafted feature harmonization. Our proposed method excelled in\nharmonization evaluation and exhibited superior LVH classification performance\ncompared to existing methods.\n","authors":["Jina Lee","Youngtaek Hong","Dawun Jeong","Yeonggul Jang","Jaeik Jeon","Sihyeon Jeong","Taekgeun Jung","Yeonyee E. Yoon","Inki Moon","Seung-Ah Lee","Hyuk-Jae Chang"],"pdf_url":"https://arxiv.org/pdf/2310.08897v3.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.13163v1","updated":"2023-11-22T05:09:50Z","published":"2023-11-22T05:09:50Z","title":"Have Your Cake and Eat It Too: Toward Efficient and Accurate Split\n  Federated Learning","summary":"  Due to its advantages in resource constraint scenarios, Split Federated\nLearning (SFL) is promising in AIoT systems. However, due to data heterogeneity\nand stragglers, SFL suffers from the challenges of low inference accuracy and\nlow efficiency. To address these issues, this paper presents a novel SFL\napproach, named Sliding Split Federated Learning (S$^2$FL), which adopts an\nadaptive sliding model split strategy and a data balance-based training\nmechanism. By dynamically dispatching different model portions to AIoT devices\naccording to their computing capability, S$^2$FL can alleviate the low training\nefficiency caused by stragglers. By combining features uploaded by devices with\ndifferent data distributions to generate multiple larger batches with a uniform\ndistribution for back-propagation, S$^2$FL can alleviate the performance\ndegradation caused by data heterogeneity. Experimental results demonstrate\nthat, compared to conventional SFL, S$^2$FL can achieve up to 16.5\\% inference\naccuracy improvement and 3.54X training acceleration.\n","authors":["Dengke Yan","Ming Hu","Zeke Xia","Yanxin Yang","Jun Xia","Xiaofei Xie","Mingsong Chen"],"pdf_url":"https://arxiv.org/pdf/2311.13163v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.08494v2","updated":"2023-11-22T04:59:04Z","published":"2022-02-17T07:56:46Z","title":"Learning continuous models for continuous physics","summary":"  Dynamical systems that evolve continuously over time are ubiquitous\nthroughout science and engineering. Machine learning (ML) provides data-driven\napproaches to model and predict the dynamics of such systems. A core issue with\nthis approach is that ML models are typically trained on discrete data, using\nML methodologies that are not aware of underlying continuity properties. This\nresults in models that often do not capture any underlying continuous dynamics\n-- either of the system of interest, or indeed of any related system. To\naddress this challenge, we develop a convergence test based on numerical\nanalysis theory. Our test verifies whether a model has learned a function that\naccurately approximates an underlying continuous dynamics. Models that fail\nthis test fail to capture relevant dynamics, rendering them of limited utility\nfor many scientific prediction tasks; while models that pass this test enable\nboth better interpolation and better extrapolation in multiple ways. Our\nresults illustrate how principled numerical analysis methods can be coupled\nwith existing ML training/testing methodologies to validate models for science\nand engineering applications.\n","authors":["Aditi S. Krishnapriyan","Alejandro F. Queiruga","N. Benjamin Erichson","Michael W. Mahoney"],"pdf_url":"https://arxiv.org/pdf/2202.08494v2.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2311.13159v1","updated":"2023-11-22T04:49:16Z","published":"2023-11-22T04:49:16Z","title":"Multi-Objective Optimization via Wasserstein-Fisher-Rao Gradient Flow","summary":"  Multi-objective optimization (MOO) aims to optimize multiple, possibly\nconflicting objectives with widespread applications. We introduce a novel\ninteracting particle method for MOO inspired by molecular dynamics simulations.\nOur approach combines overdamped Langevin and birth-death dynamics,\nincorporating a \"dominance potential\" to steer particles toward global Pareto\noptimality. In contrast to previous methods, our method is able to relocate\ndominated particles, making it particularly adept at managing Pareto fronts of\ncomplicated geometries. Our method is also theoretically grounded as a\nWasserstein-Fisher-Rao gradient flow with convergence guarantees. Extensive\nexperiments confirm that our approach outperforms state-of-the-art methods on\nchallenging synthetic and real-world datasets.\n","authors":["Yinuo Ren","Tesi Xiao","Tanmay Gangwani","Anshuka Rangi","Holakou Rahmanian","Lexing Ying","Subhajit Sanyal"],"pdf_url":"https://arxiv.org/pdf/2311.13159v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.14606v2","updated":"2023-11-22T04:34:57Z","published":"2023-08-28T14:20:53Z","title":"On the Tradeoff between Privacy Preservation and Byzantine-Robustness in\n  Decentralized Learning","summary":"  This paper jointly considers privacy preservation and Byzantine-robustness in\ndecentralized learning. In a decentralized network, honest-but-curious agents\nfaithfully follow the prescribed algorithm, but expect to infer their\nneighbors' private data from messages received during the learning process,\nwhile dishonest-and-Byzantine agents disobey the prescribed algorithm, and\ndeliberately disseminate wrong messages to their neighbors so as to bias the\nlearning process. For this novel setting, we investigate a generic\nprivacy-preserving and Byzantine-robust decentralized stochastic gradient\ndescent (SGD) framework, in which Gaussian noise is injected to preserve\nprivacy and robust aggregation rules are adopted to counteract Byzantine\nattacks. We analyze its learning error and privacy guarantee, discovering an\nessential tradeoff between privacy preservation and Byzantine-robustness in\ndecentralized learning -- the learning error caused by defending against\nByzantine attacks is exacerbated by the Gaussian noise added to preserve\nprivacy. For a class of state-of-the-art robust aggregation rules, we give\nunified analysis of the \"mixing abilities\". Building upon this analysis, we\nreveal how the \"mixing abilities\" affect the tradeoff between privacy\npreservation and Byzantine-robustness. The theoretical results provide\nguidelines for achieving a favorable tradeoff with proper design of robust\naggregation rules. Numerical experiments are conducted and corroborate our\ntheoretical findings.\n","authors":["Haoxiang Ye","Heng Zhu","Qing Ling"],"pdf_url":"https://arxiv.org/pdf/2308.14606v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13154v1","updated":"2023-11-22T04:34:09Z","published":"2023-11-22T04:34:09Z","title":"Testing Closeness of Multivariate Distributions via Ramsey Theory","summary":"  We investigate the statistical task of closeness (or equivalence) testing for\nmultidimensional distributions. Specifically, given sample access to two\nunknown distributions $\\mathbf p, \\mathbf q$ on $\\mathbb R^d$, we want to\ndistinguish between the case that $\\mathbf p=\\mathbf q$ versus $\\|\\mathbf\np-\\mathbf q\\|_{A_k} > \\epsilon$, where $\\|\\mathbf p-\\mathbf q\\|_{A_k}$ denotes\nthe generalized ${A}_k$ distance between $\\mathbf p$ and $\\mathbf q$ --\nmeasuring the maximum discrepancy between the distributions over any collection\nof $k$ disjoint, axis-aligned rectangles. Our main result is the first\ncloseness tester for this problem with {\\em sub-learning} sample complexity in\nany fixed dimension and a nearly-matching sample complexity lower bound.\n  In more detail, we provide a computationally efficient closeness tester with\nsample complexity $O\\left((k^{6/7}/ \\mathrm{poly}_d(\\epsilon))\n\\log^d(k)\\right)$. On the lower bound side, we establish a qualitatively\nmatching sample complexity lower bound of\n$\\Omega(k^{6/7}/\\mathrm{poly}(\\epsilon))$, even for $d=2$. These sample\ncomplexity bounds are surprising because the sample complexity of the problem\nin the univariate setting is $\\Theta(k^{4/5}/\\mathrm{poly}(\\epsilon))$. This\nhas the interesting consequence that the jump from one to two dimensions leads\nto a substantial increase in sample complexity, while increases beyond that do\nnot.\n  As a corollary of our general $A_k$ tester, we obtain $d_{\\mathrm\nTV}$-closeness testers for pairs of $k$-histograms on $\\mathbb R^d$ over a\ncommon unknown partition, and pairs of uniform distributions supported on the\nunion of $k$ unknown disjoint axis-aligned rectangles.\n  Both our algorithm and our lower bound make essential use of tools from\nRamsey theory.\n","authors":["Ilias Diakonikolas","Daniel M. Kane","Sihan Liu"],"pdf_url":"https://arxiv.org/pdf/2311.13154v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.09936v2","updated":"2023-11-22T04:29:33Z","published":"2023-08-19T07:53:43Z","title":"BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual\n  Questions","summary":"  Vision Language Models (VLMs), which extend Large Language Models (LLM) by\nincorporating visual understanding capability, have demonstrated significant\nadvancements in addressing open-ended visual question-answering (VQA) tasks.\nHowever, these models cannot accurately interpret images infused with text, a\ncommon occurrence in real-world scenarios. Standard procedures for extracting\ninformation from images often involve learning a fixed set of query embeddings.\nThese embeddings are designed to encapsulate image contexts and are later used\nas soft prompt inputs in LLMs. Yet, this process is limited to the token count,\npotentially curtailing the recognition of scenes with text-rich context. To\nimprove upon them, the present study introduces BLIVA: an augmented version of\nInstructBLIP with Visual Assistant. BLIVA incorporates the query embeddings\nfrom InstructBLIP and also directly projects encoded patch embeddings into the\nLLM, a technique inspired by LLaVA. This approach assists the model to capture\nintricate details potentially missed during the query decoding process.\nEmpirical evidence demonstrates that our model, BLIVA, significantly enhances\nperformance in processing text-rich VQA benchmarks (up to 17.76% in OCR-VQA\nbenchmark) and in undertaking general (not particularly text-rich) VQA\nbenchmarks (up to 7.9% in Visual Spatial Reasoning benchmark), comparing to our\nbaseline InstructBLIP. BLIVA demonstrates significant capability in decoding\nreal-world images, irrespective of text presence. To demonstrate the broad\nindustry applications enabled by BLIVA, we evaluate the model using a new\ndataset comprising YouTube thumbnails paired with question-answer sets across\n11 diverse categories. For researchers interested in further exploration, our\ncode and models are freely accessible at https://github.com/mlpc-ucsd/BLIVA.\n","authors":["Wenbo Hu","Yifan Xu","Yi Li","Weiyue Li","Zeyuan Chen","Zhuowen Tu"],"pdf_url":"https://arxiv.org/pdf/2308.09936v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13147v1","updated":"2023-11-22T04:18:23Z","published":"2023-11-22T04:18:23Z","title":"Optimal Transport with Cyclic Symmetry","summary":"  We propose novel fast algorithms for optimal transport (OT) utilizing a\ncyclic symmetry structure of input data. Such OT with cyclic symmetry appears\nuniversally in various real-world examples: image processing, urban planning,\nand graph processing. Our main idea is to reduce OT to a small optimization\nproblem that has significantly fewer variables by utilizing cyclic symmetry and\nvarious optimization techniques. On the basis of this reduction, our algorithms\nsolve the small optimization problem instead of the original OT. As a result,\nour algorithms obtain the optimal solution and the objective function value of\nthe original OT faster than solving the original OT directly. In this paper,\nour focus is on two crucial OT formulations: the linear programming OT (LOT)\nand the strongly convex-regularized OT, which includes the well-known\nentropy-regularized OT (EROT). Experiments show the effectiveness of our\nalgorithms for LOT and EROT in synthetic/real-world data that has a\nstrict/approximate cyclic symmetry structure. Through theoretical and\nexperimental results, this paper successfully introduces the concept of\nsymmetry into the OT research field for the first time.\n","authors":["Shoichiro Takeda","Yasunori Akagi","Naoki Marumo","Kenta Niwa"],"pdf_url":"https://arxiv.org/pdf/2311.13147v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12068v2","updated":"2023-11-22T04:13:38Z","published":"2023-11-19T17:28:28Z","title":"Enhancing Novel Object Detection via Cooperative Foundational Models","summary":"  In this work, we address the challenging and emergent problem of novel object\ndetection (NOD), focusing on the accurate detection of both known and novel\nobject categories during inference. Traditional object detection algorithms are\ninherently closed-set, limiting their capability to handle NOD. We present a\nnovel approach to transform existing closed-set detectors into open-set\ndetectors. This transformation is achieved by leveraging the complementary\nstrengths of pre-trained foundational models, specifically CLIP and SAM,\nthrough our cooperative mechanism. Furthermore, by integrating this mechanism\nwith state-of-the-art open-set detectors such as GDINO, we establish new\nbenchmarks in object detection performance. Our method achieves 17.42 mAP in\nnovel object detection and 42.08 mAP for known objects on the challenging LVIS\ndataset. Adapting our approach to the COCO OVD split, we surpass the current\nstate-of-the-art by a margin of 7.2 $ \\text{AP}_{50} $ for novel classes. Our\ncode is available at\nhttps://github.com/rohit901/cooperative-foundational-models .\n","authors":["Rohit Bharadwaj","Muzammal Naseer","Salman Khan","Fahad Shahbaz Khan"],"pdf_url":"https://arxiv.org/pdf/2311.12068v2.pdf","comment":"Code: https://github.com/rohit901/cooperative-foundational-models"},{"id":"http://arxiv.org/abs/2309.11983v2","updated":"2023-11-22T04:10:53Z","published":"2023-09-21T11:39:33Z","title":"Variational Connectionist Temporal Classification for Order-Preserving\n  Sequence Modeling","summary":"  Connectionist temporal classification (CTC) is commonly adopted for sequence\nmodeling tasks like speech recognition, where it is necessary to preserve order\nbetween the input and target sequences. However, CTC is only applied to\ndeterministic sequence models, where the latent space is discontinuous and\nsparse, which in turn makes them less capable of handling data variability when\ncompared to variational models. In this paper, we integrate CTC with a\nvariational model and derive loss functions that can be used to train more\ngeneralizable sequence models that preserve order. Specifically, we derive two\nversions of the novel variational CTC based on two reasonable assumptions, the\nfirst being that the variational latent variables at each time step are\nconditionally independent; and the second being that these latent variables are\nMarkovian. We show that both loss functions allow direct optimization of the\nvariational lower bound for the model log-likelihood, and present\ncomputationally tractable forms for implementing them.\n","authors":["Zheng Nan","Ting Dang","Vidhyasaharan Sethu","Beena Ahmed"],"pdf_url":"https://arxiv.org/pdf/2309.11983v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.02645v4","updated":"2023-11-22T03:43:55Z","published":"2022-05-05T13:44:24Z","title":"Discovering stochastic dynamical equations from biological time series\n  data","summary":"  Stochastic differential equations (SDEs) are an important framework to model\ndynamics with randomness, as is common in most biological systems. The inverse\nproblem of integrating these models with empirical data remains a major\nchallenge. Here, we present a software package, PyDaDDy (Python Library for\nData Driven Dynamics) that takes time series data as an input and outputs an\ninterpretable SDE. We achieve this by combining traditional approaches from\nstochastic calculus literature with state-of-the-art equation discovery\ntechniques. We validate our approach on synthetic datasets, and demonstrate the\ngenerality and applicability of the method on two real-world datasets of vastly\ndifferent spatiotemporal scales: (i) collective movement of fish school where\nstochasticity plays a crucial role, and (ii) confined migration of a single\ncell, primarily following a relaxed oscillation. We make the method available\nas an easy-to-use, open-source Python package, PyDaddy (Python Library for Data\nDriven Dynamics).\n","authors":["Arshed Nabeel","Ashwin Karichannavar","Shuaib Palathingal","Jitesh Jhawar","David B. Brückner","Danny Raj M.","Vishwesha Guttal"],"pdf_url":"https://arxiv.org/pdf/2205.02645v4.pdf","comment":"15 pages (+ 9 page appendix), 6 figures (+ 8 appendix figures).\n  Updates: v3: Significantly reorganized the paper and added a section analysis\n  of a cell migration dataset. v4: Update arXiv title to match the updated\n  title of the manuscript"},{"id":"http://arxiv.org/abs/2311.13133v1","updated":"2023-11-22T03:37:01Z","published":"2023-11-22T03:37:01Z","title":"LIMIT: Less Is More for Instruction Tuning Across Evaluation Paradigms","summary":"  Large Language Models are traditionally finetuned on large instruction\ndatasets. However recent studies suggest that small, high-quality datasets can\nsuffice for general purpose instruction following. This lack of consensus\nsurrounding finetuning best practices is in part due to rapidly diverging\napproaches to LLM evaluation. In this study, we ask whether a small amount of\ndiverse finetuning samples can improve performance on both traditional\nperplexity-based NLP benchmarks, and on open-ended, model-based evaluation. We\nfinetune open-source MPT-7B and MPT-30B models on instruction finetuning\ndatasets of various sizes ranging from 1k to 60k samples. We find that subsets\nof 1k-6k instruction finetuning samples are sufficient to achieve good\nperformance on both (1) traditional NLP benchmarks and (2) model-based\nevaluation. Finally, we show that mixing textbook-style and open-ended QA\nfinetuning datasets optimizes performance on both evaluation paradigms.\n","authors":["Aditi Jha","Sam Havens","Jeremey Dohmann","Alex Trott","Jacob Portes"],"pdf_url":"https://arxiv.org/pdf/2311.13133v1.pdf","comment":"36 pages, 12 figures, NeurIPS 2023 Workshop on Instruction Tuning and\n  Instruction Following"},{"id":"http://arxiv.org/abs/2306.08280v2","updated":"2023-11-22T03:22:18Z","published":"2023-06-14T06:35:10Z","title":"Differentially Private Wireless Federated Learning Using Orthogonal\n  Sequences","summary":"  We propose a privacy-preserving uplink over-the-air computation (AirComp)\nmethod, termed FLORAS, for single-input single-output (SISO) wireless federated\nlearning (FL) systems. From the perspective of communication designs, FLORAS\neliminates the requirement of channel state information at the transmitters\n(CSIT) by leveraging the properties of orthogonal sequences. From the privacy\nperspective, we prove that FLORAS offers both item-level and client-level\ndifferential privacy (DP) guarantees. Moreover, by properly adjusting the\nsystem parameters, FLORAS can flexibly achieve different DP levels at no\nadditional cost. A new FL convergence bound is derived which, combined with the\nprivacy guarantees, allows for a smooth tradeoff between the achieved\nconvergence rate and differential privacy levels. Experimental results\ndemonstrate the advantages of FLORAS compared with the baseline AirComp method,\nand validate that the analytical results can guide the design of\nprivacy-preserving FL with different tradeoff requirements on the model\nconvergence and privacy levels.\n","authors":["Xizixiang Wei","Tianhao Wang","Ruiquan Huang","Cong Shen","Jing Yang","H. Vincent Poor"],"pdf_url":"https://arxiv.org/pdf/2306.08280v2.pdf","comment":"33 pages, 5 figures"},{"id":"http://arxiv.org/abs/2306.04889v2","updated":"2023-11-22T03:02:46Z","published":"2023-06-08T02:35:30Z","title":"ShaDDR: Interactive Example-Based Geometry and Texture Generation via 3D\n  Shape Detailization and Differentiable Rendering","summary":"  We present ShaDDR, an example-based deep generative neural network which\nproduces a high-resolution textured 3D shape through geometry detailization and\nconditional texture generation applied to an input coarse voxel shape. Trained\non a small set of detailed and textured exemplar shapes, our method learns to\ndetailize the geometry via multi-resolution voxel upsampling and generate\ntextures on voxel surfaces via differentiable rendering against exemplar\ntexture images from a few views. The generation is interactive, taking less\nthan 1 second to produce a 3D model with voxel resolutions up to 512^3. The\ngenerated shape preserves the overall structure of the input coarse voxel\nmodel, while the style of the generated geometric details and textures can be\nmanipulated through learned latent codes. In the experiments, we show that our\nmethod can generate higher-resolution shapes with plausible and improved\ngeometric details and clean textures compared to prior works. Furthermore, we\nshowcase the ability of our method to learn geometric details and textures from\nshapes reconstructed from real-world photos. In addition, we have developed an\ninteractive modeling application to demonstrate the generalizability of our\nmethod to various user inputs and the controllability it offers, allowing users\nto interactively sculpt a coarse voxel shape to define the overall structure of\nthe detailized 3D shape. Code and data are available at\nhttps://github.com/qiminchen/ShaDDR.\n","authors":["Qimin Chen","Zhiqin Chen","Hang Zhou","Hao Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.04889v2.pdf","comment":"Accepted to SIGGRAPH Asia 2023 conference track. Code:\n  https://github.com/qiminchen/ShaDDR"},{"id":"http://arxiv.org/abs/2311.10863v3","updated":"2023-11-22T03:01:59Z","published":"2023-11-17T20:51:24Z","title":"Verified Compositional Neuro-Symbolic Control for Stochastic Systems\n  with Temporal Logic Tasks","summary":"  Several methods have been proposed recently to learn neural network (NN)\ncontrollers for autonomous agents, with unknown and stochastic dynamics, tasked\nwith complex missions captured by Linear Temporal Logic (LTL). Due to the\nsample-inefficiency of the majority of these works, compositional learning\nmethods have been proposed decomposing the LTL specification into smaller\nsub-tasks. Then, separate controllers are learned and composed to satisfy the\noriginal task. A key challenge within these approaches is that they often lack\nsafety guarantees or the provided guarantees are impractical. This paper aims\nto address this challenge. Particularly, we consider autonomous systems with\nunknown and stochastic dynamics and LTL-encoded tasks. We assume that the\nsystem is equipped with a finite set of base skills modeled by trained NN\nfeedback controllers. Our goal is to check if there exists a temporal\ncomposition of the trained NN controllers - and if so, to compute it - that\nwill yield a composite system behavior that satisfies the assigned LTL task\nwith probability one. We propose a new approach that relies on a novel\nintegration of automata theory and data-driven reachability analysis tools for\nNN-controlled stochastic systems. The resulting neuro-symbolic controller\nallows the agent to generate safe behaviors for unseen complex temporal logic\ntasks in a zero-shot fashion by leveraging its base skills. We show correctness\nof the proposed method and we provide conditions under which it is complete. To\nthe best of our knowledge, this is the first work that designs verified\ntemporal compositions of NN controllers for unknown and stochastic systems.\nFinally, we provide extensive numerical simulations and hardware experiments on\nrobot navigation tasks to demonstrate the proposed method.\n","authors":["Jun Wang","Haojun Chen","Zihe Sun","Yiannis Kantaros"],"pdf_url":"https://arxiv.org/pdf/2311.10863v3.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2209.06130"},{"id":"http://arxiv.org/abs/2311.13118v1","updated":"2023-11-22T02:45:01Z","published":"2023-11-22T02:45:01Z","title":"Combatting Human Trafficking in the Cyberspace: A Natural Language\n  Processing-Based Methodology to Analyze the Language in Online Advertisements","summary":"  This project tackles the pressing issue of human trafficking in online C2C\nmarketplaces through advanced Natural Language Processing (NLP) techniques. We\nintroduce a novel methodology for generating pseudo-labeled datasets with\nminimal supervision, serving as a rich resource for training state-of-the-art\nNLP models. Focusing on tasks like Human Trafficking Risk Prediction (HTRP) and\nOrganized Activity Detection (OAD), we employ cutting-edge Transformer models\nfor analysis. A key contribution is the implementation of an interpretability\nframework using Integrated Gradients, providing explainable insights crucial\nfor law enforcement. This work not only fills a critical gap in the literature\nbut also offers a scalable, machine learning-driven approach to combat human\nexploitation online. It serves as a foundation for future research and\npractical applications, emphasizing the role of machine learning in addressing\ncomplex social issues.\n","authors":["Alejandro Rodriguez Perez","Pablo Rivas"],"pdf_url":"https://arxiv.org/pdf/2311.13118v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08131v2","updated":"2023-11-22T02:35:37Z","published":"2022-12-15T20:36:10Z","title":"Bridging the Gap Between Offline and Online Reinforcement Learning\n  Evaluation Methodologies","summary":"  Reinforcement learning (RL) has shown great promise with algorithms learning\nin environments with large state and action spaces purely from scalar reward\nsignals. A crucial challenge for current deep RL algorithms is that they\nrequire a tremendous amount of environment interactions for learning. This can\nbe infeasible in situations where such interactions are expensive; such as in\nrobotics. Offline RL algorithms try to address this issue by bootstrapping the\nlearning process from existing logged data without needing to interact with the\nenvironment from the very beginning. While online RL algorithms are typically\nevaluated as a function of the number of environment interactions, there exists\nno single established protocol for evaluating offline RL methods.In this paper,\nwe propose a sequential approach to evaluate offline RL algorithms as a\nfunction of the training set size and thus by their data efficiency. Sequential\nevaluation provides valuable insights into the data efficiency of the learning\nprocess and the robustness of algorithms to distribution changes in the dataset\nwhile also harmonizing the visualization of the offline and online learning\nphases. Our approach is generally applicable and easy to implement. We compare\nseveral existing offline RL algorithms using this approach and present insights\nfrom a variety of tasks and offline datasets.\n","authors":["Shivakanth Sujit","Pedro H. M. Braga","Jorg Bornschein","Samira Ebrahimi Kahou"],"pdf_url":"https://arxiv.org/pdf/2212.08131v2.pdf","comment":"TMLR 2023"},{"id":"http://arxiv.org/abs/2305.16854v3","updated":"2023-11-22T02:29:13Z","published":"2023-05-26T12:04:59Z","title":"Channel and Gradient-Importance Aware Device Scheduling for Over-the-Air\n  Federated Learning","summary":"  Federated learning (FL) is a popular privacy-preserving distributed training\nscheme, where multiple devices collaborate to train machine learning models by\nuploading local model updates. To improve communication efficiency,\nover-the-air computation (AirComp) has been applied to FL, which leverages\nanalog modulation to harness the superposition property of radio waves such\nthat numerous devices can upload their model updates concurrently for\naggregation. However, the uplink channel noise incurs considerable model\naggregation distortion, which is critically determined by the device scheduling\nand compromises the learned model performance. In this paper, we propose a\nprobabilistic device scheduling framework for over-the-air FL, named PO-FL, to\nmitigate the negative impact of channel noise, where each device is scheduled\naccording to a certain probability and its model update is reweighted using\nthis probability in aggregation. We prove the unbiasedness of this aggregation\nscheme and demonstrate the convergence of PO-FL on both convex and non-convex\nloss functions. Our convergence bounds unveil that the device scheduling\naffects the learning performance through the communication distortion and\nglobal update variance. Based on the convergence analysis, we further develop a\nchannel and gradient-importance aware algorithm to optimize the device\nscheduling probabilities in PO-FL. Extensive simulation results show that the\nproposed PO-FL framework with channel and gradient-importance awareness\nachieves faster convergence and produces better models than baseline methods.\n","authors":["Yuchang Sun","Zehong lin","Yuyi Mao","Shi Jin","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.16854v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13110v1","updated":"2023-11-22T02:23:32Z","published":"2023-11-22T02:23:32Z","title":"White-Box Transformers via Sparse Rate Reduction: Compression Is All\n  There Is?","summary":"  In this paper, we contend that a natural objective of representation learning\nis to compress and transform the distribution of the data, say sets of tokens,\ntowards a low-dimensional Gaussian mixture supported on incoherent subspaces.\nThe goodness of such a representation can be evaluated by a principled measure,\ncalled sparse rate reduction, that simultaneously maximizes the intrinsic\ninformation gain and extrinsic sparsity of the learned representation. From\nthis perspective, popular deep network architectures, including transformers,\ncan be viewed as realizing iterative schemes to optimize this measure.\nParticularly, we derive a transformer block from alternating optimization on\nparts of this objective: the multi-head self-attention operator compresses the\nrepresentation by implementing an approximate gradient descent step on the\ncoding rate of the features, and the subsequent multi-layer perceptron\nsparsifies the features. This leads to a family of white-box transformer-like\ndeep network architectures, named CRATE, which are mathematically fully\ninterpretable. We show, by way of a novel connection between denoising and\ncompression, that the inverse to the aforementioned compressive encoding can be\nrealized by the same class of CRATE architectures. Thus, the so-derived\nwhite-box architectures are universal to both encoders and decoders.\nExperiments show that these networks, despite their simplicity, indeed learn to\ncompress and sparsify representations of large-scale real-world image and text\ndatasets, and achieve performance very close to highly engineered\ntransformer-based models: ViT, MAE, DINO, BERT, and GPT2. We believe the\nproposed computational framework demonstrates great potential in bridging the\ngap between theory and practice of deep learning, from a unified perspective of\ndata compression. Code is available at: https://ma-lab-berkeley.github.io/CRATE .\n","authors":["Yaodong Yu","Sam Buchanan","Druv Pai","Tianzhe Chu","Ziyang Wu","Shengbang Tong","Hao Bai","Yuexiang Zhai","Benjamin D. Haeffele","Yi Ma"],"pdf_url":"https://arxiv.org/pdf/2311.13110v1.pdf","comment":"This paper integrates the works arXiv:2306.01129 and\n  arXiv:2308.16271, as well as this under-review work:\n  https://openreview.net/forum?id=PvyOYleymy into a complete story. In this\n  paper, we improve the writing and organization, and also add conceptual,\n  empirical, and theoretical improvements over the previous work"},{"id":"http://arxiv.org/abs/2311.13102v1","updated":"2023-11-22T02:04:35Z","published":"2023-11-22T02:04:35Z","title":"Detecting out-of-distribution text using topological features of\n  transformer-based language models","summary":"  We attempt to detect out-of-distribution (OOD) text samples though applying\nTopological Data Analysis (TDA) to attention maps in transformer-based language\nmodels. We evaluate our proposed TDA-based approach for out-of-distribution\ndetection on BERT, a transformer-based language model, and compare the to a\nmore traditional OOD approach based on BERT CLS embeddings. We found that our\nTDA approach outperforms the CLS embedding approach at distinguishing\nin-distribution data (politics and entertainment news articles from HuffPost)\nfrom far out-of-domain samples (IMDB reviews), but its effectiveness\ndeteriorates with near out-of-domain (CNN/Dailymail) or same-domain (business\nnews articles from HuffPost) datasets.\n","authors":["Andres Pollano","Anupam Chaudhuri","Anj Simmons"],"pdf_url":"https://arxiv.org/pdf/2311.13102v1.pdf","comment":"12 pages, 6 figures, 3 tables"},{"id":"http://arxiv.org/abs/2311.13099v1","updated":"2023-11-22T01:58:26Z","published":"2023-11-22T01:58:26Z","title":"PIE-NeRF: Physics-based Interactive Elastodynamics with NeRF","summary":"  We show that physics-based simulations can be seamlessly integrated with NeRF\nto generate high-quality elastodynamics of real-world objects. Unlike existing\nmethods, we discretize nonlinear hyperelasticity in a meshless way, obviating\nthe necessity for intermediate auxiliary shape proxies like a tetrahedral mesh\nor voxel grid. A quadratic generalized moving least square (Q-GMLS) is employed\nto capture nonlinear dynamics and large deformation on the implicit model. Such\nmeshless integration enables versatile simulations of complex and codimensional\nshapes. We adaptively place the least-square kernels according to the NeRF\ndensity field to significantly reduce the complexity of the nonlinear\nsimulation. As a result, physically realistic animations can be conveniently\nsynthesized using our method for a wide range of hyperelastic materials at an\ninteractive rate. For more information, please visit our project page at\nhttps://fytalon.github.io/pienerf/.\n","authors":["Yutao Feng","Yintong Shang","Xuan Li","Tianjia Shao","Chenfanfu Jiang","Yin Yang"],"pdf_url":"https://arxiv.org/pdf/2311.13099v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13094v1","updated":"2023-11-22T01:50:43Z","published":"2023-11-22T01:50:43Z","title":"Newton-CG methods for nonconvex unconstrained optimization with Hölder\n  continuous Hessian","summary":"  In this paper we consider a nonconvex unconstrained optimization problem\nminimizing a twice differentiable objective function with H\\\"older continuous\nHessian. Specifically, we first propose a Newton-conjugate gradient (Newton-CG)\nmethod for finding an approximate first-order stationary point (FOSP) of this\nproblem, assuming the associated the H\\\"older parameters are explicitly known.\nThen we develop a parameter-free Newton-CG method without requiring any prior\nknowledge of these parameters. To the best of our knowledge, this method is the\nfirst parameter-free second-order method achieving the best-known iteration and\noperation complexity for finding an approximate FOSP of this problem.\nFurthermore, we propose a Newton-CG method for finding an approximate\nsecond-order stationary point (SOSP) of the considered problem with high\nprobability and establish its iteration and operation complexity. Finally, we\npresent preliminary numerical results to demonstrate the superior practical\nperformance of our parameter-free Newton-CG method over a well-known\nregularized Newton method.\n","authors":["Chuan He","Zhaosong Lu"],"pdf_url":"https://arxiv.org/pdf/2311.13094v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2301.03139"},{"id":"http://arxiv.org/abs/2311.13091v1","updated":"2023-11-22T01:43:57Z","published":"2023-11-22T01:43:57Z","title":"Stable Unlearnable Example: Enhancing the Robustness of Unlearnable\n  Examples via Stable Error-Minimizing Noise","summary":"  The open source of large amounts of image data promotes the development of\ndeep learning techniques. Along with this comes the privacy risk of these\nopen-source image datasets being exploited by unauthorized third parties to\ntrain deep learning models for commercial or illegal purposes. To avoid the\nabuse of public data, a poisoning-based technique, the unlearnable example, is\nproposed to significantly degrade the generalization performance of models by\nadding a kind of imperceptible noise to the data. To further enhance its\nrobustness against adversarial training, existing works leverage iterative\nadversarial training on both the defensive noise and the surrogate model.\nHowever, it still remains unknown whether the robustness of unlearnable\nexamples primarily comes from the effect of enhancement in the surrogate model\nor the defensive noise. Observing that simply removing the adversarial noise on\nthe training process of the defensive noise can improve the performance of\nrobust unlearnable examples, we identify that solely the surrogate model's\nrobustness contributes to the performance. Furthermore, we found a negative\ncorrelation exists between the robustness of defensive noise and the protection\nperformance, indicating defensive noise's instability issue. Motivated by this,\nto further boost the robust unlearnable example, we introduce stable\nerror-minimizing noise (SEM), which trains the defensive noise against random\nperturbation instead of the time-consuming adversarial perturbation to improve\nthe stability of defensive noise. Through extensive experiments, we demonstrate\nthat SEM achieves a new state-of-the-art performance on CIFAR-10, CIFAR-100,\nand ImageNet Subset in terms of both effectiveness and efficiency. The code is\navailable at https://github.com/liuyixin-louis/Stable-Unlearnable-Example.\n","authors":["Yixin Liu","Kaidi Xu","Xun Chen","Lichao Sun"],"pdf_url":"https://arxiv.org/pdf/2311.13091v1.pdf","comment":"14 pages, 11 figures, 13 tables"},{"id":"http://arxiv.org/abs/2311.12166v2","updated":"2023-11-22T01:42:59Z","published":"2023-11-20T20:32:14Z","title":"Creating Temporally Correlated High-Resolution Power Injection Profiles\n  Using Physics-Aware GAN","summary":"  Traditional smart meter measurements lack the granularity needed for\nreal-time decision-making. To address this practical problem, we create a\ngenerative adversarial networks (GAN) model that enforces temporal consistency\non its high-resolution outputs via hard inequality constraints using a convex\noptimization layer. A unique feature of our GAN model is that it is trained\nsolely on slow timescale aggregated power information obtained from historical\nsmart meter data. The results demonstrate that the model can successfully\ncreate minutely interval temporally-correlated instantaneous power injection\nprofiles from 15-minute average power consumption information. This innovative\napproach, emphasizing inter-neuron constraints, offers a promising avenue for\nimproved high-speed state estimation in distribution systems and enhances the\napplicability of data-driven solutions for monitoring such systems.\n","authors":["Hritik Gopal Shah","Behrouz Azimian","Anamitra Pal"],"pdf_url":"https://arxiv.org/pdf/2311.12166v2.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2310.12942v3","updated":"2023-11-22T01:39:59Z","published":"2023-10-19T17:39:47Z","title":"On the Representational Capacity of Recurrent Neural Language Models","summary":"  This work investigates the computational expressivity of language models\n(LMs) based on recurrent neural networks (RNNs). Siegelmann and Sontag (1992)\nfamously showed that RNNs with rational weights and hidden states and unbounded\ncomputation time are Turing complete. However, LMs define weightings over\nstrings in addition to just (unweighted) language membership and the analysis\nof the computational power of RNN LMs (RLMs) should reflect this. We extend the\nTuring completeness result to the probabilistic case, showing how a rationally\nweighted RLM with unbounded computation time can simulate any deterministic\nprobabilistic Turing machine (PTM) with rationally weighted transitions. Since,\nin practice, RLMs work in real-time, processing a symbol at every time step, we\ntreat the above result as an upper bound on the expressivity of RLMs. We also\nprovide a lower bound by showing that under the restriction to real-time\ncomputation, such models can simulate deterministic real-time rational PTMs.\n","authors":["Franz Nowak","Anej Svete","Li Du","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2310.12942v3.pdf","comment":"To be published at EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.13087v1","updated":"2023-11-22T01:32:06Z","published":"2023-11-22T01:32:06Z","title":"Predict-Then-Optimize by Proxy: Learning Joint Models of Prediction and\n  Optimization","summary":"  Many real-world decision processes are modeled by optimization problems whose\ndefining parameters are unknown and must be inferred from observable data. The\nPredict-Then-Optimize framework uses machine learning models to predict unknown\nparameters of an optimization problem from features before solving. Recent\nworks show that decision quality can be improved in this setting by solving and\ndifferentiating the optimization problem in the training loop, enabling\nend-to-end training with loss functions defined directly on the resulting\ndecisions. However, this approach can be inefficient and requires handcrafted,\nproblem-specific rules for backpropagation through the optimization step. This\npaper proposes an alternative method, in which optimal solutions are learned\ndirectly from the observable features by predictive models. The approach is\ngeneric, and based on an adaptation of the Learning-to-Optimize paradigm, from\nwhich a rich variety of existing techniques can be employed. Experimental\nevaluations show the ability of several Learning-to-Optimize methods to provide\nefficient, accurate, and flexible solutions to an array of challenging\nPredict-Then-Optimize problems.\n","authors":["James Kotary","Vincenzo Di Vito","Jacob Christopher","Pascal Van Hentenryck","Ferdinando Fioretto"],"pdf_url":"https://arxiv.org/pdf/2311.13087v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2108.00527v3","updated":"2023-11-22T01:11:46Z","published":"2021-08-01T19:20:34Z","title":"Gates Are Not What You Need in RNNs","summary":"  Recurrent neural networks have flourished in many areas. Consequently, we can\nsee new RNN cells being developed continuously, usually by creating or using\ngates in a new, original way. But what if we told you that gates in RNNs are\nredundant? In this paper, we propose a new recurrent cell called Residual\nRecurrent Unit (RRU) which beats traditional cells and does not employ a single\ngate. It is based on the residual shortcut connection, linear transformations,\nReLU, and normalization. To evaluate our cell's effectiveness, we compare its\nperformance against the widely-used GRU and LSTM cells and the recently\nproposed Mogrifier LSTM on several tasks including, polyphonic music modeling,\nlanguage modeling, and sentiment analysis. Our experiments show that RRU\noutperforms the traditional gated units on most of these tasks. Also, it has\nbetter robustness to parameter selection, allowing immediate application in new\ntasks without much tuning. We have implemented the RRU in TensorFlow, and the\ncode is made available at https://github.com/LUMII-Syslab/RRU .\n","authors":["Ronalds Zakovskis","Andis Draguns","Eliza Gaile","Emils Ozolins","Karlis Freivalds"],"pdf_url":"https://arxiv.org/pdf/2108.00527v3.pdf","comment":"Published in Artificial Intelligence and Soft Computing. ICAISC 2023.\n  Lecture Notes in Computer Science(), vol 14125. Springer, Cham., and is\n  available online at https://doi.org/10.1007/978-3-031-42505-9_27"},{"id":"http://arxiv.org/abs/2311.13081v1","updated":"2023-11-22T01:06:45Z","published":"2023-11-22T01:06:45Z","title":"Learning to Fly in Seconds","summary":"  Learning-based methods, particularly Reinforcement Learning (RL), hold great\npromise for streamlining deployment, enhancing performance, and achieving\ngeneralization in the control of autonomous multirotor aerial vehicles. Deep RL\nhas been able to control complex systems with impressive fidelity and agility\nin simulation but the simulation-to-reality transfer often brings a\nhard-to-bridge reality gap. Moreover, RL is commonly plagued by prohibitively\nlong training times. In this work, we propose a novel asymmetric\nactor-critic-based architecture coupled with a highly reliable RL-based\ntraining paradigm for end-to-end quadrotor control. We show how curriculum\nlearning and a highly optimized simulator enhance sample complexity and lead to\nfast training times. To precisely discuss the challenges related to\nlow-level/end-to-end multirotor control, we also introduce a taxonomy that\nclassifies the existing levels of control abstractions as well as\nnon-linearities and domain parameters. Our framework enables\nSimulation-to-Reality (Sim2Real) transfer for direct RPM control after only 18\nseconds of training on a consumer-grade laptop as well as its deployment on\nmicrocontrollers to control a multirotor under real-time guarantees. Finally,\nour solution exhibits competitive performance in trajectory tracking, as\ndemonstrated through various experimental comparisons with existing\nstate-of-the-art control solutions using a real Crazyflie nano quadrotor. We\nopen source the code including a very fast multirotor dynamics simulator that\ncan simulate about 5 months of flight per second on a laptop GPU. The fast\ntraining times and deployment to a cheap, off-the-shelf quadrotor lower the\nbarriers to entry and help democratize the research and development of these\nsystems.\n","authors":["Jonas Eschmann","Dario Albani","Giuseppe Loianno"],"pdf_url":"https://arxiv.org/pdf/2311.13081v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06202v3","updated":"2023-11-22T00:57:54Z","published":"2023-06-09T19:10:16Z","title":"NeuroGraph: Benchmarks for Graph Machine Learning in Brain Connectomics","summary":"  Machine learning provides a valuable tool for analyzing high-dimensional\nfunctional neuroimaging data, and is proving effective in predicting various\nneurological conditions, psychiatric disorders, and cognitive patterns. In\nfunctional magnetic resonance imaging (MRI) research, interactions between\nbrain regions are commonly modeled using graph-based representations. The\npotency of graph machine learning methods has been established across myriad\ndomains, marking a transformative step in data interpretation and predictive\nmodeling. Yet, despite their promise, the transposition of these techniques to\nthe neuroimaging domain has been challenging due to the expansive number of\npotential preprocessing pipelines and the large parameter search space for\ngraph-based dataset construction. In this paper, we introduce NeuroGraph, a\ncollection of graph-based neuroimaging datasets, and demonstrated its utility\nfor predicting multiple categories of behavioral and cognitive traits. We delve\ndeeply into the dataset generation search space by crafting 35 datasets that\nencompass static and dynamic brain connectivity, running in excess of 15\nbaseline methods for benchmarking. Additionally, we provide generic frameworks\nfor learning on both static and dynamic graphs. Our extensive experiments lead\nto several key observations. Notably, using correlation vectors as node\nfeatures, incorporating larger number of regions of interest, and employing\nsparser graphs lead to improved performance. To foster further advancements in\ngraph-based data driven neuroimaging analysis, we offer a comprehensive\nopen-source Python package that includes the benchmark datasets, baseline\nimplementations, model training, and standard evaluation.\n","authors":["Anwar Said","Roza G. Bayrak","Tyler Derr","Mudassir Shabbir","Daniel Moyer","Catie Chang","Xenofon Koutsoukos"],"pdf_url":"https://arxiv.org/pdf/2306.06202v3.pdf","comment":"NeurIPS23"},{"id":"http://arxiv.org/abs/2311.13073v1","updated":"2023-11-22T00:26:15Z","published":"2023-11-22T00:26:15Z","title":"FusionFrames: Efficient Architectural Aspects for Text-to-Video\n  Generation Pipeline","summary":"  Multimedia generation approaches occupy a prominent place in artificial\nintelligence research. Text-to-image models achieved high-quality results over\nthe last few years. However, video synthesis methods recently started to\ndevelop. This paper presents a new two-stage latent diffusion text-to-video\ngeneration architecture based on the text-to-image diffusion model. The first\nstage concerns keyframes synthesis to figure the storyline of a video, while\nthe second one is devoted to interpolation frames generation to make movements\nof the scene and objects smooth. We compare several temporal conditioning\napproaches for keyframes generation. The results show the advantage of using\nseparate temporal blocks over temporal layers in terms of metrics reflecting\nvideo generation quality aspects and human preference. The design of our\ninterpolation model significantly reduces computational costs compared to other\nmasked frame interpolation approaches. Furthermore, we evaluate different\nconfigurations of MoVQ-based video decoding scheme to improve consistency and\nachieve higher PSNR, SSIM, MSE, and LPIPS scores. Finally, we compare our\npipeline with existing solutions and achieve top-2 scores overall and top-1\namong open-source solutions: CLIPSIM = 0.2976 and FVD = 433.054. Project page:\nhttps://ai-forever.github.io/kandinsky-video/\n","authors":["Vladimir Arkhipkin","Zein Shaheen","Viacheslav Vasilev","Elizaveta Dakhova","Andrey Kuznetsov","Denis Dimitrov"],"pdf_url":"https://arxiv.org/pdf/2311.13073v1.pdf","comment":"Project page: https://ai-forever.github.io/kandinsky-video/"},{"id":"http://arxiv.org/abs/2311.11254v2","updated":"2023-11-22T00:10:58Z","published":"2023-11-19T06:44:13Z","title":"BOIS: Bayesian Optimization of Interconnected Systems","summary":"  Bayesian optimization (BO) has proven to be an effective paradigm for the\nglobal optimization of expensive-to-sample systems. One of the main advantages\nof BO is its use of Gaussian processes (GPs) to characterize model uncertainty\nwhich can be leveraged to guide the learning and search process. However, BO\ntypically treats systems as black-boxes and this limits the ability to exploit\nstructural knowledge (e.g., physics and sparse interconnections). Composite\nfunctions of the form $f(x, y(x))$, wherein GP modeling is shifted from the\nperformance function $f$ to an intermediate function $y$, offer an avenue for\nexploiting structural knowledge. However, the use of composite functions in a\nBO framework is complicated by the need to generate a probability density for\n$f$ from the Gaussian density of $y$ calculated by the GP (e.g., when $f$ is\nnonlinear it is not possible to obtain a closed-form expression). Previous work\nhas handled this issue using sampling techniques; these are easy to implement\nand flexible but are computationally intensive. In this work, we introduce a\nnew paradigm which allows for the efficient use of composite functions in BO;\nthis uses adaptive linearizations of $f$ to obtain closed-form expressions for\nthe statistical moments of the composite function. We show that this simple\napproach (which we call BOIS) enables the exploitation of structural knowledge,\nsuch as that arising in interconnected systems as well as systems that embed\nmultiple GP models and combinations of physics and GP models. Using a chemical\nprocess optimization case study, we benchmark the effectiveness of BOIS against\nstandard BO and sampling approaches. Our results indicate that BOIS achieves\nperformance gains and accurately captures the statistics of composite\nfunctions.\n","authors":["Leonardo D. González","Victor M. Zavala"],"pdf_url":"https://arxiv.org/pdf/2311.11254v2.pdf","comment":"6 pages, 5 figures"},{"id":"http://arxiv.org/abs/2310.12036v2","updated":"2023-11-22T00:02:49Z","published":"2023-10-18T15:21:28Z","title":"A General Theoretical Paradigm to Understand Learning from Human\n  Preferences","summary":"  The prevalent deployment of learning from human preferences through\nreinforcement learning (RLHF) relies on two important approximations: the first\nassumes that pairwise preferences can be substituted with pointwise rewards.\nThe second assumes that a reward model trained on these pointwise rewards can\ngeneralize from collected data to out-of-distribution data sampled by the\npolicy. Recently, Direct Preference Optimisation (DPO) has been proposed as an\napproach that bypasses the second approximation and learn directly a policy\nfrom collected data without the reward modelling stage. However, this method\nstill heavily relies on the first approximation.\n  In this paper we try to gain a deeper theoretical understanding of these\npractical algorithms. In particular we derive a new general objective called\n$\\Psi$PO for learning from human preferences that is expressed in terms of\npairwise preferences and therefore bypasses both approximations. This new\ngeneral objective allows us to perform an in-depth analysis of the behavior of\nRLHF and DPO (as special cases of $\\Psi$PO) and to identify their potential\npitfalls. We then consider another special case for $\\Psi$PO by setting $\\Psi$\nsimply to Identity, for which we can derive an efficient optimisation\nprocedure, prove performance guarantees and demonstrate its empirical\nsuperiority to DPO on some illustrative examples.\n","authors":["Mohammad Gheshlaghi Azar","Mark Rowland","Bilal Piot","Daniel Guo","Daniele Calandriello","Michal Valko","Rémi Munos"],"pdf_url":"https://arxiv.org/pdf/2310.12036v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13491v1","updated":"2023-11-22T16:08:38Z","published":"2023-11-22T16:08:38Z","title":"Grad-Shafranov equilibria via data-free physics informed neural networks","summary":"  A large number of magnetohydrodynamic (MHD) equilibrium calculations are\noften required for uncertainty quantification, optimization, and real-time\ndiagnostic information, making MHD equilibrium codes vital to the field of\nplasma physics. In this paper, we explore a method for solving the\nGrad-Shafranov equation by using Physics-Informed Neural Networks (PINNs). For\nPINNs, we optimize neural networks by directly minimizing the residual of the\nPDE as a loss function. We show that PINNs can accurately and effectively solve\nthe Grad-Shafranov equation with several different boundary conditions. We also\nexplore the parameter space by varying the size of the model, the learning\nrate, and boundary conditions to map various trade-offs such as between\nreconstruction error and computational speed. Additionally, we introduce a\nparameterized PINN framework, expanding the input space to include variables\nsuch as pressure, aspect ratio, elongation, and triangularity in order to\nhandle a broader range of plasma scenarios within a single network.\nParametrized PINNs could be used in future work to solve inverse problems such\nas shape optimization.\n","authors":["Byoungchan Jang","Alan A. Kaptanoglu","Rahul Gaur","Shaowu Pan","Matt Landreman","William Dorland"],"pdf_url":"https://arxiv.org/pdf/2311.13491v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2207.11900v6","updated":"2023-11-22T17:05:42Z","published":"2022-07-25T04:22:41Z","title":"GA2MIF: Graph and Attention Based Two-Stage Multi-Source Information\n  Fusion for Conversational Emotion Detection","summary":"  Multimodal Emotion Recognition in Conversation (ERC) plays an influential\nrole in the field of human-computer interaction and conversational robotics\nsince it can motivate machines to provide empathetic services. Multimodal data\nmodeling is an up-and-coming research area in recent years, which is inspired\nby human capability to integrate multiple senses. Several graph-based\napproaches claim to capture interactive information between modalities, but the\nheterogeneity of multimodal data makes these methods prohibit optimal\nsolutions. In this work, we introduce a multimodal fusion approach named Graph\nand Attention based Two-stage Multi-source Information Fusion (GA2MIF) for\nemotion detection in conversation. Our proposed method circumvents the problem\nof taking heterogeneous graph as input to the model while eliminating complex\nredundant connections in the construction of graph. GA2MIF focuses on\ncontextual modeling and cross-modal modeling through leveraging Multi-head\nDirected Graph ATtention networks (MDGATs) and Multi-head Pairwise Cross-modal\nATtention networks (MPCATs), respectively. Extensive experiments on two public\ndatasets (i.e., IEMOCAP and MELD) demonstrate that the proposed GA2MIF has the\ncapacity to validly capture intra-modal long-range contextual information and\ninter-modal complementary information, as well as outperforms the prevalent\nState-Of-The-Art (SOTA) models by a remarkable margin.\n","authors":["Jiang Li","Xiaoping Wang","Guoqing Lv","Zhigang Zeng"],"pdf_url":"https://arxiv.org/pdf/2207.11900v6.pdf","comment":"Accepted by IEEE Transactions on Affective Computing"},{"id":"http://arxiv.org/abs/2207.12261v4","updated":"2023-11-22T16:59:55Z","published":"2022-07-06T13:56:48Z","title":"GraphCFC: A Directed Graph Based Cross-Modal Feature Complementation\n  Approach for Multimodal Conversational Emotion Recognition","summary":"  Emotion Recognition in Conversation (ERC) plays a significant part in\nHuman-Computer Interaction (HCI) systems since it can provide empathetic\nservices. Multimodal ERC can mitigate the drawbacks of uni-modal approaches.\nRecently, Graph Neural Networks (GNNs) have been widely used in a variety of\nfields due to their superior performance in relation modeling. In multimodal\nERC, GNNs are capable of extracting both long-distance contextual information\nand inter-modal interactive information. Unfortunately, since existing methods\nsuch as MMGCN directly fuse multiple modalities, redundant information may be\ngenerated and diverse information may be lost. In this work, we present a\ndirected Graph based Cross-modal Feature Complementation (GraphCFC) module that\ncan efficiently model contextual and interactive information. GraphCFC\nalleviates the problem of heterogeneity gap in multimodal fusion by utilizing\nmultiple subspace extractors and Pair-wise Cross-modal Complementary (PairCC)\nstrategy. We extract various types of edges from the constructed graph for\nencoding, thus enabling GNNs to extract crucial contextual and interactive\ninformation more accurately when performing message passing. Furthermore, we\ndesign a GNN structure called GAT-MLP, which can provide a new unified network\nframework for multimodal learning. The experimental results on two benchmark\ndatasets show that our GraphCFC outperforms the state-of-the-art (SOTA)\napproaches.\n","authors":["Jiang Li","Xiaoping Wang","Guoqing Lv","Zhigang Zeng"],"pdf_url":"https://arxiv.org/pdf/2207.12261v4.pdf","comment":"Accepted by IEEE Transactions on Multimedia (TMM)"},{"id":"http://arxiv.org/abs/2311.11284v2","updated":"2023-11-22T16:54:17Z","published":"2023-11-19T09:59:09Z","title":"LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval\n  Score Matching","summary":"  The recent advancements in text-to-3D generation mark a significant milestone\nin generative models, unlocking new possibilities for creating imaginative 3D\nassets across various real-world scenarios. While recent advancements in\ntext-to-3D generation have shown promise, they often fall short in rendering\ndetailed and high-quality 3D models. This problem is especially prevalent as\nmany methods base themselves on Score Distillation Sampling (SDS). This paper\nidentifies a notable deficiency in SDS, that it brings inconsistent and\nlow-quality updating direction for the 3D model, causing the over-smoothing\neffect. To address this, we propose a novel approach called Interval Score\nMatching (ISM). ISM employs deterministic diffusing trajectories and utilizes\ninterval-based score matching to counteract over-smoothing. Furthermore, we\nincorporate 3D Gaussian Splatting into our text-to-3D generation pipeline.\nExtensive experiments show that our model largely outperforms the\nstate-of-the-art in quality and training efficiency.\n","authors":["Yixun Liang","Xin Yang","Jiantao Lin","Haodong Li","Xiaogang Xu","Yingcong Chen"],"pdf_url":"https://arxiv.org/pdf/2311.11284v2.pdf","comment":"The first two authors contributed equally to this work. Our code will\n  be available at: https://github.com/EnVision-Research/LucidDreamer"},{"id":"http://arxiv.org/abs/2208.00339v4","updated":"2023-11-22T16:17:19Z","published":"2022-07-31T02:23:24Z","title":"GraphMFT: A Graph Network based Multimodal Fusion Technique for Emotion\n  Recognition in Conversation","summary":"  Multimodal machine learning is an emerging area of research, which has\nreceived a great deal of scholarly attention in recent years. Up to now, there\nare few studies on multimodal Emotion Recognition in Conversation (ERC). Since\nGraph Neural Networks (GNNs) possess the powerful capacity of relational\nmodeling, they have an inherent advantage in the field of multimodal learning.\nGNNs leverage the graph constructed from multimodal data to perform intra- and\ninter-modal information interaction, which effectively facilitates the\nintegration and complementation of multimodal data. In this work, we propose a\nnovel Graph network based Multimodal Fusion Technique (GraphMFT) for emotion\nrecognition in conversation. Multimodal data can be modeled as a graph, where\neach data object is regarded as a node, and both intra- and inter-modal\ndependencies existing between data objects can be regarded as edges. GraphMFT\nutilizes multiple improved graph attention networks to capture intra-modal\ncontextual information and inter-modal complementary information. In addition,\nthe proposed GraphMFT attempts to address the challenges of existing\ngraph-based multimodal conversational emotion recognition models such as MMGCN.\nEmpirical results on two public multimodal datasets reveal that our model\noutperforms the State-Of-The-Art (SOTA) approaches with the accuracy of 67.90%\nand 61.30%.\n","authors":["Jiang Li","Xiaoping Wang","Guoqing Lv","Zhigang Zeng"],"pdf_url":"https://arxiv.org/pdf/2208.00339v4.pdf","comment":"Accepted by Neurocomputing"},{"id":"http://arxiv.org/abs/2311.13409v1","updated":"2023-11-22T14:13:27Z","published":"2023-11-22T14:13:27Z","title":"CompenHR: Efficient Full Compensation for High-resolution Projector","summary":"  Full projector compensation is a practical task of projector-camera systems.\nIt aims to find a projector input image, named compensation image, such that\nwhen projected it cancels the geometric and photometric distortions due to the\nphysical environment and hardware. State-of-the-art methods use deep learning\nto address this problem and show promising performance for low-resolution\nsetups. However, directly applying deep learning to high-resolution setups is\nimpractical due to the long training time and high memory cost. To address this\nissue, this paper proposes a practical full compensation solution. Firstly, we\ndesign an attention-based grid refinement network to improve geometric\ncorrection quality. Secondly, we integrate a novel sampling scheme into an\nend-to-end compensation network to alleviate computation and introduce\nattention blocks to preserve key features. Finally, we construct a benchmark\ndataset for high-resolution projector full compensation. In experiments, our\nmethod demonstrates clear advantages in both efficiency and quality.\n","authors":["Yuxi Wang","Haibin Ling","Bingyao Huang"],"pdf_url":"https://arxiv.org/pdf/2311.13409v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13307v1","updated":"2023-11-22T10:55:36Z","published":"2023-11-22T10:55:36Z","title":"Rethinking Radiology Report Generation via Causal Reasoning and\n  Counterfactual Augmentation","summary":"  Radiology Report Generation (RRG) draws attention as an interaction between\nvision and language fields. Previous works inherited the ideology of\nvision-to-language generation tasks,aiming to generate paragraphs with high\nconsistency as reports. However, one unique characteristic of RRG, the\nindependence between diseases, was neglected, leading to the injection of the\nspurious confounder, i.e., the disease co-occurrence. Unfortunately, this\nconfounder confuses the process of report generation worse because of the\nbiased RRG data distribution. In this paper, to rethink this issue thoroughly,\nwe reason about its causes and effects from a novel perspective of statistics\nand causality, where the Joint Vision Coupling and the Conditional Sentence\nCoherence Coupling are two aspects prone to implicitly decrease the accuracy of\nreports. Then, a counterfactual augmentation strategy that contains the\nCounterfactual Sample Synthesis and the Counterfactual Report Reconstruction\nsub-methods is proposed to break these two aspects of spurious effects.\nExperimental results and further analyses on two widely used datasets justify\nour reasoning and proposed methods.\n","authors":["Xiao Song","Jiafan Liu","Yun Li","Wenbin Lei","Ruxin Wang"],"pdf_url":"https://arxiv.org/pdf/2311.13307v1.pdf","comment":"10 pages,5 figures"},{"id":"http://arxiv.org/abs/2311.13073v1","updated":"2023-11-22T00:26:15Z","published":"2023-11-22T00:26:15Z","title":"FusionFrames: Efficient Architectural Aspects for Text-to-Video\n  Generation Pipeline","summary":"  Multimedia generation approaches occupy a prominent place in artificial\nintelligence research. Text-to-image models achieved high-quality results over\nthe last few years. However, video synthesis methods recently started to\ndevelop. This paper presents a new two-stage latent diffusion text-to-video\ngeneration architecture based on the text-to-image diffusion model. The first\nstage concerns keyframes synthesis to figure the storyline of a video, while\nthe second one is devoted to interpolation frames generation to make movements\nof the scene and objects smooth. We compare several temporal conditioning\napproaches for keyframes generation. The results show the advantage of using\nseparate temporal blocks over temporal layers in terms of metrics reflecting\nvideo generation quality aspects and human preference. The design of our\ninterpolation model significantly reduces computational costs compared to other\nmasked frame interpolation approaches. Furthermore, we evaluate different\nconfigurations of MoVQ-based video decoding scheme to improve consistency and\nachieve higher PSNR, SSIM, MSE, and LPIPS scores. Finally, we compare our\npipeline with existing solutions and achieve top-2 scores overall and top-1\namong open-source solutions: CLIPSIM = 0.2976 and FVD = 433.054. Project page:\nhttps://ai-forever.github.io/kandinsky-video/\n","authors":["Vladimir Arkhipkin","Zein Shaheen","Viacheslav Vasilev","Elizaveta Dakhova","Andrey Kuznetsov","Denis Dimitrov"],"pdf_url":"https://arxiv.org/pdf/2311.13073v1.pdf","comment":"Project page: https://ai-forever.github.io/kandinsky-video/"}]}}